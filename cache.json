{"2022-12-15T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2212.08061v1","updated":"2022-12-15T18:59:32Z","published":"2022-12-15T18:59:32Z","title":"On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in\n  Zero-Shot Reasoning","summary":"  Generating a chain of thought (CoT) can increase large language model (LLM)\nperformance on a wide range of tasks. Zero-shot CoT evaluations, however, have\nbeen conducted primarily on logical tasks (e.g. arithmetic, commonsense QA). In\nthis paper, we perform a controlled evaluation of zero-shot CoT across two\nsensitive domains: harmful questions and stereotype benchmarks. We find that\nusing zero-shot CoT reasoning in a prompt can significantly increase a model's\nlikelihood to produce undesirable output. Without future advances in alignment\nor explicit mitigation instructions, zero-shot CoT should be avoided on tasks\nwhere models can make inferences about marginalized groups or harmful topics.\n","authors":["Omar Shaikh","Hongxin Zhang","William Held","Michael Bernstein","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2212.08061v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2212.08055v1","updated":"2022-12-15T18:58:28Z","published":"2022-12-15T18:58:28Z","title":"UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units","summary":"  Direct speech-to-speech translation (S2ST), in which all components can be\noptimized jointly, is advantageous over cascaded approaches to achieve fast\ninference with a simplified pipeline. We present a novel two-pass direct S2ST\narchitecture, {\\textit UnitY}, which first generates textual representations\nand predicts discrete acoustic units subsequently. We enhance the model\nperformance by subword prediction in the first-pass decoder, advanced two-pass\ndecoder architecture design and search strategy, and better training\nregularization. To leverage large amounts of unlabeled text data, we pre-train\nthe first-pass text decoder based on the self-supervised denoising\nauto-encoding task. Experimental evaluations on benchmark datasets at various\ndata scales demonstrate that UnitY outperforms a single-pass speech-to-unit\ntranslation model by 2.5-4.2 ASR-BLEU with 2.83x decoding speed-up. We show\nthat the proposed methods boost the performance even when predicting\nspectrogram in the second pass. However, predicting discrete units achieves\n2.51x decoding speed-up compared to that case.\n","authors":["Hirofumi Inaguma","Sravya Popuri","Ilia Kulikov","Peng-Jen Chen","Changhan Wang","Yu-An Chung","Yun Tang","Ann Lee","Shinji Watanabe","Juan Pino"],"pdf_url":"https://arxiv.org/pdf/2212.08055v1.pdf","comment":"Early draft. Work in progress"},{"id":"http://arxiv.org/abs/2212.08054v1","updated":"2022-12-15T18:58:07Z","published":"2022-12-15T18:58:07Z","title":"DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue","summary":"  Modern virtual assistants use internal semantic parsing engines to convert\nuser utterances to actionable commands. However, prior work has demonstrated\nthat semantic parsing is a difficult multilingual transfer task with low\ntransfer efficiency compared to other tasks. In global markets such as India\nand Latin America, this is a critical issue as switching between languages is\nprevalent for bilingual users. In this work we dramatically improve the\nzero-shot performance of a multilingual and codeswitched semantic parsing\nsystem using two stages of multilingual alignment. First, we show that\nconstrastive alignment pretraining improves both English performance and\ntransfer efficiency. We then introduce a constrained optimization approach for\nhyperparameter-free adversarial alignment during finetuning. Our Doubly Aligned\nMultilingual Parser (DAMP) improves mBERT transfer performance by 3x, 6x, and\n81x on the Spanglish, Hinglish and Multilingual Task Oriented Parsing\nbenchmarks respectively and outperforms XLM-R and mT5-Large using 3.2x fewer\nparameters.\n","authors":["William Held","Christopher Hidey","Fei Liu","Eric Zhu","Rahul Goel","Diyi Yang","Rushin Shah"],"pdf_url":"https://arxiv.org/pdf/2212.08054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08037v1","updated":"2022-12-15T18:45:29Z","published":"2022-12-15T18:45:29Z","title":"Attributed Question Answering: Evaluation and Modeling for Attributed\n  Large Language Models","summary":"  Large language models (LLMs) have shown impressive results across a variety\nof tasks while requiring little or no direct supervision. Further, there is\nmounting evidence that LLMs may have potential in information-seeking\nscenarios. We believe the ability of an LLM to attribute the text that it\ngenerates is likely to be crucial for both system developers and users in this\nsetting. We propose and study Attributed QA as a key first step in the\ndevelopment of attributed LLMs. We develop a reproducable evaluation framework\nfor the task, using human annotations as a gold standard and a correlated\nautomatic metric that we show is suitable for development settings. We describe\nand benchmark a broad set of architectures for the task. Our contributions give\nsome concrete answers to two key questions (How to measure attribution?, and\nHow well do current state-of-the-art methods perform on attribution?), and give\nsome hints as to how to address a third key question (How to build LLMs with\nattribution?).\n","authors":["Bernd Bohnet","Vinh Q. Tran","Pat Verga","Roee Aharoni","Daniel Andor","Livio Baldini Soares","Jacob Eisenstein","Kuzman Ganchev","Jonathan Herzig","Kai Hui","Tom Kwiatkowski","Ji Ma","Jianmo Ni","Tal Schuster","William W. Cohen","Michael Collins","Dipanjan Das","Donald Metzler","Slav Petrov","Kellie Webster"],"pdf_url":"https://arxiv.org/pdf/2212.08037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08011v1","updated":"2022-12-15T18:17:01Z","published":"2022-12-15T18:17:01Z","title":"Multi-VALUE: A Framework for Cross-Dialectal English NLP","summary":"  Dialect differences caused by regional, social, and economic barriers cause\nperformance discrepancies for many groups of users of language technology.\nFair, inclusive, and equitable language technology must critically be dialect\ninvariant, meaning that performance remains constant over dialectal shifts.\nCurrent English systems often fall significantly short of this ideal since they\nare designed and tested on a single dialect: Standard American English. We\nintroduce Multi-VALUE -- a suite of resources for evaluating and achieving\nEnglish dialect invariance. We build a controllable rule-based translation\nsystem spanning 50 English dialects and a total of 189 unique linguistic\nfeatures. Our translation maps Standard American English text to synthetic form\nof each dialect, which uses an upper-bound on the natural density of features\nin that dialect. First, we use this system to build stress tests for question\nanswering, machine translation, and semantic parsing tasks. Stress tests reveal\nsignificant performance disparities for leading models on non-standard\ndialects. Second, we use this system as a data augmentation technique to\nimprove the dialect robustness of existing systems. Finally, we partner with\nnative speakers of Chicano and Indian English to release new gold-standard\nvariants of the popular CoQA task.\n","authors":["Caleb Ziems","William Held","Jingfeng Yang","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2212.08011v1.pdf","comment":"24 pages (9 pages + appendix); 21 tables; 5 figures"},{"id":"http://arxiv.org/abs/2210.07792v2","updated":"2022-12-15T17:38:58Z","published":"2022-10-14T13:21:33Z","title":"Robust Preference Learning for Storytelling via Contrastive\n  Reinforcement Learning","summary":"  Controlled automated story generation seeks to generate natural language\nstories satisfying constraints from natural language critiques or preferences.\nExisting methods to control for story preference utilize prompt engineering\nwhich is labor intensive and often inconsistent. They may also use\nlogit-manipulation methods which require annotated datasets to exist for the\ndesired attributes. To address these issues, we first train a contrastive\nbi-encoder model to align stories with corresponding human critiques, named\nCARP, building a general purpose preference model. This is subsequently used as\na reward function to fine-tune a generative language model via reinforcement\nlearning. However, simply fine-tuning a generative language model with a\ncontrastive reward model does not always reliably result in a story generation\nsystem capable of generating stories that meet user preferences. To increase\nstory generation robustness we further fine-tune the contrastive reward model\nusing a prompt-learning technique. A human participant study is then conducted\ncomparing generations from our full system, ablations, and two baselines. We\nshow that the full fine-tuning pipeline results in a story generator preferred\nover a LLM 20x as large as well as logit-based methods. This motivates the use\nof contrastive learning for general purpose human preference modeling.\n","authors":["Louis Castricato","Alexander Havrilla","Shahbuland Matiana","Michael Pieler","Anbang Ye","Ian Yang","Spencer Frazier","Mark Riedl"],"pdf_url":"https://arxiv.org/pdf/2210.07792v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07983v1","updated":"2022-12-15T17:31:54Z","published":"2022-12-15T17:31:54Z","title":"Vision Transformers are Parameter-Efficient Audio-Visual Learners","summary":"  Vision transformers (ViTs) have achieved impressive results on various\ncomputer vision tasks in the last several years. In this work, we study the\ncapability of frozen ViTs, pretrained only on visual data, to generalize to\naudio-visual data without finetuning any of its original parameters. To do so,\nwe propose a latent audio-visual hybrid (LAVISH) adapter that adapts pretrained\nViTs to audio-visual tasks by injecting a small number of trainable parameters\ninto every layer of a frozen ViT. To efficiently fuse visual and audio cues,\nour LAVISH adapter uses a small set of latent tokens, which form an attention\nbottleneck, thus, eliminating the quadratic cost of standard cross-attention.\nCompared to the existing modality-specific audio-visual methods, our approach\nachieves competitive or even better performance on various audio-visual tasks\nwhile using fewer tunable parameters and without relying on costly audio\npretraining or external audio encoders. Our code is available at\nhttps://genjib.github.io/project_page/LAVISH/\n","authors":["Yan-Bo Lin","Yi-Lin Sung","Jie Lei","Mohit Bansal","Gedas Bertasius"],"pdf_url":"https://arxiv.org/pdf/2212.07983v1.pdf","comment":"project page: https://genjib.github.io/project_page/LAVISH/"},{"id":"http://arxiv.org/abs/2212.07981v1","updated":"2022-12-15T17:26:05Z","published":"2022-12-15T17:26:05Z","title":"Revisiting the Gold Standard: Grounding Summarization Evaluation with\n  Robust Human Evaluation","summary":"  Human evaluation is the foundation upon which the evaluation of both\nsummarization systems and automatic metrics rests. However, existing human\nevaluation protocols and benchmarks for summarization either exhibit low\ninter-annotator agreement or lack the scale needed to draw statistically\nsignificant conclusions, and an in-depth analysis of human evaluation is\nlacking. In this work, we address the shortcomings of existing summarization\nevaluation along the following axes: 1) We propose a modified summarization\nsalience protocol, Atomic Content Units (ACUs), which relies on fine-grained\nsemantic units and allows for high inter-annotator agreement. 2) We curate the\nRobust Summarization Evaluation (RoSE) benchmark, a large human evaluation\ndataset consisting of over 22k summary-level annotations over state-of-the-art\nsystems on three datasets. 3) We compare our ACU protocol with three other\nhuman evaluation protocols, underscoring potential confounding factors in\nevaluation setups. 4) We evaluate existing automatic metrics using the\ncollected human annotations across evaluation protocols and demonstrate how our\nbenchmark leads to more statistically stable and significant results.\nFurthermore, our findings have important implications for evaluating large\nlanguage models (LLMs), as we show that LLMs adjusted by human feedback (e.g.,\nGPT-3.5) may overfit unconstrained human evaluation, which is affected by the\nannotators' prior, input-agnostic preferences, calling for more robust,\ntargeted evaluation methods.\n","authors":["Yixin Liu","Alexander R. Fabbri","Pengfei Liu","Yilun Zhao","Linyong Nan","Ruilin Han","Simeng Han","Shafiq Joty","Chien-Sheng Wu","Caiming Xiong","Dragomir Radev"],"pdf_url":"https://arxiv.org/pdf/2212.07981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11443v4","updated":"2022-12-15T17:26:00Z","published":"2022-05-23T16:33:41Z","title":"Unsupervised Tokenization Learning","summary":"  In the presented study, we discover that the so-called \"transition freedom\"\nmetric appears superior for unsupervised tokenization purposes in comparison to\nstatistical metrics such as mutual information and conditional probability,\nproviding F-measure scores in range from 0.71 to 1.0 across explored\nmultilingual corpora. We find that different languages require different\noffshoots of that metric (such as derivative, variance, and \"peak values\") for\nsuccessful tokenization. Larger training corpora do not necessarily result in\nbetter tokenization quality, while compressing the models by eliminating\nstatistically weak evidence tends to improve performance. The proposed\nunsupervised tokenization technique provides quality better than or comparable\nto lexicon-based ones, depending on the language.\n","authors":["Anton Kolonin","Vignav Ramesh"],"pdf_url":"https://arxiv.org/pdf/2205.11443v4.pdf","comment":"16 pages, 9 figures; Paper accepted to the EMNLP 2022 conference"},{"id":"http://arxiv.org/abs/2212.07939v1","updated":"2022-12-15T16:17:03Z","published":"2022-12-15T16:17:03Z","title":"RWEN-TTS: Relation-aware Word Encoding Network for Natural\n  Text-to-Speech Synthesis","summary":"  With the advent of deep learning, a huge number of text-to-speech (TTS)\nmodels which produce human-like speech have emerged. Recently, by introducing\nsyntactic and semantic information w.r.t the input text, various approaches\nhave been proposed to enrich the naturalness and expressiveness of TTS models.\nAlthough these strategies showed impressive results, they still have some\nlimitations in utilizing language information. First, most approaches only use\ngraph networks to utilize syntactic and semantic information without\nconsidering linguistic features. Second, most previous works do not explicitly\nconsider adjacent words when encoding syntactic and semantic information, even\nthough it is obvious that adjacent words are usually meaningful when encoding\nthe current word. To address these issues, we propose Relation-aware Word\nEncoding Network (RWEN), which effectively allows syntactic and semantic\ninformation based on two modules (i.e., Semantic-level Relation Encoding and\nAdjacent Word Relation Encoding). Experimental results show substantial\nimprovements compared to previous works.\n","authors":["Shinhyeok Oh","HyeongRae Noh","Yoonseok Hong","Insoo Oh"],"pdf_url":"https://arxiv.org/pdf/2212.07939v1.pdf","comment":"Accepted to AAAI 2023"},{"id":"http://arxiv.org/abs/2212.07937v1","updated":"2022-12-15T16:13:25Z","published":"2022-12-15T16:13:25Z","title":"Visually-augmented pretrained language models for NLP tasks without\n  images","summary":"  Although pre-trained language models (PLMs) have shown impressive performance\nby text-only self-supervised training, they are found lack of visual semantics\nor commonsense, e.g., sizes, shapes, and colors of commonplace objects.\nExisting solutions often rely on explicit images for visual knowledge\naugmentation (requiring time-consuming retrieval or generation), and they also\nconduct the augmentation for the whole input text, without considering whether\nit is actually needed in specific inputs or tasks. To address these issues, we\npropose a novel visually-augmented fine-tuning approach that can be generally\napplied to various PLMs or NLP tasks, without using any retrieved or generated\nimages, namely VAWI. Specifically, we first identify the visually-hungry words\n(VH-words) from input text via a token selector, where three different methods\nhave been proposed, including syntax-, attention- and learning-based\nstrategies. Then, we adopt a fixed CLIP text encoder to generate the\nvisually-augmented representations of these VH-words. As it has been\npre-trained by vision-language alignment task on the large-scale corpus, it is\ncapable of injecting visual semantics into the aligned text representations.\nFinally, the visually-augmented features will be fused and transformed into the\npre-designed visual prompts based on VH-words, which can be inserted into PLMs\nto enrich the visual semantics in word representations. We conduct extensive\nexperiments on ten NLP tasks, i.e., GLUE benchmark, CommonsenseQA, CommonGen,\nand SNLI-VE. Experimental results show that our approach can consistently\nimprove the performance of BERT, RoBERTa, BART, and T5 at different scales, and\noutperform several competitive baselines significantly. Our codes and data are\npublicly available at~\\url{https://github.com/RUCAIBox/VAWI}.\n","authors":["Hangyu Guo","Kun Zhou","Wayne Xin Zhao","Qinyu Zhang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2212.07937v1.pdf","comment":"17 pages, 2 figures"},{"id":"http://arxiv.org/abs/2205.12702v3","updated":"2022-12-15T16:01:49Z","published":"2022-05-25T11:59:39Z","title":"Detecting Label Errors by using Pre-Trained Language Models","summary":"  We show that large pre-trained language models are inherently highly capable\nof identifying label errors in natural language datasets: simply examining\nout-of-sample data points in descending order of fine-tuned task loss\nsignificantly outperforms more complex error-detection mechanisms proposed in\nprevious work.\n  To this end, we contribute a novel method for introducing realistic,\nhuman-originated label noise into existing crowdsourced datasets such as SNLI\nand TweetNLP. We show that this noise has similar properties to real,\nhand-verified label errors, and is harder to detect than existing synthetic\nnoise, creating challenges for model robustness. We argue that human-originated\nnoise is a better standard for evaluation than synthetic noise.\n  Finally, we use crowdsourced verification to evaluate the detection of real\nerrors on IMDB, Amazon Reviews, and Recon, and confirm that pre-trained models\nperform at a 9-36% higher absolute Area Under the Precision-Recall Curve than\nexisting models.\n","authors":["Derek Chong","Jenny Hong","Christopher D. Manning"],"pdf_url":"https://arxiv.org/pdf/2205.12702v3.pdf","comment":"18 pages, 10 figures. Accepted to EMNLP 2022; typesetting of this\n  version slightly differs from conference version"},{"id":"http://arxiv.org/abs/2212.07919v1","updated":"2022-12-15T15:52:39Z","published":"2022-12-15T15:52:39Z","title":"ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning","summary":"  Large language models show improved downstream task performance when prompted\nto generate step-by-step reasoning to justify their final answers. These\nreasoning steps greatly improve model interpretability and verification, but\nobjectively studying their correctness (independent of the final answer) is\ndifficult without reliable methods for automatic evaluation. We simply do not\nknow how often the stated reasoning steps actually support the final end task\npredictions. In this work, we present ROSCOE, a suite of interpretable,\nunsupervised automatic scores that improve and extend previous text generation\nevaluation metrics. To evaluate ROSCOE against baseline metrics, we design a\ntypology of reasoning errors and collect synthetic and human evaluation scores\non commonly used reasoning datasets. In contrast with existing metrics, ROSCOE\ncan measure semantic consistency, logicality, informativeness, fluency, and\nfactuality - among other traits - by leveraging properties of step-by-step\nrationales. We empirically verify the strength of our metrics on five human\nannotated and six programmatically perturbed diagnostics datasets - covering a\ndiverse set of tasks that require reasoning skills and show that ROSCOE can\nconsistently outperform baseline metrics.\n","authors":["Olga Golovneva","Moya Chen","Spencer Poff","Martin Corredor","Luke Zettlemoyer","Maryam Fazel-Zarandi","Asli Celikyilmaz"],"pdf_url":"https://arxiv.org/pdf/2212.07919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07914v1","updated":"2022-12-15T15:49:27Z","published":"2022-12-15T15:49:27Z","title":"The Effects of In-domain Corpus Size on pre-training BERT","summary":"  Many prior language modeling efforts have shown that pre-training on an\nin-domain corpus can significantly improve performance on downstream\ndomain-specific NLP tasks. However, the difficulties associated with collecting\nenough in-domain data might discourage researchers from approaching this\npre-training task. In this paper, we conducted a series of experiments by\npre-training Bidirectional Encoder Representations from Transformers (BERT)\nwith different sizes of biomedical corpora. The results demonstrate that\npre-training on a relatively small amount of in-domain data (4GB) with limited\ntraining steps, can lead to better performance on downstream domain-specific\nNLP tasks compared with fine-tuning models pre-trained on general corpora.\n","authors":["Chris Sanchez","Zheyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.07914v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2211.15089v3","updated":"2022-12-15T14:27:19Z","published":"2022-11-28T06:08:54Z","title":"Continuous diffusion for categorical data","summary":"  Diffusion models have quickly become the go-to paradigm for generative\nmodelling of perceptual signals (such as images and sound) through iterative\nrefinement. Their success hinges on the fact that the underlying physical\nphenomena are continuous. For inherently discrete and categorical data such as\nlanguage, various diffusion-inspired alternatives have been proposed. However,\nthe continuous nature of diffusion models conveys many benefits, and in this\nwork we endeavour to preserve it. We propose CDCD, a framework for modelling\ncategorical data with diffusion models that are continuous both in time and\ninput space. We demonstrate its efficacy on several language modelling tasks.\n","authors":["Sander Dieleman","Laurent Sartran","Arman Roshannai","Nikolay Savinov","Yaroslav Ganin","Pierre H. Richemond","Arnaud Doucet","Robin Strudel","Chris Dyer","Conor Durkan","Curtis Hawthorne","Rémi Leblond","Will Grathwohl","Jonas Adler"],"pdf_url":"https://arxiv.org/pdf/2211.15089v3.pdf","comment":"26 pages, 8 figures; corrections and additional information about\n  hyperparameters"},{"id":"http://arxiv.org/abs/2212.07852v1","updated":"2022-12-15T14:19:33Z","published":"2022-12-15T14:19:33Z","title":"The effects of gender bias in word embeddings on depression prediction","summary":"  Word embeddings are extensively used in various NLP problems as a\nstate-of-the-art semantic feature vector representation. Despite their success\non various tasks and domains, they might exhibit an undesired bias for\nstereotypical categories due to statistical and societal biases that exist in\nthe dataset they are trained on. In this study, we analyze the gender bias in\nfour different pre-trained word embeddings specifically for the depression\ncategory in the mental disorder domain. We use contextual and non-contextual\nembeddings that are trained on domain-independent as well as clinical\ndomain-specific data. We observe that embeddings carry bias for depression\ntowards different gender groups depending on the type of embeddings. Moreover,\nwe demonstrate that these undesired correlations are transferred to the\ndownstream task for depression phenotype recognition. We find that data\naugmentation by simply swapping gender words mitigates the bias significantly\nin the downstream task.\n","authors":["Gizem Sogancioglu","Heysem Kaya"],"pdf_url":"https://arxiv.org/pdf/2212.07852v1.pdf","comment":"accepted to and published at \"A Participatory Approach to AI for\n  Mental Health (PAI4MH)\" workshop, co-located with NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.07850v1","updated":"2022-12-15T14:18:53Z","published":"2022-12-15T14:18:53Z","title":"Attention as a guide for Simultaneous Speech Translation","summary":"  The study of the attention mechanism has sparked interest in many fields,\nsuch as language modeling and machine translation. Although its patterns have\nbeen exploited to perform different tasks, from neural network understanding to\ntextual alignment, no previous work has analysed the encoder-decoder attention\nbehavior in speech translation (ST) nor used it to improve ST on a specific\ntask. In this paper, we fill this gap by proposing an attention-based policy\n(EDAtt) for simultaneous ST (SimulST) that is motivated by an analysis of the\nexisting attention relations between audio input and textual output. Its goal\nis to leverage the encoder-decoder attention scores to guide inference in real\ntime. Results on en->{de, es} show that the EDAtt policy achieves overall\nbetter results compared to the SimulST state of the art, especially in terms of\ncomputational-aware latency.\n","authors":["Sara Papi","Matteo Negri","Marco Turchi"],"pdf_url":"https://arxiv.org/pdf/2212.07850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07841v1","updated":"2022-12-15T13:57:07Z","published":"2022-12-15T13:57:07Z","title":"MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are\n  Better Dense Retrievers","summary":"  Dense retrieval aims to map queries and passages into low-dimensional vector\nspace for efficient similarity measuring, showing promising effectiveness in\nvarious large-scale retrieval tasks. Since most existing methods commonly adopt\npre-trained Transformers (e.g. BERT) for parameter initialization, some work\nfocuses on proposing new pre-training tasks for compressing the useful semantic\ninformation from passages into dense vectors, achieving remarkable\nperformances. However, it is still challenging to effectively capture the rich\nsemantic information and relations about passages into the dense vectors via\none single particular pre-training task. In this work, we propose a multi-task\npre-trained model, MASTER, that unifies and integrates multiple pre-training\ntasks with different learning objectives under the bottlenecked masked\nautoencoder architecture. Concretely, MASTER utilizes a multi-decoder\narchitecture to integrate three types of pre-training tasks: corrupted passages\nrecovering, related passage recovering and PLMs outputs recovering. By\nincorporating a shared deep encoder, we construct a representation bottleneck\nin our architecture, compressing the abundant semantic information across tasks\ninto dense vectors. The first two types of tasks concentrate on capturing the\nsemantic information of passages and relationships among them within the\npre-training corpus. The third one can capture the knowledge beyond the corpus\nfrom external PLMs (e.g. GPT-2). Extensive experiments on several large-scale\npassage retrieval datasets have shown that our approach outperforms the\nprevious state-of-the-art dense retrieval methods. Our code and data are\npublicly released in https://github.com/microsoft/SimXNS\n","authors":["Kun Zhou","Xiao Liu","Yeyun Gong","Wayne Xin Zhao","Daxin Jiang","Nan Duan","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2212.07841v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2212.07839v1","updated":"2022-12-15T13:52:03Z","published":"2022-12-15T13:52:03Z","title":"TeTIm-Eval: a novel curated evaluation data set for comparing\n  text-to-image models","summary":"  Evaluating and comparing text-to-image models is a challenging problem.\nSignificant advances in the field have recently been made, piquing interest of\nvarious industrial sectors. As a consequence, a gold standard in the field\nshould cover a variety of tasks and application contexts. In this paper a novel\nevaluation approach is experimented, on the basis of: (i) a curated data set,\nmade by high-quality royalty-free image-text pairs, divided into ten\ncategories; (ii) a quantitative metric, the CLIP-score, (iii) a human\nevaluation task to distinguish, for a given text, the real and the generated\nimages. The proposed method has been applied to the most recent models, i.e.,\nDALLE2, Latent Diffusion, Stable Diffusion, GLIDE and Craiyon. Early\nexperimental results show that the accuracy of the human judgement is fully\ncoherent with the CLIP-score. The dataset has been made available to the\npublic.\n","authors":["Federico A. Galatolo","Mario G. C. A. Cimino","Edoardo Cogotti"],"pdf_url":"https://arxiv.org/pdf/2212.07839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07769v1","updated":"2022-12-15T12:47:18Z","published":"2022-12-15T12:47:18Z","title":"CLAM: Selective Clarification for Ambiguous Questions with Large\n  Language Models","summary":"  State-of-the-art language models are often accurate on many\nquestion-answering benchmarks with well-defined questions. Yet, in real\nsettings questions are often unanswerable without asking the user for\nclarifying information. We show that current SotA models often do not ask the\nuser for clarification when presented with imprecise questions and instead\nprovide incorrect answers or \"hallucinate\". To address this, we introduce CLAM,\na framework that first uses the model to detect ambiguous questions, and if an\nambiguous question is detected, prompts the model to ask the user for\nclarification. Furthermore, we show how to construct a scalable and\ncost-effective automatic evaluation protocol using an oracle language model\nwith privileged information to provide clarifying information. We show that our\nmethod achieves a 20.15 percentage point accuracy improvement over SotA on a\nnovel ambiguous question-answering answering data set derived from TriviaQA.\n","authors":["Lorenz Kuhn","Yarin Gal","Sebastian Farquhar"],"pdf_url":"https://arxiv.org/pdf/2212.07769v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07767v1","updated":"2022-12-15T12:37:28Z","published":"2022-12-15T12:37:28Z","title":"COLA: Improving Conversational Recommender Systems by Collaborative\n  Augmentation","summary":"  Conversational recommender systems (CRS) aim to employ natural language\nconversations to suggest suitable products to users. Understanding user\npreferences for prospective items and learning efficient item representations\nare crucial for CRS. Despite various attempts, earlier studies mostly learned\nitem representations based on individual conversations, ignoring item\npopularity embodied among all others. Besides, they still need support in\nefficiently capturing user preferences since the information reflected in a\nsingle conversation is limited. Inspired by collaborative filtering, we propose\na collaborative augmentation (COLA) method to simultaneously improve both item\nrepresentation learning and user preference modeling to address these issues.\nWe construct an interactive user-item graph from all conversations, which\naugments item representations with user-aware information, i.e., item\npopularity. To improve user preference modeling, we retrieve similar\nconversations from the training corpus, where the involved items and attributes\nthat reflect the user's potential interests are used to augment the user\nrepresentation through gate control. Extensive experiments on two benchmark\ndatasets demonstrate the effectiveness of our method. Our code and data are\navailable at https://github.com/DongdingLin/COLA.\n","authors":["Dongding Lin","Jian Wang","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2212.07767v1.pdf","comment":"Accepted by AAAI-2023"},{"id":"http://arxiv.org/abs/2212.07752v1","updated":"2022-12-15T12:14:25Z","published":"2022-12-15T12:14:25Z","title":"TRIP: Triangular Document-level Pre-training for Multilingual Language\n  Models","summary":"  Despite the current success of multilingual pre-training, most prior works\nfocus on leveraging monolingual data or bilingual parallel data and overlooked\nthe value of trilingual parallel data. This paper presents \\textbf{Tri}angular\nDocument-level \\textbf{P}re-training (\\textbf{TRIP}), which is the first in the\nfield to extend the conventional monolingual and bilingual pre-training to a\ntrilingual setting by (i) \\textbf{Grafting} the same documents in two languages\ninto one mixed document, and (ii) predicting the remaining one language as the\nreference translation. Our experiments on document-level MT and cross-lingual\nabstractive summarization show that TRIP brings by up to 3.65 d-BLEU points and\n6.2 ROUGE-L points on three multilingual document-level machine translation\nbenchmarks and one cross-lingual abstractive summarization benchmark, including\nmultiple strong state-of-the-art (SOTA) scores. In-depth analysis indicates\nthat TRIP improves document-level machine translation and captures better\ndocument contexts in at least three characteristics: (i) tense consistency,\n(ii) noun consistency and (iii) conjunction presence.\n","authors":["Hongyuan Lu","Haoyang Huang","Shuming Ma","Dongdong Zhang","Wai Lam","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.07752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06282v2","updated":"2022-12-15T11:38:59Z","published":"2022-10-12T15:05:28Z","title":"Towards Generalized and Explainable Long-Range Context Representation\n  for Dialogue Systems","summary":"  Long-range context modeling is crucial to both dialogue understanding and\ngeneration. The most popular method for dialogue context representation is to\nconcatenate the last-$k$ previous utterances. However, this method may not be\nideal for conversations containing long-range dependencies. In this work, we\npropose DialoGX, a novel encoder-decoder based framework for conversational\nresponse generation with a generalized and explainable context representation\nthat can look beyond the last-$k$ utterances. Hence the method is adaptive to\nconversations with long-range dependencies. The main idea of our approach is to\nidentify and utilize the most relevant historical utterances instead of the\nlast-$k$ utterances in chronological order. We study the effectiveness of our\nproposed method on both dialogue generation (open-domain) and understanding\n(DST) tasks. DialoGX achieves comparable performance with the state-of-the-art\nmodels on DailyDialog dataset. We also observe performance gain in existing DST\nmodels with our proposed context representation strategy on MultiWOZ dataset.\nWe justify our context representation through the lens of psycholinguistics and\nshow that the relevance score of previous utterances agrees well with human\ncognition which makes DialoGX explainable as well.\n","authors":["Suvodip Dey","Maunendra Sankar Desarkar","P. K. Srijith"],"pdf_url":"https://arxiv.org/pdf/2210.06282v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07707v1","updated":"2022-12-15T10:32:29Z","published":"2022-12-15T10:32:29Z","title":"FreCDo: A Large Corpus for French Cross-Domain Dialect Identification","summary":"  We present a novel corpus for French dialect identification comprising\n413,522 French text samples collected from public news websites in Belgium,\nCanada, France and Switzerland. To ensure an accurate estimation of the dialect\nidentification performance of models, we designed the corpus to eliminate\npotential biases related to topic, writing style, and publication source. More\nprecisely, the training, validation and test splits are collected from\ndifferent news websites, while searching for different keywords (topics). This\nleads to a French cross-domain (FreCDo) dialect identification task. We conduct\nexperiments with four competitive baselines, a fine-tuned CamemBERT model, an\nXGBoost based on fine-tuned CamemBERT features, a Support Vector Machines (SVM)\nclassifier based on fine-tuned CamemBERT features, and an SVM based on word\nn-grams. Aside from presenting quantitative results, we also make an analysis\nof the most discriminative features learned by CamemBERT. Our corpus is\navailable at https://github.com/MihaelaGaman/FreCDo.\n","authors":["Mihaela Gaman","Adrian-Gabriel Chifu","William Domingues","Radu Tudor Ionescu"],"pdf_url":"https://arxiv.org/pdf/2212.07707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07699v1","updated":"2022-12-15T10:20:42Z","published":"2022-12-15T10:20:42Z","title":"Retrieval-based Disentanglement with Distant Supervision","summary":"  Disentangled representation learning remains challenging as ground truth\nfactors of variation do not naturally exist. To address this, we present\nVocabulary Disentanglement Retrieval~(VDR), a simple yet effective\nretrieval-based disentanglement framework that leverages nature language as\ndistant supervision. Our approach is built upon the widely-used bi-encoder\narchitecture with disentanglement heads and is trained on data-text pairs that\nare readily available on the web or in existing datasets. This makes our\napproach task- and modality-agnostic with potential for a wide range of\ndownstream applications. We conduct experiments on 16 datasets in both\ntext-to-text and cross-modal scenarios and evaluate VDR in a zero-shot setting.\nWith the incorporation of disentanglement heads and a minor increase in\nparameters, VDR achieves significant improvements over the base retriever it is\nbuilt upon, with a 9% higher on NDCG@10 scores in zero-shot text-to-text\nretrieval and an average of 13% higher recall in cross-modal retrieval. In\ncomparison to other baselines, VDR outperforms them in most tasks, while also\nimproving explainability and efficiency.\n","authors":["Jiawei Zhou","Xiaoguang Li","Lifeng Shang","Xin Jiang","Qun Liu","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2212.07699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.03276v3","updated":"2022-12-15T09:30:58Z","published":"2022-04-07T08:01:13Z","title":"PALBERT: Teaching ALBERT to Ponder","summary":"  Currently, pre-trained models can be considered the default choice for a wide\nrange of NLP tasks. Despite their SoTA results, there is practical evidence\nthat these models may require a different number of computing layers for\ndifferent input sequences, since evaluating all layers leads to overconfidence\nin wrong predictions (namely overthinking). This problem can potentially be\nsolved by implementing adaptive computation time approaches, which were first\ndesigned to improve inference speed. Recently proposed PonderNet may be a\npromising solution for performing an early exit by treating the exit layer's\nindex as a latent variable. However, the originally proposed exit criterion,\nrelying on sampling from trained posterior distribution on the probability of\nexiting from the $i$-th layer, introduces major variance in exit layer indices,\nsignificantly reducing the resulting model's performance. In this paper, we\npropose improving PonderNet with a novel deterministic Q-exit criterion and a\nrevisited model architecture. We adapted the proposed mechanism to ALBERT and\nRoBERTa and compared it with recent methods for performing an early exit. We\nobserved that the proposed changes can be considered significant improvements\non the original PonderNet architecture and outperform PABEE on a wide range of\nGLUE tasks. In addition, we also performed an in-depth ablation study of the\nproposed architecture to further understand Lambda layers and their\nperformance.\n","authors":["Nikita Balagansky","Daniil Gavrilov"],"pdf_url":"https://arxiv.org/pdf/2204.03276v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07677v1","updated":"2022-12-15T09:21:21Z","published":"2022-12-15T09:21:21Z","title":"Transformers learn in-context by gradient descent","summary":"  Transformers have become the state-of-the-art neural network architecture\nacross numerous domains of machine learning. This is partly due to their\ncelebrated ability to transfer and to learn in-context based on few examples.\nNevertheless, the mechanisms by which Transformers become in-context learners\nare not well understood and remain mostly an intuition. Here, we argue that\ntraining Transformers on auto-regressive tasks can be closely related to\nwell-known gradient-based meta-learning formulations. We start by providing a\nsimple weight construction that shows the equivalence of data transformations\ninduced by 1) a single linear self-attention layer and by 2) gradient-descent\n(GD) on a regression loss. Motivated by that construction, we show empirically\nthat when training self-attention-only Transformers on simple regression tasks\neither the models learned by GD and Transformers show great similarity or,\nremarkably, the weights found by optimization match the construction. Thus we\nshow how trained Transformers implement gradient descent in their forward pass.\nThis allows us, at least in the domain of regression problems, to\nmechanistically understand the inner workings of optimized Transformers that\nlearn in-context. Furthermore, we identify how Transformers surpass plain\ngradient descent by an iterative curvature correction and learn linear models\non deep data representations to solve non-linear regression tasks. Finally, we\ndiscuss intriguing parallels to a mechanism identified to be crucial for\nin-context learning termed induction-head (Olsson et al., 2022) and show how it\ncould be understood as a specific case of in-context learning by gradient\ndescent learning within Transformers.\n","authors":["Johannes von Oswald","Eyvind Niklasson","Ettore Randazzo","João Sacramento","Alexander Mordvintsev","Andrey Zhmoginov","Max Vladymyrov"],"pdf_url":"https://arxiv.org/pdf/2212.07677v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07127v2","updated":"2022-12-15T09:10:16Z","published":"2022-12-14T09:26:07Z","title":"Towards mapping the contemporary art world with ArtLM: an art-specific\n  NLP model","summary":"  With an increasing amount of data in the art world, discovering artists and\nartworks suitable to collectors' tastes becomes a challenge. It is no longer\nenough to use visual information, as contextual information about the artist\nhas become just as important in contemporary art. In this work, we present a\ngeneric Natural Language Processing framework (called ArtLM) to discover the\nconnections among contemporary artists based on their biographies. In this\napproach, we first continue to pre-train the existing general English language\nmodels with a large amount of unlabelled art-related data. We then fine-tune\nthis new pre-trained model with our biography pair dataset manually annotated\nby a team of professionals in the art industry. With extensive experiments, we\ndemonstrate that our ArtLM achieves 85.6% accuracy and 84.0% F1 score and\noutperforms other baseline models. We also provide a visualisation and a\nqualitative analysis of the artist network built from ArtLM's outputs.\n","authors":["Qinkai Chen","Mohamed El-Mennaoui","Antoine Fosset","Amine Rebei","Haoyang Cao","Christy Eóin O'Beirne","Sasha Shevchenko","Mathieu Rosenbaum"],"pdf_url":"https://arxiv.org/pdf/2212.07127v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07672v1","updated":"2022-12-15T09:05:26Z","published":"2022-12-15T09:05:26Z","title":"Summary-Oriented Vision Modeling for Multimodal Abstractive\n  Summarization","summary":"  The goal of multimodal abstractive summarization (MAS) is to produce a\nconcise summary given the multimodal data (text and vision). Existing studies\non MAS mainly focus on how to effectively use the extracted visual features,\nhaving achieved impressive success on the high-resource English dataset.\nHowever, less attention has been paid to the quality of the visual features to\nthe summary, which may limit the model performance especially in the low- and\nzero-resource scenarios. In this paper, we propose to improve the summary\nquality through summary-oriented visual features. To this end, we devise two\nauxiliary tasks including \\emph{vision to summary task} and \\emph{masked image\nmodeling task}. Together with the main summarization task, we optimize the MAS\nmodel via the training objectives of all these tasks. By these means, the MAS\nmodel can be enhanced by capturing the summary-oriented visual features,\nthereby yielding more accurate summaries. Experiments on 44 languages, covering\nmid-high-, low-, and zero-resource scenarios, verify the effectiveness and\nsuperiority of the proposed approach, which achieves state-of-the-art\nperformance under all scenarios.\n","authors":["Yunlong Liang","Fandong Meng","Jinan Xu","Jiaan Wang","Yufeng Chen","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.07672v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2212.07669v1","updated":"2022-12-15T08:57:30Z","published":"2022-12-15T08:57:30Z","title":"Using Two Losses and Two Datasets Simultaneously to Improve TempoWiC\n  Accuracy","summary":"  WSD (Word Sense Disambiguation) is the task of identifying which sense of a\nword is meant in a sentence or other segment of text. Researchers have worked\non this task (e.g. Pustejovsky, 2002) for years but it's still a challenging\none even for SOTA (state-of-the-art) LMs (language models). The new dataset,\nTempoWiC introduced by Loureiro et al. (2022b) focuses on the fact that words\nchange over time. Their best baseline achieves 70.33% macro-F1. In this work,\nwe use two different losses simultaneously to train RoBERTa-based\nclassification models. We also improve our model by using another similar\ndataset to generalize better. Our best configuration beats their best baseline\nby 4.23% and reaches 74.56% macroF1.\n","authors":["Mohammad Javad Pirhadi","Motahhare Mirzaei","Sauleh Eetemadi"],"pdf_url":"https://arxiv.org/pdf/2212.07669v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07649v1","updated":"2022-12-15T08:15:32Z","published":"2022-12-15T08:15:32Z","title":"Improve Text Classification Accuracy with Intent Information","summary":"  Text classification, a core component of task-oriented dialogue systems,\nattracts continuous research from both the research and industry community, and\nhas resulted in tremendous progress. However, existing method does not consider\nthe use of label information, which may weaken the performance of text\nclassification systems in some token-aware scenarios. To address the problem,\nin this paper, we introduce the use of label information as label embedding for\nthe task of text classification and achieve remarkable performance on benchmark\ndataset.\n","authors":["Yifeng Xie"],"pdf_url":"https://arxiv.org/pdf/2212.07649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.11761v2","updated":"2022-12-15T07:32:25Z","published":"2022-08-24T20:14:52Z","title":"IndicSUPERB: A Speech Processing Universal Performance Benchmark for\n  Indian languages","summary":"  A cornerstone in AI research has been the creation and adoption of\nstandardized training and test datasets to earmark the progress of\nstate-of-the-art models. A particularly successful example is the GLUE dataset\nfor training and evaluating Natural Language Understanding (NLU) models for\nEnglish. The large body of research around self-supervised BERT-based language\nmodels revolved around performance improvements on NLU tasks in GLUE. To\nevaluate language models in other languages, several language-specific GLUE\ndatasets were created. The area of speech language understanding (SLU) has\nfollowed a similar trajectory. The success of large self-supervised models such\nas wav2vec2 enable creation of speech models with relatively easy to access\nunlabelled data. These models can then be evaluated on SLU tasks, such as the\nSUPERB benchmark. In this work, we extend this to Indic languages by releasing\nthe IndicSUPERB benchmark. Specifically, we make the following three\ncontributions. (i) We collect Kathbath containing 1,684 hours of labelled\nspeech data across 12 Indian languages from 1,218 contributors located in 203\ndistricts in India. (ii) Using Kathbath, we create benchmarks across 6 speech\ntasks: Automatic Speech Recognition, Speaker Verification, Speaker\nIdentification (mono/multi), Language Identification, Query By Example, and\nKeyword Spotting for 12 languages. (iii) On the released benchmarks, we train\nand evaluate different self-supervised models alongside a commonly used\nbaseline FBANK. We show that language-specific fine-tuned models are more\naccurate than baseline on most of the tasks, including a large gap of 76\\% for\nthe Language Identification task. However, for speaker identification,\nself-supervised models trained on large datasets demonstrate an advantage. We\nhope IndicSUPERB contributes to the progress of developing speech language\nunderstanding models for Indian languages.\n","authors":["Tahir Javed","Kaushal Santosh Bhogale","Abhigyan Raman","Anoop Kunchukuttan","Pratyush Kumar","Mitesh M. Khapra"],"pdf_url":"https://arxiv.org/pdf/2208.11761v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07634v1","updated":"2022-12-15T06:52:31Z","published":"2022-12-15T06:52:31Z","title":"Gradient-based Intra-attention Pruning on Pre-trained Language Models","summary":"  Pre-trained language models achieve superior performance, but they are\ncomputationally expensive due to their large size. Techniques such as pruning\nand knowledge distillation (KD) have been developed to reduce their size and\nlatency. In most structural pruning methods, the pruning units, such as\nattention heads and feed-forward hidden dimensions, only span a small model\nstructure space and limit the structures that the pruning algorithm can\nexplore. In this work, we propose Gradient-based Intra-attention pruning\n(GRAIN), which inspects fine intra-attention structures, and allows different\nheads to have different sizes. Intra-attention pruning greatly expands the\nsearching space of model structures and yields highly heterogeneous structures.\nWe further propose structure regularization to encourage generating more\nregular structures, which achieves higher speedups than heterogeneous ones. We\nalso integrate KD into the pruning process with a gradient separation strategy\nto reduce the interference of KD with the pruning process. GRAIN is evaluated\non a variety of tasks. Results show that it notably outperforms other methods\nat the same or similar model size. Even under extreme compression where only\n$3\\%$ weights in transformers remain, the pruned model is still competitive.\n","authors":["Ziqing Yang","Yiming Cui","Xin Yao","Shijin Wang"],"pdf_url":"https://arxiv.org/pdf/2212.07634v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.07617v1","updated":"2022-12-15T05:01:59Z","published":"2022-12-15T05:01:59Z","title":"Efficient Pre-training of Masked Language Model via Concept-based\n  Curriculum Masking","summary":"  Masked language modeling (MLM) has been widely used for pre-training\neffective bidirectional representations, but incurs substantial training costs.\nIn this paper, we propose a novel concept-based curriculum masking (CCM) method\nto efficiently pre-train a language model. CCM has two key differences from\nexisting curriculum learning approaches to effectively reflect the nature of\nMLM. First, we introduce a carefully-designed linguistic difficulty criterion\nthat evaluates the MLM difficulty of each token. Second, we construct a\ncurriculum that gradually masks words related to the previously masked words by\nretrieving a knowledge graph. Experimental results show that CCM significantly\nimproves pre-training efficiency. Specifically, the model trained with CCM\nshows comparative performance with the original BERT on the General Language\nUnderstanding Evaluation benchmark at half of the training cost.\n","authors":["Mingyu Lee","Jun-Hyung Park","Junho Kim","Kang-Min Kim","SangKeun Lee"],"pdf_url":"https://arxiv.org/pdf/2212.07617v1.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2212.05970v2","updated":"2022-12-15T02:52:34Z","published":"2022-12-09T03:29:38Z","title":"Decomposing a Recurrent Neural Network into Modules for Enabling\n  Reusability and Replacement","summary":"  Can we take a recurrent neural network (RNN) trained to translate between\nlanguages and augment it to support a new natural language without retraining\nthe model from scratch? Can we fix the faulty behavior of the RNN by replacing\nportions associated with the faulty behavior? Recent works on decomposing a\nfully connected neural network (FCNN) and convolutional neural network (CNN)\ninto modules have shown the value of engineering deep models in this manner,\nwhich is standard in traditional SE but foreign for deep learning models.\nHowever, prior works focus on the image-based multiclass classification\nproblems and cannot be applied to RNN due to (a) different layer structures,\n(b) loop structures, (c) different types of input-output architectures, and (d)\nusage of both nonlinear and logistic activation functions. In this work, we\npropose the first approach to decompose an RNN into modules. We study different\ntypes of RNNs, i.e., Vanilla, LSTM, and GRU. Further, we show how such RNN\nmodules can be reused and replaced in various scenarios. We evaluate our\napproach against 5 canonical datasets (i.e., Math QA, Brown Corpus,\nWiki-toxicity, Clinc OOS, and Tatoeba) and 4 model variants for each dataset.\nWe found that decomposing a trained model has a small cost (Accuracy: -0.6%,\nBLEU score: +0.10%). Also, the decomposed modules can be reused and replaced\nwithout needing to retrain.\n","authors":["Sayem Mohammad Imtiaz","Fraol Batole","Astha Singh","Rangeet Pan","Breno Dantas Cruz","Hridesh Rajan"],"pdf_url":"https://arxiv.org/pdf/2212.05970v2.pdf","comment":"Accepted at 45th international conference on software engineering\n  (ICSE'2023)"},{"id":"http://arxiv.org/abs/2212.05506v2","updated":"2022-12-15T01:07:43Z","published":"2022-12-11T13:43:22Z","title":"FastClass: A Time-Efficient Approach to Weakly-Supervised Text\n  Classification","summary":"  Weakly-supervised text classification aims to train a classifier using only\nclass descriptions and unlabeled data. Recent research shows that\nkeyword-driven methods can achieve state-of-the-art performance on various\ntasks. However, these methods not only rely on carefully-crafted class\ndescriptions to obtain class-specific keywords but also require substantial\namount of unlabeled data and takes a long time to train. This paper proposes\nFastClass, an efficient weakly-supervised classification approach. It uses\ndense text representation to retrieve class-relevant documents from external\nunlabeled corpus and selects an optimal subset to train a classifier. Compared\nto keyword-driven methods, our approach is less reliant on initial class\ndescriptions as it no longer needs to expand each class description into a set\nof class-specific keywords. Experiments on a wide range of classification tasks\nshow that the proposed approach frequently outperforms keyword-driven models in\nterms of classification accuracy and often enjoys orders-of-magnitude faster\ntraining speed.\n","authors":["Tingyu Xia","Yue Wang","Yuan Tian","Yi Chang"],"pdf_url":"https://arxiv.org/pdf/2212.05506v2.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2212.07571v1","updated":"2022-12-15T01:06:55Z","published":"2022-12-15T01:06:55Z","title":"Fixing MoE Over-Fitting on Low-Resource Languages in Multilingual\n  Machine Translation","summary":"  Sparsely gated Mixture of Experts (MoE) models have been shown to be a\ncompute-efficient method to scale model capacity for multilingual machine\ntranslation. However, for low-resource tasks, MoE models severely over-fit. We\nshow effective regularization strategies, namely dropout techniques for MoE\nlayers in EOM and FOM, Conditional MoE Routing and Curriculum Learning methods\nthat prevent over-fitting and improve the performance of MoE models on\nlow-resource tasks without adversely affecting high-resource tasks. On a\nmassively multilingual machine translation benchmark, our strategies result in\nabout +1 chrF++ improvement in very low resource language pairs. We perform an\nextensive analysis of the learned MoE routing to better understand the impact\nof our regularization methods and how we can improve them.\n","authors":["Maha Elbayad","Anna Sun","Shruti Bhosale"],"pdf_url":"https://arxiv.org/pdf/2212.07571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07562v2","updated":"2022-12-15T00:43:13Z","published":"2022-09-15T19:01:21Z","title":"TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for\n  Multilingual Tweet Representations","summary":"  We present TwHIN-BERT, a multilingual language model trained on in-domain\ndata from the popular social network Twitter. TwHIN-BERT differs from prior\npre-trained language models as it is trained with not only text-based\nself-supervision, but also with a social objective based on the rich social\nengagements within a Twitter heterogeneous information network (TwHIN). Our\nmodel is trained on 7 billion tweets covering over 100 distinct languages\nproviding a valuable representation to model short, noisy, user-generated text.\nWe evaluate our model on a variety of multilingual social recommendation and\nsemantic understanding tasks and demonstrate significant metric improvement\nover established pre-trained language models. We will freely open-source\nTwHIN-BERT and our curated hashtag prediction and social engagement benchmark\ndatasets to the research community.\n","authors":["Xinyang Zhang","Yury Malkov","Omar Florez","Serim Park","Brian McWilliams","Jiawei Han","Ahmed El-Kishky"],"pdf_url":"https://arxiv.org/pdf/2209.07562v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08196v1","updated":"2022-12-15T23:41:20Z","published":"2022-12-15T23:41:20Z","title":"Saved You A Click: Automatically Answering Clickbait Titles","summary":"  Often clickbait articles have a title that is phrased as a question or vague\nteaser that entices the user to click on the link and read the article to find\nthe explanation. We developed a system that will automatically find the answer\nor explanation of the clickbait hook from the website text so that the user\ndoes not need to read through the text themselves. We fine-tune an extractive\nquestion and answering model (RoBERTa) and an abstractive one (T5), using data\nscraped from the 'StopClickbait' Facebook pages and Reddit's 'SavedYouAClick'\nsubforum. We find that both extractive and abstractive models improve\nsignificantly after finetuning. We find that the extractive model performs\nslightly better according to ROUGE scores, while the abstractive one has a\nslight edge in terms of BERTscores.\n","authors":["Oliver Johnson","Beicheng Lou","Janet Zhong","Andrey Kurenkov"],"pdf_url":"https://arxiv.org/pdf/2212.08196v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08195v1","updated":"2022-12-15T23:38:31Z","published":"2022-12-15T23:38:31Z","title":"Improving Chess Commentaries by Combining Language Models with Symbolic\n  Reasoning Engines","summary":"  Despite many recent advancements in language modeling, state-of-the-art\nlanguage models lack grounding in the real world and struggle with tasks\ninvolving complex reasoning. Meanwhile, advances in the symbolic reasoning\ncapabilities of AI have led to systems that outperform humans in games like\nchess and Go (Silver et al., 2018). Chess commentary provides an interesting\ndomain for bridging these two fields of research, as it requires reasoning over\na complex board state and providing analyses in natural language. In this work\nwe demonstrate how to combine symbolic reasoning engines with controllable\nlanguage models to generate chess commentaries. We conduct experiments to\ndemonstrate that our approach generates commentaries that are preferred by\nhuman judges over previous baselines.\n","authors":["Andrew Lee","David Wu","Emily Dinan","Mike Lewis"],"pdf_url":"https://arxiv.org/pdf/2212.08195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08192v1","updated":"2022-12-15T23:26:54Z","published":"2022-12-15T23:26:54Z","title":"The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources\n  in Natural Language Understanding Systems","summary":"  Many state-of-the-art natural language understanding (NLU) models are based\non pretrained neural language models. These models often make inferences using\ninformation from multiple sources. An important class of such inferences are\nthose that require both background knowledge, presumably contained in a model's\npretrained parameters, and instance-specific information that is supplied at\ninference time. However, the integration and reasoning abilities of NLU models\nin the presence of multiple knowledge sources have been largely understudied.\nIn this work, we propose a test suite of coreference resolution tasks that\nrequire reasoning over multiple facts. Our dataset is organized into subtasks\nthat differ in terms of which knowledge sources contain relevant facts. We\nevaluate state-of-the-art coreference resolution models on our dataset. Our\nresults indicate that several models struggle to reason on-the-fly over\nknowledge observed both at pretrain time and at inference time. However, with\ntask-specific training, a subset of models demonstrates the ability to\nintegrate certain knowledge types from multiple sources.\n","authors":["Akshatha Arodi","Martin Pömsl","Kaheer Suleman","Adam Trischler","Alexandra Olteanu","Jackie Chi Kit Cheung"],"pdf_url":"https://arxiv.org/pdf/2212.08192v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2210.01959v2","updated":"2022-12-15T23:16:30Z","published":"2022-10-04T23:33:52Z","title":"Detect, Retrieve, Comprehend: A Flexible Framework for Zero-Shot\n  Document-Level Question Answering","summary":"  Researchers produce thousands of scholarly documents containing valuable\ntechnical knowledge. The community faces the laborious task of reading these\ndocuments to identify, extract, and synthesize information. To automate\ninformation gathering, document-level question answering (QA) offers a flexible\nframework where human-posed questions can be adapted to extract diverse\nknowledge. Finetuning QA systems requires access to labeled data (tuples of\ncontext, question and answer). However, data curation for document QA is\nuniquely challenging because the context (i.e. answer evidence passage) needs\nto be retrieved from potentially long, ill-formatted documents. Existing QA\ndatasets sidestep this challenge by providing short, well-defined contexts that\nare unrealistic in real-world applications. We present a three-stage document\nQA approach: (1) text extraction from PDF; (2) evidence retrieval from\nextracted texts to form well-posed contexts; (3) QA to extract knowledge from\ncontexts to return high-quality answers -- extractive, abstractive, or Boolean.\nUsing QASPER for evaluation, our detect-retrieve-comprehend (DRC) system\nachieves a +7.19 improvement in Answer-F1 over existing baselines while\ndelivering superior context selection. Our results demonstrate that DRC holds\ntremendous promise as a flexible framework for practical scientific document\nQA.\n","authors":["Tavish McDonald","Brian Tsan","Amar Saini","Juanita Ordonez","Luis Gutierrez","Phan Nguyen","Blake Mason","Brenda Ng"],"pdf_url":"https://arxiv.org/pdf/2210.01959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08184v1","updated":"2022-12-15T23:00:33Z","published":"2022-12-15T23:00:33Z","title":"NBC-Softmax : Darkweb Author fingerprinting and migration tracking","summary":"  Metric learning aims to learn distances from the data, which enhances the\nperformance of similarity-based algorithms. An author style detection task is a\nmetric learning problem, where learning style features with small intra-class\nvariations and larger inter-class differences is of great importance to achieve\nbetter performance. Recently, metric learning based on softmax loss has been\nused successfully for style detection. While softmax loss can produce separable\nrepresentations, its discriminative power is relatively poor. In this work, we\npropose NBC-Softmax, a contrastive loss based clustering technique for softmax\nloss, which is more intuitive and able to achieve superior performance. Our\ntechnique meets the criterion for larger number of samples, thus achieving\nblock contrastiveness, which is proven to outperform pair-wise losses. It uses\nmini-batch sampling effectively and is scalable. Experiments on 4 darkweb\nsocial forums, with NBCSAuthor that uses the proposed NBC-Softmax for author\nand sybil detection, shows that our negative block contrastive approach\nconstantly outperforms state-of-the-art methods using the same network\narchitecture.\n  Our code is publicly available at : https://github.com/gayanku/NBC-Softmax\n","authors":["Gayan K. Kulatilleke","Shekhar S. Chandra","Marius Portmann"],"pdf_url":"https://arxiv.org/pdf/2212.08184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09718v2","updated":"2022-12-15T22:45:46Z","published":"2022-11-02T00:58:02Z","title":"Numerical Optimizations for Weighted Low-rank Estimation on Language\n  Model","summary":"  Singular value decomposition (SVD) is one of the most popular compression\nmethods that approximate a target matrix with smaller matrices. However,\nstandard SVD treats the parameters within the matrix with equal importance,\nwhich is a simple but unrealistic assumption. The parameters of a trained\nneural network model may affect task performance unevenly, which suggests\nnon-equal importance among the parameters. Compared to SVD, the decomposition\nmethod aware of parameter importance is the more practical choice in real\ncases. Unlike standard SVD, weighted value decomposition is a non-convex\noptimization problem that lacks a closed-form solution. We systematically\ninvestigated multiple optimization strategies to tackle the problem and\nexamined our method by compressing Transformer-based language models. Further,\nwe designed a metric to predict when the SVD may introduce a significant\nperformance drop, for which our method can be a rescue strategy. The extensive\nevaluations demonstrate that our method can perform better than current SOTA\nmethods in compressing Transformer-based language models.\n","authors":["Ting Hua","Yen-Chang Hsu","Felicity Wang","Qian Lou","Yilin Shen","Hongxia Jin"],"pdf_url":"https://arxiv.org/pdf/2211.09718v2.pdf","comment":"long paper EMNLP 2022"},{"id":"http://arxiv.org/abs/2212.08172v1","updated":"2022-12-15T22:15:11Z","published":"2022-12-15T22:15:11Z","title":"Reliable Measures of Spread in High Dimensional Latent Spaces","summary":"  Understanding geometric properties of natural language processing models'\nlatent spaces allows the manipulation of these properties for improved\nperformance on downstream tasks. One such property is the amount of data spread\nin a model's latent space, or how fully the available latent space is being\nused. In this work, we define data spread and demonstrate that the commonly\nused measures of data spread, Average Cosine Similarity and a partition\nfunction min/max ratio I(V), do not provide reliable metrics to compare the use\nof latent space across models. We propose and examine eight alternative\nmeasures of data spread, all but one of which improve over these current\nmetrics when applied to seven synthetic data distributions. Of our proposed\nmeasures, we recommend one principal component-based measure and one\nentropy-based measure that provide reliable, relative measures of spread and\ncan be used to compare models of different sizes and dimensionalities.\n","authors":["Anna C. Marbut","Katy McKinney-Bock","Travis J. Wheeler"],"pdf_url":"https://arxiv.org/pdf/2212.08172v1.pdf","comment":"24 pages, 11 figures, 13 tables"},{"id":"http://arxiv.org/abs/2211.16822v2","updated":"2022-12-15T21:53:05Z","published":"2022-11-30T08:44:30Z","title":"A Probabilistic-Logic based Commonsense Representation Framework for\n  Modelling Inferences with Multiple Antecedents and Varying Likelihoods","summary":"  Commonsense knowledge-graphs (CKGs) are important resources towards building\nmachines that can 'reason' on text or environmental inputs and make inferences\nbeyond perception. While current CKGs encode world knowledge for a large number\nof concepts and have been effectively utilized for incorporating commonsense in\nneural models, they primarily encode declarative or single-condition\ninferential knowledge and assume all conceptual beliefs to have the same\nlikelihood. Further, these CKGs utilize a limited set of relations shared\nacross concepts and lack a coherent knowledge organization structure resulting\nin redundancies as well as sparsity across the larger knowledge graph.\nConsequently, today's CKGs, while useful for a first level of reasoning, do not\nadequately capture deeper human-level commonsense inferences which can be more\nnuanced and influenced by multiple contextual or situational factors.\n  Accordingly, in this work, we study how commonsense knowledge can be better\nrepresented by -- (i) utilizing a probabilistic logic representation scheme to\nmodel composite inferential knowledge and represent conceptual beliefs with\nvarying likelihoods and (ii) incorporating a hierarchical conceptual ontology\nto identify salient concept-relevant relations and organize beliefs at\ndifferent conceptual levels. Our resulting knowledge representation framework\ncan encode a wider variety of world knowledge and represent beliefs flexibly\nusing grounded concepts as well as free-text phrases. As a result, the\nframework can be utilized as both a traditional free-text knowledge graph and a\ngrounded logic-based inference system more suitable for neuro-symbolic\napplications. We describe how we extend the PrimeNet knowledge base with our\nframework through crowd-sourcing and expert-annotation, and demonstrate its\napplication for more interpretable passage-based semantic parsing and question\nanswering.\n","authors":["Shantanu Jaiswal","Liu Yan","Dongkyu Choi","Kenneth Kwok"],"pdf_url":"https://arxiv.org/pdf/2211.16822v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08158v1","updated":"2022-12-15T21:41:06Z","published":"2022-12-15T21:41:06Z","title":"MM-SHAP: A Performance-agnostic Metric for Measuring Multimodal\n  Contributions in Vision and Language Models & Tasks","summary":"  Vision and language models (VL) are known to exploit unrobust indicators in\nindividual modalities (e.g., introduced by distributional biases), instead of\nfocusing on relevant information in each modality. A small drop in accuracy\nobtained on a VL task with a unimodal model suggests that so-called unimodal\ncollapse occurred. But how to quantify the amount of unimodal collapse\nreliably, at dataset and instance-level, to diagnose and combat unimodal\ncollapse in a targeted way? We present MM-SHAP, a performance-agnostic\nmultimodality score that quantifies the proportion by which a model uses\nindividual modalities in multimodal tasks. MM-SHAP is based on Shapley values\nand will be applied in two ways: (1) to compare models for their degree of\nmultimodality, and (2) to measure the contribution of individual modalities for\na given task and dataset. Experiments with 6 VL models -- LXMERT, CLIP and four\nALBEF variants -- on four VL tasks highlight that unimodal collapse can occur\nto different degrees and in different directions, contradicting the wide-spread\nassumption that unimodal collapse is one-sided. We recommend MM-SHAP for\nanalysing multimodal tasks, to diagnose and guide progress towards multimodal\nintegration. Code available at: https://github.com/Heidelberg-NLP/MM-SHAP\n","authors":["Letitia Parcalabescu","Anette Frank"],"pdf_url":"https://arxiv.org/pdf/2212.08158v1.pdf","comment":"10 pages, 13 appendix pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2212.08153v1","updated":"2022-12-15T21:35:46Z","published":"2022-12-15T21:35:46Z","title":"FiDO: Fusion-in-Decoder optimized for stronger performance and faster\n  inference","summary":"  Fusion-in-Decoder (FiD) is a powerful retrieval-augmented language model that\nsets the state-of-the-art on many knowledge-intensive NLP tasks. However, FiD\nsuffers from very expensive inference. We show that the majority of inference\ntime results from memory bandwidth constraints in the decoder, and propose two\nsimple changes to the FiD architecture to speed up inference by 7x. The faster\ndecoder inference then allows for a much larger decoder. We denote FiD with the\nabove modifications as FiDO, and show that it strongly improves performance\nover existing FiD models for a wide range of inference budgets. For example,\nFiDO-Large-XXL performs faster inference than FiD-Base and achieves better\nperformance than FiD-Large.\n","authors":["Michiel de Jong","Yury Zemlyanskiy","Joshua Ainslie","Nicholas FitzGerald","Sumit Sanghai","Fei Sha","William Cohen"],"pdf_url":"https://arxiv.org/pdf/2212.08153v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08136v1","updated":"2022-12-15T20:51:27Z","published":"2022-12-15T20:51:27Z","title":"Efficient Long Sequence Modeling via State Space Augmented Transformer","summary":"  Transformer models have achieved superior performance in various natural\nlanguage processing tasks. However, the quadratic computational cost of the\nattention mechanism limits its practicality for long sequences. There are\nexisting attention variants that improve the computational efficiency, but they\nhave limited ability to effectively compute global information. In parallel to\nTransformer models, state space models (SSMs) are tailored for long sequences,\nbut they are not flexible enough to capture complicated local information. We\npropose SPADE, short for $\\underline{\\textbf{S}}$tate\ns$\\underline{\\textbf{P}}$ace\n$\\underline{\\textbf{A}}$ugmente$\\underline{\\textbf{D}}$\nTransform$\\underline{\\textbf{E}}$r. Specifically, we augment a SSM into the\nbottom layer of SPADE, and we employ efficient local attention methods for the\nother layers. The SSM augments global information, which complements the lack\nof long-range dependency issue in local attention methods. Experimental results\non the Long Range Arena benchmark and language modeling tasks demonstrate the\neffectiveness of the proposed method. To further demonstrate the scalability of\nSPADE, we pre-train large encoder-decoder models and present fine-tuning\nresults on natural language understanding and natural language generation\ntasks.\n","authors":["Simiao Zuo","Xiaodong Liu","Jian Jiao","Denis Charles","Eren Manavoglu","Tuo Zhao","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2212.08136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.05952v3","updated":"2022-12-15T20:38:08Z","published":"2021-09-13T13:26:30Z","title":"Adapting the Tesseract Open-Source OCR Engine for Tamil and Sinhala\n  Legacy Fonts and Creating a Parallel Corpus for Tamil-Sinhala-English","summary":"  Most low-resource languages do not have the necessary resources to create\neven a substantial monolingual corpus. These languages may often be found in\ngovernment proceedings but mainly in Portable Document Format (PDF) that\ncontains legacy fonts. Extracting text from these documents to create a\nmonolingual corpus is challenging due to legacy font usage and printer-friendly\nencoding, which are not optimized for text extraction. Therefore, we propose a\nsimple, automatic, and novel idea that can scale for Tamil, Sinhala, English\nlanguages, and many documents along with parallel corpora. Since Tamil and\nSinhala are Low-Resource Languages, we improved the performance of Tesseract by\nemploying LSTM-based training on more than 20 legacy fonts to recognize printed\ncharacters in these languages. Especially, our model detects code-mixed text,\nnumbers, and special characters from the printed document. It is shown that\nthis approach can reduce the character-level error rate of Tesseract from 6.03\nto 2.61 for Tamil (-3.42% relative change) and 7.61 to 4.74 for Sinhala (-2.87%\nrelative change), as well as the word-level error rate from 39.68 to 20.61 for\nTamil (-19.07% relative change) and 35.04 to 26.58 for Sinhala (-8.46% relative\nchange) on the test set. Also, our newly created parallel corpus consists of\n185.4k, 168.9k, and 181.04k sentences and 2.11M, 2.22M, and 2.33M Words in\nTamil, Sinhala, and English respectively. This study shows that fine-tuning\nTesseract models on multiple new fonts help to understand the texts and\nenhances the performance of the OCR. We made newly trained models and the\nsource code for fine-tuning Tesseract, freely available.\n","authors":["Charangan Vasantharajan","Laksika Tharmalingam","Uthayasanker Thayasivam"],"pdf_url":"https://arxiv.org/pdf/2109.05952v3.pdf","comment":"7 Pages"},{"id":"http://arxiv.org/abs/2212.08120v1","updated":"2022-12-15T20:15:05Z","published":"2022-12-15T20:15:05Z","title":"Injecting Domain Knowledge in Language Models for Task-Oriented Dialogue\n  Systems","summary":"  Pre-trained language models (PLM) have advanced the state-of-the-art across\nNLP applications, but lack domain-specific knowledge that does not naturally\noccur in pre-training data. Previous studies augmented PLMs with symbolic\nknowledge for different downstream NLP tasks. However, knowledge bases (KBs)\nutilized in these studies are usually large-scale and static, in contrast to\nsmall, domain-specific, and modifiable knowledge bases that are prominent in\nreal-world task-oriented dialogue (TOD) systems. In this paper, we showcase the\nadvantages of injecting domain-specific knowledge prior to fine-tuning on TOD\ntasks. To this end, we utilize light-weight adapters that can be easily\nintegrated with PLMs and serve as a repository for facts learned from different\nKBs. To measure the efficacy of proposed knowledge injection methods, we\nintroduce Knowledge Probing using Response Selection (KPRS) -- a probe designed\nspecifically for TOD models. Experiments on KPRS and the response generation\ntask show improvements of knowledge injection with adapters over strong\nbaselines.\n","authors":["Denis Emelin","Daniele Bonadiman","Sawsan Alqahtani","Yi Zhang","Saab Mansour"],"pdf_url":"https://arxiv.org/pdf/2212.08120v1.pdf","comment":"Published at EMNLP 2022 (main conference)"},{"id":"http://arxiv.org/abs/2212.08094v1","updated":"2022-12-15T19:13:42Z","published":"2022-12-15T19:13:42Z","title":"Joint processing of linguistic properties in brains and language models","summary":"  Language models have been shown to be very effective in predicting brain\nrecordings of subjects experiencing complex language stimuli. For a deeper\nunderstanding of this alignment, it is important to understand the alignment\nbetween the detailed processing of linguistic information by the human brain\nversus language models. In NLP, linguistic probing tasks have revealed a\nhierarchy of information processing in neural language models that progresses\nfrom simple to complex with an increase in depth. On the other hand, in\nneuroscience, the strongest alignment with high-level language brain regions\nhas consistently been observed in the middle layers. These findings leave an\nopen question as to what linguistic information actually underlies the observed\nalignment between brains and language models. We investigate this question via\na direct approach, in which we eliminate information related to specific\nlinguistic properties in the language model representations and observe how\nthis intervention affects the alignment with fMRI brain recordings obtained\nwhile participants listened to a story. We investigate a range of linguistic\nproperties (surface, syntactic and semantic) and find that the elimination of\neach one results in a significant decrease in brain alignment across all layers\nof a language model. These findings provide direct evidence for the role of\nspecific linguistic information in the alignment between brain and language\nmodels, and opens new avenues for mapping the joint information processing in\nboth systems.\n","authors":["Subba Reddy Oota","Manish Gupta","Mariya Toneva"],"pdf_url":"https://arxiv.org/pdf/2212.08094v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.08073v1","updated":"2022-12-15T06:19:23Z","published":"2022-12-15T06:19:23Z","title":"Constitutional AI: Harmlessness from AI Feedback","summary":"  As AI systems become more capable, we would like to enlist their help to\nsupervise other AIs. We experiment with methods for training a harmless AI\nassistant through self-improvement, without any human labels identifying\nharmful outputs. The only human oversight is provided through a list of rules\nor principles, and so we refer to the method as 'Constitutional AI'. The\nprocess involves both a supervised learning and a reinforcement learning phase.\nIn the supervised phase we sample from an initial model, then generate\nself-critiques and revisions, and then finetune the original model on revised\nresponses. In the RL phase, we sample from the finetuned model, use a model to\nevaluate which of the two samples is better, and then train a preference model\nfrom this dataset of AI preferences. We then train with RL using the preference\nmodel as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF). As a\nresult we are able to train a harmless but non-evasive AI assistant that\nengages with harmful queries by explaining its objections to them. Both the SL\nand RL methods can leverage chain-of-thought style reasoning to improve the\nhuman-judged performance and transparency of AI decision making. These methods\nmake it possible to control AI behavior more precisely and with far fewer human\nlabels.\n","authors":["Yuntao Bai","Saurav Kadavath","Sandipan Kundu","Amanda Askell","Jackson Kernion","Andy Jones","Anna Chen","Anna Goldie","Azalia Mirhoseini","Cameron McKinnon","Carol Chen","Catherine Olsson","Christopher Olah","Danny Hernandez","Dawn Drain","Deep Ganguli","Dustin Li","Eli Tran-Johnson","Ethan Perez","Jamie Kerr","Jared Mueller","Jeffrey Ladish","Joshua Landau","Kamal Ndousse","Kamile Lukosuite","Liane Lovitt","Michael Sellitto","Nelson Elhage","Nicholas Schiefer","Noemi Mercado","Nova DasSarma","Robert Lasenby","Robin Larson","Sam Ringer","Scott Johnston","Shauna Kravec","Sheer El Showk","Stanislav Fort","Tamera Lanham","Timothy Telleen-Lawton","Tom Conerly","Tom Henighan","Tristan Hume","Samuel R. Bowman","Zac Hatfield-Dodds","Ben Mann","Dario Amodei","Nicholas Joseph","Sam McCandlish","Tom Brown","Jared Kaplan"],"pdf_url":"https://arxiv.org/pdf/2212.08073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08475v1","updated":"2022-12-15T02:28:52Z","published":"2022-12-15T02:28:52Z","title":"Best-Answer Prediction in Q&A Sites Using User Information","summary":"  Community Question Answering (CQA) sites have spread and multiplied\nsignificantly in recent years. Sites like Reddit, Quora, and Stack Exchange are\nbecoming popular amongst people interested in finding answers to diverse\nquestions. One practical way of finding such answers is automatically\npredicting the best candidate given existing answers and comments. Many studies\nwere conducted on answer prediction in CQA but with limited focus on using the\nbackground information of the questionnaires. We address this limitation using\na novel method for predicting the best answers using the questioner's\nbackground information and other features, such as the textual content or the\nrelationships with other participants. Our answer classification model was\ntrained using the Stack Exchange dataset and validated using the Area Under the\nCurve (AUC) metric. The experimental results show that the proposed method\ncomplements previous methods by pointing out the importance of the\nrelationships between users, particularly throughout the level of involvement\nin different communities on Stack Exchange. Furthermore, we point out that\nthere is little overlap between user-relation information and the information\nrepresented by the shallow text features and the meta-features, such as time\ndifferences.\n","authors":["Rafik Hadfi","Ahmed Moustafa","Kai Yoshino","Takayuki Ito"],"pdf_url":"https://arxiv.org/pdf/2212.08475v1.pdf","comment":"22 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2212.07571v1","updated":"2022-12-15T01:06:55Z","published":"2022-12-15T01:06:55Z","title":"Fixing MoE Over-Fitting on Low-Resource Languages in Multilingual\n  Machine Translation","summary":"  Sparsely gated Mixture of Experts (MoE) models have been shown to be a\ncompute-efficient method to scale model capacity for multilingual machine\ntranslation. However, for low-resource tasks, MoE models severely over-fit. We\nshow effective regularization strategies, namely dropout techniques for MoE\nlayers in EOM and FOM, Conditional MoE Routing and Curriculum Learning methods\nthat prevent over-fitting and improve the performance of MoE models on\nlow-resource tasks without adversely affecting high-resource tasks. On a\nmassively multilingual machine translation benchmark, our strategies result in\nabout +1 chrF++ improvement in very low resource language pairs. We perform an\nextensive analysis of the learned MoE routing to better understand the impact\nof our regularization methods and how we can improve them.\n","authors":["Maha Elbayad","Anna Sun","Shruti Bhosale"],"pdf_url":"https://arxiv.org/pdf/2212.07571v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2207.04672"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2212.08071v1","updated":"2022-12-15T18:59:59Z","published":"2022-12-15T18:59:59Z","title":"MAViL: Masked Audio-Video Learners","summary":"  We present Masked Audio-Video Learners (MAViL) to train audio-visual\nrepresentations. Our approach learns with three complementary forms of\nself-supervision: (1) reconstruction of masked audio and video input data, (2)\nintra- and inter-modal contrastive learning with masking, and (3) self-training\nby reconstructing joint audio-video contextualized features learned from the\nfirst two objectives. Pre-training with MAViL not only enables the model to\nperform well in audio-visual classification and retrieval tasks but also\nimproves representations of each modality in isolation, without using\ninformation from the other modality for fine-tuning or inference. Empirically,\nMAViL sets a new state-of-the-art on AudioSet (53.1 mAP) and VGGSound (67.1%\naccuracy). For the first time, a self-supervised audio-visual model outperforms\nones that use external supervision on these benchmarks. Code will be available\nsoon.\n","authors":["Po-Yao Huang","Vasu Sharma","Hu Xu","Chaitanya Ryali","Haoqi Fan","Yanghao Li","Shang-Wen Li","Gargi Ghosh","Jitendra Malik","Christoph Feichtenhofer"],"pdf_url":"https://arxiv.org/pdf/2212.08071v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2212.08070v1","updated":"2022-12-15T18:59:58Z","published":"2022-12-15T18:59:58Z","title":"NeRF-Art: Text-Driven Neural Radiance Fields Stylization","summary":"  As a powerful representation of 3D scenes, the neural radiance field (NeRF)\nenables high-quality novel view synthesis from multi-view images. Stylizing\nNeRF, however, remains challenging, especially on simulating a text-guided\nstyle with both the appearance and the geometry altered simultaneously. In this\npaper, we present NeRF-Art, a text-guided NeRF stylization approach that\nmanipulates the style of a pre-trained NeRF model with a simple text prompt.\nUnlike previous approaches that either lack sufficient geometry deformations\nand texture details or require meshes to guide the stylization, our method can\nshift a 3D scene to the target style characterized by desired geometry and\nappearance variations without any mesh guidance. This is achieved by\nintroducing a novel global-local contrastive learning strategy, combined with\nthe directional constraint to simultaneously control both the trajectory and\nthe strength of the target style. Moreover, we adopt a weight regularization\nmethod to effectively suppress cloudy artifacts and geometry noises which arise\neasily when the density field is transformed during geometry stylization.\nThrough extensive experiments on various styles, we demonstrate that our method\nis effective and robust regarding both single-view stylization quality and\ncross-view consistency. The code and more results can be found in our project\npage: https://cassiepython.github.io/nerfart/.\n","authors":["Can Wang","Ruixiang Jiang","Menglei Chai","Mingming He","Dongdong Chen","Jing Liao"],"pdf_url":"https://arxiv.org/pdf/2212.08070v1.pdf","comment":"Project page: https://cassiepython.github.io/nerfart/"},{"id":"http://arxiv.org/abs/2212.08067v1","updated":"2022-12-15T18:59:54Z","published":"2022-12-15T18:59:54Z","title":"VolRecon: Volume Rendering of Signed Ray Distance Functions for\n  Generalizable Multi-View Reconstruction","summary":"  With the success of neural volume rendering in novel view synthesis, neural\nimplicit reconstruction with volume rendering has become popular. However, most\nmethods optimize per-scene functions and are unable to generalize to novel\nscenes. We introduce VolRecon, a generalizable implicit reconstruction method\nwith Signed Ray Distance Function (SRDF). To reconstruct with fine details and\nlittle noise, we combine projection features, aggregated from multi-view\nfeatures with a view transformer, and volume features interpolated from a\ncoarse global feature volume. A ray transformer computes SRDF values of all the\nsamples along a ray to estimate the surface location, which are used for volume\nrendering of color and depth. Extensive experiments on DTU and ETH3D\ndemonstrate the effectiveness and generalization ability of our method. On DTU,\nour method outperforms SparseNeuS by about 30% in sparse view reconstruction\nand achieves comparable quality as MVSNet in full view reconstruction. Besides,\nour method shows good generalization ability on the large-scale ETH3D\nbenchmark. Project page: https://fangjinhuawang.github.io/VolRecon.\n","authors":["Yufan Ren","Fangjinhua Wang","Tong Zhang","Marc Pollefeys","Sabine Süsstrunk"],"pdf_url":"https://arxiv.org/pdf/2212.08067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08066v1","updated":"2022-12-15T18:59:52Z","published":"2022-12-15T18:59:52Z","title":"Mod-Squad: Designing Mixture of Experts As Modular Multi-Task Learners","summary":"  Optimization in multi-task learning (MTL) is more challenging than\nsingle-task learning (STL), as the gradient from different tasks can be\ncontradictory. When tasks are related, it can be beneficial to share some\nparameters among them (cooperation). However, some tasks require additional\nparameters with expertise in a specific type of data or discrimination\n(specialization). To address the MTL challenge, we propose Mod-Squad, a new\nmodel that is Modularized into groups of experts (a 'Squad'). This structure\nallows us to formalize cooperation and specialization as the process of\nmatching experts and tasks. We optimize this matching process during the\ntraining of a single model. Specifically, we incorporate mixture of experts\n(MoE) layers into a transformer model, with a new loss that incorporates the\nmutual dependence between tasks and experts. As a result, only a small set of\nexperts are activated for each task. This prevents the sharing of the entire\nbackbone model between all tasks, which strengthens the model, especially when\nthe training set size and the number of tasks scale up. More interestingly, for\neach task, we can extract the small set of experts as a standalone model that\nmaintains the same performance as the large model. Extensive experiments on the\nTaskonomy dataset with 13 vision tasks and the PASCAL-Context dataset with 5\nvision tasks show the superiority of our approach.\n","authors":["Zitian Chen","Yikang Shen","Mingyu Ding","Zhenfang Chen","Hengshuang Zhao","Erik Learned-Miller","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2212.08066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08062v1","updated":"2022-12-15T18:59:33Z","published":"2022-12-15T18:59:33Z","title":"MetaPortrait: Identity-Preserving Talking Head Generation with Fast\n  Personalized Adaptation","summary":"  In this work, we propose an ID-preserving talking head generation framework,\nwhich advances previous methods in two aspects. First, as opposed to\ninterpolating from sparse flow, we claim that dense landmarks are crucial to\nachieving accurate geometry-aware flow fields. Second, inspired by\nface-swapping methods, we adaptively fuse the source identity during synthesis,\nso that the network better preserves the key characteristics of the image\nportrait. Although the proposed model surpasses prior generation fidelity on\nestablished benchmarks, to further make the talking head generation qualified\nfor real usage, personalized fine-tuning is usually needed. However, this\nprocess is rather computationally demanding that is unaffordable to standard\nusers. To solve this, we propose a fast adaptation model using a meta-learning\napproach. The learned model can be adapted to a high-quality personalized model\nas fast as 30 seconds. Last but not the least, a spatial-temporal enhancement\nmodule is proposed to improve the fine details while ensuring temporal\ncoherency. Extensive experiments prove the significant superiority of our\napproach over the state of the arts in both one-shot and personalized settings.\n","authors":["Bowen Zhang","Chenyang Qi","Pan Zhang","Bo Zhang","HsiangTao Wu","Dong Chen","Qifeng Chen","Yong Wang","Fang Wen"],"pdf_url":"https://arxiv.org/pdf/2212.08062v1.pdf","comment":"Project Page: https://meta-portrait.github.io"},{"id":"http://arxiv.org/abs/2212.08059v1","updated":"2022-12-15T18:59:12Z","published":"2022-12-15T18:59:12Z","title":"Rethinking Vision Transformers for MobileNet Size and Speed","summary":"  With the success of Vision Transformers (ViTs) in computer vision tasks,\nrecent arts try to optimize the performance and complexity of ViTs to enable\nefficient deployment on mobile devices. Multiple approaches are proposed to\naccelerate attention mechanism, improve inefficient designs, or incorporate\nmobile-friendly lightweight convolutions to form hybrid architectures. However,\nViT and its variants still have higher latency or considerably more parameters\nthan lightweight CNNs, even true for the years-old MobileNet. In practice,\nlatency and size are both crucial for efficient deployment on\nresource-constraint hardware. In this work, we investigate a central question,\ncan transformer models run as fast as MobileNet and maintain a similar size? We\nrevisit the design choices of ViTs and propose an improved supernet with low\nlatency and high parameter efficiency. We further introduce a fine-grained\njoint search strategy that can find efficient architectures by optimizing\nlatency and number of parameters simultaneously. The proposed models,\nEfficientFormerV2, achieve about $4\\%$ higher top-1 accuracy than MobileNetV2\nand MobileNetV2$\\times1.4$ on ImageNet-1K with similar latency and parameters.\nWe demonstrate that properly designed and optimized vision transformers can\nachieve high performance with MobileNet-level size and speed.\n","authors":["Yanyu Li","Ju Hu","Yang Wen","Georgios Evangelidis","Kamyar Salahi","Yanzhi Wang","Sergey Tulyakov","Jian Ren"],"pdf_url":"https://arxiv.org/pdf/2212.08059v1.pdf","comment":"Code is available at:\n  https://github.com/snap-research/EfficientFormer"},{"id":"http://arxiv.org/abs/2212.08058v1","updated":"2022-12-15T18:59:07Z","published":"2022-12-15T18:59:07Z","title":"Learning a Fast 3D Spectral Approach to Object Segmentation and Tracking\n  over Space and Time","summary":"  We pose video object segmentation as spectral graph clustering in space and\ntime, with one graph node for each pixel and edges forming local space-time\nneighborhoods. We claim that the strongest cluster in this video graph\nrepresents the salient object. We start by introducing a novel and efficient\nmethod based on 3D filtering for approximating the spectral solution, as the\nprincipal eigenvector of the graph's adjacency matrix, without explicitly\nbuilding the matrix. This key property allows us to have a fast parallel\nimplementation on GPU, orders of magnitude faster than classical approaches for\ncomputing the eigenvector. Our motivation for a spectral space-time clustering\napproach, unique in video semantic segmentation literature, is that such\nclustering is dedicated to preserving object consistency over time, which we\nevaluate using our novel segmentation consistency measure. Further on, we show\nhow to efficiently learn the solution over multiple input feature channels.\nFinally, we extend the formulation of our approach beyond the segmentation\ntask, into the realm of object tracking. In extensive experiments we show\nsignificant improvements over top methods, as well as over powerful ensembles\nthat combine them, achieving state-of-the-art on multiple benchmarks, both for\ntracking and segmentation.\n","authors":["Elena Burceanu","Marius Leordeanu"],"pdf_url":"https://arxiv.org/pdf/2212.08058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08057v1","updated":"2022-12-15T18:58:56Z","published":"2022-12-15T18:58:56Z","title":"Real-Time Neural Light Field on Mobile Devices","summary":"  Recent efforts in Neural Rendering Fields (NeRF) have shown impressive\nresults on novel view synthesis by utilizing implicit neural representation to\nrepresent 3D scenes. Due to the process of volumetric rendering, the inference\nspeed for NeRF is extremely slow, limiting the application scenarios of\nutilizing NeRF on resource-constrained hardware, such as mobile devices. Many\nworks have been conducted to reduce the latency of running NeRF models.\nHowever, most of them still require high-end GPU for acceleration or extra\nstorage memory, which is all unavailable on mobile devices. Another emerging\ndirection utilizes the neural light field (NeLF) for speedup, as only one\nforward pass is performed on a ray to predict the pixel color. Nevertheless, to\nreach a similar rendering quality as NeRF, the network in NeLF is designed with\nintensive computation, which is not mobile-friendly. In this work, we propose\nan efficient network that runs in real-time on mobile devices for neural\nrendering. We follow the setting of NeLF to train our network. Unlike existing\nworks, we introduce a novel network architecture that runs efficiently on\nmobile devices with low latency and small size, i.e., saving $15\\times \\sim\n24\\times$ storage compared with MobileNeRF. Our model achieves high-resolution\ngeneration while maintaining real-time inference for both synthetic and\nreal-world scenes on mobile devices, e.g., $18.04$ms (iPhone 13) for rendering\none $1008\\times756$ image of real 3D scenes. Additionally, we achieve similar\nimage quality as NeRF and better quality than MobileNeRF (PSNR $26.15$ vs.\n$25.91$ on the real-world forward-facing dataset).\n","authors":["Junli Cao","Huan Wang","Pavlo Chemerys","Vladislav Shakhrai","Ju Hu","Yun Fu","Denys Makoviichuk","Sergey Tulyakov","Jian Ren"],"pdf_url":"https://arxiv.org/pdf/2212.08057v1.pdf","comment":"Project page: https://snap-research.github.io/MobileR2L/"},{"id":"http://arxiv.org/abs/2212.08051v1","updated":"2022-12-15T18:56:53Z","published":"2022-12-15T18:56:53Z","title":"Objaverse: A Universe of Annotated 3D Objects","summary":"  Massive data corpora like WebText, Wikipedia, Conceptual Captions,\nWebImageText, and LAION have propelled recent dramatic progress in AI. Large\nneural models trained on such datasets produce impressive results and top many\nof today's benchmarks. A notable omission within this family of large-scale\ndatasets is 3D data. Despite considerable interest and potential applications\nin 3D vision, datasets of high-fidelity 3D models continue to be mid-sized with\nlimited diversity of object categories. Addressing this gap, we present\nObjaverse 1.0, a large dataset of objects with 800K+ (and growing) 3D models\nwith descriptive captions, tags, and animations. Objaverse improves upon\npresent day 3D repositories in terms of scale, number of categories, and in the\nvisual diversity of instances within a category. We demonstrate the large\npotential of Objaverse via four diverse applications: training generative 3D\nmodels, improving tail category segmentation on the LVIS benchmark, training\nopen-vocabulary object-navigation models for Embodied AI, and creating a new\nbenchmark for robustness analysis of vision models. Objaverse can open new\ndirections for research and enable new applications across the field of AI.\n","authors":["Matt Deitke","Dustin Schwenk","Jordi Salvador","Luca Weihs","Oscar Michel","Eli VanderBilt","Ludwig Schmidt","Kiana Ehsani","Aniruddha Kembhavi","Ali Farhadi"],"pdf_url":"https://arxiv.org/pdf/2212.08051v1.pdf","comment":"Website: objaverse.allenai.org"},{"id":"http://arxiv.org/abs/2212.08045v1","updated":"2022-12-15T18:52:08Z","published":"2022-12-15T18:52:08Z","title":"Image-and-Language Understanding from Pixels Only","summary":"  Multimodal models are becoming increasingly effective, in part due to unified\ncomponents, such as the Transformer architecture. However, multimodal models\nstill often consist of many task- and modality-specific pieces and training\nprocedures. For example, CLIP (Radford et al., 2021) trains independent text\nand image towers via a contrastive loss. We explore an additional unification:\nthe use of a pure pixel-based model to perform image, text, and multimodal\ntasks. Our model is trained with contrastive loss alone, so we call it\nCLIP-Pixels Only (CLIPPO). CLIPPO uses a single encoder that processes both\nregular images and text rendered as images. CLIPPO performs image-based tasks\nsuch as retrieval and zero-shot image classification almost as well as CLIP,\nwith half the number of parameters and no text-specific tower or embedding.\nWhen trained jointly via image-text contrastive learning and next-sentence\ncontrastive learning, CLIPPO can perform well on natural language understanding\ntasks, without any word-level loss (language modelling or masked language\nmodelling), outperforming pixel-based prior work. Surprisingly, CLIPPO can\nobtain good accuracy in visual question answering, simply by rendering the\nquestion and image together. Finally, we exploit the fact that CLIPPO does not\nrequire a tokenizer to show that it can achieve strong performance on\nmultilingual multimodal retrieval without\n","authors":["Michael Tschannen","Basil Mustafa","Neil Houlsby"],"pdf_url":"https://arxiv.org/pdf/2212.08045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08044v1","updated":"2022-12-15T18:52:03Z","published":"2022-12-15T18:52:03Z","title":"Are Multimodal Models Robust to Image and Text Perturbations?","summary":"  Multimodal image-text models have shown remarkable performance in the past\nfew years. However, evaluating their robustness against distribution shifts is\ncrucial before adopting them in real-world applications. In this paper, we\ninvestigate the robustness of 9 popular open-sourced image-text models under\ncommon perturbations on five tasks (image-text retrieval, visual reasoning,\nvisual entailment, image captioning, and text-to-image generation). In\nparticular, we propose several new multimodal robustness benchmarks by applying\n17 image perturbation and 16 text perturbation techniques on top of existing\ndatasets. We observe that multimodal models are not robust to image and text\nperturbations, especially to image perturbations. Among the tested perturbation\nmethods, character-level perturbations constitute the most severe distribution\nshift for text, and zoom blur is the most severe shift for image data. We also\nintroduce two new robustness metrics (MMI and MOR) for proper evaluations of\nmultimodal models. We hope our extensive study sheds light on new directions\nfor the development of robust multimodal models.\n","authors":["Jielin Qiu","Yi Zhu","Xingjian Shi","Florian Wenzel","Zhiqiang Tang","Ding Zhao","Bo Li","Mu Li"],"pdf_url":"https://arxiv.org/pdf/2212.08044v1.pdf","comment":"The project webpage is at: https://mmrobustness.github.io/"},{"id":"http://arxiv.org/abs/2212.08013v1","updated":"2022-12-15T18:18:38Z","published":"2022-12-15T18:18:38Z","title":"FlexiViT: One Model for All Patch Sizes","summary":"  Vision Transformers convert images to sequences by slicing them into patches.\nThe size of these patches controls a speed/accuracy tradeoff, with smaller\npatches leading to higher accuracy at greater computational cost, but changing\nthe patch size typically requires retraining the model. In this paper, we\ndemonstrate that simply randomizing the patch size at training time leads to a\nsingle set of weights that performs well across a wide range of patch sizes,\nmaking it possible to tailor the model to different compute budgets at\ndeployment time. We extensively evaluate the resulting model, which we call\nFlexiViT, on a wide range of tasks, including classification, image-text\nretrieval, open-world detection, panoptic segmentation, and semantic\nsegmentation, concluding that it usually matches, and sometimes outperforms,\nstandard ViT models trained at a single patch size in an otherwise identical\nsetup. Hence, FlexiViT training is a simple drop-in improvement for ViT that\nmakes it easy to add compute-adaptive capabilities to most models relying on a\nViT backbone architecture. Code and pre-trained models are available at\nhttps://github.com/google-research/big_vision\n","authors":["Lucas Beyer","Pavel Izmailov","Alexander Kolesnikov","Mathilde Caron","Simon Kornblith","Xiaohua Zhai","Matthias Minderer","Michael Tschannen","Ibrahim Alabdulmohsin","Filip Pavetic"],"pdf_url":"https://arxiv.org/pdf/2212.08013v1.pdf","comment":"Code and pre-trained models available at\n  https://github.com/google-research/big_vision. All authors made significant\n  technical contributions"},{"id":"http://arxiv.org/abs/2212.08008v1","updated":"2022-12-15T18:14:51Z","published":"2022-12-15T18:14:51Z","title":"A New Deep Boosted CNN and Ensemble Learning based IoT Malware Detection","summary":"  Security issues are threatened in various types of networks, especially in\nthe Internet of Things (IoT) environment that requires early detection. IoT is\nthe network of real-time devices like home automation systems and can be\ncontrolled by open-source android devices, which can be an open ground for\nattackers. Attackers can access the network, initiate a different kind of\nsecurity breach, and compromises network control. Therefore, timely detecting\nthe increasing number of sophisticated malware attacks is the challenge to\nensure the credibility of network protection. In this regard, we have developed\na new malware detection framework, Deep Squeezed-Boosted and Ensemble Learning\n(DSBEL), comprised of novel Squeezed-Boosted Boundary-Region\nSplit-Transform-Merge (SB-BR-STM) CNN and ensemble learning. The proposed\nS.T.M. block employs multi-path dilated convolutional, Boundary, and regional\noperations to capture the homogenous and heterogeneous global malicious\npatterns. Moreover, diverse feature maps are achieved using transfer learning\nand multi-path-based squeezing and boosting at initial and final levels to\nlearn minute pattern variations. Finally, the boosted discriminative features\nare extracted from the developed deep SB-BR-STM CNN and provided to the\nensemble classifiers (SVM, M.L.P., and AdaboostM1) to improve the hybrid\nlearning generalization. The performance analysis of the proposed DSBEL\nframework and SB-BR-STM CNN against the existing techniques have been evaluated\nby the IOT_Malware dataset on standard performance measures. Evaluation results\nshow progressive performance as 98.50% accuracy, 97.12% F1-Score, 91.91% MCC,\n95.97 % Recall, and 98.42 % Precision. The proposed malware analysis framework\nis helpful for the timely detection of malicious activity and suggests future\nstrategies.\n","authors":["Saddam Hussain Khan","Wasi Ullah"],"pdf_url":"https://arxiv.org/pdf/2212.08008v1.pdf","comment":"20 pages, 10 figures, 6 tables; Corresponding saddamhkhan@ueas.edu.pk"},{"id":"http://arxiv.org/abs/2201.10737v5","updated":"2022-12-15T17:45:50Z","published":"2022-01-26T03:50:02Z","title":"Class-Aware Adversarial Transformers for Medical Image Segmentation","summary":"  Transformers have made remarkable progress towards modeling long-range\ndependencies within the medical image analysis domain. However, current\ntransformer-based models suffer from several disadvantages: (1) existing\nmethods fail to capture the important features of the images due to the naive\ntokenization scheme; (2) the models suffer from information loss because they\nonly consider single-scale feature representations; and (3) the segmentation\nlabel maps generated by the models are not accurate enough without considering\nrich semantic contexts and anatomical textures. In this work, we present\nCASTformer, a novel type of adversarial transformers, for 2D medical image\nsegmentation. First, we take advantage of the pyramid structure to construct\nmulti-scale representations and handle multi-scale variations. We then design a\nnovel class-aware transformer module to better learn the discriminative regions\nof objects with semantic structures. Lastly, we utilize an adversarial training\nstrategy that boosts segmentation accuracy and correspondingly allows a\ntransformer-based discriminator to capture high-level semantically correlated\ncontents and low-level anatomical features. Our experiments demonstrate that\nCASTformer dramatically outperforms previous state-of-the-art transformer-based\napproaches on three benchmarks, obtaining 2.54%-5.88% absolute improvements in\nDice over previous models. Further qualitative experiments provide a more\ndetailed picture of the model's inner workings, shed light on the challenges in\nimproved transparency, and demonstrate that transfer learning can greatly\nimprove performance and reduce the size of medical image datasets in training,\nmaking CASTformer a strong starting point for downstream medical image analysis\ntasks.\n","authors":["Chenyu You","Ruihan Zhao","Fenglin Liu","Siyuan Dong","Sandeep Chinchali","Ufuk Topcu","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2201.10737v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07992v1","updated":"2022-12-15T17:44:31Z","published":"2022-12-15T17:44:31Z","title":"Alternating Objectives Generates Stronger PGD-Based Adversarial Attacks","summary":"  Designing powerful adversarial attacks is of paramount importance for the\nevaluation of $\\ell_p$-bounded adversarial defenses. Projected Gradient Descent\n(PGD) is one of the most effective and conceptually simple algorithms to\ngenerate such adversaries. The search space of PGD is dictated by the steepest\nascent directions of an objective. Despite the plethora of objective function\nchoices, there is no universally superior option and robustness overestimation\nmay arise from ill-suited objective selection. Driven by this observation, we\npostulate that the combination of different objectives through a simple loss\nalternating scheme renders PGD more robust towards design choices. We\nexperimentally verify this assertion on a synthetic-data example and by\nevaluating our proposed method across 25 different $\\ell_{\\infty}$-robust\nmodels and 3 datasets. The performance improvement is consistent, when compared\nto the single loss counterparts. In the CIFAR-10 dataset, our strongest\nadversarial attack outperforms all of the white-box components of AutoAttack\n(AA) ensemble, as well as the most powerful attacks existing on the literature,\nachieving state-of-the-art results in the computational budget of our study\n($T=100$, no restarts).\n","authors":["Nikolaos Antoniou","Efthymios Georgiou","Alexandros Potamianos"],"pdf_url":"https://arxiv.org/pdf/2212.07992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07983v1","updated":"2022-12-15T17:31:54Z","published":"2022-12-15T17:31:54Z","title":"Vision Transformers are Parameter-Efficient Audio-Visual Learners","summary":"  Vision transformers (ViTs) have achieved impressive results on various\ncomputer vision tasks in the last several years. In this work, we study the\ncapability of frozen ViTs, pretrained only on visual data, to generalize to\naudio-visual data without finetuning any of its original parameters. To do so,\nwe propose a latent audio-visual hybrid (LAVISH) adapter that adapts pretrained\nViTs to audio-visual tasks by injecting a small number of trainable parameters\ninto every layer of a frozen ViT. To efficiently fuse visual and audio cues,\nour LAVISH adapter uses a small set of latent tokens, which form an attention\nbottleneck, thus, eliminating the quadratic cost of standard cross-attention.\nCompared to the existing modality-specific audio-visual methods, our approach\nachieves competitive or even better performance on various audio-visual tasks\nwhile using fewer tunable parameters and without relying on costly audio\npretraining or external audio encoders. Our code is available at\nhttps://genjib.github.io/project_page/LAVISH/\n","authors":["Yan-Bo Lin","Yi-Lin Sung","Jie Lei","Mohit Bansal","Gedas Bertasius"],"pdf_url":"https://arxiv.org/pdf/2212.07983v1.pdf","comment":"project page: https://genjib.github.io/project_page/LAVISH/"},{"id":"http://arxiv.org/abs/2211.16359v3","updated":"2022-12-15T16:58:04Z","published":"2022-11-29T16:42:53Z","title":"POLCOVID: a multicenter multiclass chest X-ray database (Poland,\n  2020-2021)","summary":"  The outbreak of the SARS-CoV-2 pandemic has put healthcare systems worldwide\nto their limits, resulting in increased waiting time for diagnosis and required\nmedical assistance. With chest radiographs (CXR) being one of the most common\nCOVID-19 diagnosis methods, many artificial intelligence tools for image-based\nCOVID-19 detection have been developed, often trained on a small number of\nimages from COVID-19-positive patients. Thus, the need for high-quality and\nwell-annotated CXR image databases increased. This paper introduces POLCOVID\ndataset, containing chest X-ray (CXR) images of patients with COVID-19 or\nother-type pneumonia, and healthy individuals gathered from 15 Polish\nhospitals. The original radiographs are accompanied by the preprocessed images\nlimited to the lung area and the corresponding lung masks obtained with the\nsegmentation model. Moreover, the manually created lung masks are provided for\na part of POLCOVID dataset and the other four publicly available CXR image\ncollections. POLCOVID dataset can help in pneumonia or COVID-19 diagnosis,\nwhile the set of matched images and lung masks may serve for the development of\nlung segmentation solutions.\n","authors":["Aleksandra Suwalska","Joanna Tobiasz","Wojciech Prazuch","Marek Socha","Pawel Foszner","Damian Piotrowski","Katarzyna Gruszczynska","Magdalena Sliwinska","Jerzy Walecki","Tadeusz Popiela","Grzegorz Przybylski","Mateusz Nowak","Piotr Fiedor","Malgorzata Pawlowska","Robert Flisiak","Krzysztof Simon","Gabriela Zapolska","Barbara Gizycka","Edyta Szurowska","POLCOVID Study Group","Michal Marczyk","Andrzej Cieszanowski","Joanna Polanska"],"pdf_url":"https://arxiv.org/pdf/2211.16359v3.pdf","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2201.03644v2","updated":"2022-12-15T16:24:29Z","published":"2022-01-10T20:55:59Z","title":"3D Segmentation with Fully Trainable Gabor Kernels and Pearson's\n  Correlation Coefficient","summary":"  The convolutional layer and loss function are two fundamental components in\ndeep learning. Because of the success of conventional deep learning kernels,\nthe less versatile Gabor kernels become less popular despite the fact that they\ncan provide abundant features at different frequencies, orientations, and\nscales with much fewer parameters. For existing loss functions for multi-class\nimage segmentation, there is usually a tradeoff among accuracy, robustness to\nhyperparameters, and manual weight selections for combining different losses.\nTherefore, to gain the benefits of using Gabor kernels while keeping the\nadvantage of automatic feature generation in deep learning, we propose a fully\ntrainable Gabor-based convolutional layer where all Gabor parameters are\ntrainable through backpropagation. Furthermore, we propose a loss function\nbased on the Pearson's correlation coefficient, which is accurate, robust to\nlearning rates, and does not require manual weight selections. Experiments on\n43 3D brain magnetic resonance images with 19 anatomical structures show that,\nusing the proposed loss function with a proper combination of conventional and\nGabor-based kernels, we can train a network with only 1.6 million parameters to\nachieve an average Dice coefficient of 83%. This size is 44 times smaller than\nthe original V-Net which has 71 million parameters. This paper demonstrates the\npotentials of using learnable parametric kernels in deep learning for 3D\nsegmentation.\n","authors":["Ken C. L. Wong","Mehdi Moradi"],"pdf_url":"https://arxiv.org/pdf/2201.03644v2.pdf","comment":"This paper was accepted by the International Workshop on Machine\n  Learning in Medical Imaging (MLMI 2022)"},{"id":"http://arxiv.org/abs/2212.07923v1","updated":"2022-12-15T15:55:44Z","published":"2022-12-15T15:55:44Z","title":"The Effects of Character-Level Data Augmentation on Style-Based Dating\n  of Historical Manuscripts","summary":"  Identifying the production dates of historical manuscripts is one of the main\ngoals for paleographers when studying ancient documents. Automatized methods\ncan provide paleographers with objective tools to estimate dates more\naccurately. Previously, statistical features have been used to date digitized\nhistorical manuscripts based on the hypothesis that handwriting styles change\nover periods. However, the sparse availability of such documents poses a\nchallenge in obtaining robust systems. Hence, the research of this article\nexplores the influence of data augmentation on the dating of historical\nmanuscripts. Linear Support Vector Machines were trained with k-fold\ncross-validation on textural and grapheme-based features extracted from\nhistorical manuscripts of different collections, including the Medieval\nPaleographical Scale, early Aramaic manuscripts, and the Dead Sea Scrolls.\nResults show that training models with augmented data improve the performance\nof historical manuscripts dating by 1% - 3% in cumulative scores. Additionally,\nthis indicates further enhancement possibilities by considering models specific\nto the features and the documents' scripts.\n","authors":["Lisa Koopmans","Maruf A. Dhali","Lambert Schomaker"],"pdf_url":"https://arxiv.org/pdf/2212.07923v1.pdf","comment":"Accepted after the peer-review process for ICPRAM 2023; scheduled to\n  be presented on 22 February 2023"},{"id":"http://arxiv.org/abs/2212.07911v1","updated":"2022-12-15T15:43:42Z","published":"2022-12-15T15:43:42Z","title":"Urban Scene Semantic Segmentation with Low-Cost Coarse Annotation","summary":"  For best performance, today's semantic segmentation methods use large and\ncarefully labeled datasets, requiring expensive annotation budgets. In this\nwork, we show that coarse annotation is a low-cost but highly effective\nalternative for training semantic segmentation models. Considering the urban\nscene segmentation scenario, we leverage cheap coarse annotations for\nreal-world captured data, as well as synthetic data to train our model and show\ncompetitive performance compared with finely annotated real-world data.\nSpecifically, we propose a coarse-to-fine self-training framework that\ngenerates pseudo labels for unlabeled regions of the coarsely annotated data,\nusing synthetic data to improve predictions around the boundaries between\nsemantic classes, and using cross-domain data augmentation to increase\ndiversity. Our extensive experimental results on Cityscapes and BDD100k\ndatasets demonstrate that our method achieves a significantly better\nperformance vs annotation cost tradeoff, yielding a comparable performance to\nfully annotated data with only a small fraction of the annotation budget. Also,\nwhen used as pretraining, our framework performs better compared to the\nstandard fully supervised setting.\n","authors":["Anurag Das","Yongqin Xian","Yang He","Zeynep Akata","Bernt Schiele"],"pdf_url":"https://arxiv.org/pdf/2212.07911v1.pdf","comment":"Accepted at WACV 2023"},{"id":"http://arxiv.org/abs/2212.07907v1","updated":"2022-12-15T15:39:55Z","published":"2022-12-15T15:39:55Z","title":"Automatic vehicle trajectory data reconstruction at scale","summary":"  Vehicle trajectory data has received increasing research attention over the\npast decades. With the technological sensing improvements such as\nhigh-resolution video cameras, in-vehicle radars and lidars, abundant\nindividual and contextual traffic data is now available. However, though the\ndata quantity is massive, it is by itself of limited utility for traffic\nresearch because of noise and systematic sensing errors, thus necessitates\nproper processing to ensure data quality. We draw particular attention to\nextracting high-resolution vehicle trajectory data from video cameras as\ntraffic monitoring cameras are becoming increasingly ubiquitous. We explore\nmethods for automatic trajectory data reconciliation, given \"raw\" vehicle\ndetection and tracking information from automatic video processing algorithms.\nWe propose a pipeline including a) an online data association algorithm to\nmatch fragments that are associated to the same object (vehicle), which is\nformulated as a min-cost network flow problem of a graph, and b) a trajectory\nreconciliation method formulated as a quadratic program to enhance raw\ndetection data. The pipeline leverages vehicle dynamics and physical\nconstraints to associate tracked objects when they become fragmented, remove\nmeasurement noise on trajectories and impute missing data due to\nfragmentations. The accuracy is benchmarked on a sample of manually-labeled\ndata, which shows that the reconciled trajectories improve the accuracy on all\nthe tested input data for a wide range of measures. An online version of the\nreconciliation pipeline is implemented and will be applied in a continuous\nvideo processing system running on a camera network covering a 4-mile stretch\nof Interstate-24 near Nashville, Tennessee.\n","authors":["Yanbing Wang","Derek Gloudemans","Zi Nean Teoh","Lisa Liu","Gergely Zachár","William Barbour","Daniel Work"],"pdf_url":"https://arxiv.org/pdf/2212.07907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07900v1","updated":"2022-12-15T15:35:25Z","published":"2022-12-15T15:35:25Z","title":"EVAL: Explainable Video Anomaly Localization","summary":"  We develop a novel framework for single-scene video anomaly localization that\nallows for human-understandable reasons for the decisions the system makes. We\nfirst learn general representations of objects and their motions (using deep\nnetworks) and then use these representations to build a high-level,\nlocation-dependent model of any particular scene. This model can be used to\ndetect anomalies in new videos of the same scene. Importantly, our approach is\nexplainable - our high-level appearance and motion features can provide\nhuman-understandable reasons for why any part of a video is classified as\nnormal or anomalous. We conduct experiments on standard video anomaly detection\ndatasets (Street Scene, CUHK Avenue, ShanghaiTech and UCSD Ped1, Ped2) and show\nsignificant improvements over the previous state-of-the-art.\n","authors":["Ashish Singh","Michael J. Jones","Erik Learned-Miller"],"pdf_url":"https://arxiv.org/pdf/2212.07900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10535v2","updated":"2022-12-15T15:25:28Z","published":"2022-06-21T17:08:23Z","title":"EpiGRAF: Rethinking training of 3D GANs","summary":"  A very recent trend in generative modeling is building 3D-aware generators\nfrom 2D image collections. To induce the 3D bias, such models typically rely on\nvolumetric rendering, which is expensive to employ at high resolutions. During\nthe past months, there appeared more than 10 works that address this scaling\nissue by training a separate 2D decoder to upsample a low-resolution image (or\na feature tensor) produced from a pure 3D generator. But this solution comes at\na cost: not only does it break multi-view consistency (i.e. shape and texture\nchange when the camera moves), but it also learns the geometry in a low\nfidelity. In this work, we show that it is possible to obtain a high-resolution\n3D generator with SotA image quality by following a completely different route\nof simply training the model patch-wise. We revisit and improve this\noptimization scheme in two ways. First, we design a location- and scale-aware\ndiscriminator to work on patches of different proportions and spatial\npositions. Second, we modify the patch sampling strategy based on an annealed\nbeta distribution to stabilize training and accelerate the convergence. The\nresulted model, named EpiGRAF, is an efficient, high-resolution, pure 3D\ngenerator, and we test it on four datasets (two introduced in this work) at\n$256^2$ and $512^2$ resolutions. It obtains state-of-the-art image quality,\nhigh-fidelity geometry and trains ${\\approx} 2.5 \\times$ faster than the\nupsampler-based counterparts. Project website:\nhttps://universome.github.io/epigraf.\n","authors":["Ivan Skorokhodov","Sergey Tulyakov","Yiqun Wang","Peter Wonka"],"pdf_url":"https://arxiv.org/pdf/2206.10535v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.07891v1","updated":"2022-12-15T15:20:58Z","published":"2022-12-15T15:20:58Z","title":"Emergent Behaviors in Multi-Agent Target Acquisition","summary":"  Only limited studies and superficial evaluations are available on agents'\nbehaviors and roles within a Multi-Agent System (MAS). We simulate a MAS using\nReinforcement Learning (RL) in a pursuit-evasion (a.k.a predator-prey pursuit)\ngame, which shares task goals with target acquisition, and we create different\nadversarial scenarios by replacing RL-trained pursuers' policies with two\ndistinct (non-RL) analytical strategies. Using heatmaps of agents' positions\n(state-space variable) over time, we are able to categorize an RL-trained\nevader's behaviors. The novelty of our approach entails the creation of an\ninfluential feature set that reveals underlying data regularities, which allow\nus to classify an agent's behavior. This classification may aid in catching the\n(enemy) targets by enabling us to identify and predict their behaviors, and\nwhen extended to pursuers, this approach towards identifying teammates'\nbehavior may allow agents to coordinate more effectively.\n","authors":["Piyush K. Sharma","Erin Zaroukian","Derrik E. Asher","Bryson Howell"],"pdf_url":"https://arxiv.org/pdf/2212.07891v1.pdf","comment":"This article appeared in the news at:\n  https://www.army.mil/article/258408/u_s_army_scientists_invent_a_method_to_characterize_ai_behavior"},{"id":"http://arxiv.org/abs/2212.07890v1","updated":"2022-12-15T15:19:09Z","published":"2022-12-15T15:19:09Z","title":"Full Contextual Attention for Multi-resolution Transformers in Semantic\n  Segmentation","summary":"  Transformers have proved to be very effective for visual recognition tasks.\nIn particular, vision transformers construct compressed global representations\nthrough self-attention and learnable class tokens. Multi-resolution\ntransformers have shown recent successes in semantic segmentation but can only\ncapture local interactions in high-resolution feature maps. This paper extends\nthe notion of global tokens to build GLobal Attention Multi-resolution (GLAM)\ntransformers. GLAM is a generic module that can be integrated into most\nexisting transformer backbones. GLAM includes learnable global tokens, which\nunlike previous methods can model interactions between all image regions, and\nextracts powerful representations during training. Extensive experiments show\nthat GLAM-Swin or GLAM-Swin-UNet exhibit substantially better performances than\ntheir vanilla counterparts on ADE20K and Cityscapes. Moreover, GLAM can be used\nto segment large 3D medical images, and GLAM-nnFormer achieves new\nstate-of-the-art performance on the BCV dataset.\n","authors":["Loic Themyr","Clement Rambour","Nicolas Thome","Toby Collins","Alexandre Hostettler"],"pdf_url":"https://arxiv.org/pdf/2212.07890v1.pdf","comment":"Winter Conference on Applications of Computer Vision (WACV 2023)"},{"id":"http://arxiv.org/abs/2212.07886v1","updated":"2022-12-15T15:11:38Z","published":"2022-12-15T15:11:38Z","title":"Meta-Learned Kernel For Blind Super-Resolution Kernel Estimation","summary":"  Recent image degradation estimation methods have enabled single-image\nsuper-resolution (SR) approaches to better upsample real-world images. Among\nthese methods, explicit kernel estimation approaches have demonstrated\nunprecedented performance at handling unknown degradations. Nonetheless, a\nnumber of limitations constrain their efficacy when used by downstream SR\nmodels. Specifically, this family of methods yields i) excessive inference time\ndue to long per-image adaptation times and ii) inferior image fidelity due to\nkernel mismatch. In this work, we introduce a learning-to-learn approach that\nmeta-learns from the information contained in a distribution of images, thereby\nenabling significantly faster adaptation to new images with substantially\nimproved performance in both kernel estimation and image fidelity.\nSpecifically, we meta-train a kernel-generating GAN, named MetaKernelGAN, on a\nrange of tasks, such that when a new image is presented, the generator starts\nfrom an informed kernel estimate and the discriminator starts with a strong\ncapability to distinguish between patch distributions. Compared with\nstate-of-the-art methods, our experiments show that MetaKernelGAN better\nestimates the magnitude and covariance of the kernel, leading to\nstate-of-the-art blind SR results within a similar computational regime when\ncombined with a non-blind SR model. Through supervised learning of an\nunsupervised learner, our method maintains the generalizability of the\nunsupervised learner, improves the optimization stability of kernel estimation,\nand hence image adaptation, and leads to a faster inference with a speedup\nbetween 14.24 to 102.1x over existing methods.\n","authors":["Royson Lee","Rui Li","Stylianos I. Venieris","Timothy Hospedales","Ferenc Huszár","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2212.07886v1.pdf","comment":"Preprint: under review"},{"id":"http://arxiv.org/abs/2212.07867v1","updated":"2022-12-15T14:34:12Z","published":"2022-12-15T14:34:12Z","title":"Localizing Scan Targets from Human Pose for Autonomous Lung Ultrasound\n  Imaging","summary":"  Ultrasound is progressing toward becoming an affordable and versatile\nsolution to medical imaging. With the advent of COVID-19 global pandemic, there\nis a need to fully automate ultrasound imaging as it requires trained operators\nin close proximity to patients for long period of time. In this work, we\ninvestigate the important yet seldom-studied problem of scan target\nlocalization, under the setting of lung ultrasound imaging. We propose a purely\nvision-based, data driven method that incorporates learning-based computer\nvision techniques. We combine a human pose estimation model with a specially\ndesigned regression model to predict the lung ultrasound scan targets, and\ndeploy multiview stereo vision to enhance the consistency of 3D target\nlocalization. While related works mostly focus on phantom experiments, we\ncollect data from 30 human subjects for testing. Our method attains an accuracy\nlevel of 15.52 (9.47) mm for probe positioning and 4.32 (3.69){\\deg} for probe\norientation, with a success rate above 80% under an error threshold of 25mm for\nall scan targets. Moreover, our approach can serve as a general solution to\nother types of ultrasound modalities. The code for implementation has been\nreleased.\n","authors":["Jianzhi Long","Jicang Cai","Abdullah Al-Battal","Shiwei Jin","Jing Zhang","Dacheng Tao","Truong Nguyen"],"pdf_url":"https://arxiv.org/pdf/2212.07867v1.pdf","comment":"First arxiv submission"},{"id":"http://arxiv.org/abs/2212.07855v1","updated":"2022-12-15T14:22:49Z","published":"2022-12-15T14:22:49Z","title":"QueryPose: Sparse Multi-Person Pose Regression via Spatial-Aware\n  Part-Level Query","summary":"  We propose a sparse end-to-end multi-person pose regression framework, termed\nQueryPose, which can directly predict multi-person keypoint sequences from the\ninput image. The existing end-to-end methods rely on dense representations to\npreserve the spatial detail and structure for precise keypoint localization.\nHowever, the dense paradigm introduces complex and redundant post-processes\nduring inference. In our framework, each human instance is encoded by several\nlearnable spatial-aware part-level queries associated with an instance-level\nquery. First, we propose the Spatial Part Embedding Generation Module (SPEGM)\nthat considers the local spatial attention mechanism to generate several\nspatial-sensitive part embeddings, which contain spatial details and structural\ninformation for enhancing the part-level queries. Second, we introduce the\nSelective Iteration Module (SIM) to adaptively update the sparse part-level\nqueries via the generated spatial-sensitive part embeddings stage-by-stage.\nBased on the two proposed modules, the part-level queries are able to fully\nencode the spatial details and structural information for precise keypoint\nregression. With the bipartite matching, QueryPose avoids the hand-designed\npost-processes and surpasses the existing dense end-to-end methods with 73.6 AP\non MS COCO mini-val set and 72.7 AP on CrowdPose test set. Code is available at\nhttps://github.com/buptxyb666/QueryPose.\n","authors":["Yabo Xiao","Kai Su","Xiaojuan Wang","Dongdong Yu","Lei Jin","Mingshu He","Zehuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2212.07855v1.pdf","comment":"Published on NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.07849v1","updated":"2022-12-15T14:18:47Z","published":"2022-12-15T14:18:47Z","title":"DETR4D: Direct Multi-View 3D Object Detection with Sparse Attention","summary":"  3D object detection with surround-view images is an essential task for\nautonomous driving. In this work, we propose DETR4D, a Transformer-based\nframework that explores sparse attention and direct feature query for 3D object\ndetection in multi-view images. We design a novel projective cross-attention\nmechanism for query-image interaction to address the limitations of existing\nmethods in terms of geometric cue exploitation and information loss for\ncross-view objects. In addition, we introduce a heatmap generation technique\nthat bridges 3D and 2D spaces efficiently via query initialization.\nFurthermore, unlike the common practice of fusing intermediate spatial features\nfor temporal aggregation, we provide a new perspective by introducing a novel\nhybrid approach that performs cross-frame fusion over past object queries and\nimage features, enabling efficient and robust modeling of temporal information.\nExtensive experiments on the nuScenes dataset demonstrate the effectiveness and\nefficiency of the proposed DETR4D.\n","authors":["Zhipeng Luo","Changqing Zhou","Gongjie Zhang","Shijian Lu"],"pdf_url":"https://arxiv.org/pdf/2212.07849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.00842v2","updated":"2022-12-15T14:01:12Z","published":"2022-12-01T20:00:00Z","title":"3D-LDM: Neural Implicit 3D Shape Generation with Latent Diffusion Models","summary":"  Diffusion models have shown great promise for image generation, beating GANs\nin terms of generation diversity, with comparable image quality. However, their\napplication to 3D shapes has been limited to point or voxel representations\nthat can in practice not accurately represent a 3D surface. We propose a\ndiffusion model for neural implicit representations of 3D shapes that operates\nin the latent space of an auto-decoder. This allows us to generate diverse and\nhigh quality 3D surfaces. We additionally show that we can condition our model\non images or text to enable image-to-3D generation and text-to-3D generation\nusing CLIP embeddings. Furthermore, adding noise to the latent codes of\nexisting shapes allows us to explore shape variations.\n","authors":["Gimin Nam","Mariem Khlifi","Andrew Rodriguez","Alberto Tono","Linqi Zhou","Paul Guerrero"],"pdf_url":"https://arxiv.org/pdf/2212.00842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07839v1","updated":"2022-12-15T13:52:03Z","published":"2022-12-15T13:52:03Z","title":"TeTIm-Eval: a novel curated evaluation data set for comparing\n  text-to-image models","summary":"  Evaluating and comparing text-to-image models is a challenging problem.\nSignificant advances in the field have recently been made, piquing interest of\nvarious industrial sectors. As a consequence, a gold standard in the field\nshould cover a variety of tasks and application contexts. In this paper a novel\nevaluation approach is experimented, on the basis of: (i) a curated data set,\nmade by high-quality royalty-free image-text pairs, divided into ten\ncategories; (ii) a quantitative metric, the CLIP-score, (iii) a human\nevaluation task to distinguish, for a given text, the real and the generated\nimages. The proposed method has been applied to the most recent models, i.e.,\nDALLE2, Latent Diffusion, Stable Diffusion, GLIDE and Craiyon. Early\nexperimental results show that the accuracy of the human judgement is fully\ncoherent with the CLIP-score. The dataset has been made available to the\npublic.\n","authors":["Federico A. Galatolo","Mario G. C. A. Cimino","Edoardo Cogotti"],"pdf_url":"https://arxiv.org/pdf/2212.07839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07834v1","updated":"2022-12-15T13:43:11Z","published":"2022-12-15T13:43:11Z","title":"Unsupervised Object Localization: Observing the Background to Discover\n  Objects","summary":"  Recent advances in self-supervised visual representation learning have paved\nthe way for unsupervised methods tackling tasks such as object discovery and\ninstance segmentation. However, discovering objects in an image with no\nsupervision is a very hard task; what are the desired objects, when to separate\nthem into parts, how many are there, and of what classes? The answers to these\nquestions depend on the tasks and datasets of evaluation. In this work, we take\na different approach and propose to look for the background instead. This way,\nthe salient objects emerge as a by-product without any strong assumption on\nwhat an object should be. We propose FOUND, a simple model made of a single\n$conv1\\times1$ initialized with coarse background masks extracted from\nself-supervised patch-based representations. After fast training and refining\nthese seed masks, the model reaches state-of-the-art results on unsupervised\nsaliency detection and object discovery benchmarks. Moreover, we show that our\napproach yields good results in the unsupervised semantic segmentation\nretrieval task. The code to reproduce our results is available at\nhttps://github.com/valeoai/FOUND.\n","authors":["Oriane Siméoni","Chloé Sekkat","Gilles Puy","Antonin Vobecky","Éloi Zablocki","Patrick Pérez"],"pdf_url":"https://arxiv.org/pdf/2212.07834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.13279v4","updated":"2022-12-15T12:58:41Z","published":"2022-01-31T14:42:35Z","title":"UQGAN: A Unified Model for Uncertainty Quantification of Deep\n  Classifiers trained via Conditional GANs","summary":"  We present an approach to quantifying both aleatoric and epistemic\nuncertainty for deep neural networks in image classification, based on\ngenerative adversarial networks (GANs). While most works in the literature that\nuse GANs to generate out-of-distribution (OoD) examples only focus on the\nevaluation of OoD detection, we present a GAN based approach to learn a\nclassifier that produces proper uncertainties for OoD examples as well as for\nfalse positives (FPs). Instead of shielding the entire in-distribution data\nwith GAN generated OoD examples which is state-of-the-art, we shield each class\nseparately with out-of-class examples generated by a conditional GAN and\ncomplement this with a one-vs-all image classifier. In our experiments, in\nparticular on CIFAR10, CIFAR100 and Tiny ImageNet, we improve over the OoD\ndetection and FP detection performance of state-of-the-art GAN-training based\nclassifiers. Furthermore, we also find that the generated GAN examples do not\nsignificantly affect the calibration error of our classifier and result in a\nsignificant gain in model accuracy.\n","authors":["Philipp Oberdiek","Gernot A. Fink","Matthias Rottmann"],"pdf_url":"https://arxiv.org/pdf/2201.13279v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07778v1","updated":"2022-12-15T12:54:21Z","published":"2022-12-15T12:54:21Z","title":"Efficient Visual Computing with Camera RAW Snapshots","summary":"  Conventional cameras capture image irradiance on a sensor and convert it to\nRGB images using an image signal processor (ISP). The images can then be used\nfor photography or visual computing tasks in a variety of applications, such as\npublic safety surveillance and autonomous driving. One can argue that since RAW\nimages contain all the captured information, the conversion of RAW to RGB using\nan ISP is not necessary for visual computing. In this paper, we propose a novel\n$\\rho$-Vision framework to perform high-level semantic understanding and\nlow-level compression using RAW images without the ISP subsystem used for\ndecades. Considering the scarcity of available RAW image datasets, we first\ndevelop an unpaired CycleR2R network based on unsupervised CycleGAN to train\nmodular unrolled ISP and inverse ISP (invISP) models using unpaired RAW and RGB\nimages. We can then flexibly generate simulated RAW images (simRAW) using any\nexisting RGB image dataset and finetune different models originally trained for\nthe RGB domain to process real-world camera RAW images. We demonstrate object\ndetection and image compression capabilities in RAW-domain using RAW-domain\nYOLOv3 and RAW image compressor (RIC) on snapshots from various cameras.\nQuantitative results reveal that RAW-domain task inference provides better\ndetection accuracy and compression compared to RGB-domain processing.\nFurthermore, the proposed \\r{ho}-Vision generalizes across various camera\nsensors and different task-specific models. Additional advantages of the\nproposed $\\rho$-Vision that eliminates the ISP are the potential reductions in\ncomputations and processing times.\n","authors":["Zhihao Li","Ming Lu","Xu Zhang","Xin Feng","M. Salman Asif","Zhan Ma"],"pdf_url":"https://arxiv.org/pdf/2212.07778v1.pdf","comment":"home page: https://njuvision.github.io/rho-vision"},{"id":"http://arxiv.org/abs/2212.07776v1","updated":"2022-12-15T12:53:26Z","published":"2022-12-15T12:53:26Z","title":"Enhancing Indic Handwritten Text Recognition Using Global Semantic\n  Information","summary":"  Handwritten Text Recognition (HTR) is more interesting and challenging than\nprinted text due to uneven variations in the handwriting style of the writers,\ncontent, and time. HTR becomes more challenging for the Indic languages because\nof (i) multiple characters combined to form conjuncts which increase the number\nof characters of respective languages, and (ii) near to 100 unique basic\nUnicode characters in each Indic script. Recently, many recognition methods\nbased on the encoder-decoder framework have been proposed to handle such\nproblems. They still face many challenges, such as image blur and incomplete\ncharacters due to varying writing styles and ink density. We argue that most\nencoder-decoder methods are based on local visual features without explicit\nglobal semantic information.\n  In this work, we enhance the performance of Indic handwritten text\nrecognizers using global semantic information. We use a semantic module in an\nencoder-decoder framework for extracting global semantic information to\nrecognize the Indic handwritten texts. The semantic information is used in both\nthe encoder for supervision and the decoder for initialization. The semantic\ninformation is predicted from the word embedding of a pre-trained language\nmodel. Extensive experiments demonstrate that the proposed framework achieves\nstate-of-the-art results on handwritten texts of ten Indic languages.\n","authors":["Ajoy Mondal","C. V. Jawahar"],"pdf_url":"https://arxiv.org/pdf/2212.07776v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07768v1","updated":"2022-12-15T12:46:31Z","published":"2022-12-15T12:46:31Z","title":"A scalable framework for annotating photovoltaic cell defects in\n  electroluminescence images","summary":"  The correct functioning of photovoltaic (PV) cells is critical to ensuring\nthe optimal performance of a solar plant. Anomaly detection techniques for PV\ncells can result in significant cost savings in operation and maintenance\n(O&M). Recent research has focused on deep learning techniques for\nautomatically detecting anomalies in Electroluminescence (EL) images. Automated\nanomaly annotations can improve current O&M methodologies and help develop\ndecision-making systems to extend the life-cycle of the PV cells and predict\nfailures. This paper addresses the lack of anomaly segmentation annotations in\nthe literature by proposing a combination of state-of-the-art data-driven\ntechniques to create a Golden Standard benchmark. The proposed method stands\nout for (1) its adaptability to new PV cell types, (2) cost-efficient\nfine-tuning, and (3) leverage public datasets to generate advanced annotations.\nThe methodology has been validated in the annotation of a widely used dataset,\nobtaining a reduction of the annotation cost by 60%.\n","authors":["Urtzi Otamendi","Inigo Martinez","Igor G. Olaizola","Marco Quartulli"],"pdf_url":"https://arxiv.org/pdf/2212.07768v1.pdf","comment":"10 pages, 10 figures, 1 table, accepted at IEEE Transactions on\n  Industrial Informatics"},{"id":"http://arxiv.org/abs/2206.13500v2","updated":"2022-12-15T12:37:36Z","published":"2022-06-27T17:59:45Z","title":"Neural Neural Textures Make Sim2Real Consistent","summary":"  Unpaired image translation algorithms can be used for sim2real tasks, but\nmany fail to generate temporally consistent results. We present a new approach\nthat combines differentiable rendering with image translation to achieve\ntemporal consistency over indefinite timescales, using surface consistency\nlosses and \\emph{neural neural textures}. We call this algorithm TRITON\n(Texture Recovering Image Translation Network): an unsupervised, end-to-end,\nstateless sim2real algorithm that leverages the underlying 3D geometry of input\nscenes by generating realistic-looking learnable neural textures. By settling\non a particular texture for the objects in a scene, we ensure consistency\nbetween frames statelessly. Unlike previous algorithms, TRITON is not limited\nto camera movements -- it can handle the movement of objects as well, making it\nuseful for downstream tasks such as robotic manipulation.\n","authors":["Ryan Burgert","Jinghuan Shang","Xiang Li","Michael Ryoo"],"pdf_url":"https://arxiv.org/pdf/2206.13500v2.pdf","comment":"9 pages, 10 figures (without references or appendix); 16 pages, 16\n  figures (with appendix)"},{"id":"http://arxiv.org/abs/2212.07766v1","updated":"2022-12-15T12:36:49Z","published":"2022-12-15T12:36:49Z","title":"DeepLSD: Line Segment Detection and Refinement with Deep Image Gradients","summary":"  Line segments are ubiquitous in our human-made world and are increasingly\nused in vision tasks. They are complementary to feature points thanks to their\nspatial extent and the structural information they provide. Traditional line\ndetectors based on the image gradient are extremely fast and accurate, but lack\nrobustness in noisy images and challenging conditions. Their learned\ncounterparts are more repeatable and can handle challenging images, but at the\ncost of a lower accuracy and a bias towards wireframe lines. We propose to\ncombine traditional and learned approaches to get the best of both worlds: an\naccurate and robust line detector that can be trained in the wild without\nground truth lines. Our new line segment detector, DeepLSD, processes images\nwith a deep network to generate a line attraction field, before converting it\nto a surrogate image gradient magnitude and angle, which is then fed to any\nexisting handcrafted line detector. Additionally, we propose a new optimization\ntool to refine line segments based on the attraction field and vanishing\npoints. This refinement improves the accuracy of current deep detectors by a\nlarge margin. We demonstrate the performance of our method on low-level line\ndetection metrics, as well as on several downstream tasks using multiple\nchallenging datasets. The source code and models are available at\nhttps://github.com/cvg/DeepLSD.\n","authors":["Rémi Pautrat","Daniel Barath","Viktor Larsson","Martin R. Oswald","Marc Pollefeys"],"pdf_url":"https://arxiv.org/pdf/2212.07766v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2207.09280v3","updated":"2022-12-15T12:20:33Z","published":"2022-07-19T13:49:30Z","title":"Exploiting Inter-Sample Affinity for Knowability-Aware Universal Domain\n  Adaptation","summary":"  Universal domain adaptation (UDA) aims to transfer the knowledge of common\nclasses from source domain to target domain without any prior knowledge on the\nlabel set, which requires to distinguish the unknown samples from the known\nones in the target domain. Recent methods preferred to increase the\ninter-sample affinity within a known class, while they ignored the inter-sample\naffinity between the unknown samples and the known ones. This paper reveals\nthat exploiting such inter-sample affinity can significantly improve the\nperformance of UDA and proposes a knowability-aware UDA framework based on it.\nFirst, we estimate the knowability of each target sample by searching its\nneighboring samples in the source domain. Then, we propose an auto-thresholding\nscheme applied to the estimated knowability to determine whether a target\nsample is unknown or known. Next, in addition to increasing the inter-sample\naffinity within each known class like previous methods, we design new losses\nbased on the estimated knowability to reduce the inter-sample affinity between\nthe unknown target samples and the known ones. Finally, experiments on four\npublic datasets demonstrate that our method significantly outperforms existing\nstate-of-the-art methods.\n","authors":["Yifan Wang","Lin Zhang","Ran Song","Lin Ma","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2207.09280v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07754v1","updated":"2022-12-15T12:18:13Z","published":"2022-12-15T12:18:13Z","title":"Event-based Visual Tracking in Dynamic Environments","summary":"  Visual object tracking under challenging conditions of motion and light can\nbe hindered by the capabilities of conventional cameras, prone to producing\nimages with motion blur. Event cameras are novel sensors suited to robustly\nperform vision tasks under these conditions. However, due to the nature of\ntheir output, applying them to object detection and tracking is non-trivial. In\nthis work, we propose a framework to take advantage of both event cameras and\noff-the-shelf deep learning for object tracking. We show that reconstructing\nevent data into intensity frames improves the tracking performance in\nconditions under which conventional cameras fail to provide acceptable results.\n","authors":["Irene Perez-Salesa","Rodrigo Aldana-Lopez","Carlos Sagues"],"pdf_url":"https://arxiv.org/pdf/2212.07754v1.pdf","comment":"This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in ROBOT2022: Fifth Iberian Robotics Conference"},{"id":"http://arxiv.org/abs/2212.07751v1","updated":"2022-12-15T12:09:02Z","published":"2022-12-15T12:09:02Z","title":"Combating Uncertainty and Class Imbalance in Facial Expression\n  Recognition","summary":"  Recognition of facial expression is a challenge when it comes to computer\nvision. The primary reasons are class imbalance due to data collection and\nuncertainty due to inherent noise such as fuzzy facial expressions and\ninconsistent labels. However, current research has focused either on the\nproblem of class imbalance or on the problem of uncertainty, ignoring the\nintersection of how to address these two problems. Therefore, in this paper, we\npropose a framework based on Resnet and Attention to solve the above problems.\nWe design weight for each class. Through the penalty mechanism, our model will\npay more attention to the learning of small samples during training, and the\nresulting decrease in model accuracy can be improved by a Convolutional Block\nAttention Module (CBAM). Meanwhile, our backbone network will also learn an\nuncertain feature for each sample. By mixing uncertain features between\nsamples, the model can better learn those features that can be used for\nclassification, thus suppressing uncertainty. Experiments show that our method\nsurpasses most basic methods in terms of accuracy on facial expression data\nsets (e.g., AffectNet, RAF-DB), and it also solves the problem of class\nimbalance well.\n","authors":["Jiaxiang Fan","Jian Zhou","Xiaoyu Deng","Huabin Wang","Liang Tao","Hon Keung Kwan"],"pdf_url":"https://arxiv.org/pdf/2212.07751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.11582v3","updated":"2022-12-15T11:18:41Z","published":"2022-10-20T20:51:48Z","title":"Deep Learning for Diagonal Earlobe Crease Detection","summary":"  An article published on Medical News Today in June 2022 presented a\nfundamental question in its title: Can an earlobe crease predict heart attacks?\nThe author explained that end arteries supply the heart and ears. In other\nwords, if they lose blood supply, no other arteries can take over, resulting in\ntissue damage. Consequently, some earlobes have a diagonal crease, line, or\ndeep fold that resembles a wrinkle. In this paper, we take a step toward\ndetecting this specific marker, commonly known as DELC or Frank's Sign. For\nthis reason, we have made the first DELC dataset available to the public. In\naddition, we have investigated the performance of numerous cutting-edge\nbackbones on annotated photos. Experimentally, we demonstrate that it is\npossible to solve this challenge by combining pre-trained encoders with a\ncustomized classifier to achieve 97.7% accuracy. Moreover, we have analyzed the\nbackbone trade-off between performance and size, estimating MobileNet as the\nmost promising encoder.\n","authors":["Sara L. Almonacid-Uribe","Oliverio J. Santana","Daniel Hernández-Sosa","David Freire-Obregón"],"pdf_url":"https://arxiv.org/pdf/2210.11582v3.pdf","comment":"Accepted at 12th International Conference on Pattern Recognition\n  Applications (ICPRAM 2023)"},{"id":"http://arxiv.org/abs/2204.02810v4","updated":"2022-12-15T11:17:07Z","published":"2022-04-06T13:22:24Z","title":"Expression-preserving face frontalization improves visually assisted\n  speech processing","summary":"  Face frontalization consists of synthesizing a frontally-viewed face from an\narbitrarily-viewed one. The main contribution of this paper is a frontalization\nmethodology that preserves non-rigid facial deformations in order to boost the\nperformance of visually assisted speech communication. The method alternates\nbetween the estimation of (i)~the rigid transformation (scale, rotation, and\ntranslation) and (ii)~the non-rigid deformation between an arbitrarily-viewed\nface and a face model. The method has two important merits: it can deal with\nnon-Gaussian errors in the data and it incorporates a dynamical face\ndeformation model. For that purpose, we use the generalized Student\nt-distribution in combination with a linear dynamic system in order to account\nfor both rigid head motions and time-varying facial deformations caused by\nspeech production. We propose to use the zero-mean normalized cross-correlation\n(ZNCC) score to evaluate the ability of the method to preserve facial\nexpressions. The method is thoroughly evaluated and compared with several state\nof the art methods, either based on traditional geometric models or on deep\nlearning. Moreover, we show that the method, when incorporated into deep\nlearning pipelines, namely lip reading and speech enhancement, improves word\nrecognition and speech intelligibilty scores by a considerable margin.\nSupplemental material is accessible at\nhttps://team.inria.fr/robotlearn/research/facefrontalization/\n","authors":["Zhiqi Kang","Mostafa Sadeghi","Radu Horaud","Xavier Alameda-Pineda"],"pdf_url":"https://arxiv.org/pdf/2204.02810v4.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.00538"},{"id":"http://arxiv.org/abs/2212.07729v1","updated":"2022-12-15T11:15:14Z","published":"2022-12-15T11:15:14Z","title":"HUM3DIL: Semi-supervised Multi-modal 3D Human Pose Estimation for\n  Autonomous Driving","summary":"  Autonomous driving is an exciting new industry, posing important research\nquestions. Within the perception module, 3D human pose estimation is an\nemerging technology, which can enable the autonomous vehicle to perceive and\nunderstand the subtle and complex behaviors of pedestrians. While hardware\nsystems and sensors have dramatically improved over the decades -- with cars\npotentially boasting complex LiDAR and vision systems and with a growing\nexpansion of the available body of dedicated datasets for this newly available\ninformation -- not much work has been done to harness these novel signals for\nthe core problem of 3D human pose estimation. Our method, which we coin HUM3DIL\n(HUMan 3D from Images and LiDAR), efficiently makes use of these complementary\nsignals, in a semi-supervised fashion and outperforms existing methods with a\nlarge margin. It is a fast and compact model for onboard deployment.\nSpecifically, we embed LiDAR points into pixel-aligned multi-modal features,\nwhich we pass through a sequence of Transformer refinement stages. Quantitative\nexperiments on the Waymo Open Dataset support these claims, where we achieve\nstate-of-the-art results on the task of 3D pose estimation.\n","authors":["Andrei Zanfir","Mihai Zanfir","Alexander Gorban","Jingwei Ji","Yin Zhou","Dragomir Anguelov","Cristian Sminchisescu"],"pdf_url":"https://arxiv.org/pdf/2212.07729v1.pdf","comment":"Published at the 6th Conference on Robot Learning (CoRL 2022),\n  Auckland, New Zealand"},{"id":"http://arxiv.org/abs/2212.07724v1","updated":"2022-12-15T11:07:23Z","published":"2022-12-15T11:07:23Z","title":"Attention-based Multiple Instance Learning for Survival Prediction on\n  Lung Cancer Tissue Microarrays","summary":"  Attention-based multiple instance learning (AMIL) algorithms have proven to\nbe successful in utilizing gigapixel whole-slide images (WSIs) for a variety of\ndifferent computational pathology tasks such as outcome prediction and cancer\nsubtyping problems. We extended an AMIL approach to the task of survival\nprediction by utilizing the classical Cox partial likelihood as a loss\nfunction, converting the AMIL model into a nonlinear proportional hazards\nmodel. We applied the model to tissue microarray (TMA) slides of 330 lung\ncancer patients. The results show that AMIL approaches can handle very small\namounts of tissue from a TMA and reach similar C-index performance compared to\nestablished survival prediction methods trained with highly discriminative\nclinical factors such as age, cancer grade, and cancer stage\n","authors":["Jonas Ammeling","Lars-Henning Schmidt","Jonathan Ganz","Tanja Niedermair","Christoph Brochhausen-Delius","Christian Schulz","Katharina Breininger","Marc Aubreville"],"pdf_url":"https://arxiv.org/pdf/2212.07724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07721v1","updated":"2022-12-15T10:56:47Z","published":"2022-12-15T10:56:47Z","title":"Deep Learning-Based Automatic Assessment of AgNOR-scores in\n  Histopathology Images","summary":"  Nucleolar organizer regions (NORs) are parts of the DNA that are involved in\nRNA transcription. Due to the silver affinity of associated proteins,\nargyrophilic NORs (AgNORs) can be visualized using silver-based staining. The\naverage number of AgNORs per nucleus has been shown to be a prognostic factor\nfor predicting the outcome of many tumors. Since manual detection of AgNORs is\nlaborious, automation is of high interest. We present a deep learning-based\npipeline for automatically determining the AgNOR-score from histopathological\nsections. An additional annotation experiment was conducted with six\npathologists to provide an independent performance evaluation of our approach.\nAcross all raters and images, we found a mean squared error of 0.054 between\nthe AgNOR- scores of the experts and those of the model, indicating that our\napproach offers performance comparable to humans.\n","authors":["Jonathan Ganz","Karoline Lipnik","Jonas Ammeling","Barbara Richter","Chloé Puget","Eda Parlak","Laura Diehl","Robert Klopfleisch","Taryn A. Donovan","Matti Kiupel","Christof A. Bertram","Katharina Breininger","Marc Aubreville"],"pdf_url":"https://arxiv.org/pdf/2212.07721v1.pdf","comment":"6 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2212.07700v1","updated":"2022-12-15T10:23:32Z","published":"2022-12-15T10:23:32Z","title":"Colab NAS: Obtaining lightweight task-specific convolutional neural\n  networks following Occam's razor","summary":"  The current trend of applying transfer learning from CNNs trained on large\ndatasets can be an overkill when the target application is a custom and\ndelimited problem with enough data to train a network from scratch. On the\nother hand, the training of custom and lighter CNNs requires expertise, in the\nfrom-scratch case, and or high-end resources, as in the case of hardware-aware\nneural architecture search (HW NAS), limiting access to the technology by\nnon-habitual NN developers.\n  For this reason, we present Colab NAS, an affordable HW NAS technique for\nproducing lightweight task-specific CNNs. Its novel derivative-free search\nstrategy, inspired by Occam's razor, allows it to obtain state-of-the-art\nresults on the Visual Wake Word dataset in just 4.5 GPU hours using free online\nGPU services such as Google Colaboratory and Kaggle Kernel.\n","authors":["Andrea Mattia Garavagno","Daniele Leonardis","Antonio Frisoli"],"pdf_url":"https://arxiv.org/pdf/2212.07700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07699v1","updated":"2022-12-15T10:20:42Z","published":"2022-12-15T10:20:42Z","title":"Retrieval-based Disentanglement with Distant Supervision","summary":"  Disentangled representation learning remains challenging as ground truth\nfactors of variation do not naturally exist. To address this, we present\nVocabulary Disentanglement Retrieval~(VDR), a simple yet effective\nretrieval-based disentanglement framework that leverages nature language as\ndistant supervision. Our approach is built upon the widely-used bi-encoder\narchitecture with disentanglement heads and is trained on data-text pairs that\nare readily available on the web or in existing datasets. This makes our\napproach task- and modality-agnostic with potential for a wide range of\ndownstream applications. We conduct experiments on 16 datasets in both\ntext-to-text and cross-modal scenarios and evaluate VDR in a zero-shot setting.\nWith the incorporation of disentanglement heads and a minor increase in\nparameters, VDR achieves significant improvements over the base retriever it is\nbuilt upon, with a 9% higher on NDCG@10 scores in zero-shot text-to-text\nretrieval and an average of 13% higher recall in cross-modal retrieval. In\ncomparison to other baselines, VDR outperforms them in most tasks, while also\nimproving explainability and efficiency.\n","authors":["Jiawei Zhou","Xiaoguang Li","Lifeng Shang","Xin Jiang","Qun Liu","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2212.07699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.01992v7","updated":"2022-12-15T10:15:34Z","published":"2022-06-04T13:45:08Z","title":"CAINNFlow: Convolutional block Attention modules and Invertible Neural\n  Networks Flow for anomaly detection and localization tasks","summary":"  Detection of object anomalies is crucial in industrial processes, but\nunsupervised anomaly detection and localization is particularly important due\nto the difficulty of obtaining a large number of defective samples and the\nunpredictable types of anomalies in real life. Among the existing unsupervised\nanomaly detection and localization methods, the NF-based scheme has achieved\nbetter results. However, the two subnets (complex functions) $s_{i}(u_{i})$ and\n$t_{i}(u_{i})$ in NF are usually multilayer perceptrons, which need to squeeze\nthe input visual features from 2D flattening to 1D, destroying the spatial\nlocation relationship in the feature map and losing the spatial structure\ninformation. In order to retain and effectively extract spatial structure\ninformation, we design in this study a complex function model with alternating\nCBAM embedded in a stacked $3\\times3$ full convolution, which is able to retain\nand effectively extract spatial structure information in the normalized flow\nmodel. Extensive experimental results on the MVTec AD dataset show that\nCAINNFlow achieves advanced levels of accuracy and inference efficiency based\non CNN and Transformer backbone networks as feature extractors, and CAINNFlow\nachieves a pixel-level AUC of $98.64\\%$ for anomaly detection in MVTec AD.\n","authors":["Ruiqing Yan","Fan Zhang","Mengyuan Huang","Wu Liu","Dongyu Hu","Jinfeng Li","Qiang Liu","Jinrong Jiang","Qianjin Guo","Linghan Zheng"],"pdf_url":"https://arxiv.org/pdf/2206.01992v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15444v2","updated":"2022-12-15T10:03:25Z","published":"2022-11-23T17:59:12Z","title":"DAMO-YOLO : A Report on Real-Time Object Detection Design","summary":"  In this report, we present a fast and accurate object detection method dubbed\nDAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO\nseries. DAMO-YOLO is extended from YOLO with some new technologies, including\nNeural Architecture Search (NAS), efficient Reparameterized Generalized-FPN\n(RepGFPN), a lightweight head with AlignedOTA label assignment, and\ndistillation enhancement. In particular, we use MAE-NAS, a method guided by the\nprinciple of maximum entropy, to search our detection backbone under the\nconstraints of low latency and high performance, producing ResNet-like /\nCSP-like structures with spatial pyramid pooling and focus modules. In the\ndesign of necks and heads, we follow the rule of \"large neck, small head\". We\nimport Generalized-FPN with accelerated queen-fusion to build the detector neck\nand upgrade its CSPNet with efficient layer aggregation networks (ELAN) and\nreparameterization. Then we investigate how detector head size affects\ndetection performance and find that a heavy neck with only one task projection\nlayer would yield better results. In addition, AlignedOTA is proposed to solve\nthe misalignment problem in label assignment. And a distillation schema is\nintroduced to improve performance to a higher level. Based on these new techs,\nwe build a suite of models at various scales to meet the needs of different\nscenarios, i.e., DAMO-YOLO-Tiny/Small/Medium. They can achieve 43.0/46.8/50.0\nmAPs on COCO with the latency of 2.78/3.83/5.62 ms on T4 GPUs respectively. The\ncode is available at https://github.com/tinyvision/damo-yolo.\n","authors":["Xianzhe Xu","Yiqi Jiang","Weihua Chen","Yilun Huang","Yuan Zhang","Xiuyu Sun"],"pdf_url":"https://arxiv.org/pdf/2211.15444v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07692v1","updated":"2022-12-15T09:57:19Z","published":"2022-12-15T09:57:19Z","title":"CNN-based real-time 2D-3D deformable registration from a single X-ray\n  projection","summary":"  Purpose: The purpose of this paper is to present a method for real-time 2D-3D\nnon-rigid registration using a single fluoroscopic image. Such a method can\nfind applications in surgery, interventional radiology and radiotherapy. By\nestimating a three-dimensional displacement field from a 2D X-ray image,\nanatomical structures segmented in the preoperative scan can be projected onto\nthe 2D image, thus providing a mixed reality view. Methods: A dataset composed\nof displacement fields and 2D projections of the anatomy is generated from the\npreoperative scan. From this dataset, a neural network is trained to recover\nthe unknown 3D displacement field from a single projection image. Results: Our\nmethod is validated on lung 4D CT data at different stages of the lung\ndeformation. The training is performed on a 3D CT using random (non\ndomain-specific) diffeomorphic deformations, to which perturbations mimicking\nthe pose uncertainty are added. The model achieves a mean TRE over a series of\nlandmarks ranging from 2.3 to 5.5 mm depending on the amplitude of deformation.\nConclusion: In this paper, a CNN-based method for real-time 2D-3D non-rigid\nregistration is presented. This method is able to cope with pose estimation\nuncertainties, making it applicable to actual clinical scenarios, such as lung\nsurgery, where the C-arm pose is planned before the intervention.\n","authors":["François Lecomte","Jean-Louis Dillenseger","Stéphane Cotin"],"pdf_url":"https://arxiv.org/pdf/2212.07692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10911v4","updated":"2022-12-15T09:21:22Z","published":"2022-06-22T08:33:52Z","title":"Influence of uncertainty estimation techniques on false-positive\n  reduction in liver lesion detection","summary":"  Deep learning techniques show success in detecting objects in medical images,\nbut still suffer from false-positive predictions that may hinder accurate\ndiagnosis. The estimated uncertainty of the neural network output has been used\nto flag incorrect predictions. We study the role played by features computed\nfrom neural network uncertainty estimates and shape-based features computed\nfrom binary predictions in reducing false positives in liver lesion detection\nby developing a classification-based post-processing step for different\nuncertainty estimation methods. We demonstrate an improvement in the lesion\ndetection performance of the neural network (with respect to F1-score) for all\nuncertainty estimation methods on two datasets, comprising abdominal MR and CT\nimages, respectively. We show that features computed from neural network\nuncertainty estimates tend not to contribute much toward reducing false\npositives. Our results show that factors like class imbalance (true over false\npositive ratio) and shape-based features extracted from uncertainty maps play\nan important role in distinguishing false positive from true positive\npredictions. Our code can be found at https://github.com/ishaanb92/FPCPipeline.\n","authors":["Ishaan Bhat","Josien P. W. Pluim","Max A. Viergever","Hugo J. Kuijf"],"pdf_url":"https://arxiv.org/pdf/2206.10911v4.pdf","comment":"Accepted for publication in the Journal of Machine Learning for\n  Biomedical Imaging (MELBA)"},{"id":"http://arxiv.org/abs/2004.08554v3","updated":"2022-12-15T09:09:19Z","published":"2020-04-18T08:25:25Z","title":"Realistic Large-Scale Fine-Depth Dehazing Dataset from 3D Videos","summary":"  Image dehazing is one of the important and popular topics in computer vision\nand machine learning. A reliable real-time dehazing method with reliable\nperformance is highly desired for many applications such as autonomous driving,\nsecurity surveillance, etc. While recent learning-based methods require\ndatasets containing pairs of hazy images and clean ground truth, it is\nimpossible to capture them in real scenes. Many existing works compromise this\ndifficulty to generate hazy images by rendering the haze from depth on common\nRGBD datasets using the haze imaging model. However, there is still a gap\nbetween the synthetic datasets and real hazy images as large datasets with\nhigh-quality depth are mostly indoor and depth maps for outdoor are imprecise.\nIn this paper, we complement the existing datasets with a new, large, and\ndiverse dehazing dataset containing real outdoor scenes from High-Definition\n(HD) 3D movies. We select a large number of high-quality frames of real outdoor\nscenes and render haze on them using depth from stereo. Our dataset is clearly\nmore realistic and more diversified with better visual quality than existing\nones. More importantly, we demonstrate that using this dataset greatly improves\nthe dehazing performance on real scenes. In addition to the dataset, we also\nevaluate a series state of the art methods on the proposed benchmarking\ndatasets.\n","authors":["Ruoteng Li","Xiaoyi Zhang","Shaodi You","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2004.08554v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07672v1","updated":"2022-12-15T09:05:26Z","published":"2022-12-15T09:05:26Z","title":"Summary-Oriented Vision Modeling for Multimodal Abstractive\n  Summarization","summary":"  The goal of multimodal abstractive summarization (MAS) is to produce a\nconcise summary given the multimodal data (text and vision). Existing studies\non MAS mainly focus on how to effectively use the extracted visual features,\nhaving achieved impressive success on the high-resource English dataset.\nHowever, less attention has been paid to the quality of the visual features to\nthe summary, which may limit the model performance especially in the low- and\nzero-resource scenarios. In this paper, we propose to improve the summary\nquality through summary-oriented visual features. To this end, we devise two\nauxiliary tasks including \\emph{vision to summary task} and \\emph{masked image\nmodeling task}. Together with the main summarization task, we optimize the MAS\nmodel via the training objectives of all these tasks. By these means, the MAS\nmodel can be enhanced by capturing the summary-oriented visual features,\nthereby yielding more accurate summaries. Experiments on 44 languages, covering\nmid-high-, low-, and zero-resource scenarios, verify the effectiveness and\nsuperiority of the proposed approach, which achieves state-of-the-art\nperformance under all scenarios.\n","authors":["Yunlong Liang","Fandong Meng","Jinan Xu","Jiaan Wang","Yufeng Chen","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.07672v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2212.07671v1","updated":"2022-12-15T09:04:45Z","published":"2022-12-15T09:04:45Z","title":"Multi-task Fusion for Efficient Panoptic-Part Segmentation","summary":"  In this paper, we introduce a novel network that generates semantic,\ninstance, and part segmentation using a shared encoder and effectively fuses\nthem to achieve panoptic-part segmentation. Unifying these three segmentation\nproblems allows for mutually improved and consistent representation learning.\nTo fuse the predictions of all three heads efficiently, we introduce a\nparameter-free joint fusion module that dynamically balances the logits and\nfuses them to create panoptic-part segmentation. Our method is evaluated on the\nCityscapes Panoptic Parts (CPP) and Pascal Panoptic Parts (PPP) datasets. For\nCPP, the PartPQ of our proposed model with joint fusion surpasses the previous\nstate-of-the-art by 1.6 and 4.7 percentage points for all areas and segments\nwith parts, respectively. On PPP, our joint fusion outperforms a model using\nthe previous top-down merging strategy by 3.3 percentage points in PartPQ and\n10.5 percentage points in PartPQ for partitionable classes.\n","authors":["Sravan Kumar Jagadeesh","René Schuster","Didier Stricker"],"pdf_url":"https://arxiv.org/pdf/2212.07671v1.pdf","comment":"Accepted in ICPRAM 2023"},{"id":"http://arxiv.org/abs/2212.07664v1","updated":"2022-12-15T08:42:25Z","published":"2022-12-15T08:42:25Z","title":"Writer Retrieval and Writer Identification in Greek Papyri","summary":"  The analysis of digitized historical manuscripts is typically addressed by\npaleographic experts. Writer identification refers to the classification of\nknown writers while writer retrieval seeks to find the writer by means of image\nsimilarity in a dataset of images. While automatic writer\nidentification/retrieval methods already provide promising results for many\nhistorical document types, papyri data is very challenging due to the fiber\nstructures and severe artifacts. Thus, an important step for an improved writer\nidentification is the preprocessing and feature sampling process. We\ninvestigate several methods and show that a good binarization is key to an\nimproved writer identification in papyri writings. We focus mainly on writer\nretrieval using unsupervised feature methods based on traditional or\nself-supervised-based methods. It is, however, also comparable to the state of\nthe art supervised deep learning-based method in the case of writer\nclassification/re-identification.\n","authors":["Vincent Christlein","Isabelle Marthot-Santaniello","Martin Mayr","Anguelos Nicolaou","Mathias Seuret"],"pdf_url":"https://arxiv.org/pdf/2212.07664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07652v1","updated":"2022-12-15T08:19:02Z","published":"2022-12-15T08:19:02Z","title":"Body-Part Joint Detection and Association via Extended Object\n  Representation","summary":"  The detection of human body and its related parts (e.g., face, head or hands)\nhave been intensively studied and greatly improved since the breakthrough of\ndeep CNNs. However, most of these detectors are trained independently, making\nit a challenging task to associate detected body parts with people. This paper\nfocuses on the problem of joint detection of human body and its corresponding\nparts. Specifically, we propose a novel extended object representation that\nintegrates the center location offsets of body or its parts, and construct a\ndense single-stage anchor-based Body-Part Joint Detector (BPJDet). Body-part\nassociations in BPJDet are embedded into the unified representation which\ncontains both the semantic and geometric information. Therefore, BPJDet does\nnot suffer from error-prone association post-matching, and has a better\naccuracy-speed trade-off. Furthermore, BPJDet can be seamlessly generalized to\njointly detect any body part. To verify the effectiveness and superiority of\nour method, we conduct extensive experiments on the CityPersons, CrowdHuman and\nBodyHands datasets. The proposed BPJDet detector achieves state-of-the-art\nassociation performance on these three benchmarks while maintains high accuracy\nof detection. Code will be released to facilitate further studies.\n","authors":["Huayi Zhou","Fei Jiang","Hongtao Lu"],"pdf_url":"https://arxiv.org/pdf/2212.07652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07651v1","updated":"2022-12-15T08:18:37Z","published":"2022-12-15T08:18:37Z","title":"Two-stage Contextual Transformer-based Convolutional Neural Network for\n  Airway Extraction from CT Images","summary":"  Accurate airway extraction from computed tomography (CT) images is a critical\nstep for planning navigation bronchoscopy and quantitative assessment of\nairway-related chronic obstructive pulmonary disease (COPD). The existing\nmethods are challenging to sufficiently segment the airway, especially the\nhigh-generation airway, with the constraint of the limited label and cannot\nmeet the clinical use in COPD. We propose a novel two-stage 3D contextual\ntransformer-based U-Net for airway segmentation using CT images. The method\nconsists of two stages, performing initial and refined airway segmentation. The\ntwo-stage model shares the same subnetwork with different airway masks as\ninput. Contextual transformer block is performed both in the encoder and\ndecoder path of the subnetwork to finish high-quality airway segmentation\neffectively. In the first stage, the total airway mask and CT images are\nprovided to the subnetwork, and the intrapulmonary airway mask and\ncorresponding CT scans to the subnetwork in the second stage. Then the\npredictions of the two-stage method are merged as the final prediction.\nExtensive experiments were performed on in-house and multiple public datasets.\nQuantitative and qualitative analysis demonstrate that our proposed method\nextracted much more branches and lengths of the tree while accomplishing\nstate-of-the-art airway segmentation performance. The code is available at\nhttps://github.com/zhaozsq/airway_segmentation.\n","authors":["Yanan Wu","Shuiqing Zhao","Shouliang Qi","Jie Feng","Haowen Pang","Runsheng Chang","Long Bai","Mengqi Li","Shuyue Xia","Wei Qian","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.07651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07648v1","updated":"2022-12-15T08:06:03Z","published":"2022-12-15T08:06:03Z","title":"Relightable Neural Human Assets from Multi-view Gradient Illuminations","summary":"  Human modeling and relighting are two fundamental problems in computer vision\nand graphics, where high-quality datasets can largely facilitate related\nresearch. However, most existing human datasets only provide multi-view human\nimages captured under the same illumination. Although valuable for modeling\ntasks, they are not readily used in relighting problems. To promote research in\nboth fields, in this paper, we present UltraStage, a new 3D human dataset that\ncontains more than 2K high-quality human assets captured under both multi-view\nand multi-illumination settings. Specifically, for each example, we provide 32\nsurrounding views illuminated with one white light and two gradient\nilluminations. In addition to regular multi-view images, gradient illuminations\nhelp recover detailed surface normal and spatially-varying material maps,\nenabling various relighting applications. Inspired by recent advances in neural\nrepresentation, we further interpret each example into a neural human asset\nwhich allows novel view synthesis under arbitrary lighting conditions. We show\nour neural human assets can achieve extremely high capture performance and are\ncapable of representing fine details such as facial wrinkles and cloth folds.\nWe also validate UltraStage in single image relighting tasks, training neural\nnetworks with virtual relighted data from neural assets and demonstrating\nrealistic rendering improvements over prior arts. UltraStage will be publicly\navailable to the community to stimulate significant future developments in\nvarious human modeling and rendering tasks.\n","authors":["Taotao Zhou","Kai He","Di Wu","Teng Xu","Qixuan Zhang","Kuixiang Shao","Wenzheng Chen","Lan Xu","Jingyi Yi"],"pdf_url":"https://arxiv.org/pdf/2212.07648v1.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2212.07646v1","updated":"2022-12-15T07:39:50Z","published":"2022-12-15T07:39:50Z","title":"Memory-like Adaptive Modeling Multi-Agent Learning System","summary":"  In this work, we propose a self-supervised multi-agent system, termed a\nmemory-like adaptive modeling multi-agent learning system (MAMMALS), that\nrealizes online learning towards behavioral pattern clustering tasks for time\nseries. Encoding the visual behaviors as discrete time series(DTS), and\ntraining and modeling them in the multi-agent system with a bio-memory-like\nform. We finally implemented a fully decentralized multi-agent system design\nframework and completed its feasibility verification in a surveillance video\napplication scenario on vehicle path clustering. In multi-agent learning, using\nlearning methods designed for individual agents will typically perform poorly\nglobally because of the behavior of ignoring the synergy between agents.\n","authors":["Xingyu Qian","Aximu Yuemaier","Longfei Liang","Wen-Chi Yang","Xiaogang Chen","Shunfen Li","Weibang Dai","Zhitang Song"],"pdf_url":"https://arxiv.org/pdf/2212.07646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08772v3","updated":"2022-12-15T07:31:37Z","published":"2022-10-17T06:29:07Z","title":"Signal Processing for Implicit Neural Representations","summary":"  Implicit Neural Representations (INRs) encoding continuous multi-media data\nvia multi-layer perceptrons has shown undebatable promise in various computer\nvision tasks. Despite many successful applications, editing and processing an\nINR remains intractable as signals are represented by latent parameters of a\nneural network. Existing works manipulate such continuous representations via\nprocessing on their discretized instance, which breaks down the compactness and\ncontinuous nature of INR. In this work, we present a pilot study on the\nquestion: how to directly modify an INR without explicit decoding? We answer\nthis question by proposing an implicit neural signal processing network, dubbed\nINSP-Net, via differential operators on INR. Our key insight is that spatial\ngradients of neural networks can be computed analytically and are invariant to\ntranslation, while mathematically we show that any continuous convolution\nfilter can be uniformly approximated by a linear combination of high-order\ndifferential operators. With these two knobs, INSP-Net instantiates the signal\nprocessing operator as a weighted composition of computational graphs\ncorresponding to the high-order derivatives of INRs, where the weighting\nparameters can be data-driven learned. Based on our proposed INSP-Net, we\nfurther build the first Convolutional Neural Network (CNN) that implicitly runs\non INRs, named INSP-ConvNet. Our experiments validate the expressiveness of\nINSP-Net and INSP-ConvNet in fitting low-level image and geometry processing\nkernels (e.g. blurring, deblurring, denoising, inpainting, and smoothening) as\nwell as for high-level tasks on implicit fields such as image classification.\n","authors":["Dejia Xu","Peihao Wang","Yifan Jiang","Zhiwen Fan","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2210.08772v3.pdf","comment":"Advances in Neural Information Processing Systems (NeurIPS), 2022"},{"id":"http://arxiv.org/abs/2206.09604v2","updated":"2022-12-15T07:21:01Z","published":"2022-06-20T07:20:02Z","title":"Distortion-Aware Network Pruning and Feature Reuse for Real-time Video\n  Segmentation","summary":"  Real-time video segmentation is a crucial task for many real-world\napplications such as autonomous driving and robot control. Since\nstate-of-the-art semantic segmentation models are often too heavy for real-time\napplications despite their impressive performance, researchers have proposed\nlightweight architectures with speed-accuracy trade-offs, achieving real-time\nspeed at the expense of reduced accuracy. In this paper, we propose a novel\nframework to speed up any architecture with skip-connections for real-time\nvision tasks by exploiting the temporal locality in videos. Specifically, at\nthe arrival of each frame, we transform the features from the previous frame to\nreuse them at specific spatial bins. We then perform partial computation of the\nbackbone network on the regions of the current frame that captures temporal\ndifferences between the current and previous frame. This is done by dynamically\ndropping out residual blocks using a gating mechanism which decides which\nblocks to drop based on inter-frame distortion. We validate our\nSpatial-Temporal Mask Generator (STMG) on video semantic segmentation\nbenchmarks with multiple backbone networks, and show that our method largely\nspeeds up inference with minimal loss of accuracy.\n","authors":["Hyunsu Rhee","Dongchan Min","Sunil Hwang","Bruno Andreis","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2206.09604v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07629v1","updated":"2022-12-15T06:30:11Z","published":"2022-12-15T06:30:11Z","title":"EM-Paste: EM-guided Cut-Paste with DALL-E Augmentation for Image-level\n  Weakly Supervised Instance Segmentation","summary":"  We propose EM-PASTE: an Expectation Maximization(EM) guided Cut-Paste\ncompositional dataset augmentation approach for weakly-supervised instance\nsegmentation using only image-level supervision. The proposed method consists\nof three main components. The first component generates high-quality foreground\nobject masks. To this end, an EM-like approach is proposed that iteratively\nrefines an initial set of object mask proposals generated by a generic region\nproposal method. Next, in the second component, high-quality context-aware\nbackground images are generated using a text-to-image compositional synthesis\nmethod like DALL-E. Finally, the third component creates a large-scale\npseudo-labeled instance segmentation training dataset by compositing the\nforeground object masks onto the original and generated background images. The\nproposed approach achieves state-of-the-art weakly-supervised instance\nsegmentation results on both the PASCAL VOC 2012 and MS COCO datasets by using\nonly image-level, weak label information. In particular, it outperforms the\nbest baseline by +7.4 and +2.8 mAP0.50 on PASCAL and COCO, respectively.\nFurther, the method provides a new solution to the long-tail weakly-supervised\ninstance segmentation problem (when many classes may only have few training\nsamples), by selectively augmenting under-represented classes.\n","authors":["Yunhao Ge","Jiashu Xu","Brian Nlong Zhao","Laurent Itti","Vibhav Vineet"],"pdf_url":"https://arxiv.org/pdf/2212.07629v1.pdf","comment":"15 pages (including appendix), 7 figures"},{"id":"http://arxiv.org/abs/2212.07626v1","updated":"2022-12-15T05:58:45Z","published":"2022-12-15T05:58:45Z","title":"NeuralDome: A Neural Modeling Pipeline on Multi-View Human-Object\n  Interactions","summary":"  Humans constantly interact with objects in daily life tasks. Capturing such\nprocesses and subsequently conducting visual inferences from a fixed viewpoint\nsuffers from occlusions, shape and texture ambiguities, motions, etc. To\nmitigate the problem, it is essential to build a training dataset that captures\nfree-viewpoint interactions. We construct a dense multi-view dome to acquire a\ncomplex human object interaction dataset, named HODome, that consists of\n$\\sim$75M frames on 10 subjects interacting with 23 objects. To process the\nHODome dataset, we develop NeuralDome, a layer-wise neural processing pipeline\ntailored for multi-view video inputs to conduct accurate tracking, geometry\nreconstruction and free-view rendering, for both human subjects and objects.\nExtensive experiments on the HODome dataset demonstrate the effectiveness of\nNeuralDome on a variety of inference, modeling, and rendering tasks. Both the\ndataset and the NeuralDome tools will be disseminated to the community for\nfurther development.\n","authors":["Juze Zhang","Haimin Luo","Hongdi Yang","Xinru Xu","Qianyang Wu","Ye Shi","Jingyi Yu","Lan Xu","Jingya Wang"],"pdf_url":"https://arxiv.org/pdf/2212.07626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07623v1","updated":"2022-12-15T05:43:21Z","published":"2022-12-15T05:43:21Z","title":"SBSS: Stacking-Based Semantic Segmentation Framework for Very High\n  Resolution Remote Sensing Image","summary":"  Semantic segmentation of Very High Resolution (VHR) remote sensing images is\na fundamental task for many applications. However, large variations in the\nscales of objects in those VHR images pose a challenge for performing accurate\nsemantic segmentation. Existing semantic segmentation networks are able to\nanalyse an input image at up to four resizing scales, but this may be\ninsufficient given the diversity of object scales. Therefore, Multi Scale (MS)\ntest-time data augmentation is often used in practice to obtain more accurate\nsegmentation results, which makes equal use of the segmentation results\nobtained at the different resizing scales. However, it was found in this study\nthat different classes of objects had their preferred resizing scale for more\naccurate semantic segmentation. Based on this behaviour, a Stacking-Based\nSemantic Segmentation (SBSS) framework is proposed to improve the segmentation\nresults by learning this behaviour, which contains a learnable Error Correction\nModule (ECM) for segmentation result fusion and an Error Correction Scheme\n(ECS) for computational complexity control. Two ECS, i.e., ECS-MS and ECS-SS,\nare proposed and investigated in this study. The Floating-point operations\n(Flops) required for ECS-MS and ECS-SS are similar to the commonly used MS test\nand the Single-Scale (SS) test, respectively. Extensive experiments on four\ndatasets (i.e., Cityscapes, UAVid, LoveDA and Potsdam) show that SBSS is an\neffective and flexible framework. It achieved higher accuracy than MS when\nusing ECS-MS, and similar accuracy as SS with a quarter of the memory footprint\nwhen using ECS-SS.\n","authors":["Yuanzhi Cai","Lei Fan","Yuan Fang"],"pdf_url":"https://arxiv.org/pdf/2212.07623v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2212.02886v2","updated":"2022-12-15T05:10:36Z","published":"2022-12-06T11:23:16Z","title":"GAS-NeXt: Few-Shot Cross-Lingual Font Generator","summary":"  Generating new fonts is a time-consuming and labor-intensive task, especially\nin a language with a huge amount of characters like Chinese. Various deep\nlearning models have demonstrated the ability to efficiently generate new fonts\nwith a few reference characters of that style, but few models support\ncross-lingual font generation. This paper presents GAS-NeXt, a novel few-shot\ncross-lingual font generator based on AGIS-Net and Font Translator GAN, and\nimprove the performance metrics such as Fr\\'echet Inception Distance (FID),\nStructural Similarity Index Measure(SSIM), and Pixel-level Accuracy (pix-acc).\nOur approaches include replacing the original encoder and decoder with the idea\nof layer attention and context-aware attention from Font Translator GAN, while\nutilizing the shape, texture, and local discriminators of AGIS-Net. In our\nexperiment on English-to-Chinese font translation, we observed better results\nin fonts with distinct local features than conventional Chinese fonts compared\nto results obtained from Font Translator GAN. We also validate our method on\nmultiple languages and datasets.\n","authors":["Haoyang He","Xin Jin","Angela Chen"],"pdf_url":"https://arxiv.org/pdf/2212.02886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07618v1","updated":"2022-12-15T05:09:11Z","published":"2022-12-15T05:09:11Z","title":"Proposal Distribution Calibration for Few-Shot Object Detection","summary":"  Adapting object detectors learned with sufficient supervision to novel\nclasses under low data regimes is charming yet challenging. In few-shot object\ndetection (FSOD), the two-step training paradigm is widely adopted to mitigate\nthe severe sample imbalance, i.e., holistic pre-training on base classes, then\npartial fine-tuning in a balanced setting with all classes. Since unlabeled\ninstances are suppressed as backgrounds in the base training phase, the learned\nRPN is prone to produce biased proposals for novel instances, resulting in\ndramatic performance degradation. Unfortunately, the extreme data scarcity\naggravates the proposal distribution bias, hindering the RoI head from evolving\ntoward novel classes. In this paper, we introduce a simple yet effective\nproposal distribution calibration (PDC) approach to neatly enhance the\nlocalization and classification abilities of the RoI head by recycling its\nlocalization ability endowed in base training and enriching high-quality\npositive samples for semantic fine-tuning. Specifically, we sample proposals\nbased on the base proposal statistics to calibrate the distribution bias and\nimpose additional localization and classification losses upon the sampled\nproposals for fast expanding the base detector to novel classes. Experiments on\nthe commonly used Pascal VOC and MS COCO datasets with explicit\nstate-of-the-art performances justify the efficacy of our PDC for FSOD. Code is\navailable at github.com/Bohao-Lee/PDC.\n","authors":["Bohao Li","Chang Liu","Mengnan Shi","Xiaozhong Chen","Xiangyang Ji","Qixiang Ye"],"pdf_url":"https://arxiv.org/pdf/2212.07618v1.pdf","comment":"This paper is under review in IEEE TNNLS"},{"id":"http://arxiv.org/abs/2212.07613v1","updated":"2022-12-15T04:34:57Z","published":"2022-12-15T04:34:57Z","title":"DCS-RISR: Dynamic Channel Splitting for Efficient Real-world Image\n  Super-Resolution","summary":"  Real-world image super-resolution (RISR) has received increased focus for\nimproving the quality of SR images under unknown complex degradation. Existing\nmethods rely on the heavy SR models to enhance low-resolution (LR) images of\ndifferent degradation levels, which significantly restricts their practical\ndeployments on resource-limited devices. In this paper, we propose a novel\nDynamic Channel Splitting scheme for efficient Real-world Image\nSuper-Resolution, termed DCS-RISR. Specifically, we first introduce the light\ndegradation prediction network to regress the degradation vector to simulate\nthe real-world degradations, upon which the channel splitting vector is\ngenerated as the input for an efficient SR model. Then, a learnable octave\nconvolution block is proposed to adaptively decide the channel splitting scale\nfor low- and high-frequency features at each block, reducing computation\noverhead and memory cost by offering the large scale to low-frequency features\nand the small scale to the high ones. To further improve the RISR performance,\nNon-local regularization is employed to supplement the knowledge of patches\nfrom LR and HR subspace with free-computation inference. Extensive experiments\ndemonstrate the effectiveness of DCS-RISR on different benchmark datasets. Our\nDCS-RISR not only achieves the best trade-off between computation/parameter and\nPSNR/SSIM metric, and also effectively handles real-world images with different\ndegradation levels.\n","authors":["Junbo Qiao","Shaohui Lin","Yunlun Zhang","Wei Li","Hu Jie","Gaoqi He","Changbo Wang","Zhuangli Ma"],"pdf_url":"https://arxiv.org/pdf/2212.07613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06872v2","updated":"2022-12-15T04:12:59Z","published":"2022-12-13T19:38:13Z","title":"Examining the Difference Among Transformers and CNNs with Explanation\n  Methods","summary":"  We propose a methodology that systematically applies deep explanation\nalgorithms on a dataset-wide basis, to compare different types of visual\nrecognition backbones, such as convolutional networks (CNNs), global attention\nnetworks, and local attention networks. Examination of both qualitative\nvisualizations and quantitative statistics across the dataset helps us to gain\nintuitions that are not just anecdotal, but are supported by the statistics\ncomputed on the entire dataset. Specifically, we propose two methods. The first\none, sub-explanation counting, systematically searches for minimally-sufficient\nexplanations of all images and count the amount of sub-explanations for each\nnetwork. The second one, called cross-testing, computes salient regions using\none network and then evaluates the performance by only showing these regions as\nan image to other networks. Through a combination of qualitative insights and\nquantitative statistics, we illustrate that 1) there are significant\ndifferences between the salient features of CNNs and attention models; 2) the\nocclusion-robustness in local attention models and global attention models may\ncome from different decision-making mechanisms.\n","authors":["Mingqi Jiang","Saeed Khorram","Li Fuxin"],"pdf_url":"https://arxiv.org/pdf/2212.06872v2.pdf","comment":"28 pages with 39 figures"},{"id":"http://arxiv.org/abs/2212.07603v1","updated":"2022-12-15T03:26:53Z","published":"2022-12-15T03:26:53Z","title":"Text-guided mask-free local image retouching","summary":"  In the realm of multi-modality, text-guided image retouching techniques\nemerged with the advent of deep learning. Most currently available text-guided\nmethods, however, rely on object-level supervision to constrain the region that\nmay be modified. This not only makes it more challenging to develop these\nalgorithms, but it also limits how widely deep learning can be used for image\nretouching. In this paper, we offer a text-guided mask-free image retouching\napproach that yields consistent results to address this concern. In order to\nperform image retouching without mask supervision, our technique can construct\nplausible and edge-sharp masks based on the text for each object in the image.\nExtensive experiments have shown that our method can produce high-quality,\naccurate images based on spoken language. The source code will be released\nsoon.\n","authors":["Zerun Liu","Fan Zhang","Jingxuan He","Jin Wang","Zhangye Wang","Lechao Cheng"],"pdf_url":"https://arxiv.org/pdf/2212.07603v1.pdf","comment":"7 pages, 6 figures, 1 table"},{"id":"http://arxiv.org/abs/2212.07599v1","updated":"2022-12-15T03:04:48Z","published":"2022-12-15T03:04:48Z","title":"Universal Generative Modeling in Dual-domain for Dynamic MR Imaging","summary":"  Dynamic magnetic resonance image reconstruction from incomplete k-space data\nhas generated great research interest due to its capability to reduce scan\ntime. Never-theless, the reconstruction problem is still challenging due to its\nill-posed nature. Recently, diffusion models espe-cially score-based generative\nmodels have exhibited great potential in algorithm robustness and usage\nflexi-bility. Moreover, the unified framework through the variance exploding\nstochastic differential equation (VE-SDE) is proposed to enable new sampling\nmethods and further extend the capabilities of score-based gener-ative models.\nTherefore, by taking advantage of the uni-fied framework, we proposed a k-space\nand image Du-al-Domain collaborative Universal Generative Model (DD-UGM) which\ncombines the score-based prior with low-rank regularization penalty to\nreconstruct highly under-sampled measurements. More precisely, we extract prior\ncomponents from both image and k-space domains via a universal generative model\nand adaptively handle these prior components for faster processing while\nmaintaining good generation quality. Experimental comparisons demonstrated the\nnoise reduction and detail preservation abilities of the proposed method. Much\nmore than that, DD-UGM can reconstruct data of differ-ent frames by only\ntraining a single frame image, which reflects the flexibility of the proposed\nmodel.\n","authors":["Chuanming Yu","Yu Guan","Ziwen Ke","Dong Liang","Qiegen Liu"],"pdf_url":"https://arxiv.org/pdf/2212.07599v1.pdf","comment":"12 pages, 11 figures"},{"id":"http://arxiv.org/abs/2210.08585v3","updated":"2022-12-15T02:56:29Z","published":"2022-10-16T17:10:52Z","title":"A new trigonometric kernel function for support vector machine","summary":"  In the last few years, various types of machine learning algorithms, such as\nSupport Vector Machine (SVM), Support Vector Regression (SVR), and Non-negative\nMatrix Factorization (NMF) have been introduced. The kernel approach is an\neffective method for increasing the classification accuracy of machine learning\nalgorithms. This paper introduces a family of one-parameter kernel functions\nfor improving the accuracy of SVM classification. The proposed kernel function\nconsists of a trigonometric term and differs from all existing kernel\nfunctions. We show this function is a positive definite kernel function.\nFinally, we evaluate the SVM method based on the new trigonometric kernel, the\nGaussian kernel, the polynomial kernel, and a convex combination of the new\nkernel function and the Gaussian kernel function on various types of datasets.\nEmpirical results show that the SVM based on the new trigonometric kernel\nfunction and the mixed kernel function achieve the best classification\naccuracy. Moreover, some numerical results of performing the SVR based on the\nnew trigonometric kernel function and the mixed kernel function are presented.\n","authors":["Sajad Fathi Hafshejani","Zahra Moberfard"],"pdf_url":"https://arxiv.org/pdf/2210.08585v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05245v2","updated":"2022-12-15T02:48:41Z","published":"2022-12-10T08:49:19Z","title":"Joint Spatio-Temporal Modeling for the Semantic Change Detection in\n  Remote Sensing Images","summary":"  Semantic Change Detection (SCD) refers to the task of simultaneously\nextracting the changed areas and the semantic categories (before and after the\nchanges) in Remote Sensing Images (RSIs). This is more meaningful than Binary\nChange Detection (BCD) since it enables detailed change analysis in the\nobserved areas. Previous works established triple-branch Convolutional Neural\nNetwork (CNN) architectures as the paradigm for SCD. However, it remains\nchallenging to exploit semantic information with a limited amount of change\nsamples. In this work, we investigate to jointly consider the spatio-temporal\ndependencies to improve the accuracy of SCD. First, we propose a Semantic\nChange Transformer (SCanFormer) to explicitly model the 'from-to' semantic\ntransitions between the bi-temporal RSIs. Then, we introduce a semantic\nlearning scheme to leverage the spatio-temporal constraints, which are coherent\nto the SCD task, to guide the learning of semantic changes. The resulting\nnetwork (SCanNet) significantly outperforms the baseline method in terms of\nboth detection of critical semantic changes and semantic consistency in the\nobtained bi-temporal results. It achieves the SOTA accuracy on two benchmark\ndatasets for the SCD.\n","authors":["Lei Ding","Jing Zhang","Kai Zhang","Haitao Guo","Bing Liu","Lorenzo Bruzzone"],"pdf_url":"https://arxiv.org/pdf/2212.05245v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07593v1","updated":"2022-12-15T02:45:57Z","published":"2022-12-15T02:45:57Z","title":"Enhanced Training of Query-Based Object Detection via Selective Query\n  Recollection","summary":"  This paper investigates a phenomenon where query-based object detectors\nmispredict at the last decoding stage while predicting correctly at an\nintermediate stage. We review the training process and attribute the overlooked\nphenomenon to two limitations: lack of training emphasis and cascading errors\nfrom decoding sequence. We design and present Selective Query Recollection\n(SQR), a simple and effective training strategy for query-based object\ndetectors. It cumulatively collects intermediate queries as decoding stages go\ndeeper and selectively forwards the queries to the downstream stages aside from\nthe sequential structure. Such-wise, SQR places training emphasis on later\nstages and allows later stages to work with intermediate queries from earlier\nstages directly. SQR can be easily plugged into various query-based object\ndetectors and significantly enhances their performance while leaving the\ninference pipeline unchanged. As a result, we apply SQR on Adamixer, DAB-DETR,\nand Deformable-DETR across various settings (backbone, number of queries,\nschedule) and consistently brings 1.4-2.8 AP improvement.\n","authors":["Fangyi Chen","Han Zhang","Kai Hu","Yu-kai Huang","Chenchen Zhu","Marios Savvides"],"pdf_url":"https://arxiv.org/pdf/2212.07593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07592v1","updated":"2022-12-15T02:44:13Z","published":"2022-12-15T02:44:13Z","title":"Solve the Puzzle of Instance Segmentation in Videos: A Weakly Supervised\n  Framework with Spatio-Temporal Collaboration","summary":"  Instance segmentation in videos, which aims to segment and track multiple\nobjects in video frames, has garnered a flurry of research attention in recent\nyears. In this paper, we present a novel weakly supervised framework with\n\\textbf{S}patio-\\textbf{T}emporal \\textbf{C}ollaboration for instance\n\\textbf{Seg}mentation in videos, namely \\textbf{STC-Seg}. Concretely, STC-Seg\ndemonstrates four contributions. First, we leverage the complementary\nrepresentations from unsupervised depth estimation and optical flow to produce\neffective pseudo-labels for training deep networks and predicting high-quality\ninstance masks. Second, to enhance the mask generation, we devise a puzzle\nloss, which enables end-to-end training using box-level annotations. Third, our\ntracking module jointly utilizes bounding-box diagonal points with\nspatio-temporal discrepancy to model movements, which largely improves the\nrobustness to different object appearances. Finally, our framework is flexible\nand enables image-level instance segmentation methods to operate the\nvideo-level task. We conduct an extensive set of experiments on the KITTI MOTS\nand YT-VIS datasets. Experimental results demonstrate that our method achieves\nstrong performance and even outperforms fully supervised TrackR-CNN and\nMaskTrack R-CNN. We believe that STC-Seg can be a valuable addition to the\ncommunity, as it reflects the tip of an iceberg about the innovative\nopportunities in the weakly supervised paradigm for instance segmentation in\nvideos.\n","authors":["Liqi Yan","Qifan Wang","Siqi Ma","Jingang Wang","Changbin Yu"],"pdf_url":"https://arxiv.org/pdf/2212.07592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.04993v4","updated":"2022-12-15T02:33:40Z","published":"2022-10-10T19:58:23Z","title":"Continual Learning with Evolving Class Ontologies","summary":"  Lifelong learners must recognize concept vocabularies that evolve over time.\nA common yet underexplored scenario is learning with class labels that\ncontinually refine/expand old classes. For example, humans learn to recognize\n${\\tt dog}$ before dog breeds. In practical settings, dataset\n$\\textit{versioning}$ often introduces refinement to ontologies, such as\nautonomous vehicle benchmarks that refine a previous ${\\tt vehicle}$ class into\n${\\tt school-bus}$ as autonomous operations expand to new cities. This paper\nformalizes a protocol for studying the problem of $\\textit{Learning with\nEvolving Class Ontology}$ (LECO). LECO requires learning classifiers in\ndistinct time periods (TPs); each TP introduces a new ontology of \"fine\" labels\nthat refines old ontologies of \"coarse\" labels (e.g., dog breeds that refine\nthe previous ${\\tt dog}$). LECO explores such questions as whether to annotate\nnew data or relabel the old, how to leverage coarse labels, and whether to\nfinetune the previous TP's model or train from scratch. To answer these\nquestions, we leverage insights from related problems such as class-incremental\nlearning. We validate them under the LECO protocol through the lens of image\nclassification (CIFAR and iNaturalist) and semantic segmentation (Mapillary).\nOur experiments lead to surprising conclusions; while the current status quo is\nto relabel existing datasets with new ontologies (such as COCO-to-LVIS or\nMapillary1.2-to-2.0), LECO demonstrates that a far better strategy is to\nannotate $\\textit{new}$ data with the new ontology. However, this produces an\naggregate dataset with inconsistent old-vs-new labels, complicating learning.\nTo address this challenge, we adopt methods from semi-supervised and\npartial-label learning. Such strategies can surprisingly be made near-optimal,\napproaching an \"oracle\" that learns on the aggregate dataset exhaustively\nlabeled with the newest ontology.\n","authors":["Zhiqiu Lin","Deepak Pathak","Yu-Xiong Wang","Deva Ramanan","Shu Kong"],"pdf_url":"https://arxiv.org/pdf/2210.04993v4.pdf","comment":"NeurIPS 2022; Website: https://linzhiqiu.github.io/papers/leco/"},{"id":"http://arxiv.org/abs/2212.07585v1","updated":"2022-12-15T02:25:22Z","published":"2022-12-15T02:25:22Z","title":"Co-Learning with Pre-Trained Networks Improves Source-Free Domain\n  Adaptation","summary":"  Source-free domain adaptation aims to adapt a source model trained on\nfully-labeled source domain data to a target domain with unlabeled target\ndomain data. Source data is assumed inaccessible due to proprietary or privacy\nreasons. Existing works use the source model to pseudolabel target data, but\nthe pseudolabels are unreliable due to data distribution shift between source\nand target domain. In this work, we propose to leverage an ImageNet pre-trained\nfeature extractor in a new co-learning framework to improve target pseudolabel\nquality for finetuning the source model. Benefits of the ImageNet feature\nextractor include that it is not source-biased and it provides an alternate\nview of features and classification decisions different from the source model.\nSuch pre-trained feature extractors are also publicly available, which allows\nus to readily leverage modern network architectures that have strong\nrepresentation learning ability. After co-learning, we sharpen predictions of\nnon-pseudolabeled samples by entropy minimization. Evaluation on 3 benchmark\ndatasets show that our proposed method can outperform existing source-free\ndomain adaptation methods, as well as unsupervised domain adaptation methods\nwhich assume joint access to source and target data.\n","authors":["Wenyu Zhang","Li Shen","Chuan-Sheng Foo"],"pdf_url":"https://arxiv.org/pdf/2212.07585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07582v1","updated":"2022-12-15T02:05:12Z","published":"2022-12-15T02:05:12Z","title":"Edema Estimation From Facial Images Taken Before and After Dialysis via\n  Contrastive Multi-Patient Pre-Training","summary":"  Edema is a common symptom of kidney disease, and quantitative measurement of\nedema is desired. This paper presents a method to estimate the degree of edema\nfrom facial images taken before and after dialysis of renal failure patients.\nAs tasks to estimate the degree of edema, we perform pre- and post-dialysis\nclassification and body weight prediction. We develop a multi-patient\npre-training framework for acquiring knowledge of edema and transfer the\npre-trained model to a model for each patient. For effective pre-training, we\npropose a novel contrastive representation learning, called weight-aware\nsupervised momentum contrast (WeightSupMoCo). WeightSupMoCo aims to make\nfeature representations of facial images closer in similarity of patient weight\nwhen the pre- and post-dialysis labels are the same. Experimental results show\nthat our pre-training approach improves the accuracy of pre- and post-dialysis\nclassification by 15.1% and reduces the mean absolute error of weight\nprediction by 0.243 kg compared with training from scratch. The proposed method\naccurately estimate the degree of edema from facial images; our edema\nestimation system could thus be beneficial to dialysis patients.\n","authors":["Yusuke Akamatsu","Yoshifumi Onishi","Hitoshi Imaoka","Junko Kameyama","Hideo Tsurushima"],"pdf_url":"https://arxiv.org/pdf/2212.07582v1.pdf","comment":"Published in IEEE Journal of Biomedical and Health Informatics\n  (J-BHI)"},{"id":"http://arxiv.org/abs/2104.03509v2","updated":"2022-12-15T02:03:57Z","published":"2021-04-08T04:52:21Z","title":"Py-Feat: Python Facial Expression Analysis Toolbox","summary":"  Studying facial expressions is a notoriously difficult endeavor. Recent\nadvances in the field of affective computing have yielded impressive progress\nin automatically detecting facial expressions from pictures and videos.\nHowever, much of this work has yet to be widely disseminated in social science\ndomains such as psychology. Current state of the art models require\nconsiderable domain expertise that is not traditionally incorporated into\nsocial science training programs. Furthermore, there is a notable absence of\nuser-friendly and open-source software that provides a comprehensive set of\ntools and functions that support facial expression research. In this paper, we\nintroduce Py-Feat, an open-source Python toolbox that provides support for\ndetecting, preprocessing, analyzing, and visualizing facial expression data.\nPy-Feat makes it easy for domain experts to disseminate and benchmark computer\nvision models and also for end users to quickly process, analyze, and visualize\nface expression data. We hope this platform will facilitate increased use of\nfacial expression data in human behavior research.\n","authors":["Eshin Jolly","Jin Hyun Cheong","Tiankang Xie","Sophie Byrne","Matthew Kenny","Luke J. Chang"],"pdf_url":"https://arxiv.org/pdf/2104.03509v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07579v1","updated":"2022-12-15T01:56:22Z","published":"2022-12-15T01:56:22Z","title":"Learning to Detect Semantic Boundaries with Image-level Class Labels","summary":"  This paper presents the first attempt to learn semantic boundary detection\nusing image-level class labels as supervision. Our method starts by estimating\ncoarse areas of object classes through attentions drawn by an image\nclassification network. Since boundaries will locate somewhere between such\nareas of different classes, our task is formulated as a multiple instance\nlearning (MIL) problem, where pixels on a line segment connecting areas of two\ndifferent classes are regarded as a bag of boundary candidates. Moreover, we\ndesign a new neural network architecture that can learn to estimate semantic\nboundaries reliably even with uncertain supervision given by the MIL strategy.\nOur network is used to generate pseudo semantic boundary labels of training\nimages, which are in turn used to train fully supervised models. The final\nmodel trained with our pseudo labels achieves an outstanding performance on the\nSBD dataset, where it is as competitive as some of previous arts trained with\nstronger supervision.\n","authors":["Namyup Kim","Sehyun Hwang","Suha Kwak"],"pdf_url":"https://arxiv.org/pdf/2212.07579v1.pdf","comment":"International Journal of Computer Vision (IJCV), 2022"},{"id":"http://arxiv.org/abs/2212.07575v1","updated":"2022-12-15T01:26:09Z","published":"2022-12-15T01:26:09Z","title":"Evaluation of direct attacks to fingerprint verification systems","summary":"  The vulnerabilities of fingerprint-based recognition systems to direct\nattacks with and without the cooperation of the user are studied. Two different\nsystems, one minutiae-based and one ridge feature-based, are evaluated on a\ndatabase of real and fake fingerprints. Based on the fingerprint images quality\nand on the results achieved on different operational scenarios, we obtain a\nnumber of statistically significant observations regarding the robustness of\nthe systems.\n","authors":["J. Galbally","J. Fierrez","F. Alonso-Fernandez","M. Martinez-Diaz"],"pdf_url":"https://arxiv.org/pdf/2212.07575v1.pdf","comment":"Published at Springer Journal of Telecommunication Systems, Special\n  Issue of Biometrics Systems & Applications"},{"id":"http://arxiv.org/abs/2212.07567v1","updated":"2022-12-15T00:53:42Z","published":"2022-12-15T00:53:42Z","title":"Learning Markerless Robot-Depth Camera Calibration and End-Effector Pose\n  Estimation","summary":"  Traditional approaches to extrinsic calibration use fiducial markers and\nlearning-based approaches rely heavily on simulation data. In this work, we\npresent a learning-based markerless extrinsic calibration system that uses a\ndepth camera and does not rely on simulation data. We learn models for\nend-effector (EE) segmentation, single-frame rotation prediction and keypoint\ndetection, from automatically generated real-world data. We use a\ntransformation trick to get EE pose estimates from rotation predictions and a\nmatching algorithm to get EE pose estimates from keypoint predictions. We\nfurther utilize the iterative closest point algorithm, multiple-frames,\nfiltering and outlier detection to increase calibration robustness. Our\nevaluations with training data from multiple camera poses and test data from\npreviously unseen poses give sub-centimeter and sub-deciradian average\ncalibration and pose estimation errors. We also show that a carefully selected\nsingle training pose gives comparable results.\n","authors":["Bugra C. Sefercik","Baris Akgun"],"pdf_url":"https://arxiv.org/pdf/2212.07567v1.pdf","comment":"8 pages, 6 figures, Conference on Robot Learning"},{"id":"http://arxiv.org/abs/2212.07564v1","updated":"2022-12-15T00:41:09Z","published":"2022-12-15T00:41:09Z","title":"AirfRANS: High Fidelity Computational Fluid Dynamics Dataset for\n  Approximating Reynolds-Averaged Navier-Stokes Solutions","summary":"  Surrogate models are necessary to optimize meaningful quantities in physical\ndynamics as their recursive numerical resolutions are often prohibitively\nexpensive. It is mainly the case for fluid dynamics and the resolution of\nNavier-Stokes equations. However, despite the fast-growing field of data-driven\nmodels for physical systems, reference datasets representing real-world\nphenomena are lacking. In this work, we develop AirfRANS, a dataset for\nstudying the two-dimensional incompressible steady-state Reynolds-Averaged\nNavier-Stokes equations over airfoils at a subsonic regime and for different\nangles of attacks. We also introduce metrics on the stress forces at the\nsurface of geometries and visualization of boundary layers to assess the\ncapabilities of models to accurately predict the meaningful information of the\nproblem. Finally, we propose deep learning baselines on four machine learning\ntasks to study AirfRANS under different constraints for generalization\nconsiderations: big and scarce data regime, Reynolds number, and angle of\nattack extrapolation.\n","authors":["Florent Bonnet","Ahmed Jocelyn Mazari","Paola Cinnella","Patrick Gallinari"],"pdf_url":"https://arxiv.org/pdf/2212.07564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07560v1","updated":"2022-12-15T00:25:05Z","published":"2022-12-15T00:25:05Z","title":"Multi-level and multi-modal feature fusion for accurate 3D object\n  detection in Connected and Automated Vehicles","summary":"  Aiming at highly accurate object detection for connected and automated\nvehicles (CAVs), this paper presents a Deep Neural Network based 3D object\ndetection model that leverages a three-stage feature extractor by developing a\nnovel LIDAR-Camera fusion scheme. The proposed feature extractor extracts\nhigh-level features from two input sensory modalities and recovers the\nimportant features discarded during the convolutional process. The novel fusion\nscheme effectively fuses features across sensory modalities and convolutional\nlayers to find the best representative global features. The fused features are\nshared by a two-stage network: the region proposal network (RPN) and the\ndetection head (DH). The RPN generates high-recall proposals, and the DH\nproduces final detection results. The experimental results show the proposed\nmodel outperforms more recent research on the KITTI 2D and 3D detection\nbenchmark, particularly for distant and highly occluded instances.\n","authors":["Yiming Hou","Mahdi Rezaei","Richard Romano"],"pdf_url":"https://arxiv.org/pdf/2212.07560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.00114v5","updated":"2022-12-15T00:13:44Z","published":"2021-04-30T22:34:45Z","title":"Improved Real-Time Monocular SLAM Using Semantic Segmentation on\n  Selective Frames","summary":"  Monocular simultaneous localization and mapping (SLAM) is emerging in\nadvanced driver assistance systems and autonomous driving, because a single\ncamera is cheap and easy to install. Conventional monocular SLAM has two major\nchallenges leading inaccurate localization and mapping. First, it is\nchallenging to estimate scales in localization and mapping. Second,\nconventional monocular SLAM uses inappropriate mapping factors such as dynamic\nobjects and low-parallax areas in mapping. This paper proposes an improved\nreal-time monocular SLAM that resolves the aforementioned challenges by\nefficiently using deep learning-based semantic segmentation. To achieve the\nreal-time execution of the proposed method, we apply semantic segmentation only\nto downsampled keyframes in parallel with mapping processes. In addition, the\nproposed method corrects scales of camera poses and three-dimensional (3D)\npoints, using estimated ground plane from road-labeled 3D points and the real\ncamera height. The proposed method also removes inappropriate corner features\nlabeled as moving objects and low parallax areas. Experiments with eight video\nsequences demonstrate that the proposed monocular SLAM system achieves\nsignificantly improved and comparable trajectory tracking accuracy, compared to\nexisting state-of-the-art monocular and stereo SLAM systems, respectively. The\nproposed system can achieve real-time tracking on a standard CPU potentially\nwith a standard GPU support, whereas existing segmentation-aided monocular SLAM\ndoes not.\n","authors":["Jinkyu Lee","Muhyun Back","Sung Soo Hwang","Il Yong Chun"],"pdf_url":"https://arxiv.org/pdf/2105.00114v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10047v3","updated":"2022-12-15T23:47:39Z","published":"2022-10-18T17:59:55Z","title":"From Play to Policy: Conditional Behavior Generation from Uncurated\n  Robot Data","summary":"  While large-scale sequence modeling from offline data has led to impressive\nperformance gains in natural language and image generation, directly\ntranslating such ideas to robotics has been challenging. One critical reason\nfor this is that uncurated robot demonstration data, i.e. play data, collected\nfrom non-expert human demonstrators are often noisy, diverse, and\ndistributionally multi-modal. This makes extracting useful, task-centric\nbehaviors from such data a difficult generative modeling problem. In this work,\nwe present Conditional Behavior Transformers (C-BeT), a method that combines\nthe multi-modal generation ability of Behavior Transformer with\nfuture-conditioned goal specification. On a suite of simulated benchmark tasks,\nwe find that C-BeT improves upon prior state-of-the-art work in learning from\nplay data by an average of 45.7%. Further, we demonstrate for the first time\nthat useful task-centric behaviors can be learned on a real-world robot purely\nfrom play data without any task labels or reward information. Robot videos are\nbest viewed on our project website: https://play-to-policy.github.io\n","authors":["Zichen Jeff Cui","Yibin Wang","Nur Muhammad Mahi Shafiullah","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2210.10047v3.pdf","comment":"Code and data available at: https://play-to-policy.github.io; (fixed\n  metadata author name format)"},{"id":"http://arxiv.org/abs/2009.04709v4","updated":"2022-12-15T23:35:23Z","published":"2020-09-10T07:48:42Z","title":"Quantifying the Preferential Direction of the Model Gradient in\n  Adversarial Training With Projected Gradient Descent","summary":"  Adversarial training, especially projected gradient descent (PGD), has proven\nto be a successful approach for improving robustness against adversarial\nattacks. After adversarial training, gradients of models with respect to their\ninputs have a preferential direction. However, the direction of alignment is\nnot mathematically well established, making it difficult to evaluate\nquantitatively. We propose a novel definition of this direction as the\ndirection of the vector pointing toward the closest point of the support of the\nclosest inaccurate class in decision space. To evaluate the alignment with this\ndirection after adversarial training, we apply a metric that uses generative\nadversarial networks to produce the smallest residual needed to change the\nclass present in the image. We show that PGD-trained models have a higher\nalignment than the baseline according to our definition, that our metric\npresents higher alignment values than a competing metric formulation, and that\nenforcing this alignment increases the robustness of models.\n","authors":["Ricardo Bigolin Lanfredi","Joyce D. Schroeder","Tolga Tasdizen"],"pdf_url":"https://arxiv.org/pdf/2009.04709v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08187v1","updated":"2022-12-15T23:20:13Z","published":"2022-12-15T23:20:13Z","title":"Dual Moving Average Pseudo-Labeling for Source-Free Inductive Domain\n  Adaptation","summary":"  Unsupervised domain adaptation reduces the reliance on data annotation in\ndeep learning by adapting knowledge from a source to a target domain. For\nprivacy and efficiency concerns, source-free domain adaptation extends\nunsupervised domain adaptation by adapting a pre-trained source model to an\nunlabeled target domain without accessing the source data. However, most\nexisting source-free domain adaptation methods to date focus on the\ntransductive setting, where the target training set is also the testing set. In\nthis paper, we address source-free domain adaptation in the more realistic\ninductive setting, where the target training and testing sets are mutually\nexclusive. We propose a new semi-supervised fine-tuning method named Dual\nMoving Average Pseudo-Labeling (DMAPL) for source-free inductive domain\nadaptation. We first split the unlabeled training set in the target domain into\na pseudo-labeled confident subset and an unlabeled less-confident subset\naccording to the prediction confidence scores from the pre-trained source\nmodel. Then we propose a soft-label moving-average updating strategy for the\nunlabeled subset based on a moving-average prototypical classifier, which\ngradually adapts the source model towards the target domain. Experiments show\nthat our proposed method achieves state-of-the-art performance and outperforms\nprevious methods by large margins.\n","authors":["Hao Yan","Yuhong Guo"],"pdf_url":"https://arxiv.org/pdf/2212.08187v1.pdf","comment":"BMVC 2022"},{"id":"http://arxiv.org/abs/2212.08158v1","updated":"2022-12-15T21:41:06Z","published":"2022-12-15T21:41:06Z","title":"MM-SHAP: A Performance-agnostic Metric for Measuring Multimodal\n  Contributions in Vision and Language Models & Tasks","summary":"  Vision and language models (VL) are known to exploit unrobust indicators in\nindividual modalities (e.g., introduced by distributional biases), instead of\nfocusing on relevant information in each modality. A small drop in accuracy\nobtained on a VL task with a unimodal model suggests that so-called unimodal\ncollapse occurred. But how to quantify the amount of unimodal collapse\nreliably, at dataset and instance-level, to diagnose and combat unimodal\ncollapse in a targeted way? We present MM-SHAP, a performance-agnostic\nmultimodality score that quantifies the proportion by which a model uses\nindividual modalities in multimodal tasks. MM-SHAP is based on Shapley values\nand will be applied in two ways: (1) to compare models for their degree of\nmultimodality, and (2) to measure the contribution of individual modalities for\na given task and dataset. Experiments with 6 VL models -- LXMERT, CLIP and four\nALBEF variants -- on four VL tasks highlight that unimodal collapse can occur\nto different degrees and in different directions, contradicting the wide-spread\nassumption that unimodal collapse is one-sided. We recommend MM-SHAP for\nanalysing multimodal tasks, to diagnose and guide progress towards multimodal\nintegration. Code available at: https://github.com/Heidelberg-NLP/MM-SHAP\n","authors":["Letitia Parcalabescu","Anette Frank"],"pdf_url":"https://arxiv.org/pdf/2212.08158v1.pdf","comment":"10 pages, 13 appendix pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2205.11495v3","updated":"2022-12-15T20:57:59Z","published":"2022-05-23T17:51:48Z","title":"Flexible Diffusion Modeling of Long Videos","summary":"  We present a framework for video modeling based on denoising diffusion\nprobabilistic models that produces long-duration video completions in a variety\nof realistic environments. We introduce a generative model that can at\ntest-time sample any arbitrary subset of video frames conditioned on any other\nsubset and present an architecture adapted for this purpose. Doing so allows us\nto efficiently compare and optimize a variety of schedules for the order in\nwhich frames in a long video are sampled and use selective sparse and\nlong-range conditioning on previously sampled frames. We demonstrate improved\nvideo modeling over prior work on a number of datasets and sample temporally\ncoherent videos over 25 minutes in length. We additionally release a new video\nmodeling dataset and semantically meaningful metrics based on videos generated\nin the CARLA autonomous driving simulator.\n","authors":["William Harvey","Saeid Naderiparizi","Vaden Masrani","Christian Weilbach","Frank Wood"],"pdf_url":"https://arxiv.org/pdf/2205.11495v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08130v1","updated":"2022-12-15T20:35:48Z","published":"2022-12-15T20:35:48Z","title":"On Evaluating Adversarial Robustness of Chest X-ray Classification:\n  Pitfalls and Best Practices","summary":"  Vulnerability to adversarial attacks is a well-known weakness of Deep Neural\nNetworks. While most of the studies focus on natural images with standardized\nbenchmarks like ImageNet and CIFAR, little research has considered real world\napplications, in particular in the medical domain. Our research shows that,\ncontrary to previous claims, robustness of chest x-ray classification is much\nharder to evaluate and leads to very different assessments based on the\ndataset, the architecture and robustness metric. We argue that previous studies\ndid not take into account the peculiarity of medical diagnosis, like the\nco-occurrence of diseases, the disagreement of labellers (domain experts), the\nthreat model of the attacks and the risk implications for each successful\nattack.\n  In this paper, we discuss the methodological foundations, review the pitfalls\nand best practices, and suggest new methodological considerations for\nevaluating the robustness of chest xray classification models. Our evaluation\non 3 datasets, 7 models, and 18 diseases is the largest evaluation of\nrobustness of chest x-ray classification models.\n","authors":["Salah Ghamizi","Maxime Cordy","Michail Papadakis","Yves Le Traon"],"pdf_url":"https://arxiv.org/pdf/2212.08130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08123v1","updated":"2022-12-15T20:23:09Z","published":"2022-12-15T20:23:09Z","title":"Bayesian posterior approximation with stochastic ensembles","summary":"  We introduce ensembles of stochastic neural networks to approximate the\nBayesian posterior, combining stochastic methods such as dropout with deep\nensembles. The stochastic ensembles are formulated as families of distributions\nand trained to approximate the Bayesian posterior with variational inference.\nWe implement stochastic ensembles based on Monte Carlo dropout, DropConnect and\na novel non-parametric version of dropout and evaluate them on a toy problem\nand CIFAR image classification. For CIFAR, the stochastic ensembles are\nquantitatively compared to published Hamiltonian Monte Carlo results for a\nResNet-20 architecture. We also test the quality of the posteriors directly\nagainst Hamiltonian Monte Carlo simulations in a simplified toy model. Our\nresults show that in a number of settings, stochastic ensembles provide more\naccurate posterior estimates than regular deep ensembles.\n","authors":["Oleksandr Balabanov","Bernhard Mehlig","Hampus Linander"],"pdf_url":"https://arxiv.org/pdf/2212.08123v1.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.08121v1","updated":"2022-12-15T20:20:18Z","published":"2022-12-15T20:20:18Z","title":"Backdoor Attack Detection in Computer Vision by Applying Matrix\n  Factorization on the Weights of Deep Networks","summary":"  The increasing importance of both deep neural networks (DNNs) and cloud\nservices for training them means that bad actors have more incentive and\nopportunity to insert backdoors to alter the behavior of trained models. In\nthis paper, we introduce a novel method for backdoor detection that extracts\nfeatures from pre-trained DNN's weights using independent vector analysis (IVA)\nfollowed by a machine learning classifier. In comparison to other detection\ntechniques, this has a number of benefits, such as not requiring any training\ndata, being applicable across domains, operating with a wide range of network\narchitectures, not assuming the nature of the triggers used to change network\nbehavior, and being highly scalable. We discuss the detection pipeline, and\nthen demonstrate the results on two computer vision datasets regarding image\nclassification and object detection. Our method outperforms the competing\nalgorithms in terms of efficiency and is more accurate, helping to ensure the\nsafe application of deep learning and AI.\n","authors":["Khondoker Murad Hossain","Tim Oates"],"pdf_url":"https://arxiv.org/pdf/2212.08121v1.pdf","comment":"7 pages, 4 figures, 5 tables, AAAI Workshop on Safe AI 2023"},{"id":"http://arxiv.org/abs/2205.14100v5","updated":"2022-12-15T19:21:35Z","published":"2022-05-27T17:03:38Z","title":"GIT: A Generative Image-to-text Transformer for Vision and Language","summary":"  In this paper, we design and train a Generative Image-to-text Transformer,\nGIT, to unify vision-language tasks such as image/video captioning and question\nanswering. While generative models provide a consistent network architecture\nbetween pre-training and fine-tuning, existing work typically contains complex\nstructures (uni/multi-modal encoder/decoder) and depends on external modules\nsuch as object detectors/taggers and optical character recognition (OCR). In\nGIT, we simplify the architecture as one image encoder and one text decoder\nunder a single language modeling task. We also scale up the pre-training data\nand the model size to boost the model performance. Without bells and whistles,\nour GIT establishes new state of the arts on 12 challenging benchmarks with a\nlarge margin. For instance, our model surpasses the human performance for the\nfirst time on TextCaps (138.2 vs. 125.5 in CIDEr). Furthermore, we present a\nnew scheme of generation-based image classification and scene text recognition,\nachieving decent performance on standard benchmarks. Codes are released at\n\\url{https://github.com/microsoft/GenerativeImage2Text}.\n","authors":["Jianfeng Wang","Zhengyuan Yang","Xiaowei Hu","Linjie Li","Kevin Lin","Zhe Gan","Zicheng Liu","Ce Liu","Lijuan Wang"],"pdf_url":"https://arxiv.org/pdf/2205.14100v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.05701v2","updated":"2022-12-15T19:03:06Z","published":"2022-03-11T01:19:04Z","title":"6-DoF Pose Estimation of Household Objects for Robotic Manipulation: An\n  Accessible Dataset and Benchmark","summary":"  We present a new dataset for 6-DoF pose estimation of known objects, with a\nfocus on robotic manipulation research. We propose a set of toy grocery\nobjects, whose physical instantiations are readily available for purchase and\nare appropriately sized for robotic grasping and manipulation. We provide 3D\nscanned textured models of these objects, suitable for generating synthetic\ntraining data, as well as RGBD images of the objects in challenging, cluttered\nscenes exhibiting partial occlusion, extreme lighting variations, multiple\ninstances per image, and a large variety of poses. Using semi-automated\nRGBD-to-model texture correspondences, the images are annotated with ground\ntruth poses accurate within a few millimeters. We also propose a new pose\nevaluation metric called ADD-H based on the Hungarian assignment algorithm that\nis robust to symmetries in object geometry without requiring their explicit\nenumeration. We share pre-trained pose estimators for all the toy grocery\nobjects, along with their baseline performance on both validation and test\nsets. We offer this dataset to the community to help connect the efforts of\ncomputer vision researchers with the needs of roboticists.\n","authors":["Stephen Tyree","Jonathan Tremblay","Thang To","Jia Cheng","Terry Mosier","Jeffrey Smith","Stan Birchfield"],"pdf_url":"https://arxiv.org/pdf/2203.05701v2.pdf","comment":"IROS 2022. Project page is at https://github.com/swtyree/hope-dataset"},{"id":"http://arxiv.org/abs/2102.07085v2","updated":"2022-12-15T15:44:21Z","published":"2021-02-14T06:44:47Z","title":"Light Field Reconstruction via Deep Adaptive Fusion of Hybrid Lenses","summary":"  This paper explores the problem of reconstructing high-resolution light field\n(LF) images from hybrid lenses, including a high-resolution camera surrounded\nby multiple low-resolution cameras. The performance of existing methods is\nstill limited, as they produce either blurry results on plain textured areas or\ndistortions around depth discontinuous boundaries. To tackle this challenge, we\npropose a novel end-to-end learning-based approach, which can comprehensively\nutilize the specific characteristics of the input from two complementary and\nparallel perspectives. Specifically, one module regresses a spatially\nconsistent intermediate estimation by learning a deep multidimensional and\ncross-domain feature representation, while the other module warps another\nintermediate estimation, which maintains the high-frequency textures, by\npropagating the information of the high-resolution view. We finally leverage\nthe advantages of the two intermediate estimations adaptively via the learned\nattention maps, leading to the final high-resolution LF image with satisfactory\nresults on both plain textured areas and depth discontinuous boundaries.\nBesides, to promote the effectiveness of our method trained with simulated\nhybrid data on real hybrid data captured by a hybrid LF imaging system, we\ncarefully design the network architecture and the training strategy. Extensive\nexperiments on both real and simulated hybrid data demonstrate the significant\nsuperiority of our approach over state-of-the-art ones. To the best of our\nknowledge, this is the first end-to-end deep learning method for LF\nreconstruction from a real hybrid input. We believe our framework could\npotentially decrease the cost of high-resolution LF data acquisition and\nbenefit LF data storage and transmission.\n","authors":["Jing Jin","Mantang Guo","Hui Liu","Junhui Hou","Hongkai Xiong"],"pdf_url":"https://arxiv.org/pdf/2102.07085v2.pdf","comment":"18 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:1907.09640"},{"id":"http://arxiv.org/abs/2212.07409v2","updated":"2022-12-15T12:22:08Z","published":"2022-12-14T18:49:50Z","title":"Self-Supervised Geometry-Aware Encoder for Style-Based 3D GAN Inversion","summary":"  StyleGAN has achieved great progress in 2D face reconstruction and semantic\nediting via image inversion and latent editing. While studies over extending 2D\nStyleGAN to 3D faces have emerged, a corresponding generic 3D GAN inversion\nframework is still missing, limiting the applications of 3D face reconstruction\nand semantic editing. In this paper, we study the challenging problem of 3D GAN\ninversion where a latent code is predicted given a single face image to\nfaithfully recover its 3D shapes and detailed textures. The problem is\nill-posed: innumerable compositions of shape and texture could be rendered to\nthe current image. Furthermore, with the limited capacity of a global latent\ncode, 2D inversion methods cannot preserve faithful shape and texture at the\nsame time when applied to 3D models. To solve this problem, we devise an\neffective self-training scheme to constrain the learning of inversion. The\nlearning is done efficiently without any real-world 2D-3D training pairs but\nproxy samples generated from a 3D GAN. In addition, apart from a global latent\ncode that captures the coarse shape and texture information, we augment the\ngeneration network with a local branch, where pixel-aligned features are added\nto faithfully reconstruct face details. We further consider a new pipeline to\nperform 3D view-consistent editing. Extensive experiments show that our method\noutperforms state-of-the-art inversion methods in both shape and texture\nreconstruction quality. Code and data will be released.\n","authors":["Yushi Lan","Xuyi Meng","Shuai Yang","Chen Change Loy","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2212.07409v2.pdf","comment":"An encoder-based 3D GAN inversion method. Project page:\n  https://nirvanalan.github.io/projects/E3DGE/index.html"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.07841v1","updated":"2022-12-15T13:57:07Z","published":"2022-12-15T13:57:07Z","title":"MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are\n  Better Dense Retrievers","summary":"  Dense retrieval aims to map queries and passages into low-dimensional vector\nspace for efficient similarity measuring, showing promising effectiveness in\nvarious large-scale retrieval tasks. Since most existing methods commonly adopt\npre-trained Transformers (e.g. BERT) for parameter initialization, some work\nfocuses on proposing new pre-training tasks for compressing the useful semantic\ninformation from passages into dense vectors, achieving remarkable\nperformances. However, it is still challenging to effectively capture the rich\nsemantic information and relations about passages into the dense vectors via\none single particular pre-training task. In this work, we propose a multi-task\npre-trained model, MASTER, that unifies and integrates multiple pre-training\ntasks with different learning objectives under the bottlenecked masked\nautoencoder architecture. Concretely, MASTER utilizes a multi-decoder\narchitecture to integrate three types of pre-training tasks: corrupted passages\nrecovering, related passage recovering and PLMs outputs recovering. By\nincorporating a shared deep encoder, we construct a representation bottleneck\nin our architecture, compressing the abundant semantic information across tasks\ninto dense vectors. The first two types of tasks concentrate on capturing the\nsemantic information of passages and relationships among them within the\npre-training corpus. The third one can capture the knowledge beyond the corpus\nfrom external PLMs (e.g. GPT-2). Extensive experiments on several large-scale\npassage retrieval datasets have shown that our approach outperforms the\nprevious state-of-the-art dense retrieval methods. Our code and data are\npublicly released in https://github.com/microsoft/SimXNS\n","authors":["Kun Zhou","Xiao Liu","Yeyun Gong","Wayne Xin Zhao","Daxin Jiang","Nan Duan","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2212.07841v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2212.07835v1","updated":"2022-12-15T13:44:28Z","published":"2022-12-15T13:44:28Z","title":"You were saying? -- Spoken Language in the V3C Dataset","summary":"  This paper presents an analysis of the distribution of spoken language in the\nV3C video retrieval benchmark dataset based on automatically generated\ntranscripts. It finds that a large portion of the dataset is covered by spoken\nlanguage. Since language transcripts can be quickly and accurately described,\nthis has implications for retrieval tasks such as known-item search.\n","authors":["Luca Rossetto"],"pdf_url":"https://arxiv.org/pdf/2212.07835v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07767v1","updated":"2022-12-15T12:37:28Z","published":"2022-12-15T12:37:28Z","title":"COLA: Improving Conversational Recommender Systems by Collaborative\n  Augmentation","summary":"  Conversational recommender systems (CRS) aim to employ natural language\nconversations to suggest suitable products to users. Understanding user\npreferences for prospective items and learning efficient item representations\nare crucial for CRS. Despite various attempts, earlier studies mostly learned\nitem representations based on individual conversations, ignoring item\npopularity embodied among all others. Besides, they still need support in\nefficiently capturing user preferences since the information reflected in a\nsingle conversation is limited. Inspired by collaborative filtering, we propose\na collaborative augmentation (COLA) method to simultaneously improve both item\nrepresentation learning and user preference modeling to address these issues.\nWe construct an interactive user-item graph from all conversations, which\naugments item representations with user-aware information, i.e., item\npopularity. To improve user preference modeling, we retrieve similar\nconversations from the training corpus, where the involved items and attributes\nthat reflect the user's potential interests are used to augment the user\nrepresentation through gate control. Extensive experiments on two benchmark\ndatasets demonstrate the effectiveness of our method. Our code and data are\navailable at https://github.com/DongdingLin/COLA.\n","authors":["Dongding Lin","Jian Wang","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2212.07767v1.pdf","comment":"Accepted by AAAI-2023"},{"id":"http://arxiv.org/abs/2212.07742v1","updated":"2022-12-15T11:45:10Z","published":"2022-12-15T11:45:10Z","title":"Analysis of information cascading and propagation barriers across\n  distinctive news events","summary":"  News reporting on events that occur in our society can have different styles\nand structures as well as different dynamics of news spreading over time. News\npublishers have the potential to spread their news and reach out to a large\nnumber of readers worldwide. In this paper we would like to understand how well\nthey are doing it and which kind of obstacles the news may encounter when\nspreading. The news to be spread wider cross multiple barriers such as\nlinguistic (the most evident one as they get published in other natural\nlanguages), economic, geographical, political, time zone, and cultural\nbarriers. Observing potential differences between spreading of news on\ndifferent events published by multiple publishers can bring insights into what\nmay influence the differences in the spreading patterns. There are multiple\nreasons, possibly many hidden, influencing the speed and geographical spread of\nnews. This paper studies information cascading and propagation barriers,\napplying the proposed methodology on three distinctive kinds of events: Global\nWarming, earthquakes, and FIFA World Cup.\n","authors":["Abdul Sittar","Dunja Mladenic","Marko Grobelnik"],"pdf_url":"https://arxiv.org/pdf/2212.07742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07679v1","updated":"2022-12-15T09:23:31Z","published":"2022-12-15T09:23:31Z","title":"Exact fixed-radius nearest neighbor search with an application to\n  clustering","summary":"  Fixed-radius nearest-neighbor search is a common database operation that\nretrieves all data points within a user-specified distance to a query point.\nThere are efficient approximate nearest neighbor search algorithms that provide\nfast query responses but they often have a very compute-intensive indexing\nphase and require parameter tuning. Therefore, exact brute force and tree-based\nsearch methods are still widely used. Here we propose a new fixed-radius\nnearest neighbor search method that significantly improves over brute force and\ntree-based methods in terms of index and query time, returns exact results, and\nrequires no parameter tuning. The method exploits a sorting of the data points\nby their first principal component, thereby facilitating a reduction in query\nsearch space. Further speedup is gained from an efficient implementation using\nhigh-level Basic Linear Algebra Subprograms (BLAS). We provide theoretical\nanalysis of our method and demonstrate its practical performance when used\nstand-alone and when applied within a clustering algorithm.\n","authors":["Xinye Chen","Stefan Güttel"],"pdf_url":"https://arxiv.org/pdf/2212.07679v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.01456"},{"id":"http://arxiv.org/abs/2212.08184v1","updated":"2022-12-15T23:00:33Z","published":"2022-12-15T23:00:33Z","title":"NBC-Softmax : Darkweb Author fingerprinting and migration tracking","summary":"  Metric learning aims to learn distances from the data, which enhances the\nperformance of similarity-based algorithms. An author style detection task is a\nmetric learning problem, where learning style features with small intra-class\nvariations and larger inter-class differences is of great importance to achieve\nbetter performance. Recently, metric learning based on softmax loss has been\nused successfully for style detection. While softmax loss can produce separable\nrepresentations, its discriminative power is relatively poor. In this work, we\npropose NBC-Softmax, a contrastive loss based clustering technique for softmax\nloss, which is more intuitive and able to achieve superior performance. Our\ntechnique meets the criterion for larger number of samples, thus achieving\nblock contrastiveness, which is proven to outperform pair-wise losses. It uses\nmini-batch sampling effectively and is scalable. Experiments on 4 darkweb\nsocial forums, with NBCSAuthor that uses the proposed NBC-Softmax for author\nand sybil detection, shows that our negative block contrastive approach\nconstantly outperforms state-of-the-art methods using the same network\narchitecture.\n  Our code is publicly available at : https://github.com/gayanku/NBC-Softmax\n","authors":["Gayan K. Kulatilleke","Shekhar S. Chandra","Marius Portmann"],"pdf_url":"https://arxiv.org/pdf/2212.08184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08475v1","updated":"2022-12-15T02:28:52Z","published":"2022-12-15T02:28:52Z","title":"Best-Answer Prediction in Q&A Sites Using User Information","summary":"  Community Question Answering (CQA) sites have spread and multiplied\nsignificantly in recent years. Sites like Reddit, Quora, and Stack Exchange are\nbecoming popular amongst people interested in finding answers to diverse\nquestions. One practical way of finding such answers is automatically\npredicting the best candidate given existing answers and comments. Many studies\nwere conducted on answer prediction in CQA but with limited focus on using the\nbackground information of the questionnaires. We address this limitation using\na novel method for predicting the best answers using the questioner's\nbackground information and other features, such as the textual content or the\nrelationships with other participants. Our answer classification model was\ntrained using the Stack Exchange dataset and validated using the Area Under the\nCurve (AUC) metric. The experimental results show that the proposed method\ncomplements previous methods by pointing out the importance of the\nrelationships between users, particularly throughout the level of involvement\nin different communities on Stack Exchange. Furthermore, we point out that\nthere is little overlap between user-relation information and the information\nrepresented by the shallow text features and the meta-features, such as time\ndifferences.\n","authors":["Rafik Hadfi","Ahmed Moustafa","Kai Yoshino","Takayuki Ito"],"pdf_url":"https://arxiv.org/pdf/2212.08475v1.pdf","comment":"22 pages, 3 figures, 4 tables"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2212.08066v1","updated":"2022-12-15T18:59:52Z","published":"2022-12-15T18:59:52Z","title":"Mod-Squad: Designing Mixture of Experts As Modular Multi-Task Learners","summary":"  Optimization in multi-task learning (MTL) is more challenging than\nsingle-task learning (STL), as the gradient from different tasks can be\ncontradictory. When tasks are related, it can be beneficial to share some\nparameters among them (cooperation). However, some tasks require additional\nparameters with expertise in a specific type of data or discrimination\n(specialization). To address the MTL challenge, we propose Mod-Squad, a new\nmodel that is Modularized into groups of experts (a 'Squad'). This structure\nallows us to formalize cooperation and specialization as the process of\nmatching experts and tasks. We optimize this matching process during the\ntraining of a single model. Specifically, we incorporate mixture of experts\n(MoE) layers into a transformer model, with a new loss that incorporates the\nmutual dependence between tasks and experts. As a result, only a small set of\nexperts are activated for each task. This prevents the sharing of the entire\nbackbone model between all tasks, which strengthens the model, especially when\nthe training set size and the number of tasks scale up. More interestingly, for\neach task, we can extract the small set of experts as a standalone model that\nmaintains the same performance as the large model. Extensive experiments on the\nTaskonomy dataset with 13 vision tasks and the PASCAL-Context dataset with 5\nvision tasks show the superiority of our approach.\n","authors":["Zitian Chen","Yikang Shen","Mingyu Ding","Zhenfang Chen","Hengshuang Zhao","Erik Learned-Miller","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2212.08066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08059v1","updated":"2022-12-15T18:59:12Z","published":"2022-12-15T18:59:12Z","title":"Rethinking Vision Transformers for MobileNet Size and Speed","summary":"  With the success of Vision Transformers (ViTs) in computer vision tasks,\nrecent arts try to optimize the performance and complexity of ViTs to enable\nefficient deployment on mobile devices. Multiple approaches are proposed to\naccelerate attention mechanism, improve inefficient designs, or incorporate\nmobile-friendly lightweight convolutions to form hybrid architectures. However,\nViT and its variants still have higher latency or considerably more parameters\nthan lightweight CNNs, even true for the years-old MobileNet. In practice,\nlatency and size are both crucial for efficient deployment on\nresource-constraint hardware. In this work, we investigate a central question,\ncan transformer models run as fast as MobileNet and maintain a similar size? We\nrevisit the design choices of ViTs and propose an improved supernet with low\nlatency and high parameter efficiency. We further introduce a fine-grained\njoint search strategy that can find efficient architectures by optimizing\nlatency and number of parameters simultaneously. The proposed models,\nEfficientFormerV2, achieve about $4\\%$ higher top-1 accuracy than MobileNetV2\nand MobileNetV2$\\times1.4$ on ImageNet-1K with similar latency and parameters.\nWe demonstrate that properly designed and optimized vision transformers can\nachieve high performance with MobileNet-level size and speed.\n","authors":["Yanyu Li","Ju Hu","Yang Wen","Georgios Evangelidis","Kamyar Salahi","Yanzhi Wang","Sergey Tulyakov","Jian Ren"],"pdf_url":"https://arxiv.org/pdf/2212.08059v1.pdf","comment":"Code is available at:\n  https://github.com/snap-research/EfficientFormer"},{"id":"http://arxiv.org/abs/2212.08057v1","updated":"2022-12-15T18:58:56Z","published":"2022-12-15T18:58:56Z","title":"Real-Time Neural Light Field on Mobile Devices","summary":"  Recent efforts in Neural Rendering Fields (NeRF) have shown impressive\nresults on novel view synthesis by utilizing implicit neural representation to\nrepresent 3D scenes. Due to the process of volumetric rendering, the inference\nspeed for NeRF is extremely slow, limiting the application scenarios of\nutilizing NeRF on resource-constrained hardware, such as mobile devices. Many\nworks have been conducted to reduce the latency of running NeRF models.\nHowever, most of them still require high-end GPU for acceleration or extra\nstorage memory, which is all unavailable on mobile devices. Another emerging\ndirection utilizes the neural light field (NeLF) for speedup, as only one\nforward pass is performed on a ray to predict the pixel color. Nevertheless, to\nreach a similar rendering quality as NeRF, the network in NeLF is designed with\nintensive computation, which is not mobile-friendly. In this work, we propose\nan efficient network that runs in real-time on mobile devices for neural\nrendering. We follow the setting of NeLF to train our network. Unlike existing\nworks, we introduce a novel network architecture that runs efficiently on\nmobile devices with low latency and small size, i.e., saving $15\\times \\sim\n24\\times$ storage compared with MobileNeRF. Our model achieves high-resolution\ngeneration while maintaining real-time inference for both synthetic and\nreal-world scenes on mobile devices, e.g., $18.04$ms (iPhone 13) for rendering\none $1008\\times756$ image of real 3D scenes. Additionally, we achieve similar\nimage quality as NeRF and better quality than MobileNeRF (PSNR $26.15$ vs.\n$25.91$ on the real-world forward-facing dataset).\n","authors":["Junli Cao","Huan Wang","Pavlo Chemerys","Vladislav Shakhrai","Ju Hu","Yun Fu","Denys Makoviichuk","Sergey Tulyakov","Jian Ren"],"pdf_url":"https://arxiv.org/pdf/2212.08057v1.pdf","comment":"Project page: https://snap-research.github.io/MobileR2L/"},{"id":"http://arxiv.org/abs/2212.08054v1","updated":"2022-12-15T18:58:07Z","published":"2022-12-15T18:58:07Z","title":"DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue","summary":"  Modern virtual assistants use internal semantic parsing engines to convert\nuser utterances to actionable commands. However, prior work has demonstrated\nthat semantic parsing is a difficult multilingual transfer task with low\ntransfer efficiency compared to other tasks. In global markets such as India\nand Latin America, this is a critical issue as switching between languages is\nprevalent for bilingual users. In this work we dramatically improve the\nzero-shot performance of a multilingual and codeswitched semantic parsing\nsystem using two stages of multilingual alignment. First, we show that\nconstrastive alignment pretraining improves both English performance and\ntransfer efficiency. We then introduce a constrained optimization approach for\nhyperparameter-free adversarial alignment during finetuning. Our Doubly Aligned\nMultilingual Parser (DAMP) improves mBERT transfer performance by 3x, 6x, and\n81x on the Spanglish, Hinglish and Multilingual Task Oriented Parsing\nbenchmarks respectively and outperforms XLM-R and mT5-Large using 3.2x fewer\nparameters.\n","authors":["William Held","Christopher Hidey","Fei Liu","Eric Zhu","Rahul Goel","Diyi Yang","Rushin Shah"],"pdf_url":"https://arxiv.org/pdf/2212.08054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04486v2","updated":"2022-12-15T18:57:30Z","published":"2022-12-08T18:56:37Z","title":"DP-RAFT: A Differentially Private Recipe for Accelerated Fine-Tuning","summary":"  A major direction in differentially private machine learning is\ndifferentially private fine-tuning: pretraining a model on a source of \"public\ndata\" and transferring the extracted features to downstream tasks.\n  This is an important setting because many industry deployments fine-tune\npublicly available feature extractors on proprietary data for downstream tasks.\n  In this paper, we carefully integrate techniques, both new and from prior\nwork, to solve benchmark tasks in computer vision and natural language\nprocessing using differentially private fine-tuning. Our key insight is that by\naccelerating training with the choice of key hyperparameters, we can quickly\ndrive the model parameters to regions in parameter space where the impact of\nnoise is minimized. We obtain new state-of-the art performance on CIFAR10,\nCIFAR100, FashionMNIST, STL10, and PersonaChat, including $99 \\%$ on CIFAR10\nfor $\\varepsilon=1, \\delta=1e-5$-DP.\n","authors":["Ashwinee Panda","Xinyu Tang","Vikash Sehwag","Saeed Mahloujifar","Prateek Mittal"],"pdf_url":"https://arxiv.org/pdf/2212.04486v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08049v1","updated":"2022-12-15T18:55:23Z","published":"2022-12-15T18:55:23Z","title":"Sliced Optimal Partial Transport","summary":"  Optimal transport (OT) has become exceedingly popular in machine learning,\ndata science, and computer vision. The core assumption in the OT problem is the\nequal total amount of mass in source and target measures, which limits its\napplication. Optimal Partial Transport (OPT) is a recently proposed solution to\nthis limitation. Similar to the OT problem, the computation of OPT relies on\nsolving a linear programming problem (often in high dimensions), which can\nbecome computationally prohibitive. In this paper, we propose an efficient\nalgorithm for calculating the OPT problem between two non-negative measures in\none dimension. Next, following the idea of sliced OT distances, we utilize\nslicing to define the sliced OPT distance. Finally, we demonstrate the\ncomputational and accuracy benefits of the sliced OPT-based method in various\nnumerical experiments. In particular, we show an application of our proposed\nSliced-OPT in noisy point cloud registration.\n","authors":["Yikun Bai","Bernard Schmitzer","Mathew Thorpe","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2212.08049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08046v1","updated":"2022-12-15T18:52:27Z","published":"2022-12-15T18:52:27Z","title":"Silhouette: Toward Performance-Conscious and Transferable CPU Embeddings","summary":"  Learned embeddings are widely used to obtain concise data representation and\nenable transfer learning between different data sets and tasks. In this paper,\nwe present Silhouette, our approach that leverages publicly-available\nperformance data sets to learn CPU embeddings. We show how these embeddings\nenable transfer learning between data sets of different types and sizes. Each\nof these scenarios leads to an improvement in accuracy for the target data set.\n","authors":["Tarikul Islam Papon","Abdul Wasay"],"pdf_url":"https://arxiv.org/pdf/2212.08046v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08032v1","updated":"2022-12-15T18:41:15Z","published":"2022-12-15T18:41:15Z","title":"Demonstration of machine-learning-enhanced Bayesian quantum state\n  estimation","summary":"  Machine learning (ML) has found broad applicability in quantum information\nscience in topics as diverse as experimental design, state classification, and\neven studies on quantum foundations. Here, we experimentally realize an\napproach for defining custom prior distributions that are automatically tuned\nusing ML for use with Bayesian quantum state estimation methods. Previously,\nresearchers have looked to Bayesian quantum state tomography due to its unique\nadvantages like natural uncertainty quantification, the return of reliable\nestimates under any measurement condition, and minimal mean-squared error.\nHowever, practical challenges related to long computation times and conceptual\nissues concerning how to incorporate prior knowledge most suitably can\novershadow these benefits. Using both simulated and experimental measurement\nresults, we demonstrate that ML-defined prior distributions reduce net\nconvergence times and provide a natural way to incorporate both implicit and\nexplicit information directly into the prior distribution. These results\nconstitute a promising path toward practical implementations of Bayesian\nquantum state tomography.\n","authors":["Sanjaya Lohani","Joseph M. Lukens","Atiyya A. Davis","Amirali Khannejad","Sangita Regmi","Daniel E. Jones","Ryan T. Glasser","Thomas A. Searles","Brian T. Kirby"],"pdf_url":"https://arxiv.org/pdf/2212.08032v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2212.08013v1","updated":"2022-12-15T18:18:38Z","published":"2022-12-15T18:18:38Z","title":"FlexiViT: One Model for All Patch Sizes","summary":"  Vision Transformers convert images to sequences by slicing them into patches.\nThe size of these patches controls a speed/accuracy tradeoff, with smaller\npatches leading to higher accuracy at greater computational cost, but changing\nthe patch size typically requires retraining the model. In this paper, we\ndemonstrate that simply randomizing the patch size at training time leads to a\nsingle set of weights that performs well across a wide range of patch sizes,\nmaking it possible to tailor the model to different compute budgets at\ndeployment time. We extensively evaluate the resulting model, which we call\nFlexiViT, on a wide range of tasks, including classification, image-text\nretrieval, open-world detection, panoptic segmentation, and semantic\nsegmentation, concluding that it usually matches, and sometimes outperforms,\nstandard ViT models trained at a single patch size in an otherwise identical\nsetup. Hence, FlexiViT training is a simple drop-in improvement for ViT that\nmakes it easy to add compute-adaptive capabilities to most models relying on a\nViT backbone architecture. Code and pre-trained models are available at\nhttps://github.com/google-research/big_vision\n","authors":["Lucas Beyer","Pavel Izmailov","Alexander Kolesnikov","Mathilde Caron","Simon Kornblith","Xiaohua Zhai","Matthias Minderer","Michael Tschannen","Ibrahim Alabdulmohsin","Filip Pavetic"],"pdf_url":"https://arxiv.org/pdf/2212.08013v1.pdf","comment":"Code and pre-trained models available at\n  https://github.com/google-research/big_vision. All authors made significant\n  technical contributions"},{"id":"http://arxiv.org/abs/2201.10737v5","updated":"2022-12-15T17:45:50Z","published":"2022-01-26T03:50:02Z","title":"Class-Aware Adversarial Transformers for Medical Image Segmentation","summary":"  Transformers have made remarkable progress towards modeling long-range\ndependencies within the medical image analysis domain. However, current\ntransformer-based models suffer from several disadvantages: (1) existing\nmethods fail to capture the important features of the images due to the naive\ntokenization scheme; (2) the models suffer from information loss because they\nonly consider single-scale feature representations; and (3) the segmentation\nlabel maps generated by the models are not accurate enough without considering\nrich semantic contexts and anatomical textures. In this work, we present\nCASTformer, a novel type of adversarial transformers, for 2D medical image\nsegmentation. First, we take advantage of the pyramid structure to construct\nmulti-scale representations and handle multi-scale variations. We then design a\nnovel class-aware transformer module to better learn the discriminative regions\nof objects with semantic structures. Lastly, we utilize an adversarial training\nstrategy that boosts segmentation accuracy and correspondingly allows a\ntransformer-based discriminator to capture high-level semantically correlated\ncontents and low-level anatomical features. Our experiments demonstrate that\nCASTformer dramatically outperforms previous state-of-the-art transformer-based\napproaches on three benchmarks, obtaining 2.54%-5.88% absolute improvements in\nDice over previous models. Further qualitative experiments provide a more\ndetailed picture of the model's inner workings, shed light on the challenges in\nimproved transparency, and demonstrate that transfer learning can greatly\nimprove performance and reduce the size of medical image datasets in training,\nmaking CASTformer a strong starting point for downstream medical image analysis\ntasks.\n","authors":["Chenyu You","Ruihan Zhao","Fenglin Liu","Siyuan Dong","Sandeep Chinchali","Ufuk Topcu","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2201.10737v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07992v1","updated":"2022-12-15T17:44:31Z","published":"2022-12-15T17:44:31Z","title":"Alternating Objectives Generates Stronger PGD-Based Adversarial Attacks","summary":"  Designing powerful adversarial attacks is of paramount importance for the\nevaluation of $\\ell_p$-bounded adversarial defenses. Projected Gradient Descent\n(PGD) is one of the most effective and conceptually simple algorithms to\ngenerate such adversaries. The search space of PGD is dictated by the steepest\nascent directions of an objective. Despite the plethora of objective function\nchoices, there is no universally superior option and robustness overestimation\nmay arise from ill-suited objective selection. Driven by this observation, we\npostulate that the combination of different objectives through a simple loss\nalternating scheme renders PGD more robust towards design choices. We\nexperimentally verify this assertion on a synthetic-data example and by\nevaluating our proposed method across 25 different $\\ell_{\\infty}$-robust\nmodels and 3 datasets. The performance improvement is consistent, when compared\nto the single loss counterparts. In the CIFAR-10 dataset, our strongest\nadversarial attack outperforms all of the white-box components of AutoAttack\n(AA) ensemble, as well as the most powerful attacks existing on the literature,\nachieving state-of-the-art results in the computational budget of our study\n($T=100$, no restarts).\n","authors":["Nikolaos Antoniou","Efthymios Georgiou","Alexandros Potamianos"],"pdf_url":"https://arxiv.org/pdf/2212.07992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07983v1","updated":"2022-12-15T17:31:54Z","published":"2022-12-15T17:31:54Z","title":"Vision Transformers are Parameter-Efficient Audio-Visual Learners","summary":"  Vision transformers (ViTs) have achieved impressive results on various\ncomputer vision tasks in the last several years. In this work, we study the\ncapability of frozen ViTs, pretrained only on visual data, to generalize to\naudio-visual data without finetuning any of its original parameters. To do so,\nwe propose a latent audio-visual hybrid (LAVISH) adapter that adapts pretrained\nViTs to audio-visual tasks by injecting a small number of trainable parameters\ninto every layer of a frozen ViT. To efficiently fuse visual and audio cues,\nour LAVISH adapter uses a small set of latent tokens, which form an attention\nbottleneck, thus, eliminating the quadratic cost of standard cross-attention.\nCompared to the existing modality-specific audio-visual methods, our approach\nachieves competitive or even better performance on various audio-visual tasks\nwhile using fewer tunable parameters and without relying on costly audio\npretraining or external audio encoders. Our code is available at\nhttps://genjib.github.io/project_page/LAVISH/\n","authors":["Yan-Bo Lin","Yi-Lin Sung","Jie Lei","Mohit Bansal","Gedas Bertasius"],"pdf_url":"https://arxiv.org/pdf/2212.07983v1.pdf","comment":"project page: https://genjib.github.io/project_page/LAVISH/"},{"id":"http://arxiv.org/abs/2212.07967v1","updated":"2022-12-15T17:01:56Z","published":"2022-12-15T17:01:56Z","title":"Distributed-Training-and-Execution Multi-Agent Reinforcement Learning\n  for Power Control in HetNet","summary":"  In heterogeneous networks (HetNets), the overlap of small cells and the macro\ncell causes severe cross-tier interference. Although there exist some\napproaches to address this problem, they usually require global channel state\ninformation, which is hard to obtain in practice, and get the sub-optimal power\nallocation policy with high computational complexity. To overcome these\nlimitations, we propose a multi-agent deep reinforcement learning (MADRL) based\npower control scheme for the HetNet, where each access point makes power\ncontrol decisions independently based on local information. To promote\ncooperation among agents, we develop a penalty-based Q learning (PQL) algorithm\nfor MADRL systems. By introducing regularization terms in the loss function,\neach agent tends to choose an experienced action with high reward when\nrevisiting a state, and thus the policy updating speed slows down. In this way,\nan agent's policy can be learned by other agents more easily, resulting in a\nmore efficient collaboration process. We then implement the proposed PQL in the\nconsidered HetNet and compare it with other distributed-training-and-execution\n(DTE) algorithms. Simulation results show that our proposed PQL can learn the\ndesired power control policy from a dynamic environment where the locations of\nusers change episodically and outperform existing DTE MADRL algorithms.\n","authors":["Kaidi Xu","Nguyen Van Huynh","Geoffrey Ye Li"],"pdf_url":"https://arxiv.org/pdf/2212.07967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07959v1","updated":"2022-12-15T16:49:23Z","published":"2022-12-15T16:49:23Z","title":"Scalable Bayesian Uncertainty Quantification for Neural Network\n  Potentials: Promise and Pitfalls","summary":"  Neural network (NN) potentials promise highly accurate molecular dynamics\n(MD) simulations within the computational complexity of classical MD force\nfields. However, when applied outside their training domain, NN potential\npredictions can be inaccurate, increasing the need for Uncertainty\nQuantification (UQ). Bayesian modeling provides the mathematical framework for\nUQ, but classical Bayesian methods based on Markov chain Monte Carlo (MCMC) are\ncomputationally intractable for NN potentials. By training graph NN potentials\nfor coarse-grained systems of liquid water and alanine dipeptide, we\ndemonstrate here that scalable Bayesian UQ via stochastic gradient MCMC\n(SG-MCMC) yields reliable uncertainty estimates for MD observables. We show\nthat cold posteriors can reduce the required training data size and that for\nreliable UQ, multiple Markov chains are needed. Additionally, we find that\nSG-MCMC and the Deep Ensemble method achieve comparable results, despite\nshorter training and less hyperparameter tuning of the latter. We show that\nboth methods can capture aleatoric and epistemic uncertainty reliably, but not\nsystematic uncertainty, which needs to be minimized by adequate modeling to\nobtain accurate credible intervals for MD observables. Our results represent a\nstep towards accurate UQ that is of vital importance for trustworthy NN\npotential-based MD simulations required for decision-making in practice.\n","authors":["Stephan Thaler","Gregor Doehner","Julija Zavadlav"],"pdf_url":"https://arxiv.org/pdf/2212.07959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07951v1","updated":"2022-12-15T16:34:39Z","published":"2022-12-15T16:34:39Z","title":"A Data Source Dependency Analysis Framework for Large Scale Data Science\n  Projects","summary":"  Dependency hell is a well-known pain point in the development of large\nsoftware projects and machine learning (ML) code bases are not immune from it.\nIn fact, ML applications suffer from an additional form, namely, \"data source\ndependency hell\". This term refers to the central role played by data and its\nunique quirks that often lead to unexpected failures of ML models which cannot\nbe explained by code changes. In this paper, we present an automated dependency\nmapping framework that allows MLOps engineers to monitor the whole dependency\nmap of their models in a fast paced engineering environment and thus mitigate\nahead of time the consequences of any data source changes (e.g., re-train\nmodel, ignore data, set default data etc.). Our system is based on a unified\nand generic approach, employing techniques from static analysis, from which\ndata sources can be identified reliably for any type of dependency on a wide\nrange of source languages and artefacts. The dependency mapping framework is\nexposed as a REST web API where the only input is the path to the Git\nrepository hosting the code base. Currently used by MLOps engineers at\nMicrosoft, we expect such dependency map APIs to be adopted more widely by\nMLOps engineers in the future.\n","authors":["Laurent Boué","Pratap Kunireddy","Pavle Subotić"],"pdf_url":"https://arxiv.org/pdf/2212.07951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1901.11457v8","updated":"2022-12-15T16:30:46Z","published":"2019-01-31T16:30:41Z","title":"Improving SGD convergence by online linear regression of gradients in\n  multiple statistically relevant directions","summary":"  Deep neural networks are usually trained with stochastic gradient descent\n(SGD), which minimizes objective function using very rough approximations of\ngradient, only averaging to the real gradient. Standard approaches like\nmomentum or ADAM only consider a single direction, and do not try to model\ndistance from extremum - neglecting valuable information from calculated\nsequence of gradients, often stagnating in some suboptimal plateau. Second\norder methods could exploit these missed opportunities, however, beside\nsuffering from very large cost and numerical instabilities, many of them\nattract to suboptimal points like saddles due to negligence of signs of\ncurvatures (as eigenvalues of Hessian).\n  Saddle-free Newton method is a rare example of addressing this issue -\nchanges saddle attraction into repulsion, and was shown to provide essential\nimprovement for final value this way. However, it neglects noise while\nmodelling second order behavior, focuses on Krylov subspace for numerical\nreasons, and requires costly eigendecomposion.\n  Maintaining SFN advantages, there are proposed inexpensive ways for\nexploiting these opportunities. Second order behavior is linear dependence of\nfirst derivative - we can optimally estimate it from sequence of noisy\ngradients with least square linear regression, in online setting here: with\nweakening weights of old gradients. Statistically relevant subspace is\nsuggested by PCA of recent noisy gradients - in online setting it can be made\nby slowly rotating considered directions toward new gradients, gradually\nreplacing old directions with recent statistically relevant. Eigendecomposition\ncan be also performed online: with regularly performed step of QR method to\nmaintain diagonal Hessian. Outside the second order modeled subspace we can\nsimultaneously perform gradient descent.\n","authors":["Jarek Duda"],"pdf_url":"https://arxiv.org/pdf/1901.11457v8.pdf","comment":"11 pages, 2 figure"},{"id":"http://arxiv.org/abs/2212.07946v1","updated":"2022-12-15T16:28:06Z","published":"2022-12-15T16:28:06Z","title":"Combining information-seeking exploration and reward maximization:\n  Unified inference on continuous state and action spaces under partial\n  observability","summary":"  Reinforcement learning (RL) gained considerable attention by creating\ndecision-making agents that maximize rewards received from fully observable\nenvironments. However, many real-world problems are partially or noisily\nobservable by nature, where agents do not receive the true and complete state\nof the environment. Such problems are formulated as partially observable Markov\ndecision processes (POMDPs). Some studies applied RL to POMDPs by recalling\nprevious decisions and observations or inferring the true state of the\nenvironment from received observations. Nevertheless, aggregating observations\nand decisions over time is impractical for environments with high-dimensional\ncontinuous state and action spaces. Moreover, so-called inference-based RL\napproaches require large number of samples to perform well since agents eschew\nuncertainty in the inferred state for the decision-making. Active inference is\na framework that is naturally formulated in POMDPs and directs agents to select\ndecisions by minimising expected free energy (EFE). This supplies\nreward-maximising (exploitative) behaviour in RL, with an information-seeking\n(exploratory) behaviour. Despite this exploratory behaviour of active\ninference, its usage is limited to discrete state and action spaces due to the\ncomputational difficulty of the EFE. We propose a unified principle for joint\ninformation-seeking and reward maximization that clarifies a theoretical\nconnection between active inference and RL, unifies active inference and RL,\nand overcomes their aforementioned limitations. Our findings are supported by\nstrong theoretical analysis. The proposed framework's superior exploration\nproperty is also validated by experimental results on partial observable tasks\nwith high-dimensional continuous state and action spaces. Moreover, the results\nshow that our model solves reward-free problems, making task reward design\noptional.\n","authors":["Parvin Malekzadeh","Konstantinos N. Plataniotis"],"pdf_url":"https://arxiv.org/pdf/2212.07946v1.pdf","comment":"34 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.07944v1","updated":"2022-12-15T16:23:25Z","published":"2022-12-15T16:23:25Z","title":"Variable Clustering via Distributionally Robust Nodewise Regression","summary":"  We study a multi-factor block model for variable clustering and connect it to\nthe regularized subspace clustering by formulating a distributionally robust\nversion of the nodewise regression. To solve the latter problem, we derive a\nconvex relaxation, provide guidance on selecting the size of the robust region,\nand hence the regularization weighting parameter, based on the data, and\npropose an ADMM algorithm for implementation. We validate our method in an\nextensive simulation study. Finally, we propose and apply a variant of our\nmethod to stock return data, obtain interpretable clusters that facilitate\nportfolio selection and compare its out-of-sample performance with other\nclustering methods in an empirical study.\n","authors":["Kaizheng Wang","Xiao Xu","Xun Yu Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.07944v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2212.07939v1","updated":"2022-12-15T16:17:03Z","published":"2022-12-15T16:17:03Z","title":"RWEN-TTS: Relation-aware Word Encoding Network for Natural\n  Text-to-Speech Synthesis","summary":"  With the advent of deep learning, a huge number of text-to-speech (TTS)\nmodels which produce human-like speech have emerged. Recently, by introducing\nsyntactic and semantic information w.r.t the input text, various approaches\nhave been proposed to enrich the naturalness and expressiveness of TTS models.\nAlthough these strategies showed impressive results, they still have some\nlimitations in utilizing language information. First, most approaches only use\ngraph networks to utilize syntactic and semantic information without\nconsidering linguistic features. Second, most previous works do not explicitly\nconsider adjacent words when encoding syntactic and semantic information, even\nthough it is obvious that adjacent words are usually meaningful when encoding\nthe current word. To address these issues, we propose Relation-aware Word\nEncoding Network (RWEN), which effectively allows syntactic and semantic\ninformation based on two modules (i.e., Semantic-level Relation Encoding and\nAdjacent Word Relation Encoding). Experimental results show substantial\nimprovements compared to previous works.\n","authors":["Shinhyeok Oh","HyeongRae Noh","Yoonseok Hong","Insoo Oh"],"pdf_url":"https://arxiv.org/pdf/2212.07939v1.pdf","comment":"Accepted to AAAI 2023"},{"id":"http://arxiv.org/abs/2212.07936v1","updated":"2022-12-15T16:11:40Z","published":"2022-12-15T16:11:40Z","title":"A Study on the Intersection of GPU Utilization and CNN Inference","summary":"  There has been significant progress in developing neural network\narchitectures that both achieve high predictive performance and that also\nachieve high application-level inference throughput (e.g., frames per second).\nAnother metric of increasing importance is GPU utilization during inference:\nthe measurement of how well a deployed neural network uses the computational\ncapabilities of the GPU on which it runs. Achieving high GPU utilization is\ncritical to increasing application-level throughput and ensuring a good return\non investment for deploying GPUs.\n  This paper analyzes the GPU utilization of convolutional neural network (CNN)\ninference. We first survey the GPU utilization of CNNs to show that there is\nroom to improve the GPU utilization of many of these CNNs. We then investigate\nthe GPU utilization of networks within a neural architecture search (NAS)\nsearch space, and explore how using GPU utilization as a metric could\npotentially be used to accelerate NAS itself. Our study makes the case that\nthere is room to improve the inference-time GPU utilization of CNNs and that\nknowledge of GPU utilization has the potential to benefit even applications\nthat do not target utilization itself. We hope that the results of this study\nwill spur future innovation in designing GPU-efficient neural networks.\n","authors":["Jack Kosaian","Amar Phanishayee"],"pdf_url":"https://arxiv.org/pdf/2212.07936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07933v1","updated":"2022-12-15T16:09:47Z","published":"2022-12-15T16:09:47Z","title":"Bridging POMDPs and Bayesian decision making for robust maintenance\n  planning under model uncertainty: An application to railway systems","summary":"  Structural Health Monitoring (SHM) describes a process for inferring\nquantifiable metrics of structural condition, which can serve as input to\nsupport decisions on the operation and maintenance of infrastructure assets.\nGiven the long lifespan of critical structures, this problem can be cast as a\nsequential decision making problem over prescribed horizons. Partially\nObservable Markov Decision Processes (POMDPs) offer a formal framework to solve\nthe underlying optimal planning task. However, two issues can undermine the\nPOMDP solutions. Firstly, the need for a model that can adequately describe the\nevolution of the structural condition under deterioration or corrective actions\nand, secondly, the non-trivial task of recovery of the observation process\nparameters from available monitoring data. Despite these potential challenges,\nthe adopted POMDP models do not typically account for uncertainty on model\nparameters, leading to solutions which can be unrealistically confident. In\nthis work, we address both key issues. We present a framework to estimate POMDP\ntransition and observation model parameters directly from available data, via\nMarkov Chain Monte Carlo (MCMC) sampling of a Hidden Markov Model (HMM)\nconditioned on actions. The MCMC inference estimates distributions of the\ninvolved model parameters. We then form and solve the POMDP problem by\nexploiting the inferred distributions, to derive solutions that are robust to\nmodel uncertainty. We successfully apply our approach on maintenance planning\nfor railway track assets on the basis of a \"fractal value\" indicator, which is\ncomputed from actual railway monitoring data.\n","authors":["Giacomo Arcieri","Cyprien Hoelzl","Oliver Schwery","Daniel Straub","Konstantinos G. Papakonstantinou","Eleni Chatzi"],"pdf_url":"https://arxiv.org/pdf/2212.07933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2002.10904v3","updated":"2022-12-15T16:00:42Z","published":"2020-02-25T14:44:25Z","title":"Reward Shaping for Human Learning via Inverse Reinforcement Learning","summary":"  Humans are spectacular reinforcement learners, constantly learning from and\nadjusting to experience and feedback. Unfortunately, this doesn't necessarily\nmean humans are fast learners. When tasks are challenging, learning can become\nunacceptably slow. Fortunately, humans do not have to learn tabula rasa, and\nlearning speed can be greatly increased with learning aids. In this work we\nvalidate a new type of learning aid -- reward shaping for humans via inverse\nreinforcement learning (IRL). The goal of this aid is to increase the speed\nwith which humans can learn good policies for specific tasks. Furthermore this\napproach compliments alternative machine learning techniques such as safety\nfeatures that try to prevent individuals from making poor decisions. To achieve\nour results we first extend a well known IRL algorithm via kernel methods.\nAfterwards we conduct two human subjects experiments using an online game where\nplayers have limited time to learn a good policy. We show with statistical\nsignificance that players who receive our learning aid are able to approach\ndesired policies more quickly than the control group.\n","authors":["Mark A. Rucker","Layne T. Watson","Matthew S. Gerber","Laura E. Barnes"],"pdf_url":"https://arxiv.org/pdf/2002.10904v3.pdf","comment":"This paper has been modified considerably for resubmission to Journal\n  of Machine Learning Research, for source code, see\n  https://github.com/mrucker/kpirl-kla"},{"id":"http://arxiv.org/abs/2212.07923v1","updated":"2022-12-15T15:55:44Z","published":"2022-12-15T15:55:44Z","title":"The Effects of Character-Level Data Augmentation on Style-Based Dating\n  of Historical Manuscripts","summary":"  Identifying the production dates of historical manuscripts is one of the main\ngoals for paleographers when studying ancient documents. Automatized methods\ncan provide paleographers with objective tools to estimate dates more\naccurately. Previously, statistical features have been used to date digitized\nhistorical manuscripts based on the hypothesis that handwriting styles change\nover periods. However, the sparse availability of such documents poses a\nchallenge in obtaining robust systems. Hence, the research of this article\nexplores the influence of data augmentation on the dating of historical\nmanuscripts. Linear Support Vector Machines were trained with k-fold\ncross-validation on textural and grapheme-based features extracted from\nhistorical manuscripts of different collections, including the Medieval\nPaleographical Scale, early Aramaic manuscripts, and the Dead Sea Scrolls.\nResults show that training models with augmented data improve the performance\nof historical manuscripts dating by 1% - 3% in cumulative scores. Additionally,\nthis indicates further enhancement possibilities by considering models specific\nto the features and the documents' scripts.\n","authors":["Lisa Koopmans","Maruf A. Dhali","Lambert Schomaker"],"pdf_url":"https://arxiv.org/pdf/2212.07923v1.pdf","comment":"Accepted after the peer-review process for ICPRAM 2023; scheduled to\n  be presented on 22 February 2023"},{"id":"http://arxiv.org/abs/2212.07919v1","updated":"2022-12-15T15:52:39Z","published":"2022-12-15T15:52:39Z","title":"ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning","summary":"  Large language models show improved downstream task performance when prompted\nto generate step-by-step reasoning to justify their final answers. These\nreasoning steps greatly improve model interpretability and verification, but\nobjectively studying their correctness (independent of the final answer) is\ndifficult without reliable methods for automatic evaluation. We simply do not\nknow how often the stated reasoning steps actually support the final end task\npredictions. In this work, we present ROSCOE, a suite of interpretable,\nunsupervised automatic scores that improve and extend previous text generation\nevaluation metrics. To evaluate ROSCOE against baseline metrics, we design a\ntypology of reasoning errors and collect synthetic and human evaluation scores\non commonly used reasoning datasets. In contrast with existing metrics, ROSCOE\ncan measure semantic consistency, logicality, informativeness, fluency, and\nfactuality - among other traits - by leveraging properties of step-by-step\nrationales. We empirically verify the strength of our metrics on five human\nannotated and six programmatically perturbed diagnostics datasets - covering a\ndiverse set of tasks that require reasoning skills and show that ROSCOE can\nconsistently outperform baseline metrics.\n","authors":["Olga Golovneva","Moya Chen","Spencer Poff","Martin Corredor","Luke Zettlemoyer","Maryam Fazel-Zarandi","Asli Celikyilmaz"],"pdf_url":"https://arxiv.org/pdf/2212.07919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07918v1","updated":"2022-12-15T15:52:18Z","published":"2022-12-15T15:52:18Z","title":"Construction of a Surrogate Model: Multivariate Time Series Prediction\n  with a Hybrid Model","summary":"  Recent developments of advanced driver-assistance systems necessitate an\nincreasing number of tests to validate new technologies. These tests cannot be\ncarried out on track in a reasonable amount of time and automotive groups rely\non simulators to perform most tests. The reliability of these simulators for\nconstantly refined tasks is becoming an issue and, to increase the number of\ntests, the industry is now developing surrogate models, that should mimic the\nbehavior of the simulator while being much faster to run on specific tasks.\n  In this paper we aim to construct a surrogate model to mimic and replace the\nsimulator. We first test several classical methods such as random forests,\nridge regression or convolutional neural networks. Then we build three hybrid\nmodels that use all these methods and combine them to obtain an efficient\nhybrid surrogate model.\n","authors":["Clara Carlier","Arnaud Franju","Matthieu Lerasle","Mathias Obrebski"],"pdf_url":"https://arxiv.org/pdf/2212.07918v1.pdf","comment":"6 pages, 8 figures, 7 tables"},{"id":"http://arxiv.org/abs/2212.06653v2","updated":"2022-12-15T15:36:36Z","published":"2022-12-10T22:50:00Z","title":"Spatiotemporal Residual Regularization with Dynamic Mixtures for Traffic\n  Forecasting","summary":"  Existing deep learning-based traffic forecasting models are mainly trained\nwith MSE (or MAE) as the loss function, assuming that residuals/errors follow\nindependent and isotropic Gaussian (or Laplacian) distribution for simplicity.\nHowever, this assumption rarely holds for real-world traffic forecasting tasks,\nwhere the unexplained residuals are often correlated in both space and time. In\nthis study, we propose Spatiotemporal Residual Regularization by modeling\nresiduals with a dynamic (e.g., time-varying) mixture of zero-mean multivariate\nGaussian distribution with learnable spatiotemporal covariance matrices. This\napproach allows us to directly capture spatiotemporally correlated residuals.\nFor scalability, we model the spatiotemporal covariance for each mixture\ncomponent using a Kronecker product structure, which significantly reduces the\nnumber of parameters and computation complexity. We evaluate the performance of\nthe proposed method on a traffic speed forecasting task. Our results show that,\nby properly modeling residual distribution, the proposed method not only\nimproves the model performance but also provides interpretable structures.\n","authors":["Seongjin Choi","Nicolas Saunier","Martin Trepanier","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.06653v2.pdf","comment":"8 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2206.10535v2","updated":"2022-12-15T15:25:28Z","published":"2022-06-21T17:08:23Z","title":"EpiGRAF: Rethinking training of 3D GANs","summary":"  A very recent trend in generative modeling is building 3D-aware generators\nfrom 2D image collections. To induce the 3D bias, such models typically rely on\nvolumetric rendering, which is expensive to employ at high resolutions. During\nthe past months, there appeared more than 10 works that address this scaling\nissue by training a separate 2D decoder to upsample a low-resolution image (or\na feature tensor) produced from a pure 3D generator. But this solution comes at\na cost: not only does it break multi-view consistency (i.e. shape and texture\nchange when the camera moves), but it also learns the geometry in a low\nfidelity. In this work, we show that it is possible to obtain a high-resolution\n3D generator with SotA image quality by following a completely different route\nof simply training the model patch-wise. We revisit and improve this\noptimization scheme in two ways. First, we design a location- and scale-aware\ndiscriminator to work on patches of different proportions and spatial\npositions. Second, we modify the patch sampling strategy based on an annealed\nbeta distribution to stabilize training and accelerate the convergence. The\nresulted model, named EpiGRAF, is an efficient, high-resolution, pure 3D\ngenerator, and we test it on four datasets (two introduced in this work) at\n$256^2$ and $512^2$ resolutions. It obtains state-of-the-art image quality,\nhigh-fidelity geometry and trains ${\\approx} 2.5 \\times$ faster than the\nupsampler-based counterparts. Project website:\nhttps://universome.github.io/epigraf.\n","authors":["Ivan Skorokhodov","Sergey Tulyakov","Yiqun Wang","Peter Wonka"],"pdf_url":"https://arxiv.org/pdf/2206.10535v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.07892v1","updated":"2022-12-15T15:21:28Z","published":"2022-12-15T15:21:28Z","title":"Multimodal Teacher Forcing for Reconstructing Nonlinear Dynamical\n  Systems","summary":"  Many, if not most, systems of interest in science are naturally described as\nnonlinear dynamical systems (DS). Empirically, we commonly access these systems\nthrough time series measurements, where often we have time series from\ndifferent types of data modalities simultaneously. For instance, we may have\nevent counts in addition to some continuous signal. While by now there are many\npowerful machine learning (ML) tools for integrating different data modalities\ninto predictive models, this has rarely been approached so far from the\nperspective of uncovering the underlying, data-generating DS (aka DS\nreconstruction). Recently, sparse teacher forcing (TF) has been suggested as an\nefficient control-theoretic method for dealing with exploding loss gradients\nwhen training ML models on chaotic DS. Here we incorporate this idea into a\nnovel recurrent neural network (RNN) training framework for DS reconstruction\nbased on multimodal variational autoencoders (MVAE). The forcing signal for the\nRNN is generated by the MVAE which integrates different types of simultaneously\ngiven time series data into a joint latent code optimal for DS reconstruction.\nWe show that this training method achieves significantly better reconstructions\non multimodal datasets generated from chaotic DS benchmarks than various\nalternative methods.\n","authors":["Manuel Brenner","Georgia Koppe","Daniel Durstewitz"],"pdf_url":"https://arxiv.org/pdf/2212.07892v1.pdf","comment":"Published as a workshop paper for the AAAI 2023 Workshop MLmDS"},{"id":"http://arxiv.org/abs/2212.07891v1","updated":"2022-12-15T15:20:58Z","published":"2022-12-15T15:20:58Z","title":"Emergent Behaviors in Multi-Agent Target Acquisition","summary":"  Only limited studies and superficial evaluations are available on agents'\nbehaviors and roles within a Multi-Agent System (MAS). We simulate a MAS using\nReinforcement Learning (RL) in a pursuit-evasion (a.k.a predator-prey pursuit)\ngame, which shares task goals with target acquisition, and we create different\nadversarial scenarios by replacing RL-trained pursuers' policies with two\ndistinct (non-RL) analytical strategies. Using heatmaps of agents' positions\n(state-space variable) over time, we are able to categorize an RL-trained\nevader's behaviors. The novelty of our approach entails the creation of an\ninfluential feature set that reveals underlying data regularities, which allow\nus to classify an agent's behavior. This classification may aid in catching the\n(enemy) targets by enabling us to identify and predict their behaviors, and\nwhen extended to pursuers, this approach towards identifying teammates'\nbehavior may allow agents to coordinate more effectively.\n","authors":["Piyush K. Sharma","Erin Zaroukian","Derrik E. Asher","Bryson Howell"],"pdf_url":"https://arxiv.org/pdf/2212.07891v1.pdf","comment":"This article appeared in the news at:\n  https://www.army.mil/article/258408/u_s_army_scientists_invent_a_method_to_characterize_ai_behavior"},{"id":"http://arxiv.org/abs/2211.10760v2","updated":"2022-12-15T15:00:12Z","published":"2022-11-19T18:18:52Z","title":"An experimental study on Synthetic Tabular Data Evaluation","summary":"  In this paper, we present the findings of various methodologies for measuring\nthe similarity of synthetic data generated from tabular data samples. We\nparticularly apply our research to the case where the synthetic data has many\nmore samples than the real data. This task has a special complexity: validating\nthe reliability of this synthetically generated data with a much higher number\nof samples than the original. We evaluated the most commonly used global\nmetrics found in the literature. We introduced a novel approach based on the\ndata's topological signature analysis. Topological data analysis has several\nadvantages in addressing this latter challenge. The study of qualitative\ngeometric information focuses on geometric properties while neglecting\nquantitative distance function values. This is especially useful with\nhigh-dimensional synthetic data where the sample size has been significantly\nincreased. It is comparable to introducing new data points into the data space\nwithin the limits set by the original data. Then, in large synthetic data\nspaces, points will be much more concentrated than in the original space, and\ntheir analysis will become much more sensitive to both the metrics used and\nnoise. Instead, the concept of \"closeness\" between points is used for\nqualitative geometric information. Finally, we suggest an approach based on\ndata Eigen vectors for evaluating the level of noise in synthetic data. This\napproach can also be used to assess the similarity of original and synthetic\ndata.\n","authors":["Javier Marin"],"pdf_url":"https://arxiv.org/pdf/2211.10760v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07876v1","updated":"2022-12-15T14:49:01Z","published":"2022-12-15T14:49:01Z","title":"Forgetful Forests: high performance learning data structures for\n  streaming data under concept drift","summary":"  Database research can help machine learning performance in many ways. One way\nis to design better data structures. This paper combines the use of incremental\ncomputation and sequential and probabilistic filtering to enable \"forgetful\"\ntree-based learning algorithms to cope with concept drift data (i.e., data\nwhose function from input to classification changes over time).\n  The forgetful algorithms described in this paper achieve high time\nperformance while maintaining high quality predictions on streaming data.\nSpecifically, the algorithms are up to 24 times faster than state-of-the-art\nincremental algorithms with at most a 2% loss of accuracy, or at least twice\nfaster without any loss of accuracy. This makes such structures suitable for\nhigh volume streaming applications.\n","authors":["Zhehu Yuan","Yinqi Sun","Dennis Shasha"],"pdf_url":"https://arxiv.org/pdf/2212.07876v1.pdf","comment":"21 pages, 12 Figures, 7 algorithms"},{"id":"http://arxiv.org/abs/2206.05124v2","updated":"2022-12-15T14:34:52Z","published":"2022-06-10T14:00:06Z","title":"Stochastic Zeroth order Descent with Structured Directions","summary":"  We introduce and analyze Structured Stochastic Zeroth order Descent (S-SZD),\na finite difference approach which approximates a stochastic gradient on a set\nof $l\\leq d$ orthogonal directions, where $d$ is the dimension of the ambient\nspace. These directions are randomly chosen, and may change at each step. For\nsmooth convex functions we prove almost sure convergence of the iterates and a\nconvergence rate on the function values of the form $O(d/l k^{-c})$ for every\n$c<1/2$, which is arbitrarily close to the one of Stochastic Gradient Descent\n(SGD) in terms of number of iterations. Our bound also shows the benefits of\nusing $l$ multiple directions instead of one. For non-convex functions\nsatisfying the Polyak-{\\L}ojasiewicz condition, we establish the first\nconvergence rates for stochastic zeroth order algorithms under such an\nassumption. We corroborate our theoretical findings in numerical simulations\nwhere assumptions are satisfied and on the real-world problem of\nhyper-parameter optimization, observing that S-SZD has very good practical\nperformances.\n","authors":["Marco Rando","Cesare Molinari","Silvia Villa","Lorenzo Rosasco"],"pdf_url":"https://arxiv.org/pdf/2206.05124v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07860v1","updated":"2022-12-15T14:28:56Z","published":"2022-12-15T14:28:56Z","title":"Multi-Level Association Rule Mining for Wireless Network Time Series\n  Data","summary":"  Key performance indicators(KPIs) are of great significance in the monitoring\nof wireless network service quality. The network service quality can be\nimproved by adjusting relevant configuration parameters(CPs) of the base\nstation. However, there are numerous CPs and different cells may affect each\nother, which bring great challenges to the association analysis of wireless\nnetwork data. In this paper, we propose an adjustable multi-level association\nrule mining framework, which can quantitatively mine association rules at each\nlevel with environmental information, including engineering parameters and\nperformance management(PMs), and it has interpretability at each level.\nSpecifically, We first cluster similar cells, then quantify KPIs and CPs, and\nintegrate expert knowledge into the association rule mining model, which\nimprove the robustness of the model. The experimental results in real world\ndataset prove the effectiveness of our method.\n","authors":["Chen Zhu","Chengbo Qiu","Shaoyu Dou","Minghao Liao"],"pdf_url":"https://arxiv.org/pdf/2212.07860v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2211.15089v3","updated":"2022-12-15T14:27:19Z","published":"2022-11-28T06:08:54Z","title":"Continuous diffusion for categorical data","summary":"  Diffusion models have quickly become the go-to paradigm for generative\nmodelling of perceptual signals (such as images and sound) through iterative\nrefinement. Their success hinges on the fact that the underlying physical\nphenomena are continuous. For inherently discrete and categorical data such as\nlanguage, various diffusion-inspired alternatives have been proposed. However,\nthe continuous nature of diffusion models conveys many benefits, and in this\nwork we endeavour to preserve it. We propose CDCD, a framework for modelling\ncategorical data with diffusion models that are continuous both in time and\ninput space. We demonstrate its efficacy on several language modelling tasks.\n","authors":["Sander Dieleman","Laurent Sartran","Arman Roshannai","Nikolay Savinov","Yaroslav Ganin","Pierre H. Richemond","Arnaud Doucet","Robin Strudel","Chris Dyer","Conor Durkan","Curtis Hawthorne","Rémi Leblond","Will Grathwohl","Jonas Adler"],"pdf_url":"https://arxiv.org/pdf/2211.15089v3.pdf","comment":"26 pages, 8 figures; corrections and additional information about\n  hyperparameters"},{"id":"http://arxiv.org/abs/2212.07852v1","updated":"2022-12-15T14:19:33Z","published":"2022-12-15T14:19:33Z","title":"The effects of gender bias in word embeddings on depression prediction","summary":"  Word embeddings are extensively used in various NLP problems as a\nstate-of-the-art semantic feature vector representation. Despite their success\non various tasks and domains, they might exhibit an undesired bias for\nstereotypical categories due to statistical and societal biases that exist in\nthe dataset they are trained on. In this study, we analyze the gender bias in\nfour different pre-trained word embeddings specifically for the depression\ncategory in the mental disorder domain. We use contextual and non-contextual\nembeddings that are trained on domain-independent as well as clinical\ndomain-specific data. We observe that embeddings carry bias for depression\ntowards different gender groups depending on the type of embeddings. Moreover,\nwe demonstrate that these undesired correlations are transferred to the\ndownstream task for depression phenotype recognition. We find that data\naugmentation by simply swapping gender words mitigates the bias significantly\nin the downstream task.\n","authors":["Gizem Sogancioglu","Heysem Kaya"],"pdf_url":"https://arxiv.org/pdf/2212.07852v1.pdf","comment":"accepted to and published at \"A Participatory Approach to AI for\n  Mental Health (PAI4MH)\" workshop, co-located with NeurIPS 2022"},{"id":"http://arxiv.org/abs/2210.03430v2","updated":"2022-12-15T14:14:55Z","published":"2022-10-07T10:01:06Z","title":"Monitoring MBE substrate deoxidation via RHEED image-sequence analysis\n  by deep learning","summary":"  Reflection high-energy electron diffraction (RHEED) is a powerful tool in\nmolecular beam epitaxy (MBE), but RHEED images are often difficult to\ninterpret, requiring experienced operators. We present an approach for\nautomated surveillance of GaAs substrate deoxidation in MBE reactors using deep\nlearning based RHEED image-sequence classification. Our approach consists of an\nnon-supervised auto-encoder (AE) for feature extraction, combined with a\nsupervised convolutional classifier network. We demonstrate that our\nlightweight network model can accurately identify the exact deoxidation moment.\nFurthermore we show that the approach is very robust and allows accurate\ndeoxidation detection during months without requiring re-training. The main\nadvantage of the approach is that it can be applied to raw RHEED images without\nrequiring further information such as the rotation angle, temperature, etc.\n","authors":["Abdourahman Khaireh-Walieh","Alexandre Arnoult","Sébastien Plissard","Peter R. Wiecha"],"pdf_url":"https://arxiv.org/pdf/2210.03430v2.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.07844v1","updated":"2022-12-15T14:05:32Z","published":"2022-12-15T14:05:32Z","title":"Differentiating Nonsmooth Solutions to Parametric Monotone Inclusion\n  Problems","summary":"  We leverage path differentiability and a recent result on nonsmooth implicit\ndifferentiation calculus to give sufficient conditions ensuring that the\nsolution to a monotone inclusion problem will be path differentiable, with\nformulas for computing its generalized gradient. A direct consequence of our\nresult is that these solutions happen to be differentiable almost everywhere.\nOur approach is fully compatible with automatic differentiation and comes with\nassumptions which are easy to check, roughly speaking: semialgebraicity and\nstrong monotonicity. We illustrate the scope of our results by considering\nthree fundamental composite problem settings: strongly convex problems, dual\nsolutions to convex minimization problems and primal-dual solutions to min-max\nproblems.\n","authors":["Jérôme Bolte","Edouard Pauwels","Antonio José Silveti-Falls"],"pdf_url":"https://arxiv.org/pdf/2212.07844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07839v1","updated":"2022-12-15T13:52:03Z","published":"2022-12-15T13:52:03Z","title":"TeTIm-Eval: a novel curated evaluation data set for comparing\n  text-to-image models","summary":"  Evaluating and comparing text-to-image models is a challenging problem.\nSignificant advances in the field have recently been made, piquing interest of\nvarious industrial sectors. As a consequence, a gold standard in the field\nshould cover a variety of tasks and application contexts. In this paper a novel\nevaluation approach is experimented, on the basis of: (i) a curated data set,\nmade by high-quality royalty-free image-text pairs, divided into ten\ncategories; (ii) a quantitative metric, the CLIP-score, (iii) a human\nevaluation task to distinguish, for a given text, the real and the generated\nimages. The proposed method has been applied to the most recent models, i.e.,\nDALLE2, Latent Diffusion, Stable Diffusion, GLIDE and Craiyon. Early\nexperimental results show that the accuracy of the human judgement is fully\ncoherent with the CLIP-score. The dataset has been made available to the\npublic.\n","authors":["Federico A. Galatolo","Mario G. C. A. Cimino","Edoardo Cogotti"],"pdf_url":"https://arxiv.org/pdf/2212.07839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07836v1","updated":"2022-12-15T13:46:15Z","published":"2022-12-15T13:46:15Z","title":"Spatially-resolved Thermometry from Line-of-Sight Emission Spectroscopy\n  via Machine Learning","summary":"  A methodology is proposed, which addresses the caveat that line-of-sight\nemission spectroscopy presents in that it cannot provide spatially resolved\ntemperature measurements in nonhomogeneous temperature fields. The aim of this\nresearch is to explore the use of data-driven models in measuring temperature\ndistributions in a spatially resolved manner using emission spectroscopy data.\nTwo categories of data-driven methods are analyzed: (i) Feature engineering and\nclassical machine learning algorithms, and (ii) end-to-end convolutional neural\nnetworks (CNN). In total, combinations of fifteen feature groups and fifteen\nclassical machine learning models, and eleven CNN models are considered and\ntheir performances explored. The results indicate that the combination of\nfeature engineering and machine learning provides better performance than the\ndirect use of CNN. Notably, feature engineering which is comprised of\nphysics-guided transformation, signal representation-based feature extraction\nand Principal Component Analysis is found to be the most effective. Moreover,\nit is shown that when using the extracted features, the ensemble-based, light\nblender learning model offers the best performance with RMSE, RE, RRMSE and R\nvalues of 64.3, 0.017, 0.025 and 0.994, respectively. The proposed method,\nbased on feature engineering and the light blender model, is capable of\nmeasuring nonuniform temperature distributions from low-resolution spectra,\neven when the species concentration distribution in the gas mixtures is\nunknown.\n","authors":["Ruiyuan Kang","Dimitrios C. Kyritsis","Panos Liatsis"],"pdf_url":"https://arxiv.org/pdf/2212.07836v1.pdf","comment":"19 pages, 10 figures, systematical investigation of feature\n  engineering and machine learning for realizing spatially-resolved thermometry\n  from line-of-sight spectroscopy"},{"id":"http://arxiv.org/abs/2205.12934v4","updated":"2022-12-15T13:39:22Z","published":"2022-05-25T17:37:08Z","title":"Amortized Inference for Causal Structure Learning","summary":"  Inferring causal structure poses a combinatorial search problem that\ntypically involves evaluating structures with a score or independence test. The\nresulting search is costly, and designing suitable scores or tests that capture\nprior knowledge is difficult. In this work, we propose to amortize causal\nstructure learning. Rather than searching over structures, we train a\nvariational inference model to directly predict the causal structure from\nobservational or interventional data. This allows our inference model to\nacquire domain-specific inductive biases for causal discovery solely from data\ngenerated by a simulator, bypassing both the hand-engineering of suitable score\nfunctions and the search over graphs. The architecture of our inference model\nemulates permutation invariances that are crucial for statistical efficiency in\nstructure learning, which facilitates generalization to significantly larger\nproblem instances than seen during training. On synthetic data and\nsemisynthetic gene expression data, our models exhibit robust generalization\ncapabilities when subject to substantial distribution shifts and significantly\noutperform existing algorithms, especially in the challenging genomics domain.\nOur code and models are publicly available at:\nhttps://github.com/larslorch/avici.\n","authors":["Lars Lorch","Scott Sussex","Jonas Rothfuss","Andreas Krause","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2205.12934v4.pdf","comment":"NeurIPS 2022, fixed formatting of Figure 5"},{"id":"http://arxiv.org/abs/2212.07826v1","updated":"2022-12-15T13:36:35Z","published":"2022-12-15T13:36:35Z","title":"Hybrid Quantum Generative Adversarial Networks for Molecular Simulation\n  and Drug Discovery","summary":"  In molecular research, simulation \\& design of molecules are key areas with\nsignificant implications for drug development, material science, and other\nfields. Current classical computational power falls inadequate to simulate any\nmore than small molecules, let alone protein chains on hundreds of peptide.\nTherefore these experiment are done physically in wet-lab, but it takes a lot\nof time \\& not possible to examine every molecule due to the size of the search\narea, tens of billions of dollars are spent every year in these research\nexperiments. Molecule simulation \\& design has lately advanced significantly by\nmachine learning models, A fresh perspective on the issue of chemical synthesis\nis provided by deep generative models for graph-structured data. By optimising\ndifferentiable models that produce molecular graphs directly, it is feasible to\navoid costly search techniques in the discrete and huge space of chemical\nstructures. But these models also suffer from computational limitations when\ndimensions become huge and consume huge amount of resources. Quantum Generative\nmachine learning in recent years have shown some empirical results promising\nsignificant advantages over classical counterparts.\n","authors":["Prateek Jain","Srinjoy Ganguly"],"pdf_url":"https://arxiv.org/pdf/2212.07826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07818v1","updated":"2022-12-15T13:34:02Z","published":"2022-12-15T13:34:02Z","title":"Towards Hardware-Specific Automatic Compression of Neural Networks","summary":"  Compressing neural network architectures is important to allow the deployment\nof models to embedded or mobile devices, and pruning and quantization are the\nmajor approaches to compress neural networks nowadays. Both methods benefit\nwhen compression parameters are selected specifically for each layer. Finding\ngood combinations of compression parameters, so-called compression policies, is\nhard as the problem spans an exponentially large search space. Effective\ncompression policies consider the influence of the specific hardware\narchitecture on the used compression methods. We propose an algorithmic\nframework called Galen to search such policies using reinforcement learning\nutilizing pruning and quantization, thus providing automatic compression for\nneural networks. Contrary to other approaches we use inference latency measured\non the target hardware device as an optimization goal. With that, the framework\nsupports the compression of models specific to a given hardware target. We\nvalidate our approach using three different reinforcement learning agents for\npruning, quantization and joint pruning and quantization. Besides proving the\nfunctionality of our approach we were able to compress a ResNet18 for CIFAR-10,\non an embedded ARM processor, to 20% of the original inference latency without\nsignificant loss of accuracy. Moreover, we can demonstrate that a joint search\nand compression using pruning and quantization is superior to an individual\nsearch for policies using a single compression method.\n","authors":["Torben Krieger","Bernhard Klein","Holger Fröning"],"pdf_url":"https://arxiv.org/pdf/2212.07818v1.pdf","comment":"To be published at the AAAI Conference on Artificial Intelligence\n  2023, at the 2nd International Workshop on Practical Deep Learning in the\n  Wild"},{"id":"http://arxiv.org/abs/2212.07816v1","updated":"2022-12-15T13:32:36Z","published":"2022-12-15T13:32:36Z","title":"DUIDD: Deep-Unfolded Interleaved Detection and Decoding for MIMO\n  Wireless Systems","summary":"  Iterative detection and decoding (IDD) is known to achieve near-capacity\nperformance in multi-antenna wireless systems. We propose deep-unfolded\ninterleaved detection and decoding (DUIDD), a new paradigm that reduces the\ncomplexity of IDD while achieving even lower error rates. DUIDD interleaves the\ninner stages of the data detector and channel decoder, which expedites\nconvergence and reduces complexity. Furthermore, DUIDD applies deep unfolding\nto automatically optimize algorithmic hyperparameters, soft-information\nexchange, message damping, and state forwarding. We demonstrate the efficacy of\nDUIDD using NVIDIA's Sionna link-level simulator in a 5G-near multi-user\nMIMO-OFDM wireless system with a novel low-complexity soft-input soft-output\ndata detector, an optimized low-density parity-check decoder, and channel\nvectors from a commercial ray-tracer. Our results show that DUIDD outperforms\nclassical IDD both in terms of block error rate and computational complexity.\n","authors":["Reinhard Wiesmayr","Chris Dick","Jakob Hoydis","Christoph Studer"],"pdf_url":"https://arxiv.org/pdf/2212.07816v1.pdf","comment":"This work has been presented at the Asilomar Conference on Signals,\n  Systems, and Computers 2022"},{"id":"http://arxiv.org/abs/2105.15013v6","updated":"2022-12-15T13:29:24Z","published":"2021-05-31T14:50:52Z","title":"SHAQ: Incorporating Shapley Value Theory into Multi-Agent Q-Learning","summary":"  Value factorisation is a useful technique for multi-agent reinforcement\nlearning (MARL) in global reward game, however its underlying mechanism is not\nyet fully understood. This paper studies a theoretical framework for value\nfactorisation with interpretability via Shapley value theory. We generalise\nShapley value to Markov convex game called Markov Shapley value (MSV) and apply\nit as a value factorisation method in global reward game, which is obtained by\nthe equivalence between the two games. Based on the properties of MSV, we\nderive Shapley-Bellman optimality equation (SBOE) to evaluate the optimal MSV,\nwhich corresponds to an optimal joint deterministic policy. Furthermore, we\npropose Shapley-Bellman operator (SBO) that is proved to solve SBOE. With a\nstochastic approximation and some transformations, a new MARL algorithm called\nShapley Q-learning (SHAQ) is established, the implementation of which is guided\nby the theoretical results of SBO and MSV. We also discuss the relationship\nbetween SHAQ and relevant value factorisation methods. In the experiments, SHAQ\nexhibits not only superior performances on all tasks but also the\ninterpretability that agrees with the theoretical analysis. The implementation\nof this paper is on https://github.com/hsvgbkhgbv/shapley-q-learning.\n","authors":["Jianhong Wang","Yuan Zhang","Yunjie Gu","Tae-Kyun Kim"],"pdf_url":"https://arxiv.org/pdf/2105.15013v6.pdf","comment":"Accepted paper for NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.07802v1","updated":"2022-12-15T13:15:45Z","published":"2022-12-15T13:15:45Z","title":"Chaotic Variational Auto Encoder based One Class Classifier for\n  Insurance Fraud Detection","summary":"  Of late, insurance fraud detection has assumed immense significance owing to\nthe huge financial & reputational losses fraud entails and the phenomenal\nsuccess of the fraud detection techniques. Insurance is majorly divided into\ntwo categories: (i) Life and (ii) Non-life. Non-life insurance in turn includes\nhealth insurance and auto insurance among other things. In either of the\ncategories, the fraud detection techniques should be designed in such a way\nthat they capture as many fraudulent transactions as possible. Owing to the\nrarity of fraudulent transactions, in this paper, we propose a chaotic\nvariational autoencoder (C-VAE to perform one-class classification (OCC) on\ngenuine transactions. Here, we employed the logistic chaotic map to generate\nrandom noise in the latent space. The effectiveness of C-VAE is demonstrated on\nthe health insurance fraud and auto insurance datasets. We considered vanilla\nVariational Auto Encoder (VAE) as the baseline. It is observed that C-VAE\noutperformed VAE in both datasets. C-VAE achieved a classification rate of\n77.9% and 87.25% in health and automobile insurance datasets respectively.\nFurther, the t-test conducted at 1% level of significance and 18 degrees of\nfreedom infers that C-VAE is statistically significant than the VAE.\n","authors":["K. S. N. V. K. Gangadhar","B. Akhil Kumar","Yelleti Vivek","Vadlamani Ravi"],"pdf_url":"https://arxiv.org/pdf/2212.07802v1.pdf","comment":"19 pages, 3 figures, 6 tables"},{"id":"http://arxiv.org/abs/2212.07775v1","updated":"2022-12-15T12:52:23Z","published":"2022-12-15T12:52:23Z","title":"Calibrating AI Models for Wireless Communications via Conformal\n  Prediction","summary":"  When used in complex engineered systems, such as communication networks,\nartificial intelligence (AI) models should be not only as accurate as possible,\nbut also well calibrated. A well-calibrated AI model is one that can reliably\nquantify the uncertainty of its decisions, assigning high confidence levels to\ndecisions that are likely to be correct and low confidence levels to decisions\nthat are likely to be erroneous. This paper investigates the application of\nconformal prediction as a general framework to obtain AI models that produce\ndecisions with formal calibration guarantees. Conformal prediction transforms\nprobabilistic predictors into set predictors that are guaranteed to contain the\ncorrect answer with a probability chosen by the designer. Such formal\ncalibration guarantees hold irrespective of the true, unknown, distribution\nunderlying the generation of the variables of interest, and can be defined in\nterms of ensemble or time-averaged probabilities. In this paper, conformal\nprediction is applied for the first time to the design of AI for communication\nsystems in conjunction to both frequentist and Bayesian learning, focusing on\ndemodulation, modulation classification, and channel prediction.\n","authors":["Kfir M. Cohen","Sangwoo Park","Osvaldo Simeone","Shlomo Shamai"],"pdf_url":"https://arxiv.org/pdf/2212.07775v1.pdf","comment":"Submitted for a journal review"},{"id":"http://arxiv.org/abs/2212.07773v1","updated":"2022-12-15T12:50:42Z","published":"2022-12-15T12:50:42Z","title":"Runtime Monitoring for Out-of-Distribution Detection in Object Detection\n  Neural Networks","summary":"  Runtime monitoring provides a more realistic and applicable alternative to\nverification in the setting of real neural networks used in industry. It is\nparticularly useful for detecting out-of-distribution (OOD) inputs, for which\nthe network was not trained and can yield erroneous results. We extend a\nruntime-monitoring approach previously proposed for classification networks to\nperception systems capable of identification and localization of multiple\nobjects. Furthermore, we analyze its adequacy experimentally on different kinds\nof OOD settings, documenting the overall efficacy of our approach.\n","authors":["Vahid Hashemi","Jan Křetínsky","Sabine Rieder","Jessica Schmidt"],"pdf_url":"https://arxiv.org/pdf/2212.07773v1.pdf","comment":"14 Pages, 1 Table, 5 Figures. Accepted at the International Symposium\n  of Formal Methods 2023 (FM 2023)"},{"id":"http://arxiv.org/abs/2212.07771v1","updated":"2022-12-15T12:47:59Z","published":"2022-12-15T12:47:59Z","title":"Put Attention to Temporal Saliency Patterns of Multi-Horizon Time Series","summary":"  Time series, sets of sequences in chronological order, are essential data in\nstatistical research with many forecasting applications. Although recent\nperformance in many Transformer-based models has been noticeable, long\nmulti-horizon time series forecasting remains a very challenging task. Going\nbeyond transformers in sequence translation and transduction research, we\nobserve the effects of down-and-up samplings that can nudge temporal saliency\npatterns to emerge in time sequences. Motivated by the mentioned observation,\nin this paper, we propose a novel architecture, Temporal Saliency Detection\n(TSD), on top of the attention mechanism and apply it to multi-horizon time\nseries prediction. We renovate the traditional encoder-decoder architecture by\nmaking as a series of deep convolutional blocks to work in tandem with the\nmulti-head self-attention. The proposed TSD approach facilitates the\nmultiresolution of saliency patterns upon condensed multi-heads, thus\nprogressively enhancing complex time series forecasting. Experimental results\nillustrate that our proposed approach has significantly outperformed existing\nstate-of-the-art methods across multiple standard benchmark datasets in many\nfar-horizon forecasting settings. Overall, TSD achieves 31% and 46% relative\nimprovement over the current state-of-the-art models in multivariate and\nunivariate time series forecasting scenarios on standard benchmarks. The Git\nrepository is available at\nhttps://github.com/duongtrung/time-series-temporal-saliency-patterns.\n","authors":["Nghia Duong-Trung","Stefan Born","Kiran Madhusudhanan","Randolf Scholz","Johannes Burchert","Danh Le-Phuoc","Lars Schmidt-Thieme"],"pdf_url":"https://arxiv.org/pdf/2212.07771v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2212.07769v1","updated":"2022-12-15T12:47:18Z","published":"2022-12-15T12:47:18Z","title":"CLAM: Selective Clarification for Ambiguous Questions with Large\n  Language Models","summary":"  State-of-the-art language models are often accurate on many\nquestion-answering benchmarks with well-defined questions. Yet, in real\nsettings questions are often unanswerable without asking the user for\nclarifying information. We show that current SotA models often do not ask the\nuser for clarification when presented with imprecise questions and instead\nprovide incorrect answers or \"hallucinate\". To address this, we introduce CLAM,\na framework that first uses the model to detect ambiguous questions, and if an\nambiguous question is detected, prompts the model to ask the user for\nclarification. Furthermore, we show how to construct a scalable and\ncost-effective automatic evaluation protocol using an oracle language model\nwith privileged information to provide clarifying information. We show that our\nmethod achieves a 20.15 percentage point accuracy improvement over SotA on a\nnovel ambiguous question-answering answering data set derived from TriviaQA.\n","authors":["Lorenz Kuhn","Yarin Gal","Sebastian Farquhar"],"pdf_url":"https://arxiv.org/pdf/2212.07769v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07768v1","updated":"2022-12-15T12:46:31Z","published":"2022-12-15T12:46:31Z","title":"A scalable framework for annotating photovoltaic cell defects in\n  electroluminescence images","summary":"  The correct functioning of photovoltaic (PV) cells is critical to ensuring\nthe optimal performance of a solar plant. Anomaly detection techniques for PV\ncells can result in significant cost savings in operation and maintenance\n(O&M). Recent research has focused on deep learning techniques for\nautomatically detecting anomalies in Electroluminescence (EL) images. Automated\nanomaly annotations can improve current O&M methodologies and help develop\ndecision-making systems to extend the life-cycle of the PV cells and predict\nfailures. This paper addresses the lack of anomaly segmentation annotations in\nthe literature by proposing a combination of state-of-the-art data-driven\ntechniques to create a Golden Standard benchmark. The proposed method stands\nout for (1) its adaptability to new PV cell types, (2) cost-efficient\nfine-tuning, and (3) leverage public datasets to generate advanced annotations.\nThe methodology has been validated in the annotation of a widely used dataset,\nobtaining a reduction of the annotation cost by 60%.\n","authors":["Urtzi Otamendi","Inigo Martinez","Igor G. Olaizola","Marco Quartulli"],"pdf_url":"https://arxiv.org/pdf/2212.07768v1.pdf","comment":"10 pages, 10 figures, 1 table, accepted at IEEE Transactions on\n  Industrial Informatics"},{"id":"http://arxiv.org/abs/2206.13500v2","updated":"2022-12-15T12:37:36Z","published":"2022-06-27T17:59:45Z","title":"Neural Neural Textures Make Sim2Real Consistent","summary":"  Unpaired image translation algorithms can be used for sim2real tasks, but\nmany fail to generate temporally consistent results. We present a new approach\nthat combines differentiable rendering with image translation to achieve\ntemporal consistency over indefinite timescales, using surface consistency\nlosses and \\emph{neural neural textures}. We call this algorithm TRITON\n(Texture Recovering Image Translation Network): an unsupervised, end-to-end,\nstateless sim2real algorithm that leverages the underlying 3D geometry of input\nscenes by generating realistic-looking learnable neural textures. By settling\non a particular texture for the objects in a scene, we ensure consistency\nbetween frames statelessly. Unlike previous algorithms, TRITON is not limited\nto camera movements -- it can handle the movement of objects as well, making it\nuseful for downstream tasks such as robotic manipulation.\n","authors":["Ryan Burgert","Jinghuan Shang","Xiang Li","Michael Ryoo"],"pdf_url":"https://arxiv.org/pdf/2206.13500v2.pdf","comment":"9 pages, 10 figures (without references or appendix); 16 pages, 16\n  figures (with appendix)"},{"id":"http://arxiv.org/abs/2212.07757v1","updated":"2022-12-15T12:21:27Z","published":"2022-12-15T12:21:27Z","title":"Spatial-Temporal Anomaly Detection for Sensor Attacks in Autonomous\n  Vehicles","summary":"  Time-of-flight (ToF) distance measurement devices such as ultrasonics, LiDAR\nand radar are widely used in autonomous vehicles for environmental perception,\nnavigation and assisted braking control. Despite their relative importance in\nmaking safer driving decisions, these devices are vulnerable to multiple attack\ntypes including spoofing, triggering and false data injection. When these\nattacks are successful they can compromise the security of autonomous vehicles\nleading to severe consequences for the driver, nearby vehicles and pedestrians.\nTo handle these attacks and protect the measurement devices, we propose a\nspatial-temporal anomaly detection model \\textit{STAnDS} which incorporates a\nresidual error spatial detector, with a time-based expected change detection.\nThis approach is evaluated using a simulated quantitative environment and the\nresults show that \\textit{STAnDS} is effective at detecting multiple attack\ntypes.\n","authors":["Martin Higgins","Devki Jha","David Wallom"],"pdf_url":"https://arxiv.org/pdf/2212.07757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07743v1","updated":"2022-12-15T11:50:31Z","published":"2022-12-15T11:50:31Z","title":"Interpretable ML for Imbalanced Data","summary":"  Deep learning models are being increasingly applied to imbalanced data in\nhigh stakes fields such as medicine, autonomous driving, and intelligence\nanalysis. Imbalanced data compounds the black-box nature of deep networks\nbecause the relationships between classes may be highly skewed and unclear.\nThis can reduce trust by model users and hamper the progress of developers of\nimbalanced learning algorithms. Existing methods that investigate imbalanced\ndata complexity are geared toward binary classification, shallow learning\nmodels and low dimensional data. In addition, current eXplainable Artificial\nIntelligence (XAI) techniques mainly focus on converting opaque deep learning\nmodels into simpler models (e.g., decision trees) or mapping predictions for\nspecific instances to inputs, instead of examining global data properties and\ncomplexities. Therefore, there is a need for a framework that is tailored to\nmodern deep networks, that incorporates large, high dimensional, multi-class\ndatasets, and uncovers data complexities commonly found in imbalanced data\n(e.g., class overlap, sub-concepts, and outlier instances). We propose a set of\ntechniques that can be used by both deep learning model users to identify,\nvisualize and understand class prototypes, sub-concepts and outlier instances;\nand by imbalanced learning algorithm developers to detect features and class\nexemplars that are key to model performance. Our framework also identifies\ninstances that reside on the border of class decision boundaries, which can\ncarry highly discriminative information. Unlike many existing XAI techniques\nwhich map model decisions to gray-scale pixel locations, we use saliency\nthrough back-propagation to identify and aggregate image color bands across\nentire classes. Our framework is publicly available at\n\\url{https://github.com/dd1github/XAI_for_Imbalanced_Learning}\n","authors":["Damien A. Dablain","Colin Bellinger","Bartosz Krawczyk","David W. Aha","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2212.07743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07740v1","updated":"2022-12-15T11:44:11Z","published":"2022-12-15T11:44:11Z","title":"Sim-to-Real Transfer for Quadrupedal Locomotion via Terrain Transformer","summary":"  Deep reinforcement learning has recently emerged as an appealing alternative\nfor legged locomotion over multiple terrains by training a policy in physical\nsimulation and then transferring it to the real world (i.e., sim-to-real\ntransfer). Despite considerable progress, the capacity and scalability of\ntraditional neural networks are still limited, which may hinder their\napplications in more complex environments. In contrast, the Transformer\narchitecture has shown its superiority in a wide range of large-scale sequence\nmodeling tasks, including natural language processing and decision-making\nproblems. In this paper, we propose Terrain Transformer (TERT), a high-capacity\nTransformer model for quadrupedal locomotion control on various terrains.\nFurthermore, to better leverage Transformer in sim-to-real scenarios, we\npresent a novel two-stage training framework consisting of an offline\npretraining stage and an online correction stage, which can naturally integrate\nTransformer with privileged training. Extensive experiments in simulation\ndemonstrate that TERT outperforms state-of-the-art baselines on different\nterrains in terms of return, energy consumption and control smoothness. In\nfurther real-world validation, TERT successfully traverses nine challenging\nterrains, including sand pit and stair down, which can not be accomplished by\nstrong baselines.\n","authors":["Hang Lai","Weinan Zhang","Xialin He","Chen Yu","Zheng Tian","Yong Yu","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2212.07740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07738v1","updated":"2022-12-15T11:40:40Z","published":"2022-12-15T11:40:40Z","title":"A large-scale and PCR-referenced vocal audio dataset for COVID-19","summary":"  The UK COVID-19 Vocal Audio Dataset is designed for the training and\nevaluation of machine learning models that classify SARS-CoV-2 infection status\nor associated respiratory symptoms using vocal audio. The UK Health Security\nAgency recruited voluntary participants through the national Test and Trace\nprogramme and the REACT-1 survey in England from March 2021 to March 2022,\nduring dominant transmission of the Alpha and Delta SARS-CoV-2 variants and\nsome Omicron variant sublineages. Audio recordings of volitional coughs,\nexhalations, and speech were collected in the 'Speak up to help beat\ncoronavirus' digital survey alongside demographic, self-reported symptom and\nrespiratory condition data, and linked to SARS-CoV-2 test results. The UK\nCOVID-19 Vocal Audio Dataset represents the largest collection of SARS-CoV-2\nPCR-referenced audio recordings to date. PCR results were linked to 70,794 of\n72,999 participants and 24,155 of 25,776 positive cases. Respiratory symptoms\nwere reported by 45.62% of participants. This dataset has additional potential\nuses for bioacoustics research, with 11.30% participants reporting asthma, and\n27.20% with linked influenza PCR test results.\n","authors":["Jobie Budd","Kieran Baker","Emma Karoune","Harry Coppock","Selina Patel","Ana Tendero Cañadas","Alexander Titcomb","Richard Payne","David Hurley","Sabrina Egglestone","Lorraine Butler","Jonathon Mellor","George Nicholson","Ivan Kiskin","Vasiliki Koutra","Radka Jersakova","Rachel A. McKendry","Peter Diggle","Sylvia Richardson","Björn W. Schuller","Steven Gilmour","Davide Pigoli","Stephen Roberts","Josef Packham","Tracey Thornley","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2212.07738v1.pdf","comment":"36 pages, 4 figures"},{"id":"http://arxiv.org/abs/2211.02486v3","updated":"2022-12-15T11:19:19Z","published":"2022-11-04T14:27:11Z","title":"Decorrelation with conditional normalizing flows","summary":"  The sensitivity of many physics analyses can be enhanced by constructing\ndiscriminants that preferentially select signal events. Such discriminants\nbecome much more useful if they are uncorrelated with a set of protected\nattributes. In this paper we show that a normalizing flow conditioned on the\nprotected attributes can be used to find a decorrelated representation for any\ndiscriminant. As a normalizing flow is invertible the separation power of the\nresulting discriminant will be unchanged at any fixed value of the protected\nattributes. We demonstrate the efficacy of our approach by building supervised\njet taggers that produce almost no sculpting in the mass distribution of the\nbackground.\n","authors":["Samuel Klein","Tobias Golling"],"pdf_url":"https://arxiv.org/pdf/2211.02486v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07723v1","updated":"2022-12-15T11:01:32Z","published":"2022-12-15T11:01:32Z","title":"Physics-Informed Neural Networks for Material Model Calibration from\n  Full-Field Displacement Data","summary":"  The identification of material parameters occurring in constitutive models\nhas a wide range of applications in practice. One of these applications is the\nmonitoring and assessment of the actual condition of infrastructure buildings,\nas the material parameters directly reflect the resistance of the structures to\nexternal impacts. Physics-informed neural networks (PINNs) have recently\nemerged as a suitable method for solving inverse problems. The advantages of\nthis method are a straightforward inclusion of observation data. Unlike\ngrid-based methods, such as the finite element method updating (FEMU) approach,\nno computational grid and no interpolation of the data is required. In the\ncurrent work, we aim to further develop PINNs towards the calibration of the\nlinear-elastic constitutive model from full-field displacement and global force\ndata in a realistic regime. We show that normalization and conditioning of the\noptimization problem play a crucial role in this process. Therefore, among\nothers, we identify the material parameters for initial estimates and balance\nthe individual terms in the loss function. In order to reduce the dependence of\nthe identified material parameters on local errors in the displacement\napproximation, we base the identification not on the stress boundary conditions\nbut instead on the global balance of internal and external work. In addition,\nwe found that we get a better posed inverse problem if we reformulate it in\nterms of bulk and shear modulus instead of Young's modulus and Poisson's ratio.\nWe demonstrate that the enhanced PINNs are capable of identifying material\nparameters from both experimental one-dimensional data and synthetic full-field\ndisplacement data in a realistic regime. Since displacement data measured by,\ne.g., a digital image correlation (DIC) system is noisy, we additionally\ninvestigate the robustness of the method to different levels of noise.\n","authors":["David Anton","Henning Wessels"],"pdf_url":"https://arxiv.org/pdf/2212.07723v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.13802v3","updated":"2022-12-15T10:54:22Z","published":"2021-11-27T03:34:13Z","title":"Factorized Fourier Neural Operators","summary":"  We propose the Factorized Fourier Neural Operator (F-FNO), a learning-based\napproach for simulating partial differential equations (PDEs). Starting from a\nrecently proposed Fourier representation of flow fields, the F-FNO bridges the\nperformance gap between pure machine learning approaches to that of the best\nnumerical or hybrid solvers. This is achieved with new representations -\nseparable spectral layers and improved residual connections - and a combination\nof training strategies such as the Markov assumption, Gaussian noise, and\ncosine learning rate decay. On several challenging benchmark PDEs on regular\ngrids, structured meshes, and point clouds, the F-FNO can scale to deeper\nnetworks and outperform both the FNO and the geo-FNO, reducing the error by 83%\non the Navier-Stokes problem, 31% on the elasticity problem, 57% on the airfoil\nflow problem, and 60% on the plastic forging problem. Compared to the\nstate-of-the-art pseudo-spectral method, the F-FNO can take a step size that is\nan order of magnitude larger in time and achieve an order of magnitude speedup\nto produce the same solution quality.\n","authors":["Alasdair Tran","Alexander Mathews","Lexing Xie","Cheng Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2111.13802v3.pdf","comment":"Under review. Code is available at\n  https://github.com/alasdairtran/fourierflow"},{"id":"http://arxiv.org/abs/2211.02024v2","updated":"2022-12-15T10:48:12Z","published":"2022-10-23T15:11:37Z","title":"fMRI from EEG is only Deep Learning away: the use of interpretable DL to\n  unravel EEG-fMRI relationships","summary":"  The access to activity of subcortical structures offers unique opportunity\nfor building intention dependent brain-computer interfaces, renders abundant\noptions for exploring a broad range of cognitive phenomena in the realm of\naffective neuroscience including complex decision making processes and the\neternal free-will dilemma and facilitates diagnostics of a range of\nneurological deceases. So far this was possible only using bulky, expensive and\nimmobile fMRI equipment. Here we present an interpretable domain grounded\nsolution to recover the activity of several subcortical regions from the\nmultichannel EEG data and demonstrate up to 60% correlation between the actual\nsubcortical blood oxygenation level dependent sBOLD signal and its EEG-derived\ntwin. Then, using the novel and theoretically justified weight interpretation\nmethodology we recover individual spatial and time-frequency patterns of scalp\nEEG predictive of the hemodynamic signal in the subcortical nuclei. The\ndescribed results not only pave the road towards wearable subcortical activity\nscanners but also showcase an automatic knowledge discovery process facilitated\nby deep learning technology in combination with an interpretable domain\nconstrained architecture and the appropriate downstream task.\n","authors":["Alexander Kovalev","Ilia Mikheev","Alexei Ossadtchi"],"pdf_url":"https://arxiv.org/pdf/2211.02024v2.pdf","comment":"11 pages. Add acknowledgment"},{"id":"http://arxiv.org/abs/2212.07707v1","updated":"2022-12-15T10:32:29Z","published":"2022-12-15T10:32:29Z","title":"FreCDo: A Large Corpus for French Cross-Domain Dialect Identification","summary":"  We present a novel corpus for French dialect identification comprising\n413,522 French text samples collected from public news websites in Belgium,\nCanada, France and Switzerland. To ensure an accurate estimation of the dialect\nidentification performance of models, we designed the corpus to eliminate\npotential biases related to topic, writing style, and publication source. More\nprecisely, the training, validation and test splits are collected from\ndifferent news websites, while searching for different keywords (topics). This\nleads to a French cross-domain (FreCDo) dialect identification task. We conduct\nexperiments with four competitive baselines, a fine-tuned CamemBERT model, an\nXGBoost based on fine-tuned CamemBERT features, a Support Vector Machines (SVM)\nclassifier based on fine-tuned CamemBERT features, and an SVM based on word\nn-grams. Aside from presenting quantitative results, we also make an analysis\nof the most discriminative features learned by CamemBERT. Our corpus is\navailable at https://github.com/MihaelaGaman/FreCDo.\n","authors":["Mihaela Gaman","Adrian-Gabriel Chifu","William Domingues","Radu Tudor Ionescu"],"pdf_url":"https://arxiv.org/pdf/2212.07707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.02248v2","updated":"2022-12-15T10:10:21Z","published":"2021-07-05T19:49:14Z","title":"A comparison of LSTM and GRU networks for learning symbolic sequences","summary":"  We explore relations between the hyper-parameters of a recurrent neural\nnetwork (RNN) and the complexity of string sequences it is able to memorize. We\ncompare long short-term memory (LSTM) networks and gated recurrent units\n(GRUs). We find that an increase of RNN depth does not necessarily result in\nbetter memorization capability when the training time is constrained. Our\nresults also indicate that the learning rate and the number of units per layer\nare among the most important hyper-parameters to be tuned. Generally, GRUs\noutperform LSTM networks on low complexity sequences while on high complexity\nsequences LSTMs perform better.\n","authors":["Roberto Cahuantzi","Xinye Chen","Stefan Güttel"],"pdf_url":"https://arxiv.org/pdf/2107.02248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07691v1","updated":"2022-12-15T09:53:49Z","published":"2022-12-15T09:53:49Z","title":"Anomaly Detection in Driving by Cluster Analysis Twice","summary":"  Events deviating from normal traffic patterns in driving, anomalies, such as\naggressive driving or bumpy roads, may harm delivery efficiency for\ntransportation and logistics (T&L) business. Thus, detecting anomalies in\ndriving is critical for the T&L industry. So far numerous researches have used\nvehicle sensor data to identify anomalies. Most previous works captured\nanomalies by using deep learning or machine learning algorithms, which require\nprior training processes and huge computational costs. This study proposes a\nmethod namely Anomaly Detection in Driving by Cluster Analysis Twice (ADDCAT)\nwhich clusters the processed sensor data in different physical properties. An\nevent is said to be an anomaly if it never fits with the major cluster, which\nis considered as the pattern of normality in driving. This method provides a\nway to detect anomalies in driving with no prior training processes and huge\ncomputational costs needed. This paper validated the performance of the method\non an open dataset.\n","authors":["Chung-Hao Lee","Yen-Fu Chen"],"pdf_url":"https://arxiv.org/pdf/2212.07691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07684v1","updated":"2022-12-15T09:35:54Z","published":"2022-12-15T09:35:54Z","title":"Multi-Agent Reinforcement Learning with Shared Resources for Inventory\n  Management","summary":"  In this paper, we consider the inventory management (IM) problem where we\nneed to make replenishment decisions for a large number of stock keeping units\n(SKUs) to balance their supply and demand. In our setting, the constraint on\nthe shared resources (such as the inventory capacity) couples the otherwise\nindependent control for each SKU. We formulate the problem with this structure\nas Shared-Resource Stochastic Game (SRSG)and propose an efficient algorithm\ncalled Context-aware Decentralized PPO (CD-PPO). Through extensive experiments,\nwe demonstrate that CD-PPO can accelerate the learning procedure compared with\nstandard MARL algorithms.\n","authors":["Yuandong Ding","Mingxiao Feng","Guozi Liu","Wei Jiang","Chuheng Zhang","Li Zhao","Lei Song","Houqiang Li","Yan Jin","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2212.07684v1.pdf","comment":"Published in RL4RealLife@NeurIPS 2022"},{"id":"http://arxiv.org/abs/2204.03276v3","updated":"2022-12-15T09:30:58Z","published":"2022-04-07T08:01:13Z","title":"PALBERT: Teaching ALBERT to Ponder","summary":"  Currently, pre-trained models can be considered the default choice for a wide\nrange of NLP tasks. Despite their SoTA results, there is practical evidence\nthat these models may require a different number of computing layers for\ndifferent input sequences, since evaluating all layers leads to overconfidence\nin wrong predictions (namely overthinking). This problem can potentially be\nsolved by implementing adaptive computation time approaches, which were first\ndesigned to improve inference speed. Recently proposed PonderNet may be a\npromising solution for performing an early exit by treating the exit layer's\nindex as a latent variable. However, the originally proposed exit criterion,\nrelying on sampling from trained posterior distribution on the probability of\nexiting from the $i$-th layer, introduces major variance in exit layer indices,\nsignificantly reducing the resulting model's performance. In this paper, we\npropose improving PonderNet with a novel deterministic Q-exit criterion and a\nrevisited model architecture. We adapted the proposed mechanism to ALBERT and\nRoBERTa and compared it with recent methods for performing an early exit. We\nobserved that the proposed changes can be considered significant improvements\non the original PonderNet architecture and outperform PABEE on a wide range of\nGLUE tasks. In addition, we also performed an in-depth ablation study of the\nproposed architecture to further understand Lambda layers and their\nperformance.\n","authors":["Nikita Balagansky","Daniil Gavrilov"],"pdf_url":"https://arxiv.org/pdf/2204.03276v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.04487v2","updated":"2022-12-15T09:25:15Z","published":"2022-01-12T14:16:47Z","title":"Smoothness and continuity of cost functionals for ECG mismatch\n  computation","summary":"  The field of cardiac electrophysiology tries to abstract, describe and\nfinally model the electrical characteristics of a heartbeat. With recent\nadvances in cardiac electrophysiology, models have become more powerful and\ndescriptive as ever. However, to advance to the field of inverse\nelectrophysiological modeling, i.e. creating models from electrical\nmeasurements such as the ECG, the less investigated field of smoothness of the\nsimulated ECGs w.r.t. model parameters need to be further explored. The present\npaper discusses smoothness in terms of the whole pipeline which describes how\nfrom physiological parameters, we arrive at the simulated ECG. Employing such a\npipeline, we create a test-bench of a simplified idealized left ventricle model\nand demonstrate the most important factors for efficient inverse modeling\nthrough smooth cost functionals. Such knowledge will be important for designing\nand creating inverse models in future optimization and machine learning\nmethods.\n","authors":["Thomas Grandits","Simone Pezzuto","Gernot Plank"],"pdf_url":"https://arxiv.org/pdf/2201.04487v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10911v4","updated":"2022-12-15T09:21:22Z","published":"2022-06-22T08:33:52Z","title":"Influence of uncertainty estimation techniques on false-positive\n  reduction in liver lesion detection","summary":"  Deep learning techniques show success in detecting objects in medical images,\nbut still suffer from false-positive predictions that may hinder accurate\ndiagnosis. The estimated uncertainty of the neural network output has been used\nto flag incorrect predictions. We study the role played by features computed\nfrom neural network uncertainty estimates and shape-based features computed\nfrom binary predictions in reducing false positives in liver lesion detection\nby developing a classification-based post-processing step for different\nuncertainty estimation methods. We demonstrate an improvement in the lesion\ndetection performance of the neural network (with respect to F1-score) for all\nuncertainty estimation methods on two datasets, comprising abdominal MR and CT\nimages, respectively. We show that features computed from neural network\nuncertainty estimates tend not to contribute much toward reducing false\npositives. Our results show that factors like class imbalance (true over false\npositive ratio) and shape-based features extracted from uncertainty maps play\nan important role in distinguishing false positive from true positive\npredictions. Our code can be found at https://github.com/ishaanb92/FPCPipeline.\n","authors":["Ishaan Bhat","Josien P. W. Pluim","Max A. Viergever","Hugo J. Kuijf"],"pdf_url":"https://arxiv.org/pdf/2206.10911v4.pdf","comment":"Accepted for publication in the Journal of Machine Learning for\n  Biomedical Imaging (MELBA)"},{"id":"http://arxiv.org/abs/2212.07677v1","updated":"2022-12-15T09:21:21Z","published":"2022-12-15T09:21:21Z","title":"Transformers learn in-context by gradient descent","summary":"  Transformers have become the state-of-the-art neural network architecture\nacross numerous domains of machine learning. This is partly due to their\ncelebrated ability to transfer and to learn in-context based on few examples.\nNevertheless, the mechanisms by which Transformers become in-context learners\nare not well understood and remain mostly an intuition. Here, we argue that\ntraining Transformers on auto-regressive tasks can be closely related to\nwell-known gradient-based meta-learning formulations. We start by providing a\nsimple weight construction that shows the equivalence of data transformations\ninduced by 1) a single linear self-attention layer and by 2) gradient-descent\n(GD) on a regression loss. Motivated by that construction, we show empirically\nthat when training self-attention-only Transformers on simple regression tasks\neither the models learned by GD and Transformers show great similarity or,\nremarkably, the weights found by optimization match the construction. Thus we\nshow how trained Transformers implement gradient descent in their forward pass.\nThis allows us, at least in the domain of regression problems, to\nmechanistically understand the inner workings of optimized Transformers that\nlearn in-context. Furthermore, we identify how Transformers surpass plain\ngradient descent by an iterative curvature correction and learn linear models\non deep data representations to solve non-linear regression tasks. Finally, we\ndiscuss intriguing parallels to a mechanism identified to be crucial for\nin-context learning termed induction-head (Olsson et al., 2022) and show how it\ncould be understood as a specific case of in-context learning by gradient\ndescent learning within Transformers.\n","authors":["Johannes von Oswald","Eyvind Niklasson","Ettore Randazzo","João Sacramento","Alexander Mordvintsev","Andrey Zhmoginov","Max Vladymyrov"],"pdf_url":"https://arxiv.org/pdf/2212.07677v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07127v2","updated":"2022-12-15T09:10:16Z","published":"2022-12-14T09:26:07Z","title":"Towards mapping the contemporary art world with ArtLM: an art-specific\n  NLP model","summary":"  With an increasing amount of data in the art world, discovering artists and\nartworks suitable to collectors' tastes becomes a challenge. It is no longer\nenough to use visual information, as contextual information about the artist\nhas become just as important in contemporary art. In this work, we present a\ngeneric Natural Language Processing framework (called ArtLM) to discover the\nconnections among contemporary artists based on their biographies. In this\napproach, we first continue to pre-train the existing general English language\nmodels with a large amount of unlabelled art-related data. We then fine-tune\nthis new pre-trained model with our biography pair dataset manually annotated\nby a team of professionals in the art industry. With extensive experiments, we\ndemonstrate that our ArtLM achieves 85.6% accuracy and 84.0% F1 score and\noutperforms other baseline models. We also provide a visualisation and a\nqualitative analysis of the artist network built from ArtLM's outputs.\n","authors":["Qinkai Chen","Mohamed El-Mennaoui","Antoine Fosset","Amine Rebei","Haoyang Cao","Christy Eóin O'Beirne","Sasha Shevchenko","Mathieu Rosenbaum"],"pdf_url":"https://arxiv.org/pdf/2212.07127v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06691v2","updated":"2022-12-15T08:35:42Z","published":"2022-12-13T16:04:16Z","title":"Quantum Clustering with k-Means: a Hybrid Approach","summary":"  Quantum computing is a promising paradigm based on quantum theory for\nperforming fast computations. Quantum algorithms are expected to surpass their\nclassical counterparts in terms of computational complexity for certain tasks,\nincluding machine learning. In this paper, we design, implement, and evaluate\nthree hybrid quantum k-Means algorithms, exploiting different degree of\nparallelism. Indeed, each algorithm incrementally leverages quantum parallelism\nto reduce the complexity of the cluster assignment step up to a constant cost.\nIn particular, we exploit quantum phenomena to speed up the computation of\ndistances. The core idea is that the computation of distances between records\nand centroids can be executed simultaneously, thus saving time, especially for\nbig datasets. We show that our hybrid quantum k-Means algorithms can be more\nefficient than the classical version, still obtaining comparable clustering\nresults.\n","authors":["Alessandro Poggiali","Alessandro Berti","Anna Bernasconi","Gianna M. Del Corso","Riccardo Guidotti"],"pdf_url":"https://arxiv.org/pdf/2212.06691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07658v1","updated":"2022-12-15T08:30:23Z","published":"2022-12-15T08:30:23Z","title":"Interpolation with the polynomial kernels","summary":"  The polynomial kernels are widely used in machine learning and they are one\nof the default choices to develop kernel-based classification and regression\nmodels. However, they are rarely used and considered in numerical analysis due\nto their lack of strict positive definiteness. In particular they do not enjoy\nthe usual property of unisolvency for arbitrary point sets, which is one of the\nkey properties used to build kernel-based interpolation methods. This paper is\ndevoted to establish some initial results for the study of these kernels, and\ntheir related interpolation algorithms, in the context of approximation theory.\nWe will first prove necessary and sufficient conditions on point sets which\nguarantee the existence and uniqueness of an interpolant. We will then study\nthe Reproducing Kernel Hilbert Spaces (or native spaces) of these kernels and\ntheir norms, and provide inclusion relations between spaces corresponding to\ndifferent kernel parameters. With these spaces at hand, it will be further\npossible to derive generic error estimates which apply to sufficiently smooth\nfunctions, thus escaping the native space. Finally, we will show how to employ\nan efficient stable algorithm to these kernels to obtain accurate interpolants,\nand we will test them in some numerical experiment. After this analysis several\ncomputational and theoretical aspects remain open, and we will outline possible\nfurther research directions in a concluding section. This work builds some\nbridges between kernel and polynomial interpolation, two topics to which the\nauthors, to different extents, have been introduced under the supervision or\nthrough the work of Stefano De Marchi. For this reason, they wish to dedicate\nthis work to him in the occasion of his 60th birthday.\n","authors":["Giacomo Elefante","Wolfgang Erb","Francesco Marchetti","Emma Perracchione","Davide Poggiali","Gabriele Santin"],"pdf_url":"https://arxiv.org/pdf/2212.07658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07651v1","updated":"2022-12-15T08:18:37Z","published":"2022-12-15T08:18:37Z","title":"Two-stage Contextual Transformer-based Convolutional Neural Network for\n  Airway Extraction from CT Images","summary":"  Accurate airway extraction from computed tomography (CT) images is a critical\nstep for planning navigation bronchoscopy and quantitative assessment of\nairway-related chronic obstructive pulmonary disease (COPD). The existing\nmethods are challenging to sufficiently segment the airway, especially the\nhigh-generation airway, with the constraint of the limited label and cannot\nmeet the clinical use in COPD. We propose a novel two-stage 3D contextual\ntransformer-based U-Net for airway segmentation using CT images. The method\nconsists of two stages, performing initial and refined airway segmentation. The\ntwo-stage model shares the same subnetwork with different airway masks as\ninput. Contextual transformer block is performed both in the encoder and\ndecoder path of the subnetwork to finish high-quality airway segmentation\neffectively. In the first stage, the total airway mask and CT images are\nprovided to the subnetwork, and the intrapulmonary airway mask and\ncorresponding CT scans to the subnetwork in the second stage. Then the\npredictions of the two-stage method are merged as the final prediction.\nExtensive experiments were performed on in-house and multiple public datasets.\nQuantitative and qualitative analysis demonstrate that our proposed method\nextracted much more branches and lengths of the tree while accomplishing\nstate-of-the-art airway segmentation performance. The code is available at\nhttps://github.com/zhaozsq/airway_segmentation.\n","authors":["Yanan Wu","Shuiqing Zhao","Shouliang Qi","Jie Feng","Haowen Pang","Runsheng Chang","Long Bai","Mengqi Li","Shuyue Xia","Wei Qian","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.07651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08624v2","updated":"2022-12-15T07:52:42Z","published":"2022-11-16T02:29:05Z","title":"Leveraging Heteroscedastic Uncertainty in Learning Complex Spectral\n  Mapping for Single-channel Speech Enhancement","summary":"  Most speech enhancement (SE) models learn a point estimate, and do not make\nuse of uncertainty estimation in the learning process. In this paper, we show\nthat modeling heteroscedastic uncertainty by minimizing a multivariate Gaussian\nnegative log-likelihood (NLL) improves SE performance at no extra cost. During\ntraining, our approach augments a model learning complex spectral mapping with\na temporary submodel to predict the covariance of the enhancement error at each\ntime-frequency bin. Due to unrestricted heteroscedastic uncertainty, the\ncovariance introduces an undersampling effect, detrimental to SE performance.\nTo mitigate undersampling, our approach inflates the uncertainty lower bound\nand weights each loss component with their uncertainty, effectively\ncompensating severely undersampled components with more penalties. Our\nmultivariate setting reveals common covariance assumptions such as scalar and\ndiagonal matrices. By weakening these assumptions, we show that the NLL\nachieves superior performance compared to popular losses including the mean\nsquared error (MSE), mean absolute error (MAE), and scale-invariant\nsignal-to-distortion ratio (SI-SDR).\n","authors":["Kuan-Lin Chen","Daniel D. E. Wong","Ke Tan","Buye Xu","Anurag Kumar","Vamsi Krishna Ithapu"],"pdf_url":"https://arxiv.org/pdf/2211.08624v2.pdf","comment":"5 pages. Submitted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2211.00641v4","updated":"2022-12-15T07:18:28Z","published":"2022-10-30T13:15:19Z","title":"Transposed Variational Auto-encoder with Intrinsic Feature Learning for\n  Traffic Forecasting","summary":"  In this technical report, we present our solutions to the Traffic4cast 2022\ncore challenge and extended challenge. In this competition, the participants\nare required to predict the traffic states for the future 15-minute based on\nthe vehicle counter data in the previous hour. Compared to other competitions\nin the same series, this year focuses on the prediction of different data\nsources and sparse vertex-to-edge generalization. To address these issues, we\nintroduce the Transposed Variational Auto-encoder (TVAE) model to reconstruct\nthe missing data and Graph Attention Networks (GAT) to strengthen the\ncorrelations between learned representations. We further apply feature\nselection to learn traffic patterns from diverse but easily available data.\n  Our solutions have ranked first in both challenges on the final leaderboard.\nThe source code is available at \\url{https://github.com/Daftstone/Traffic4cast}\n","authors":["Leyan Deng","Chenwang Wu","Defu Lian","Min Zhou"],"pdf_url":"https://arxiv.org/pdf/2211.00641v4.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.07635v1","updated":"2022-12-15T07:03:54Z","published":"2022-12-15T07:03:54Z","title":"Let's consider more general nonlinear approaches to study\n  teleconnections of climate variables","summary":"  The recent work by (Rieger et al 2021) is concerned with the problem of\nextracting features from spatio-temporal geophysical signals. The authors\nintroduce the complex rotated MCA (xMCA) to deal with lagged effects and\nnon-orthogonality of the feature representation. This method essentially (1)\ntransforms the signals to a complex plane with the Hilbert transform; (2)\napplies an oblique (Varimax and Promax) rotation to remove the orthogonality\nconstraint; and (3) performs the eigendecomposition in this complex space\n(Horel et al, 1984). We argue that this method is essentially a particular case\nof the method called rotated complex kernel principal component analysis\n(ROCK-PCA) introduced in (Bueso et al., 2019, 2020), where we proposed the same\napproach: first transform the data to the complex plane with the Hilbert\ntransform and then apply the varimax rotation, with the only difference that\nthe eigendecomposition is performed in the dual (kernel) Hilbert space. The\nlatter allows us to generalize the xMCA solution by extracting nonlinear\n(curvilinear) features when nonlinear kernel functions are used. Hence, the\nsolution of xMCA boils down to ROCK-PCA when the inner product is computed in\nthe input data space instead of in the high-dimensional (possibly infinite)\nkernel Hilbert space to which data has been mapped. In this short\ncorrespondence we show theoretical proof that xMCA is a special case of\nROCK-PCA and provide quantitative evidence that more expressive and informative\nfeatures can be extracted when working with kernels; results of the\ndecomposition of global sea surface temperature (SST) fields are shown to\nillustrate the capabilities of ROCK-PCA to cope with nonlinear processes,\nunlike xMCA.\n","authors":["D. Bueso","M. Piles","G. Camps-Valls"],"pdf_url":"https://arxiv.org/pdf/2212.07635v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2011.10219v2","updated":"2022-12-15T06:53:30Z","published":"2020-11-20T04:58:13Z","title":"Certified Monotonic Neural Networks","summary":"  Learning monotonic models with respect to a subset of the inputs is a\ndesirable feature to effectively address the fairness, interpretability, and\ngeneralization issues in practice. Existing methods for learning monotonic\nneural networks either require specifically designed model structures to ensure\nmonotonicity, which can be too restrictive/complicated, or enforce monotonicity\nby adjusting the learning process, which cannot provably guarantee the learned\nmodel is monotonic on selected features. In this work, we propose to certify\nthe monotonicity of the general piece-wise linear neural networks by solving a\nmixed integer linear programming problem.This provides a new general approach\nfor learning monotonic neural networks with arbitrary model structures. Our\nmethod allows us to train neural networks with heuristic monotonicity\nregularizations, and we can gradually increase the regularization magnitude\nuntil the learned network is certified monotonic. Compared to prior works, our\napproach does not require human-designed constraints on the weight space and\nalso yields more accurate approximation. Empirical studies on various datasets\ndemonstrate the efficiency of our approach over the state-of-the-art methods,\nsuch as Deep Lattice Networks.\n","authors":["Xingchao Liu","Xing Han","Na Zhang","Qiang Liu"],"pdf_url":"https://arxiv.org/pdf/2011.10219v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07632v1","updated":"2022-12-15T06:36:14Z","published":"2022-12-15T06:36:14Z","title":"Ungeneralizable Contextual Logistic Bandit in Credit Scoring","summary":"  The application of reinforcement learning in credit scoring has created a\nunique setting for contextual logistic bandit that does not conform to the\nusual exploration-exploitation tradeoff but rather favors exploration-free\nalgorithms. Through sufficient randomness in a pool of observable contexts, the\nreinforcement learning agent can simultaneously exploit an action with the\nhighest reward while still learning more about the structure governing that\nenvironment. Thus, it is the case that greedy algorithms consistently\noutperform algorithms with efficient exploration, such as Thompson sampling.\nHowever, in a more pragmatic scenario in credit scoring, lenders can, to a\ndegree, classify each borrower as a separate group, and learning about the\ncharacteristics of each group does not infer any information to another group.\nThrough extensive simulations, we show that Thompson sampling dominates over\ngreedy algorithms given enough timesteps which increase with the complexity of\nunderlying features.\n","authors":["Pojtanut Manopanjasiri","Kantapong Visantavarakul","Seksan Kiatsupaibul"],"pdf_url":"https://arxiv.org/pdf/2212.07632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05814v2","updated":"2022-12-15T06:02:33Z","published":"2022-12-12T10:24:47Z","title":"GWRBoost:A geographically weighted gradient boosting method for\n  explainable quantification of spatially-varying relationships","summary":"  The geographically weighted regression (GWR) is an essential tool for\nestimating the spatial variation of relationships between dependent and\nindependent variables in geographical contexts. However, GWR suffers from the\nproblem that classical linear regressions, which compose the GWR model, are\nmore prone to be underfitting, especially for significant volume and complex\nnonlinear data, causing inferior comparative performance. Nevertheless, some\nadvanced models, such as the decision tree and the support vector machine, can\nlearn features from complex data more effectively while they cannot provide\nexplainable quantification for the spatial variation of localized\nrelationships. To address the above issues, we propose a geographically\ngradient boosting weighted regression model, GWRBoost, that applies the\nlocalized additive model and gradient boosting optimization method to alleviate\nunderfitting problems and retains explainable quantification capability for\nspatially-varying relationships between geographically located variables.\nFurthermore, we formulate the computation method of the Akaike information\nscore for the proposed model to conduct the comparative analysis with the\nclassic GWR algorithm. Simulation experiments and the empirical case study are\napplied to prove the efficient performance and practical value of GWRBoost. The\nresults show that our proposed model can reduce the RMSE by 18.3% in parameter\nestimation accuracy and AICc by 67.3% in the goodness of fit.\n","authors":["Han Wang","Zhou Huang","Ganmin Yin","Yi Bao","Xiao Zhou","Yong Gao"],"pdf_url":"https://arxiv.org/pdf/2212.05814v2.pdf","comment":"13 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2212.07624v1","updated":"2022-12-15T05:54:16Z","published":"2022-12-15T05:54:16Z","title":"JAX-Accelerated Neuroevolution of Physics-informed Neural Networks:\n  Benchmarks and Experimental Results","summary":"  This paper introduces the use of evolutionary algorithms for solving\ndifferential equations. The solution is obtained by optimizing a deep neural\nnetwork whose loss function is defined by the residual terms from the\ndifferential equations. Recent studies have used stochastic gradient descent\n(SGD) variants to train these physics-informed neural networks (PINNs), but\nthese methods can struggle to find accurate solutions due to optimization\nchallenges. When solving differential equations, it is important to find the\nglobally optimum parameters of the network, rather than just finding a solution\nthat works well during training. SGD only searches along a single gradient\ndirection, so it may not be the best approach for training PINNs with their\naccompanying complex optimization landscapes. In contrast, evolutionary\nalgorithms perform a parallel exploration of different solutions in order to\navoid getting stuck in local optima and can potentially find more accurate\nsolutions. However, evolutionary algorithms can be slow, which can make them\ndifficult to use in practice. To address this, we provide a set of five\nbenchmark problems with associated performance metrics and baseline results to\nsupport the development of evolutionary algorithms for enhanced PINN training.\nAs a baseline, we evaluate the performance and speed of using the widely\nadopted Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for solving\nPINNs. We provide the loss and training time for CMA-ES run on TensorFlow, and\nCMA-ES and SGD run on JAX (with GPU acceleration) for the five benchmark\nproblems. Our results show that JAX-accelerated evolutionary algorithms,\nparticularly CMA-ES, can be a useful approach for solving differential\nequations. We hope that our work will support the exploration and development\nof alternative optimization algorithms for the complex task of optimizing\nPINNs.\n","authors":["Nicholas Sung Wei Yong","Jian Cheng Wong","Pao-Hsiung Chiu","Abhishek Gupta","Chinchun Ooi","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2212.07624v1.pdf","comment":"11 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2212.07619v1","updated":"2022-12-15T05:11:04Z","published":"2022-12-15T05:11:04Z","title":"Curriculum Learning Meets Weakly Supervised Modality Correlation\n  Learning","summary":"  In the field of multimodal sentiment analysis (MSA), a few studies have\nleveraged the inherent modality correlation information stored in samples for\nself-supervised learning. However, they feed the training pairs in a random\norder without consideration of difficulty. Without human annotation, the\ngenerated training pairs of self-supervised learning often contain noise. If\nnoisy or hard pairs are used for training at the easy stage, the model might be\nstuck in bad local optimum. In this paper, we inject curriculum learning into\nweakly supervised modality correlation learning. The weakly supervised\ncorrelation learning leverages the label information to generate scores for\nnegative pairs to learn a more discriminative embedding space, where negative\npairs are defined as two unimodal embeddings from different samples. To assist\nthe correlation learning, we feed the training pairs to the model according to\ndifficulty by the proposed curriculum learning, which consists of elaborately\ndesigned scoring and feeding functions. The scoring function computes the\ndifficulty of pairs using pre-trained and current correlation predictors, where\nthe pairs with large losses are defined as hard pairs. Notably, the hardest\npairs are discarded in our algorithm, which are assumed as noisy pairs.\nMoreover, the feeding function takes the difference of correlation losses as\nfeedback to determine the feeding actions (`stay', `step back', or `step\nforward'). The proposed method reaches state-of-the-art performance on MSA.\n","authors":["Sijie Mai","Ya Sun","Haifeng Hu"],"pdf_url":"https://arxiv.org/pdf/2212.07619v1.pdf","comment":"Accepted by EMNLP 2022"},{"id":"http://arxiv.org/abs/2212.02886v2","updated":"2022-12-15T05:10:36Z","published":"2022-12-06T11:23:16Z","title":"GAS-NeXt: Few-Shot Cross-Lingual Font Generator","summary":"  Generating new fonts is a time-consuming and labor-intensive task, especially\nin a language with a huge amount of characters like Chinese. Various deep\nlearning models have demonstrated the ability to efficiently generate new fonts\nwith a few reference characters of that style, but few models support\ncross-lingual font generation. This paper presents GAS-NeXt, a novel few-shot\ncross-lingual font generator based on AGIS-Net and Font Translator GAN, and\nimprove the performance metrics such as Fr\\'echet Inception Distance (FID),\nStructural Similarity Index Measure(SSIM), and Pixel-level Accuracy (pix-acc).\nOur approaches include replacing the original encoder and decoder with the idea\nof layer attention and context-aware attention from Font Translator GAN, while\nutilizing the shape, texture, and local discriminators of AGIS-Net. In our\nexperiment on English-to-Chinese font translation, we observed better results\nin fonts with distinct local features than conventional Chinese fonts compared\nto results obtained from Font Translator GAN. We also validate our method on\nmultiple languages and datasets.\n","authors":["Haoyang He","Xin Jin","Angela Chen"],"pdf_url":"https://arxiv.org/pdf/2212.02886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07611v1","updated":"2022-12-15T04:22:21Z","published":"2022-12-15T04:22:21Z","title":"Residual Policy Learning for Powertrain Control","summary":"  Eco-driving strategies have been shown to provide significant reductions in\nfuel consumption. This paper outlines an active driver assistance approach that\nuses a residual policy learning (RPL) agent trained to provide residual actions\nto default power train controllers while balancing fuel consumption against\nother driver-accommodation objectives. Using previous experiences, our RPL\nagent learns improved traction torque and gear shifting residual policies to\nadapt the operation of the powertrain to variations and uncertainties in the\nenvironment. For comparison, we consider a traditional reinforcement learning\n(RL) agent trained from scratch. Both agents employ the off-policy Maximum A\nPosteriori Policy Optimization algorithm with an actor-critic architecture. By\nimplementing on a simulated commercial vehicle in various car-following\nscenarios, we find that the RPL agent quickly learns significantly improved\npolicies compared to a baseline source policy but in some measures not as good\nas those eventually possible with the RL agent trained from scratch.\n","authors":["Lindsey Kerbel","Beshah Ayalew","Andrej Ivanco","Keith Loiselle"],"pdf_url":"https://arxiv.org/pdf/2212.07611v1.pdf","comment":"10th IFAC Symposium on Advances in Automotive Control AAC 2022"},{"id":"http://arxiv.org/abs/2212.07608v1","updated":"2022-12-15T04:05:39Z","published":"2022-12-15T04:05:39Z","title":"Output-Dependent Gaussian Process State-Space Model","summary":"  Gaussian process state-space model (GPSSM) is a fully probabilistic\nstate-space model that has attracted much attention over the past decade.\nHowever, the outputs of the transition function in the existing GPSSMs are\nassumed to be independent, meaning that the GPSSMs cannot exploit the inductive\nbiases between different outputs and lose certain model capacities. To address\nthis issue, this paper proposes an output-dependent and more realistic GPSSM by\nutilizing the well-known, simple yet practical linear model of\ncoregionalization (LMC) framework to represent the output dependency. To\njointly learn the output-dependent GPSSM and infer the latent states, we\npropose a variational sparse GP-based learning method that only gently\nincreases the computational complexity. Experiments on both synthetic and real\ndatasets demonstrate the superiority of the output-dependent GPSSM in terms of\nlearning and inference performance.\n","authors":["Zhidi Lin","Lei Cheng","Feng Yin","Lexi Xu","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2212.07608v1.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2210.08585v3","updated":"2022-12-15T02:56:29Z","published":"2022-10-16T17:10:52Z","title":"A new trigonometric kernel function for support vector machine","summary":"  In the last few years, various types of machine learning algorithms, such as\nSupport Vector Machine (SVM), Support Vector Regression (SVR), and Non-negative\nMatrix Factorization (NMF) have been introduced. The kernel approach is an\neffective method for increasing the classification accuracy of machine learning\nalgorithms. This paper introduces a family of one-parameter kernel functions\nfor improving the accuracy of SVM classification. The proposed kernel function\nconsists of a trigonometric term and differs from all existing kernel\nfunctions. We show this function is a positive definite kernel function.\nFinally, we evaluate the SVM method based on the new trigonometric kernel, the\nGaussian kernel, the polynomial kernel, and a convex combination of the new\nkernel function and the Gaussian kernel function on various types of datasets.\nEmpirical results show that the SVM based on the new trigonometric kernel\nfunction and the mixed kernel function achieve the best classification\naccuracy. Moreover, some numerical results of performing the SVR based on the\nnew trigonometric kernel function and the mixed kernel function are presented.\n","authors":["Sajad Fathi Hafshejani","Zahra Moberfard"],"pdf_url":"https://arxiv.org/pdf/2210.08585v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05970v2","updated":"2022-12-15T02:52:34Z","published":"2022-12-09T03:29:38Z","title":"Decomposing a Recurrent Neural Network into Modules for Enabling\n  Reusability and Replacement","summary":"  Can we take a recurrent neural network (RNN) trained to translate between\nlanguages and augment it to support a new natural language without retraining\nthe model from scratch? Can we fix the faulty behavior of the RNN by replacing\nportions associated with the faulty behavior? Recent works on decomposing a\nfully connected neural network (FCNN) and convolutional neural network (CNN)\ninto modules have shown the value of engineering deep models in this manner,\nwhich is standard in traditional SE but foreign for deep learning models.\nHowever, prior works focus on the image-based multiclass classification\nproblems and cannot be applied to RNN due to (a) different layer structures,\n(b) loop structures, (c) different types of input-output architectures, and (d)\nusage of both nonlinear and logistic activation functions. In this work, we\npropose the first approach to decompose an RNN into modules. We study different\ntypes of RNNs, i.e., Vanilla, LSTM, and GRU. Further, we show how such RNN\nmodules can be reused and replaced in various scenarios. We evaluate our\napproach against 5 canonical datasets (i.e., Math QA, Brown Corpus,\nWiki-toxicity, Clinc OOS, and Tatoeba) and 4 model variants for each dataset.\nWe found that decomposing a trained model has a small cost (Accuracy: -0.6%,\nBLEU score: +0.10%). Also, the decomposed modules can be reused and replaced\nwithout needing to retrain.\n","authors":["Sayem Mohammad Imtiaz","Fraol Batole","Astha Singh","Rangeet Pan","Breno Dantas Cruz","Hridesh Rajan"],"pdf_url":"https://arxiv.org/pdf/2212.05970v2.pdf","comment":"Accepted at 45th international conference on software engineering\n  (ICSE'2023)"},{"id":"http://arxiv.org/abs/2212.07594v1","updated":"2022-12-15T02:52:07Z","published":"2022-12-15T02:52:07Z","title":"Driver Assistance Eco-driving and Transmission Control with Deep\n  Reinforcement Learning","summary":"  With the growing need to reduce energy consumption and greenhouse gas\nemissions, Eco-driving strategies provide a significant opportunity for\nadditional fuel savings on top of other technological solutions being pursued\nin the transportation sector. In this paper, a model-free deep reinforcement\nlearning (RL) control agent is proposed for active Eco-driving assistance that\ntrades-off fuel consumption against other driver-accommodation objectives, and\nlearns optimal traction torque and transmission shifting policies from\nexperience. The training scheme for the proposed RL agent uses an off-policy\nactor-critic architecture that iteratively does policy evaluation with a\nmulti-step return and policy improvement with the maximum posteriori policy\noptimization algorithm for hybrid action spaces. The proposed Eco-driving RL\nagent is implemented on a commercial vehicle in car following traffic. It shows\nsuperior performance in minimizing fuel consumption compared to a baseline\ncontroller that has full knowledge of fuel-efficiency tables.\n","authors":["Lindsey Kerbel","Beshah Ayalew","Andrej Ivanco","Keith Loiselle"],"pdf_url":"https://arxiv.org/pdf/2212.07594v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07591v1","updated":"2022-12-15T02:43:51Z","published":"2022-12-15T02:43:51Z","title":"Dissecting Distribution Inference","summary":"  A distribution inference attack aims to infer statistical properties of data\nused to train machine learning models. These attacks are sometimes surprisingly\npotent, but the factors that impact distribution inference risk are not well\nunderstood and demonstrated attacks often rely on strong and unrealistic\nassumptions such as full knowledge of training environments even in supposedly\nblack-box threat scenarios. To improve understanding of distribution inference\nrisks, we develop a new black-box attack that even outperforms the best known\nwhite-box attack in most settings. Using this new attack, we evaluate\ndistribution inference risk while relaxing a variety of assumptions about the\nadversary's knowledge under black-box access, like known model architectures\nand label-only access. Finally, we evaluate the effectiveness of previously\nproposed defenses and introduce new defenses. We find that although noise-based\ndefenses appear to be ineffective, a simple re-sampling defense can be highly\neffective. Code is available at\nhttps://github.com/iamgroot42/dissecting_distribution_inference\n","authors":["Anshuman Suri","Yifu Lu","Yanjin Chen","David Evans"],"pdf_url":"https://arxiv.org/pdf/2212.07591v1.pdf","comment":"Accepted at SaTML 2023"},{"id":"http://arxiv.org/abs/2212.07588v1","updated":"2022-12-15T02:40:57Z","published":"2022-12-15T02:40:57Z","title":"DeepJoin: Joinable Table Discovery with Pre-trained Language Models","summary":"  Due to the usefulness in data enrichment for data analysis tasks, joinable\ntable discovery has become an important operation in data lake management.\nExisting approaches target equi-joins, the most common way of combining tables\nfor creating a unified view, or semantic joins, which tolerate misspellings and\ndifferent formats to deliver more join results. They are either exact solutions\nwhose running time is linear in the sizes of query column and target table\nrepository or approximate solutions lacking precision. In this paper, we\npropose Deepjoin, a deep learning model for accurate and efficient joinable\ntable discovery. Our solution is an embedding-based retrieval, which employs a\npre-trained language model (PLM) and is designed as one framework serving both\nequi- and semantic joins. We propose a set of contextualization options to\ntransform column contents to a text sequence. The PLM reads the sequence and is\nfine-tuned to embed columns to vectors such that columns are expected to be\njoinable if they are close to each other in the vector space. Since the output\nof the PLM is fixed in length, the subsequent search procedure becomes\nindependent of the column size. With a state-of-the-art approximate nearest\nneighbor search algorithm, the search time is logarithmic in the repository\nsize. To train the model, we devise the techniques for preparing training data\nas well as data augmentation. The experiments on real datasets demonstrate that\nby training on a small subset of a corpus, Deepjoin generalizes to large\ndatasets and its precision consistently outperforms other approximate\nsolutions'. Deepjoin is even more accurate than an exact solution to semantic\njoins when evaluated with labels from experts. Moreover, when equipped with a\nGPU, Deepjoin is up to two orders of magnitude faster than existing solutions.\n","authors":["Yuyang Dong","Chuan Xiao","Takuma Nozawa","Masafumi Enomoto","Masafumi Oyamada"],"pdf_url":"https://arxiv.org/pdf/2212.07588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.04993v4","updated":"2022-12-15T02:33:40Z","published":"2022-10-10T19:58:23Z","title":"Continual Learning with Evolving Class Ontologies","summary":"  Lifelong learners must recognize concept vocabularies that evolve over time.\nA common yet underexplored scenario is learning with class labels that\ncontinually refine/expand old classes. For example, humans learn to recognize\n${\\tt dog}$ before dog breeds. In practical settings, dataset\n$\\textit{versioning}$ often introduces refinement to ontologies, such as\nautonomous vehicle benchmarks that refine a previous ${\\tt vehicle}$ class into\n${\\tt school-bus}$ as autonomous operations expand to new cities. This paper\nformalizes a protocol for studying the problem of $\\textit{Learning with\nEvolving Class Ontology}$ (LECO). LECO requires learning classifiers in\ndistinct time periods (TPs); each TP introduces a new ontology of \"fine\" labels\nthat refines old ontologies of \"coarse\" labels (e.g., dog breeds that refine\nthe previous ${\\tt dog}$). LECO explores such questions as whether to annotate\nnew data or relabel the old, how to leverage coarse labels, and whether to\nfinetune the previous TP's model or train from scratch. To answer these\nquestions, we leverage insights from related problems such as class-incremental\nlearning. We validate them under the LECO protocol through the lens of image\nclassification (CIFAR and iNaturalist) and semantic segmentation (Mapillary).\nOur experiments lead to surprising conclusions; while the current status quo is\nto relabel existing datasets with new ontologies (such as COCO-to-LVIS or\nMapillary1.2-to-2.0), LECO demonstrates that a far better strategy is to\nannotate $\\textit{new}$ data with the new ontology. However, this produces an\naggregate dataset with inconsistent old-vs-new labels, complicating learning.\nTo address this challenge, we adopt methods from semi-supervised and\npartial-label learning. Such strategies can surprisingly be made near-optimal,\napproaching an \"oracle\" that learns on the aggregate dataset exhaustively\nlabeled with the newest ontology.\n","authors":["Zhiqiu Lin","Deepak Pathak","Yu-Xiong Wang","Deva Ramanan","Shu Kong"],"pdf_url":"https://arxiv.org/pdf/2210.04993v4.pdf","comment":"NeurIPS 2022; Website: https://linzhiqiu.github.io/papers/leco/"},{"id":"http://arxiv.org/abs/2212.07585v1","updated":"2022-12-15T02:25:22Z","published":"2022-12-15T02:25:22Z","title":"Co-Learning with Pre-Trained Networks Improves Source-Free Domain\n  Adaptation","summary":"  Source-free domain adaptation aims to adapt a source model trained on\nfully-labeled source domain data to a target domain with unlabeled target\ndomain data. Source data is assumed inaccessible due to proprietary or privacy\nreasons. Existing works use the source model to pseudolabel target data, but\nthe pseudolabels are unreliable due to data distribution shift between source\nand target domain. In this work, we propose to leverage an ImageNet pre-trained\nfeature extractor in a new co-learning framework to improve target pseudolabel\nquality for finetuning the source model. Benefits of the ImageNet feature\nextractor include that it is not source-biased and it provides an alternate\nview of features and classification decisions different from the source model.\nSuch pre-trained feature extractors are also publicly available, which allows\nus to readily leverage modern network architectures that have strong\nrepresentation learning ability. After co-learning, we sharpen predictions of\nnon-pseudolabeled samples by entropy minimization. Evaluation on 3 benchmark\ndatasets show that our proposed method can outperform existing source-free\ndomain adaptation methods, as well as unsupervised domain adaptation methods\nwhich assume joint access to source and target data.\n","authors":["Wenyu Zhang","Li Shen","Chuan-Sheng Foo"],"pdf_url":"https://arxiv.org/pdf/2212.07585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.03509v2","updated":"2022-12-15T02:03:57Z","published":"2021-04-08T04:52:21Z","title":"Py-Feat: Python Facial Expression Analysis Toolbox","summary":"  Studying facial expressions is a notoriously difficult endeavor. Recent\nadvances in the field of affective computing have yielded impressive progress\nin automatically detecting facial expressions from pictures and videos.\nHowever, much of this work has yet to be widely disseminated in social science\ndomains such as psychology. Current state of the art models require\nconsiderable domain expertise that is not traditionally incorporated into\nsocial science training programs. Furthermore, there is a notable absence of\nuser-friendly and open-source software that provides a comprehensive set of\ntools and functions that support facial expression research. In this paper, we\nintroduce Py-Feat, an open-source Python toolbox that provides support for\ndetecting, preprocessing, analyzing, and visualizing facial expression data.\nPy-Feat makes it easy for domain experts to disseminate and benchmark computer\nvision models and also for end users to quickly process, analyze, and visualize\nface expression data. We hope this platform will facilitate increased use of\nfacial expression data in human behavior research.\n","authors":["Eshin Jolly","Jin Hyun Cheong","Tiankang Xie","Sophie Byrne","Matthew Kenny","Luke J. Chang"],"pdf_url":"https://arxiv.org/pdf/2104.03509v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05024v2","updated":"2022-12-15T01:17:25Z","published":"2022-12-09T18:16:41Z","title":"Decomposable Sparse Tensor on Tensor Regression","summary":"  Most regularized tensor regression research focuses on tensors predictors\nwith scalars responses or vectors predictors to tensors responses. We consider\nthe sparse low rank tensor on tensor regression where predictors $\\mathcal{X}$\nand responses $\\mathcal{Y}$ are both high-dimensional tensors. By demonstrating\nthat the general inner product or the contracted product on a unit rank tensor\ncan be decomposed into standard inner products and outer products, the problem\ncan be simply transformed into a tensor to scalar regression followed by a\ntensor decomposition. So we propose a fast solution based on stagewise search\ncomposed by contraction part and generation part which are optimized\nalternatively. We successfully demonstrate our method can out perform current\nmethods in terms of accuracy and predictors selection by effectively\nincorporating the structural information.\n","authors":["Haiyi Mao","Jason Xiaotian Dou"],"pdf_url":"https://arxiv.org/pdf/2212.05024v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07568v1","updated":"2022-12-15T01:01:11Z","published":"2022-12-15T01:01:11Z","title":"Man-recon: manifold learning for reconstruction with deep autoencoder\n  for smart seismic interpretation","summary":"  Deep learning can extract rich data representations if provided sufficient\nquantities of labeled training data. For many tasks however, annotating data\nhas significant costs in terms of time and money, owing to the high standards\nof subject matter expertise required, for example in medical and geophysical\nimage interpretation tasks. Active Learning can identify the most informative\ntraining examples for the interpreter to train, leading to higher efficiency.\nWe propose an Active learning method based on jointly learning representations\nfor supervised and unsupervised tasks. The learned manifold structure is later\nutilized to identify informative training samples most dissimilar from the\nlearned manifold from the error profiles on the unsupervised task. We verify\nthe efficiency of the proposed method on a seismic facies segmentation dataset\nfrom the Netherlands F3 block survey, significantly outperforming contemporary\nmethods to achieve the highest mean Intersection-Over-Union value of 0.773.\n","authors":["Ahmad Mustafa","Ghassan AlRegib"],"pdf_url":"https://arxiv.org/pdf/2212.07568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07564v1","updated":"2022-12-15T00:41:09Z","published":"2022-12-15T00:41:09Z","title":"AirfRANS: High Fidelity Computational Fluid Dynamics Dataset for\n  Approximating Reynolds-Averaged Navier-Stokes Solutions","summary":"  Surrogate models are necessary to optimize meaningful quantities in physical\ndynamics as their recursive numerical resolutions are often prohibitively\nexpensive. It is mainly the case for fluid dynamics and the resolution of\nNavier-Stokes equations. However, despite the fast-growing field of data-driven\nmodels for physical systems, reference datasets representing real-world\nphenomena are lacking. In this work, we develop AirfRANS, a dataset for\nstudying the two-dimensional incompressible steady-state Reynolds-Averaged\nNavier-Stokes equations over airfoils at a subsonic regime and for different\nangles of attacks. We also introduce metrics on the stress forces at the\nsurface of geometries and visualization of boundary layers to assess the\ncapabilities of models to accurately predict the meaningful information of the\nproblem. Finally, we propose deep learning baselines on four machine learning\ntasks to study AirfRANS under different constraints for generalization\nconsiderations: big and scarce data regime, Reynolds number, and angle of\nattack extrapolation.\n","authors":["Florent Bonnet","Ahmed Jocelyn Mazari","Paola Cinnella","Patrick Gallinari"],"pdf_url":"https://arxiv.org/pdf/2212.07564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07563v1","updated":"2022-12-15T00:38:14Z","published":"2022-12-15T00:38:14Z","title":"Explainable Machine Learning for Hydrocarbon Prospect Risking","summary":"  Hydrocarbon prospect risking is a critical application in geophysics\npredicting well outcomes from a variety of data including geological,\ngeophysical, and other information modalities. Traditional routines require\ninterpreters to go through a long process to arrive at the probability of\nsuccess of specific outcomes. AI has the capability to automate the process but\nits adoption has been limited thus far owing to a lack of transparency in the\nway complicated, black box models generate decisions. We demonstrate how LIME\n-- a model-agnostic explanation technique -- can be used to inject trust in\nmodel decisions by uncovering the model's reasoning process for individual\npredictions. It generates these explanations by fitting interpretable models in\nthe local neighborhood of specific datapoints being queried. On a dataset of\nwell outcomes and corresponding geophysical attribute data, we show how LIME\ncan induce trust in model's decisions by revealing the decision-making process\nto be aligned to domain knowledge. Further, it has the potential to debug\nmispredictions made due to anomalous patterns in the data or faulty training\ndatasets.\n","authors":["Ahmad Mustafa","Ghassan AlRegib"],"pdf_url":"https://arxiv.org/pdf/2212.07563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07562v1","updated":"2022-12-15T00:37:41Z","published":"2022-12-15T00:37:41Z","title":"Robustness Evaluation of Regression Tasks with Skewed Domain Preferences","summary":"  In natural phenomena, data distributions often deviate from normality. One\ncan think of cataclysms as a self-explanatory example: events that occur almost\nnever, and at the same time are many standard deviations away from the common\noutcome. In many scientific contexts it is exactly these tail events that\nresearchers are most interested in anticipating, so that adequate measures can\nbe taken to prevent or attenuate a major impact on society. Despite such\nefforts, we have yet to provide definite answers to crucial issues in\nevaluating predictive solutions in domains such as weather, pollution, health.\nIn this paper, we deal with two encapsulated problems simultaneously. First,\nassessing the performance of regression models when non-uniform preferences\napply - not all values are equally relevant concerning the accuracy of their\nprediction, and there's a particular interest in the most extreme values.\nSecond, assessing the robustness of models when dealing with uncertainty\nregarding the actual underlying distribution of values relevant for such\nproblems. We show how different levels of relevance associated with target\nvalues may impact experimental conclusions, and demonstrate the practical\nutility of the proposed methods.\n","authors":["Nuno Costa","Nuno Moniz"],"pdf_url":"https://arxiv.org/pdf/2212.07562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13741v2","updated":"2022-12-15T00:19:16Z","published":"2022-05-27T03:09:55Z","title":"Generating multivariate time series with COmmon Source CoordInated GAN\n  (COSCI-GAN)","summary":"  Generating multivariate time series is a promising approach for sharing\nsensitive data in many medical, financial, and IoT applications. A common type\nof multivariate time series originates from a single source such as the\nbiometric measurements from a medical patient. This leads to complex dynamical\npatterns between individual time series that are hard to learn by typical\ngeneration models such as GANs. There is valuable information in those patterns\nthat machine learning models can use to better classify, predict or perform\nother downstream tasks. We propose a novel framework that takes time series'\ncommon origin into account and favors channel/feature relationships\npreservation. The two key points of our method are: 1) the individual time\nseries are generated from a common point in latent space and 2) a central\ndiscriminator favors the preservation of inter-channel/feature dynamics. We\ndemonstrate empirically that our method helps preserve channel/feature\ncorrelations and that our synthetic data performs very well in downstream tasks\nwith medical and financial data.\n","authors":["Ali Seyfi","Jean-Francois Rajotte","Raymond T. Ng"],"pdf_url":"https://arxiv.org/pdf/2205.13741v2.pdf","comment":"19 pages, 16 figures"},{"id":"http://arxiv.org/abs/2212.07558v1","updated":"2022-12-15T00:08:05Z","published":"2022-12-15T00:08:05Z","title":"DOC-NAD: A Hybrid Deep One-class Classifier for Network Anomaly\n  Detection","summary":"  Machine Learning (ML) approaches have been used to enhance the detection\ncapabilities of Network Intrusion Detection Systems (NIDSs). Recent work has\nachieved near-perfect performance by following binary- and multi-class network\nanomaly detection tasks. Such systems depend on the availability of both\n(benign and malicious) network data classes during the training phase. However,\nattack data samples are often challenging to collect in most organisations due\nto security controls preventing the penetration of known malicious traffic to\ntheir networks. Therefore, this paper proposes a Deep One-Class (DOC)\nclassifier for network intrusion detection by only training on benign network\ndata samples. The novel one-class classification architecture consists of a\nhistogram-based deep feed-forward classifier to extract useful network data\nfeatures and use efficient outlier detection. The DOC classifier has been\nextensively evaluated using two benchmark NIDS datasets. The results\ndemonstrate its superiority over current state-of-the-art one-class classifiers\nin terms of detection and false positive rates.\n","authors":["Mohanad Sarhan","Gayan Kulatilleke","Wai Weng Lo","Siamak Layeghy","Marius Portmann"],"pdf_url":"https://arxiv.org/pdf/2212.07558v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08199v1","updated":"2022-12-15T23:55:01Z","published":"2022-12-15T23:55:01Z","title":"Asymptotic Analysis of Deep Residual Networks","summary":"  We investigate the asymptotic properties of deep Residual networks (ResNets)\nas the number of layers increases. We first show the existence of scaling\nregimes for trained weights markedly different from those implicitly assumed in\nthe neural ODE literature. We study the convergence of the hidden state\ndynamics in these scaling regimes, showing that one may obtain an ODE, a\nstochastic differential equation (SDE) or neither of these. In particular, our\nfindings point to the existence of a diffusive regime in which the deep network\nlimit is described by a class of stochastic differential equations (SDEs).\nFinally, we derive the corresponding scaling limits for the backpropagation\ndynamics.\n","authors":["Rama Cont","Alain Rossier","Renyuan Xu"],"pdf_url":"https://arxiv.org/pdf/2212.08199v1.pdf","comment":"49 pages, 12 figures. arXiv admin note: substantial text overlap with\n  arXiv:2105.12245"},{"id":"http://arxiv.org/abs/2210.10047v3","updated":"2022-12-15T23:47:39Z","published":"2022-10-18T17:59:55Z","title":"From Play to Policy: Conditional Behavior Generation from Uncurated\n  Robot Data","summary":"  While large-scale sequence modeling from offline data has led to impressive\nperformance gains in natural language and image generation, directly\ntranslating such ideas to robotics has been challenging. One critical reason\nfor this is that uncurated robot demonstration data, i.e. play data, collected\nfrom non-expert human demonstrators are often noisy, diverse, and\ndistributionally multi-modal. This makes extracting useful, task-centric\nbehaviors from such data a difficult generative modeling problem. In this work,\nwe present Conditional Behavior Transformers (C-BeT), a method that combines\nthe multi-modal generation ability of Behavior Transformer with\nfuture-conditioned goal specification. On a suite of simulated benchmark tasks,\nwe find that C-BeT improves upon prior state-of-the-art work in learning from\nplay data by an average of 45.7%. Further, we demonstrate for the first time\nthat useful task-centric behaviors can be learned on a real-world robot purely\nfrom play data without any task labels or reward information. Robot videos are\nbest viewed on our project website: https://play-to-policy.github.io\n","authors":["Zichen Jeff Cui","Yibin Wang","Nur Muhammad Mahi Shafiullah","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2210.10047v3.pdf","comment":"Code and data available at: https://play-to-policy.github.io; (fixed\n  metadata author name format)"},{"id":"http://arxiv.org/abs/2009.04709v4","updated":"2022-12-15T23:35:23Z","published":"2020-09-10T07:48:42Z","title":"Quantifying the Preferential Direction of the Model Gradient in\n  Adversarial Training With Projected Gradient Descent","summary":"  Adversarial training, especially projected gradient descent (PGD), has proven\nto be a successful approach for improving robustness against adversarial\nattacks. After adversarial training, gradients of models with respect to their\ninputs have a preferential direction. However, the direction of alignment is\nnot mathematically well established, making it difficult to evaluate\nquantitatively. We propose a novel definition of this direction as the\ndirection of the vector pointing toward the closest point of the support of the\nclosest inaccurate class in decision space. To evaluate the alignment with this\ndirection after adversarial training, we apply a metric that uses generative\nadversarial networks to produce the smallest residual needed to change the\nclass present in the image. We show that PGD-trained models have a higher\nalignment than the baseline according to our definition, that our metric\npresents higher alignment values than a competing metric formulation, and that\nenforcing this alignment increases the robustness of models.\n","authors":["Ricardo Bigolin Lanfredi","Joyce D. Schroeder","Tolga Tasdizen"],"pdf_url":"https://arxiv.org/pdf/2009.04709v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08192v1","updated":"2022-12-15T23:26:54Z","published":"2022-12-15T23:26:54Z","title":"The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources\n  in Natural Language Understanding Systems","summary":"  Many state-of-the-art natural language understanding (NLU) models are based\non pretrained neural language models. These models often make inferences using\ninformation from multiple sources. An important class of such inferences are\nthose that require both background knowledge, presumably contained in a model's\npretrained parameters, and instance-specific information that is supplied at\ninference time. However, the integration and reasoning abilities of NLU models\nin the presence of multiple knowledge sources have been largely understudied.\nIn this work, we propose a test suite of coreference resolution tasks that\nrequire reasoning over multiple facts. Our dataset is organized into subtasks\nthat differ in terms of which knowledge sources contain relevant facts. We\nevaluate state-of-the-art coreference resolution models on our dataset. Our\nresults indicate that several models struggle to reason on-the-fly over\nknowledge observed both at pretrain time and at inference time. However, with\ntask-specific training, a subset of models demonstrates the ability to\nintegrate certain knowledge types from multiple sources.\n","authors":["Akshatha Arodi","Martin Pömsl","Kaheer Suleman","Adam Trischler","Alexandra Olteanu","Jackie Chi Kit Cheung"],"pdf_url":"https://arxiv.org/pdf/2212.08192v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2212.08189v1","updated":"2022-12-15T23:21:49Z","published":"2022-12-15T23:21:49Z","title":"Multi-Resolution Online Deterministic Annealing: A Hierarchical and\n  Progressive Learning Architecture","summary":"  Hierarchical learning algorithms that gradually approximate a solution to a\ndata-driven optimization problem are essential to decision-making systems,\nespecially under limitations on time and computational resources. In this\nstudy, we introduce a general-purpose hierarchical learning architecture that\nis based on the progressive partitioning of a possibly multi-resolution data\nspace. The optimal partition is gradually approximated by solving a sequence of\noptimization sub-problems that yield a sequence of partitions with increasing\nnumber of subsets. We show that the solution of each optimization problem can\nbe estimated online using gradient-free stochastic approximation updates. As a\nconsequence, a function approximation problem can be defined within each subset\nof the partition and solved using the theory of two-timescale stochastic\napproximation algorithms. This simulates an annealing process and defines a\nrobust and interpretable heuristic method to gradually increase the complexity\nof the learning architecture in a task-agnostic manner, giving emphasis to\nregions of the data space that are considered more important according to a\npredefined criterion. Finally, by imposing a tree structure in the progression\nof the partitions, we provide a means to incorporate potential multi-resolution\nstructure of the data space into this approach, significantly reducing its\ncomplexity, while introducing hierarchical feature extraction properties\nsimilar to certain classes of deep learning architectures. Asymptotic\nconvergence analysis and experimental results are provided for clustering,\nclassification, and regression problems.\n","authors":["Christos Mavridis","John Baras"],"pdf_url":"https://arxiv.org/pdf/2212.08189v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08187v1","updated":"2022-12-15T23:20:13Z","published":"2022-12-15T23:20:13Z","title":"Dual Moving Average Pseudo-Labeling for Source-Free Inductive Domain\n  Adaptation","summary":"  Unsupervised domain adaptation reduces the reliance on data annotation in\ndeep learning by adapting knowledge from a source to a target domain. For\nprivacy and efficiency concerns, source-free domain adaptation extends\nunsupervised domain adaptation by adapting a pre-trained source model to an\nunlabeled target domain without accessing the source data. However, most\nexisting source-free domain adaptation methods to date focus on the\ntransductive setting, where the target training set is also the testing set. In\nthis paper, we address source-free domain adaptation in the more realistic\ninductive setting, where the target training and testing sets are mutually\nexclusive. We propose a new semi-supervised fine-tuning method named Dual\nMoving Average Pseudo-Labeling (DMAPL) for source-free inductive domain\nadaptation. We first split the unlabeled training set in the target domain into\na pseudo-labeled confident subset and an unlabeled less-confident subset\naccording to the prediction confidence scores from the pre-trained source\nmodel. Then we propose a soft-label moving-average updating strategy for the\nunlabeled subset based on a moving-average prototypical classifier, which\ngradually adapts the source model towards the target domain. Experiments show\nthat our proposed method achieves state-of-the-art performance and outperforms\nprevious methods by large margins.\n","authors":["Hao Yan","Yuhong Guo"],"pdf_url":"https://arxiv.org/pdf/2212.08187v1.pdf","comment":"BMVC 2022"},{"id":"http://arxiv.org/abs/2210.01959v2","updated":"2022-12-15T23:16:30Z","published":"2022-10-04T23:33:52Z","title":"Detect, Retrieve, Comprehend: A Flexible Framework for Zero-Shot\n  Document-Level Question Answering","summary":"  Researchers produce thousands of scholarly documents containing valuable\ntechnical knowledge. The community faces the laborious task of reading these\ndocuments to identify, extract, and synthesize information. To automate\ninformation gathering, document-level question answering (QA) offers a flexible\nframework where human-posed questions can be adapted to extract diverse\nknowledge. Finetuning QA systems requires access to labeled data (tuples of\ncontext, question and answer). However, data curation for document QA is\nuniquely challenging because the context (i.e. answer evidence passage) needs\nto be retrieved from potentially long, ill-formatted documents. Existing QA\ndatasets sidestep this challenge by providing short, well-defined contexts that\nare unrealistic in real-world applications. We present a three-stage document\nQA approach: (1) text extraction from PDF; (2) evidence retrieval from\nextracted texts to form well-posed contexts; (3) QA to extract knowledge from\ncontexts to return high-quality answers -- extractive, abstractive, or Boolean.\nUsing QASPER for evaluation, our detect-retrieve-comprehend (DRC) system\nachieves a +7.19 improvement in Answer-F1 over existing baselines while\ndelivering superior context selection. Our results demonstrate that DRC holds\ntremendous promise as a flexible framework for practical scientific document\nQA.\n","authors":["Tavish McDonald","Brian Tsan","Amar Saini","Juanita Ordonez","Luis Gutierrez","Phan Nguyen","Blake Mason","Brenda Ng"],"pdf_url":"https://arxiv.org/pdf/2210.01959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08186v1","updated":"2022-12-15T23:12:53Z","published":"2022-12-15T23:12:53Z","title":"Learning Sparsity and Randomness for Data-driven Low Rank Approximation","summary":"  Learning-based low rank approximation algorithms can significantly improve\nthe performance of randomized low rank approximation with sketch matrix. With\nthe learned value and fixed non-zero positions for sketch matrices from\nlearning-based algorithms, these matrices can reduce the test error of low rank\napproximation significantly. However, there is still no good method to learn\nnon-zero positions as well as overcome the out-of-distribution performance\nloss. In this work, we introduce two new methods Learning Sparsity and Learning\nRandomness which try to learn a better sparsity patterns and add randomness to\nthe value of sketch matrix. These two methods can be applied with any\nlearning-based algorithms which use sketch matrix directly. Our experiments\nshow that these two methods can improve the performance of previous\nlearning-based algorithm for both test error and out-of-distribution test error\nwithout adding too much complexity.\n","authors":["Tiejin Chen","Yicheng Tao"],"pdf_url":"https://arxiv.org/pdf/2212.08186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15792v2","updated":"2022-12-15T23:02:07Z","published":"2022-11-28T21:59:58Z","title":"Provably Efficient Model-free RL in Leader-Follower MDP with Linear\n  Function Approximation","summary":"  We consider a multi-agent episodic MDP setup where an agent (leader) takes\naction at each step of the episode followed by another agent (follower). The\nstate evolution and rewards depend on the joint action pair of the leader and\nthe follower. Such type of interactions can find applications in many domains\nsuch as smart grids, mechanism design, security, and policymaking. We are\ninterested in how to learn policies for both the players with provable\nperformance guarantee under a bandit feedback setting. We focus on a setup\nwhere both the leader and followers are {\\em non-myopic}, i.e., they both seek\nto maximize their rewards over the entire episode and consider a linear MDP\nwhich can model continuous state-space which is very common in many RL\napplications. We propose a {\\em model-free} RL algorithm and show that\n$\\tilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$ regret bounds can be achieved for both\nthe leader and the follower, where $d$ is the dimension of the feature mapping,\n$H$ is the length of the episode, and $T$ is the total number of steps under\nthe bandit feedback information setup. Thus, our result holds even when the\nnumber of states becomes infinite. The algorithm relies on {\\em novel}\nadaptation of the LSVI-UCB algorithm. Specifically, we replace the standard\ngreedy policy (as the best response) with the soft-max policy for both the\nleader and the follower. This turns out to be key in establishing uniform\nconcentration bound for the value functions. To the best of our knowledge, this\nis the first sub-linear regret bound guarantee for the Markov games with\nnon-myopic followers with function approximation.\n","authors":["Arnob Ghosh"],"pdf_url":"https://arxiv.org/pdf/2211.15792v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08184v1","updated":"2022-12-15T23:00:33Z","published":"2022-12-15T23:00:33Z","title":"NBC-Softmax : Darkweb Author fingerprinting and migration tracking","summary":"  Metric learning aims to learn distances from the data, which enhances the\nperformance of similarity-based algorithms. An author style detection task is a\nmetric learning problem, where learning style features with small intra-class\nvariations and larger inter-class differences is of great importance to achieve\nbetter performance. Recently, metric learning based on softmax loss has been\nused successfully for style detection. While softmax loss can produce separable\nrepresentations, its discriminative power is relatively poor. In this work, we\npropose NBC-Softmax, a contrastive loss based clustering technique for softmax\nloss, which is more intuitive and able to achieve superior performance. Our\ntechnique meets the criterion for larger number of samples, thus achieving\nblock contrastiveness, which is proven to outperform pair-wise losses. It uses\nmini-batch sampling effectively and is scalable. Experiments on 4 darkweb\nsocial forums, with NBCSAuthor that uses the proposed NBC-Softmax for author\nand sybil detection, shows that our negative block contrastive approach\nconstantly outperforms state-of-the-art methods using the same network\narchitecture.\n  Our code is publicly available at : https://github.com/gayanku/NBC-Softmax\n","authors":["Gayan K. Kulatilleke","Shekhar S. Chandra","Marius Portmann"],"pdf_url":"https://arxiv.org/pdf/2212.08184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09718v2","updated":"2022-12-15T22:45:46Z","published":"2022-11-02T00:58:02Z","title":"Numerical Optimizations for Weighted Low-rank Estimation on Language\n  Model","summary":"  Singular value decomposition (SVD) is one of the most popular compression\nmethods that approximate a target matrix with smaller matrices. However,\nstandard SVD treats the parameters within the matrix with equal importance,\nwhich is a simple but unrealistic assumption. The parameters of a trained\nneural network model may affect task performance unevenly, which suggests\nnon-equal importance among the parameters. Compared to SVD, the decomposition\nmethod aware of parameter importance is the more practical choice in real\ncases. Unlike standard SVD, weighted value decomposition is a non-convex\noptimization problem that lacks a closed-form solution. We systematically\ninvestigated multiple optimization strategies to tackle the problem and\nexamined our method by compressing Transformer-based language models. Further,\nwe designed a metric to predict when the SVD may introduce a significant\nperformance drop, for which our method can be a rescue strategy. The extensive\nevaluations demonstrate that our method can perform better than current SOTA\nmethods in compressing Transformer-based language models.\n","authors":["Ting Hua","Yen-Chang Hsu","Felicity Wang","Qian Lou","Yilin Shen","Hongxia Jin"],"pdf_url":"https://arxiv.org/pdf/2211.09718v2.pdf","comment":"long paper EMNLP 2022"},{"id":"http://arxiv.org/abs/2202.05159v3","updated":"2022-12-15T22:33:19Z","published":"2022-02-09T09:36:31Z","title":"Dimensional criterion for forecasting nonlinear systems by reservoir\n  computing","summary":"  Reservoir computers (RC) have proven useful as surrogate models in\nforecasting and replicating systems of chaotic dynamics. The quality of\nsurrogate models based on RCs is crucially dependent on their optimal\nimplementation that involves selecting optimal reservoir topology and\nhyperparameters. By systematically applying Bayesian hyperparameter\noptimization and using ensembles of reservoirs of various topology we show that\nconnectednes of reservoirs is of significance only in forecasting and\nreplication of chaotic system of sufficient complexity. By applying RCs of\ndifferent topology in forecasting and replicating the Lorenz system, a coupled\nWilson-Cowan system, and the Kuramoto-Sivashinsky system, we show that simple\nreservoirs of unconnected nodes (RUN) outperform reservoirs of connected nodes\nfor target systems whose estimated fractal dimension dimension is $d \\lesssim\n5.5$ and that linked reservoirs are better for systems with $d > 5.5$. This\nfinding is highly important for evaluation of reservoir computing methods and\non selecting a method for prediction of signals measured on nonlinear systems.\n","authors":["Pauliina Kärkkäinen","Riku Linna"],"pdf_url":"https://arxiv.org/pdf/2202.05159v3.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2206.00129v3","updated":"2022-12-15T22:32:26Z","published":"2022-05-31T22:16:44Z","title":"Fairness Transferability Subject to Bounded Distribution Shift","summary":"  Given an algorithmic predictor that is \"fair\" on some source distribution,\nwill it still be fair on an unknown target distribution that differs from the\nsource within some bound? In this paper, we study the transferability of\nstatistical group fairness for machine learning predictors (i.e., classifiers\nor regressors) subject to bounded distribution shifts. Such shifts may be\nintroduced by initial training data uncertainties, user adaptation to a\ndeployed predictor, dynamic environments, or the use of pre-trained models in\nnew settings. Herein, we develop a bound that characterizes such\ntransferability, flagging potentially inappropriate deployments of machine\nlearning for socially consequential tasks. We first develop a framework for\nbounding violations of statistical fairness subject to distribution shift,\nformulating a generic upper bound for transferred fairness violations as our\nprimary result. We then develop bounds for specific worked examples, focusing\non two commonly used fairness definitions (i.e., demographic parity and\nequalized odds) and two classes of distribution shift (i.e., covariate shift\nand label shift). Finally, we compare our theoretical bounds to deterministic\nmodels of distribution shift and against real-world data, finding that we are\nable to estimate fairness violation bounds in practice, even when simplifying\nassumptions are only approximately satisfied.\n","authors":["Yatong Chen","Reilly Raab","Jialu Wang","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2206.00129v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08174v1","updated":"2022-12-15T22:29:29Z","published":"2022-12-15T22:29:29Z","title":"Non-IID Transfer Learning on Graphs","summary":"  Transfer learning refers to the transfer of knowledge or information from a\nrelevant source domain to a target domain. However, most existing transfer\nlearning theories and algorithms focus on IID tasks, where the source/target\nsamples are assumed to be independent and identically distributed. Very little\neffort is devoted to theoretically studying the knowledge transferability on\nnon-IID tasks, e.g., cross-network mining. To bridge the gap, in this paper, we\npropose rigorous generalization bounds and algorithms for cross-network\ntransfer learning from a source graph to a target graph. The crucial idea is to\ncharacterize the cross-network knowledge transferability from the perspective\nof the Weisfeiler-Lehman graph isomorphism test. To this end, we propose a\nnovel Graph Subtree Discrepancy to measure the graph distribution shift between\nsource and target graphs. Then the generalization error bounds on cross-network\ntransfer learning, including both cross-network node classification and link\nprediction tasks, can be derived in terms of the source knowledge and the Graph\nSubtree Discrepancy across domains. This thereby motivates us to propose a\ngeneric graph adaptive network (GRADE) to minimize the distribution shift\nbetween source and target graphs for cross-network transfer learning.\nExperimental results verify the effectiveness and efficiency of our GRADE\nframework on both cross-network node classification and cross-domain\nrecommendation tasks.\n","authors":["Jun Wu","Jingrui He","Elizabeth Ainsworth"],"pdf_url":"https://arxiv.org/pdf/2212.08174v1.pdf","comment":"Accepted by AAAI-23"},{"id":"http://arxiv.org/abs/2206.07144v2","updated":"2022-12-15T22:18:44Z","published":"2022-06-14T20:09:04Z","title":"Flatten the Curve: Efficiently Training Low-Curvature Neural Networks","summary":"  The highly non-linear nature of deep neural networks causes them to be\nsusceptible to adversarial examples and have unstable gradients which hinders\ninterpretability. However, existing methods to solve these issues, such as\nadversarial training, are expensive and often sacrifice predictive accuracy.\n  In this work, we consider curvature, which is a mathematical quantity which\nencodes the degree of non-linearity. Using this, we demonstrate low-curvature\nneural networks (LCNNs) that obtain drastically lower curvature than standard\nmodels while exhibiting similar predictive performance, which leads to improved\nrobustness and stable gradients, with only a marginally increased training\ntime. To achieve this, we minimize a data-independent upper bound on the\ncurvature of a neural network, which decomposes overall curvature in terms of\ncurvatures and slopes of its constituent layers. To efficiently minimize this\nbound, we introduce two novel architectural components: first, a non-linearity\ncalled centered-softplus that is a stable variant of the softplus\nnon-linearity, and second, a Lipschitz-constrained batch normalization layer.\n  Our experiments show that LCNNs have lower curvature, more stable gradients\nand increased off-the-shelf adversarial robustness when compared to their\nstandard high-curvature counterparts, all without affecting predictive\nperformance. Our approach is easy to use and can be readily incorporated into\nexisting neural network models.\n","authors":["Suraj Srinivas","Kyle Matoba","Himabindu Lakkaraju","Francois Fleuret"],"pdf_url":"https://arxiv.org/pdf/2206.07144v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.08172v1","updated":"2022-12-15T22:15:11Z","published":"2022-12-15T22:15:11Z","title":"Reliable Measures of Spread in High Dimensional Latent Spaces","summary":"  Understanding geometric properties of natural language processing models'\nlatent spaces allows the manipulation of these properties for improved\nperformance on downstream tasks. One such property is the amount of data spread\nin a model's latent space, or how fully the available latent space is being\nused. In this work, we define data spread and demonstrate that the commonly\nused measures of data spread, Average Cosine Similarity and a partition\nfunction min/max ratio I(V), do not provide reliable metrics to compare the use\nof latent space across models. We propose and examine eight alternative\nmeasures of data spread, all but one of which improve over these current\nmetrics when applied to seven synthetic data distributions. Of our proposed\nmeasures, we recommend one principal component-based measure and one\nentropy-based measure that provide reliable, relative measures of spread and\ncan be used to compare models of different sizes and dimensionalities.\n","authors":["Anna C. Marbut","Katy McKinney-Bock","Travis J. Wheeler"],"pdf_url":"https://arxiv.org/pdf/2212.08172v1.pdf","comment":"24 pages, 11 figures, 13 tables"},{"id":"http://arxiv.org/abs/2212.08171v1","updated":"2022-12-15T22:11:34Z","published":"2022-12-15T22:11:34Z","title":"Graphon Pooling for Reducing Dimensionality of Signals and Convolutional\n  Operators on Graphs","summary":"  In this paper we propose a pooling approach for convolutional information\nprocessing on graphs relying on the theory of graphons and limits of dense\ngraph sequences. We present three methods that exploit the induced graphon\nrepresentation of graphs and graph signals on partitions of [0, 1]2 in the\ngraphon space. As a result we derive low dimensional representations of the\nconvolutional operators, while a dimensionality reduction of the signals is\nachieved by simple local interpolation of functions in L2([0, 1]). We prove\nthat those low dimensional representations constitute a convergent sequence of\ngraphs and graph signals, respectively. The methods proposed and the\ntheoretical guarantees that we provide show that the reduced graphs and signals\ninherit spectral-structural properties of the original quantities. We evaluate\nour approach with a set of numerical experiments performed on graph neural\nnetworks (GNNs) that rely on graphon pooling. We observe that graphon pooling\nperforms significantly better than other approaches proposed in the literature\nwhen dimensionality reduction ratios between layers are large. We also observe\nthat when graphon pooling is used we have, in general, less overfitting and\nlower computational cost.\n","authors":["Alejandro Parada-Mayorga","Zhiyang Wang","Alejandro Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2212.08171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08170v1","updated":"2022-12-15T22:10:11Z","published":"2022-12-15T22:10:11Z","title":"BNSynth: Bounded Boolean Functional Synthesis","summary":"  The automated synthesis of correct-by-construction Boolean functions from\nlogical specifications is known as the Boolean Functional Synthesis (BFS)\nproblem. BFS has many application areas that range from software engineering to\ncircuit design. In this paper, we introduce a tool BNSynth, that is the first\nto solve the BFS problem under a given bound on the solution space. Bounding\nthe solution space induces the synthesis of smaller functions that benefit\nresource constrained areas such as circuit design. BNSynth uses a\ncounter-example guided, neural approach to solve the bounded BFS problem.\nInitial results show promise in synthesizing smaller solutions; we observe at\nleast \\textbf{3.2X} (and up to \\textbf{24X}) improvement in the reduction of\nsolution size on average, as compared to state of the art tools on our\nbenchmarks. BNSynth is available on GitHub under an open source license.\n","authors":["Ravi Raja","Stanly Samuel","Chiranjib Bhattacharyya","Deepak D'Souza","Aditya Kanade"],"pdf_url":"https://arxiv.org/pdf/2212.08170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07231v2","updated":"2022-12-15T21:58:01Z","published":"2022-12-14T14:06:27Z","title":"Cutting Plane Selection with Analytic Centers and Multiregression","summary":"  Cutting planes are a crucial component of state-of-the-art mixed-integer\nprogramming solvers, with the choice of which subset of cuts to add being vital\nfor solver performance. We propose new distance-based measures to qualify the\nvalue of a cut by quantifying the extent to which it separates relevant parts\nof the relaxed feasible set. For this purpose, we use the analytic centers of\nthe relaxation polytope or of its optimal face, as well as alternative optimal\nsolutions of the linear programming relaxation. We assess the impact of the\nchoice of distance measure on root node performance and throughout the whole\nbranch-and-bound tree, comparing our measures against those prevalent in the\nliterature. Finally, by a multi-output regression, we predict the relative\nperformance of each measure, using static features readily available before the\nseparation process. Our results indicate that analytic center-based methods\nhelp to significantly reduce the number of branch-and-bound nodes needed to\nexplore the search space and that our multiregression approach can further\nimprove on any individual method.\n","authors":["Mark Turner","Timo Berthold","Mathieu Besançon","Thorsten Koch"],"pdf_url":"https://arxiv.org/pdf/2212.07231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08162v1","updated":"2022-12-15T21:50:54Z","published":"2022-12-15T21:50:54Z","title":"Huber-energy measure quantization","summary":"  We describe a measure quantization procedure i.e., an algorithm which finds\nthe best approximation of a target probability law (and more generally signed\nfinite variation measure) by a sum of Q Dirac masses (Q being the quantization\nparameter). The procedure is implemented by minimizing the statistical distance\nbetween the original measure and its quantized version; the distance is built\nfrom a negative definite kernel and, if necessary, can be computed on the fly\nand feed to a stochastic optimization algorithm (such as SGD, Adam, ...). We\ninvestigate theoretically the fundamental questions of existence of the optimal\nmeasure quantizer and identify what are the required kernel properties that\nguarantee suitable behavior. We test the procedure, called HEMQ, on several\ndatabases: multi-dimensional Gaussian mixtures, Wiener space cubature, Italian\nwine cultivars and the MNIST image database. The results indicate that the HEMQ\nalgorithm is robust and versatile and, for the class of Huber-energy kernels,\nit matches the expected intuitive behavior.\n","authors":["Gabriel Turinici"],"pdf_url":"https://arxiv.org/pdf/2212.08162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08153v1","updated":"2022-12-15T21:35:46Z","published":"2022-12-15T21:35:46Z","title":"FiDO: Fusion-in-Decoder optimized for stronger performance and faster\n  inference","summary":"  Fusion-in-Decoder (FiD) is a powerful retrieval-augmented language model that\nsets the state-of-the-art on many knowledge-intensive NLP tasks. However, FiD\nsuffers from very expensive inference. We show that the majority of inference\ntime results from memory bandwidth constraints in the decoder, and propose two\nsimple changes to the FiD architecture to speed up inference by 7x. The faster\ndecoder inference then allows for a much larger decoder. We denote FiD with the\nabove modifications as FiDO, and show that it strongly improves performance\nover existing FiD models for a wide range of inference budgets. For example,\nFiDO-Large-XXL performs faster inference than FiD-Base and achieves better\nperformance than FiD-Large.\n","authors":["Michiel de Jong","Yury Zemlyanskiy","Joshua Ainslie","Nicholas FitzGerald","Sumit Sanghai","Fei Sha","William Cohen"],"pdf_url":"https://arxiv.org/pdf/2212.08153v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08151v1","updated":"2022-12-15T21:34:19Z","published":"2022-12-15T21:34:19Z","title":"First De-Trend then Attend: Rethinking Attention for Time-Series\n  Forecasting","summary":"  Transformer-based models have gained large popularity and demonstrated\npromising results in long-term time-series forecasting in recent years. In\naddition to learning attention in time domain, recent works also explore\nlearning attention in frequency domains (e.g., Fourier domain, wavelet domain),\ngiven that seasonal patterns can be better captured in these domains. In this\nwork, we seek to understand the relationships between attention models in\ndifferent time and frequency domains. Theoretically, we show that attention\nmodels in different domains are equivalent under linear conditions (i.e.,\nlinear kernel to attention scores). Empirically, we analyze how attention\nmodels of different domains show different behaviors through various synthetic\nexperiments with seasonality, trend and noise, with emphasis on the role of\nsoftmax operation therein. Both these theoretical and empirical analyses\nmotivate us to propose a new method: TDformer (Trend Decomposition\nTransformer), that first applies seasonal-trend decomposition, and then\nadditively combines an MLP which predicts the trend component with Fourier\nattention which predicts the seasonal component to obtain the final prediction.\nExtensive experiments on benchmark time-series forecasting datasets demonstrate\nthat TDformer achieves state-of-the-art performance against existing\nattention-based models.\n","authors":["Xiyuan Zhang","Xiaoyong Jin","Karthick Gopalswamy","Gaurav Gupta","Youngsuk Park","Xingjian Shi","Hao Wang","Danielle C. Maddix","Yuyang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.08151v1.pdf","comment":"NeurIPS 2022 All Things Attention Workshop"},{"id":"http://arxiv.org/abs/2205.11495v3","updated":"2022-12-15T20:57:59Z","published":"2022-05-23T17:51:48Z","title":"Flexible Diffusion Modeling of Long Videos","summary":"  We present a framework for video modeling based on denoising diffusion\nprobabilistic models that produces long-duration video completions in a variety\nof realistic environments. We introduce a generative model that can at\ntest-time sample any arbitrary subset of video frames conditioned on any other\nsubset and present an architecture adapted for this purpose. Doing so allows us\nto efficiently compare and optimize a variety of schedules for the order in\nwhich frames in a long video are sampled and use selective sparse and\nlong-range conditioning on previously sampled frames. We demonstrate improved\nvideo modeling over prior work on a number of datasets and sample temporally\ncoherent videos over 25 minutes in length. We additionally release a new video\nmodeling dataset and semantically meaningful metrics based on videos generated\nin the CARLA autonomous driving simulator.\n","authors":["William Harvey","Saeid Naderiparizi","Vaden Masrani","Christian Weilbach","Frank Wood"],"pdf_url":"https://arxiv.org/pdf/2205.11495v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08136v1","updated":"2022-12-15T20:51:27Z","published":"2022-12-15T20:51:27Z","title":"Efficient Long Sequence Modeling via State Space Augmented Transformer","summary":"  Transformer models have achieved superior performance in various natural\nlanguage processing tasks. However, the quadratic computational cost of the\nattention mechanism limits its practicality for long sequences. There are\nexisting attention variants that improve the computational efficiency, but they\nhave limited ability to effectively compute global information. In parallel to\nTransformer models, state space models (SSMs) are tailored for long sequences,\nbut they are not flexible enough to capture complicated local information. We\npropose SPADE, short for $\\underline{\\textbf{S}}$tate\ns$\\underline{\\textbf{P}}$ace\n$\\underline{\\textbf{A}}$ugmente$\\underline{\\textbf{D}}$\nTransform$\\underline{\\textbf{E}}$r. Specifically, we augment a SSM into the\nbottom layer of SPADE, and we employ efficient local attention methods for the\nother layers. The SSM augments global information, which complements the lack\nof long-range dependency issue in local attention methods. Experimental results\non the Long Range Arena benchmark and language modeling tasks demonstrate the\neffectiveness of the proposed method. To further demonstrate the scalability of\nSPADE, we pre-train large encoder-decoder models and present fine-tuning\nresults on natural language understanding and natural language generation\ntasks.\n","authors":["Simiao Zuo","Xiaodong Liu","Jian Jiao","Denis Charles","Eren Manavoglu","Tuo Zhao","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2212.08136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13290v2","updated":"2022-12-15T20:42:56Z","published":"2022-08-28T21:10:56Z","title":"Domain Adaptation Principal Component Analysis: base linear method for\n  learning with out-of-distribution data","summary":"  Domain adaptation is a popular paradigm in modern machine learning which aims\nat tackling the problem of divergence (or shift) between the labeled training\nand validation datasets (source domain) and a potentially large unlabeled\ndataset (target domain). The task is to embed both datasets red into a common\nspace in which the source dataset is informative for training while the\ndivergence between source and target is minimized. The most popular domain\nadaptation solutions are based on training neural networks that combine\nclassification and adversarial learning modules, frequently making them both\ndata-hungry and difficult to train. We present a method called Domain\nAdaptation Principal Component Analysis (DAPCA) that identifies a linear\nreduced data representation useful for solving the domain adaptation task.\nDAPCA algorithm introduces positive and negative weights between pairs of data\npoints, and generalizes the supervised extension of principal component\nanalysis. DAPCA is an iterative algorithm that solves a simple quadratic\noptimization problem at each iteration. The convergence of the algorithm is\nguaranteed, and the number of iterations is small in practice. We validate the\nsuggested algorithm on previously proposed benchmarks for solving the domain\nadaptation task. We also show the benefit of using DAPCA in analyzing the\nsingle-cell omics datasets in biomedical applications. Overall, DAPCA can serve\nas a practical preprocessing step in many machine learning applications leading\nto reduced dataset representations, taking into account possible divergence\nbetween source and target domains.\n","authors":["Evgeny M Mirkes","Jonathan Bac","Aziz Fouché","Sergey V. Stasenko","Andrei Zinovyev","Alexander N. Gorban"],"pdf_url":"https://arxiv.org/pdf/2208.13290v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08131v1","updated":"2022-12-15T20:36:10Z","published":"2022-12-15T20:36:10Z","title":"Bridging the Gap Between Offline and Online Reinforcement Learning\n  Evaluation Methodologies","summary":"  Reinforcement learning (RL) has shown great promise with algorithms learning\nin environments with large state and action spaces purely from scalar reward\nsignals. A crucial challenge for current deep RL algorithms is that they\nrequire a tremendous amount of environment interactions for learning. This can\nbe infeasible in situations where such interactions are expensive; such as in\nrobotics. Offline RL algorithms try to address this issue by bootstrapping the\nlearning process from existing logged data without needing to interact with the\nenvironment from the very beginning. While online RL algorithms are typically\nevaluated as a function of the number of environment interactions, there exists\nno single established protocol for evaluating offline RL methods.In this paper,\nwe propose a sequential approach to evaluate offline RL algorithms as a\nfunction of the training set size and thus by their data efficiency. Sequential\nevaluation provides valuable insights into the data efficiency of the learning\nprocess and the robustness of algorithms to distribution changes in the dataset\nwhile also harmonizing the visualization of the offline and online learning\nphases. Our approach is generally applicable and easy to implement. We compare\nseveral existing offline RL algorithms using this approach and present insights\nfrom a variety of tasks and offline datasets.\n","authors":["Shivakanth Sujit","Pedro H. M. Braga","Jorg Bornschein","Samira Ebrahimi Kahou"],"pdf_url":"https://arxiv.org/pdf/2212.08131v1.pdf","comment":"Offline RL Workshop, NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.08130v1","updated":"2022-12-15T20:35:48Z","published":"2022-12-15T20:35:48Z","title":"On Evaluating Adversarial Robustness of Chest X-ray Classification:\n  Pitfalls and Best Practices","summary":"  Vulnerability to adversarial attacks is a well-known weakness of Deep Neural\nNetworks. While most of the studies focus on natural images with standardized\nbenchmarks like ImageNet and CIFAR, little research has considered real world\napplications, in particular in the medical domain. Our research shows that,\ncontrary to previous claims, robustness of chest x-ray classification is much\nharder to evaluate and leads to very different assessments based on the\ndataset, the architecture and robustness metric. We argue that previous studies\ndid not take into account the peculiarity of medical diagnosis, like the\nco-occurrence of diseases, the disagreement of labellers (domain experts), the\nthreat model of the attacks and the risk implications for each successful\nattack.\n  In this paper, we discuss the methodological foundations, review the pitfalls\nand best practices, and suggest new methodological considerations for\nevaluating the robustness of chest xray classification models. Our evaluation\non 3 datasets, 7 models, and 18 diseases is the largest evaluation of\nrobustness of chest x-ray classification models.\n","authors":["Salah Ghamizi","Maxime Cordy","Michail Papadakis","Yves Le Traon"],"pdf_url":"https://arxiv.org/pdf/2212.08130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.11270v3","updated":"2022-12-15T20:26:36Z","published":"2021-02-22T18:56:26Z","title":"Softmax Policy Gradient Methods Can Take Exponential Time to Converge","summary":"  The softmax policy gradient (PG) method, which performs gradient ascent under\nsoftmax policy parameterization, is arguably one of the de facto\nimplementations of policy optimization in modern reinforcement learning. For\n$\\gamma$-discounted infinite-horizon tabular Markov decision processes (MDPs),\nremarkable progress has recently been achieved towards establishing global\nconvergence of softmax PG methods in finding a near-optimal policy. However,\nprior results fall short of delineating clear dependencies of convergence rates\non salient parameters such as the cardinality of the state space $\\mathcal{S}$\nand the effective horizon $\\frac{1}{1-\\gamma}$, both of which could be\nexcessively large. In this paper, we deliver a pessimistic message regarding\nthe iteration complexity of softmax PG methods, despite assuming access to\nexact gradient computation. Specifically, we demonstrate that the softmax PG\nmethod with stepsize $\\eta$ can take \\[\n  \\frac{1}{\\eta} |\\mathcal{S}|^{2^{\\Omega\\big(\\frac{1}{1-\\gamma}\\big)}}\n~\\text{iterations} \\] to converge, even in the presence of a benign policy\ninitialization and an initial state distribution amenable to exploration (so\nthat the distribution mismatch coefficient is not exceedingly large). This is\naccomplished by characterizing the algorithmic dynamics over a\ncarefully-constructed MDP containing only three actions. Our exponential lower\nbound hints at the necessity of carefully adjusting update rules or enforcing\nproper regularization in accelerating PG methods.\n","authors":["Gen Li","Yuting Wei","Yuejie Chi","Yuxin Chen"],"pdf_url":"https://arxiv.org/pdf/2102.11270v3.pdf","comment":"accepted to Mathematical Programming (Series A); also presented in\n  part in Conference on Learning Theory (COLT) 2021"},{"id":"http://arxiv.org/abs/2212.08123v1","updated":"2022-12-15T20:23:09Z","published":"2022-12-15T20:23:09Z","title":"Bayesian posterior approximation with stochastic ensembles","summary":"  We introduce ensembles of stochastic neural networks to approximate the\nBayesian posterior, combining stochastic methods such as dropout with deep\nensembles. The stochastic ensembles are formulated as families of distributions\nand trained to approximate the Bayesian posterior with variational inference.\nWe implement stochastic ensembles based on Monte Carlo dropout, DropConnect and\na novel non-parametric version of dropout and evaluate them on a toy problem\nand CIFAR image classification. For CIFAR, the stochastic ensembles are\nquantitatively compared to published Hamiltonian Monte Carlo results for a\nResNet-20 architecture. We also test the quality of the posteriors directly\nagainst Hamiltonian Monte Carlo simulations in a simplified toy model. Our\nresults show that in a number of settings, stochastic ensembles provide more\naccurate posterior estimates than regular deep ensembles.\n","authors":["Oleksandr Balabanov","Bernhard Mehlig","Hampus Linander"],"pdf_url":"https://arxiv.org/pdf/2212.08123v1.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.08109v1","updated":"2022-12-15T19:49:34Z","published":"2022-12-15T19:49:34Z","title":"An Empirical Study of Deep Learning Models for Vulnerability Detection","summary":"  Deep learning (DL) models of code have recently reported great progress for\nvulnerability detection. In some cases, DL-based models have outperformed\nstatic analysis tools. Although many great models have been proposed, we do not\nyet have a good understanding of these models. This limits the further\nadvancement of model robustness, debugging, and deployment for the\nvulnerability detection. In this paper, we surveyed and reproduced 9\nstate-of-the-art (SOTA) deep learning models on 2 widely used vulnerability\ndetection datasets: Devign and MSR. We investigated 6 research questions in\nthree areas, namely model capabilities, training data, and model\ninterpretation. We experimentally demonstrated the variability between\ndifferent runs of a model and the low agreement among different models'\noutputs. We investigated models trained for specific types of vulnerabilities\ncompared to a model that is trained on all the vulnerabilities at once. We\nexplored the types of programs DL may consider \"hard\" to handle. We\ninvestigated the relations of training data sizes and training data composition\nwith model performance. Finally, we studied model interpretations and analyzed\nimportant features that the models used to make predictions. We believe that\nour findings can help better understand model results, provide guidance on\npreparing training data, and improve the robustness of the models. All of our\ndatasets, code, and results are available at\nhttps://figshare.com/s/284abfba67dba448fdc2.\n","authors":["Benjamin Steenhoek","Md Mahbubur Rahman","Richard Jiles","Wei Le"],"pdf_url":"https://arxiv.org/pdf/2212.08109v1.pdf","comment":"11 pages, 14 figures. Accepted at ICSE 2023 (not camera-ready\n  version)"},{"id":"http://arxiv.org/abs/2212.08108v1","updated":"2022-12-15T19:49:27Z","published":"2022-12-15T19:49:27Z","title":"DeepDFA: Dataflow Analysis-Guided Efficient Graph Learning for\n  Vulnerability Detection","summary":"  Deep learning-based vulnerability detection models have recently been shown\nto be effective and, in some cases, outperform static analysis tools. However,\nthe highest-performing approaches use token-based transformer models, which do\nnot leverage domain knowledge. Classical program analysis techniques such as\ndataflow analysis can detect many types of bugs and are the most commonly used\nmethods in practice. Motivated by the causal relationship between bugs and\ndataflow analysis, we present DeepDFA, a dataflow analysis-guided graph\nlearning framework and embedding that uses program semantic features for\nvulnerability detection. We show that DeepDFA is performant and efficient.\nDeepDFA ranked first in recall, first in generalizing over unseen projects, and\nsecond in F1 among all the state-of-the-art models we experimented with. It is\nalso the smallest model in terms of the number of parameters, and was trained\nin 9 minutes, 69x faster than the highest-performing baseline. DeepDFA can be\nused with other models. By integrating LineVul and DeepDFA, we achieved the\nbest vulnerability detection performance of 96.4 F1 score, 98.69 precision, and\n94.22 recall.\n","authors":["Benjamin Steenhoek","Wei Le","Hongyang Gao"],"pdf_url":"https://arxiv.org/pdf/2212.08108v1.pdf","comment":"10 pages, 8 figures. Under review as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2209.09024v2","updated":"2022-12-15T19:34:57Z","published":"2022-09-16T15:39:06Z","title":"Dataset Inference for Self-Supervised Models","summary":"  Self-supervised models are increasingly prevalent in machine learning (ML)\nsince they reduce the need for expensively labeled data. Because of their\nversatility in downstream applications, they are increasingly used as a service\nexposed via public APIs. At the same time, these encoder models are\nparticularly vulnerable to model stealing attacks due to the high\ndimensionality of vector representations they output. Yet, encoders remain\nundefended: existing mitigation strategies for stealing attacks focus on\nsupervised learning. We introduce a new dataset inference defense, which uses\nthe private training set of the victim encoder model to attribute its ownership\nin the event of stealing. The intuition is that the log-likelihood of an\nencoder's output representations is higher on the victim's training data than\non test data if it is stolen from the victim, but not if it is independently\ntrained. We compute this log-likelihood using density estimation models. As\npart of our evaluation, we also propose measuring the fidelity of stolen\nencoders and quantifying the effectiveness of the theft detection without\ninvolving downstream tasks; instead, we leverage mutual information and\ndistance measurements. Our extensive empirical results in the vision domain\ndemonstrate that dataset inference is a promising direction for defending\nself-supervised models against model stealing.\n","authors":["Adam Dziedzic","Haonan Duan","Muhammad Ahmad Kaleem","Nikita Dhawan","Jonas Guan","Yannis Cattan","Franziska Boenisch","Nicolas Papernot"],"pdf_url":"https://arxiv.org/pdf/2209.09024v2.pdf","comment":"Accepted at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.08101v1","updated":"2022-12-15T19:33:54Z","published":"2022-12-15T19:33:54Z","title":"Learning to repeatedly solve routing problems","summary":"  In the last years, there has been a great interest in machine-learning-based\nheuristics for solving NP-hard combinatorial optimization problems. The\ndeveloped methods have shown potential on many optimization problems. In this\npaper, we present a learned heuristic for the reoptimization of a problem after\na minor change in its data. We focus on the case of the capacited vehicle\nrouting problem with static clients (i.e., same client locations) and changed\ndemands. Given the edges of an original solution, the goal is to predict and\nfix the ones that have a high chance of remaining in an optimal solution after\na change of client demands. This partial prediction of the solution reduces the\ncomplexity of the problem and speeds up its resolution, while yielding a good\nquality solution. The proposed approach resulted in solutions with an\noptimality gap ranging from 0\\% to 1.7\\% on different benchmark instances\nwithin a reasonable computing time.\n","authors":["Mouad Morabit","Guy Desaulniers","Andrea Lodi"],"pdf_url":"https://arxiv.org/pdf/2212.08101v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2212.08071v1","updated":"2022-12-15T18:59:59Z","published":"2022-12-15T18:59:59Z","title":"MAViL: Masked Audio-Video Learners","summary":"  We present Masked Audio-Video Learners (MAViL) to train audio-visual\nrepresentations. Our approach learns with three complementary forms of\nself-supervision: (1) reconstruction of masked audio and video input data, (2)\nintra- and inter-modal contrastive learning with masking, and (3) self-training\nby reconstructing joint audio-video contextualized features learned from the\nfirst two objectives. Pre-training with MAViL not only enables the model to\nperform well in audio-visual classification and retrieval tasks but also\nimproves representations of each modality in isolation, without using\ninformation from the other modality for fine-tuning or inference. Empirically,\nMAViL sets a new state-of-the-art on AudioSet (53.1 mAP) and VGGSound (67.1%\naccuracy). For the first time, a self-supervised audio-visual model outperforms\nones that use external supervision on these benchmarks. Code will be available\nsoon.\n","authors":["Po-Yao Huang","Vasu Sharma","Hu Xu","Chaitanya Ryali","Haoqi Fan","Yanghao Li","Shang-Wen Li","Gargi Ghosh","Jitendra Malik","Christoph Feichtenhofer"],"pdf_url":"https://arxiv.org/pdf/2212.08071v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2212.07835v1","updated":"2022-12-15T13:44:28Z","published":"2022-12-15T13:44:28Z","title":"You were saying? -- Spoken Language in the V3C Dataset","summary":"  This paper presents an analysis of the distribution of spoken language in the\nV3C video retrieval benchmark dataset based on automatically generated\ntranscripts. It finds that a large portion of the dataset is covered by spoken\nlanguage. Since language transcripts can be quickly and accurately described,\nthis has implications for retrieval tasks such as known-item search.\n","authors":["Luca Rossetto"],"pdf_url":"https://arxiv.org/pdf/2212.07835v1.pdf","comment":null}]},"2022-12-16T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2212.08635v1","updated":"2022-12-16T18:23:43Z","published":"2022-12-16T18:23:43Z","title":"Self-Prompting Large Language Models for Open-Domain QA","summary":"  Open-Domain Question Answering (ODQA) requires models to answer factoid\nquestions with no context given. The common way for this task is to train\nmodels on a large-scale annotated dataset to retrieve related documents and\ngenerate answers based on these documents. In this paper, we show that the ODQA\narchitecture can be dramatically simplified by treating Large Language Models\n(LLMs) as a knowledge corpus and propose a Self-Prompting framework for LLMs to\nperform ODQA so as to eliminate the need for training data and external\nknowledge corpus. Concretely, we firstly generate multiple pseudo QA pairs with\nbackground passages and one-sentence explanations for these QAs by prompting\nLLMs step by step and then leverage the generated QA pairs for in-context\nlearning. Experimental results show our method surpasses previous\nstate-of-the-art methods by +8.8 EM averagely on three widely-used ODQA\ndatasets, and even achieves comparable performance with several\nretrieval-augmented fine-tuned models.\n","authors":["Junlong Li","Zhuosheng Zhang","Hai Zhao"],"pdf_url":"https://arxiv.org/pdf/2212.08635v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.08632v1","updated":"2022-12-16T18:12:04Z","published":"2022-12-16T18:12:04Z","title":"Enhancing Multi-modal and Multi-hop Question Answering via Structured\n  Knowledge and Unified Retrieval-Generation","summary":"  Multi-modal and multi-hop question answering aims to answer a question based\non multiple input sources from different modalities. Previous methods retrieve\nthe evidence separately and feed the retrieved evidence to a language model to\ngenerate the corresponding answer. However, these methods fail to build\nconnections between candidates and thus cannot model the inter-dependent\nrelation during retrieval. Moreover, the reasoning process over multi-modality\ncandidates can be unbalanced without building alignments between different\nmodalities. To address this limitation, we propose a Structured Knowledge and\nUnified Retrieval Generation based method (SKURG). We align the sources from\ndifferent modalities via the shared entities and map them into a shared\nsemantic space via structured knowledge. Then, we utilize a unified\nretrieval-generation decoder to integrate intermediate retrieval results for\nanswer generation and adaptively determine the number of retrieval steps. We\nperform experiments on two multi-modal and multi-hop datasets: WebQA and\nMultimodalQA. The results demonstrate that SKURG achieves state-of-the-art\nperformance on both retrieval and answer generation.\n","authors":["Qian Yang","Qian Chen","Wen Wang","Baotian Hu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.08632v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.08620v1","updated":"2022-12-16T17:57:41Z","published":"2022-12-16T17:57:41Z","title":"POTATO: The Portable Text Annotation Tool","summary":"  We present POTATO, the Portable text annotation tool, a free, fully\nopen-sourced annotation system that 1) supports labeling many types of text and\nmultimodal data; 2) offers easy-to-configure features to maximize the\nproductivity of both deployers and annotators (convenient templates for common\nML/NLP tasks, active learning, keypress shortcuts, keyword highlights,\ntooltips); and 3) supports a high degree of customization (editable UI,\ninserting pre-screening questions, attention and qualification tests).\nExperiments over two annotation tasks suggest that POTATO improves labeling\nspeed through its specially-designed productivity features, especially for long\ndocuments and complex tasks. POTATO is available at\nhttps://github.com/davidjurgens/potato and will continue to be updated.\n","authors":["Jiaxin Pei","Aparna Ananthasubramaniam","Xingyao Wang","Naitian Zhou","Jackson Sargent","Apostolos Dedeloudis","David Jurgens"],"pdf_url":"https://arxiv.org/pdf/2212.08620v1.pdf","comment":"EMNLP 2022 DEMO"},{"id":"http://arxiv.org/abs/2212.08619v1","updated":"2022-12-16T17:57:14Z","published":"2022-12-16T17:57:14Z","title":"Planting and Mitigating Memorized Content in Predictive-Text Language\n  Models","summary":"  Language models are widely deployed to provide automatic text completion\nservices in user products. However, recent research has revealed that language\nmodels (especially large ones) bear considerable risk of memorizing private\ntraining data, which is then vulnerable to leakage and extraction by\nadversaries. In this study, we test the efficacy of a range of\nprivacy-preserving techniques to mitigate unintended memorization of sensitive\nuser text, while varying other factors such as model size and adversarial\nconditions. We test both \"heuristic\" mitigations (those without formal privacy\nguarantees) and Differentially Private training, which provides provable levels\nof privacy at the cost of some model performance. Our experiments show that\n(with the exception of L2 regularization), heuristic mitigations are largely\nineffective in preventing memorization in our test suite, possibly because they\nmake too strong of assumptions about the characteristics that define\n\"sensitive\" or \"private\" text. In contrast, Differential Privacy reliably\nprevents memorization in our experiments, despite its computational and\nmodel-performance costs.\n","authors":["C. M. Downey","Wei Dai","Huseyin A. Inan","Kim Laine","Saurabh Naik","Tomasz Religa"],"pdf_url":"https://arxiv.org/pdf/2212.08619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08607v1","updated":"2022-12-16T17:36:23Z","published":"2022-12-16T17:36:23Z","title":"MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text\n  Generation","summary":"  Prompting large language models has enabled significant recent progress in\nmulti-step reasoning over text. However, when applied to text generation from\nsemi-structured data (e.g., graphs or tables), these methods typically suffer\nfrom low semantic coverage, hallucination, and logical inconsistency. We\npropose MURMUR, a neuro-symbolic modular approach to text generation from\nsemi-structured data with multi-step reasoning. MURMUR is a best-first search\nmethod that generates reasoning paths using: (1) neural and symbolic modules\nwith specific linguistic and logical skills, (2) a grammar whose production\nrules define valid compositions of modules, and (3) value functions that assess\nthe quality of each reasoning step. We conduct experiments on two diverse\ndata-to-text generation tasks like WebNLG and LogicNLG. These tasks differ in\ntheir data representations (graphs and tables) and span multiple linguistic and\nlogical skills. MURMUR obtains significant improvements over recent few-shot\nbaselines like direct prompting and chain-of-thought prompting, while also\nachieving comparable performance to fine-tuned GPT-2 on out-of-domain data.\nMoreover, human evaluation shows that MURMUR generates highly faithful and\ncorrect reasoning paths that lead to 26% more logically consistent summaries on\nLogicNLG, compared to direct prompting.\n","authors":["Swarnadeep Saha","Xinyan Velocity Yu","Mohit Bansal","Ramakanth Pasunuru","Asli Celikyilmaz"],"pdf_url":"https://arxiv.org/pdf/2212.08607v1.pdf","comment":"22 pages (9 figures, 18 tables)"},{"id":"http://arxiv.org/abs/2212.08597v1","updated":"2022-12-16T17:24:49Z","published":"2022-12-16T17:24:49Z","title":"Detecting and Mitigating Hallucinations in Machine Translation: Model\n  Internal Workings Alone Do Well, Sentence Similarity Even Better","summary":"  While the problem of hallucinations in neural machine translation has long\nbeen recognized, so far the progress on its alleviation is very little. Indeed,\nrecently it turned out that without artificially encouraging models to\nhallucinate, previously existing methods fall short and even the standard\nsequence log-probability is more informative. It means that characteristics\ninternal to the model can give much more information than we expect, and before\nusing external models and measures, we first need to ask: how far can we go if\nwe use nothing but the translation model itself ? We propose to use a method\nthat evaluates the percentage of the source contribution to a generated\ntranslation. Intuitively, hallucinations are translations \"detached\" from the\nsource, hence they can be identified by low source contribution. This method\nimproves detection accuracy for the most severe hallucinations by a factor of 2\nand is able to alleviate hallucinations at test time on par with the previous\nbest approach that relies on external models. Next, if we move away from\ninternal model characteristics and allow external tools, we show that using\nsentence similarity from cross-lingual embeddings further improves these\nresults.\n","authors":["David Dale","Elena Voita","Loïc Barrault","Marta R. Costa-jussà"],"pdf_url":"https://arxiv.org/pdf/2212.08597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.14309v2","updated":"2022-12-16T17:17:57Z","published":"2020-12-28T15:46:19Z","title":"General Mechanism of Evolution Shared by Proteins and Words","summary":"  Complex systems, such as life and languages, are governed by principles of\nevolution. The analogy and comparison between biology and\nlinguistics\\cite{alphafold2, RoseTTAFold, lang_virus, cell language, faculty1,\nlanguage of gene, Protein linguistics, dictionary, Grammar of pro_dom,\ncomplexity, genomics_nlp, InterPro, language modeling, Protein language\nmodeling} provide a computational foundation for characterizing and analyzing\nprotein sequences, human corpora, and their evolution. However, no general\nmathematical formula has been proposed so far to illuminate the origin of\nquantitative hallmarks shared by life and language. Here we show several new\nstatistical relationships shared by proteins and words, which inspire us to\nestablish a general mechanism of evolution with explicit formulations that can\nincorporate both old and new characteristics. We found natural selection can be\nquantified via the entropic formulation by the principle of least effort to\ndetermine the sequence variation that survives in evolution. Besides, the\norigin of power law behavior and how changes in the environment stimulate the\nemergence of new proteins and words can also be explained via the introduction\nof function connection network. Our results demonstrate not only the\ncorrespondence between genetics and linguistics over their different\nhierarchies but also new fundamental physical properties for the evolution of\ncomplex adaptive systems. We anticipate our statistical tests can function as\nquantitative criteria to examine whether an evolution theory of sequence is\nconsistent with the regularity of real data. In the meantime, their\ncorrespondence broadens the bridge to exchange existing knowledge, spurs new\ninterpretations, and opens Pandora's box to release several potentially\nrevolutionary challenges. For example, does linguistic arbitrariness conflict\nwith the dogma that structure determines function?\n","authors":["Li-Min Wang","Hsing-Yi Lai","Sun-Ting Tsai","Chen Siang Ng","Shan-Jyun Wu","Meng-Xue Tsai","Yi-Ching Su","Daw-Wei Wang","Tzay-Ming Hong"],"pdf_url":"https://arxiv.org/pdf/2012.14309v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08550v1","updated":"2022-12-16T16:00:19Z","published":"2022-12-16T16:00:19Z","title":"Fine-grained Czech News Article Dataset: An Interdisciplinary Approach\n  to Trustworthiness Analysis","summary":"  We present the Verifee Dataset: a novel dataset of news articles with\nfine-grained trustworthiness annotations. We develop a detailed methodology\nthat assesses the texts based on their parameters encompassing editorial\ntransparency, journalist conventions, and objective reporting while penalizing\nmanipulative techniques. We bring aboard a diverse set of researchers from\nsocial, media, and computer sciences to overcome barriers and limited framing\nof this interdisciplinary problem. We collect over $10,000$ unique articles\nfrom almost $60$ Czech online news sources. These are categorized into one of\nthe $4$ classes across the credibility spectrum we propose, raging from\nentirely trustworthy articles all the way to the manipulative ones. We produce\ndetailed statistics and study trends emerging throughout the set. Lastly, we\nfine-tune multiple popular sequence-to-sequence language models using our\ndataset on the trustworthiness classification task and report the best testing\nF-1 score of $0.52$. We open-source the dataset, annotation methodology, and\nannotators' instructions in full length at https://verifee.ai/research to\nenable easy build-up work. We believe similar methods can help prevent\ndisinformation and educate in the realm of media literacy.\n","authors":["Matyáš Boháček","Michal Bravanský","Filip Trhlík","Václav Moravec"],"pdf_url":"https://arxiv.org/pdf/2212.08550v1.pdf","comment":"13 pages, 3 figures; to be published at the Second Workshop on\n  Multimodal Fact-Checking and Hate Speech Detection (DEFACTIFY 2023) at the\n  AAAI 2023 Conference, February 14, 2023, Washington, D.C"},{"id":"http://arxiv.org/abs/2212.08542v1","updated":"2022-12-16T15:46:15Z","published":"2022-12-16T15:46:15Z","title":"Context-aware Fine-tuning of Self-supervised Speech Models","summary":"  Self-supervised pre-trained transformers have improved the state of the art\non a variety of speech tasks. Due to the quadratic time and space complexity of\nself-attention, they usually operate at the level of relatively short (e.g.,\nutterance) segments. In this paper, we study the use of context, i.e.,\nsurrounding segments, during fine-tuning and propose a new approach called\ncontext-aware fine-tuning. We attach a context module on top of the last layer\nof a pre-trained model to encode the whole segment into a context embedding\nvector which is then used as an additional feature for the final prediction.\nDuring the fine-tuning stage, we introduce an auxiliary loss that encourages\nthis context embedding vector to be similar to context vectors of surrounding\nsegments. This allows the model to make predictions without access to these\nsurrounding segments at inference time and requires only a tiny overhead\ncompared to standard fine-tuned models. We evaluate the proposed approach using\nthe SLUE and Librilight benchmarks for several downstream tasks: Automatic\nspeech recognition (ASR), named entity recognition (NER), and sentiment\nanalysis (SA). The results show that context-aware fine-tuning not only\noutperforms a standard fine-tuning baseline but also rivals a strong context\ninjection baseline that uses neighboring speech segments during inference.\n","authors":["Suwon Shon","Felix Wu","Kwangyoun Kim","Prashant Sridhar","Karen Livescu","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2212.08542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07428v2","updated":"2022-12-16T15:35:37Z","published":"2022-12-14T10:50:13Z","title":"Towards Linguistically Informed Multi-Objective Pre-Training for Natural\n  Language Inference","summary":"  We introduce a linguistically enhanced combination of pre-training methods\nfor transformers. The pre-training objectives include POS-tagging, synset\nprediction based on semantic knowledge graphs, and parent prediction based on\ndependency parse trees. Our approach achieves competitive results on the\nNatural Language Inference task, compared to the state of the art. Specifically\nfor smaller models, the method results in a significant performance boost,\nemphasizing the fact that intelligent pre-training can make up for fewer\nparameters and help building more efficient models. Combining POS-tagging and\nsynset prediction yields the overall best results.\n","authors":["Maren Pielka","Svetlana Schmidt","Lisa Pucknat","Rafet Sifa"],"pdf_url":"https://arxiv.org/pdf/2212.07428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08514v1","updated":"2022-12-16T14:54:56Z","published":"2022-12-16T14:54:56Z","title":"Check-worthy Claim Detection across Topics for Automated Fact-checking","summary":"  An important component of an automated fact-checking system is the claim\ncheck-worthiness detection system, which ranks sentences by prioritising them\nbased on their need to be checked. Despite a body of research tackling the\ntask, previous research has overlooked the challenging nature of identifying\ncheck-worthy claims across different topics. In this paper, we assess and\nquantify the challenge of detecting check-worthy claims for new, unseen topics.\nAfter highlighting the problem, we propose the AraCWA model to mitigate the\nperformance deterioration when detecting check-worthy claims across topics. The\nAraCWA model enables boosting the performance for new topics by incorporating\ntwo components for few-shot learning and data augmentation. Using a publicly\navailable dataset of Arabic tweets consisting of 14 different topics, we\ndemonstrate that our proposed data augmentation strategy achieves substantial\nimprovements across topics overall, where the extent of the improvement varies\nacross topics. Further, we analyse the semantic similarities between topics,\nsuggesting that the similarity metric could be used as a proxy to determine the\ndifficulty level of an unseen topic prior to undertaking the task of labelling\nthe underlying sentences.\n","authors":["Amani S. Abumansour","Arkaitz Zubiaga"],"pdf_url":"https://arxiv.org/pdf/2212.08514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08489v1","updated":"2022-12-16T14:01:42Z","published":"2022-12-16T14:01:42Z","title":"Effectiveness of Text, Acoustic, and Lattice-based representations in\n  Spoken Language Understanding tasks","summary":"  In this paper, we perform an exhaustive evaluation of different\nrepresentations to address the intent classification problem in a Spoken\nLanguage Understanding (SLU) setup. We benchmark three types of systems to\nperform the SLU intent detection task: 1) text-based, 2) lattice-based, and a\nnovel 3) multimodal approach. Our work provides a comprehensive analysis of\nwhat could be the achievable performance of different state-of-the-art SLU\nsystems under different circumstances, e.g., automatically- vs.\nmanually-generated transcripts. We evaluate the systems on the publicly\navailable SLURP spoken language resource corpus. Our results indicate that\nusing richer forms of Automatic Speech Recognition (ASR) outputs allows SLU\nsystems to improve in comparison to the 1-best setup (4% relative improvement).\nHowever, crossmodal approaches, i.e., learning from acoustic and text\nembeddings, obtains performance similar to the oracle setup, and a relative\nimprovement of 18% over the 1-best configuration. Thus, crossmodal\narchitectures represent a good alternative to overcome the limitations of\nworking purely automatically generated textual data.\n","authors":["Esaú Villatoro-Tello","Srikanth Madikeri","Juan Zuluaga-Gomez","Bidisha Sharma","Seyyed Saeed Sarfjoo","Iuliia Nigmatulina","Petr Motlicek","Alexei V. Ivanov","Aravind Ganapathiraju"],"pdf_url":"https://arxiv.org/pdf/2212.08489v1.pdf","comment":"Submitted to ICASSP 2023 (Under review)"},{"id":"http://arxiv.org/abs/2212.08486v1","updated":"2022-12-16T14:00:26Z","published":"2022-12-16T14:00:26Z","title":"BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric","summary":"  End-to-End speech-to-speech translation (S2ST) is generally evaluated with\ntext-based metrics. This means that generated speech has to be automatically\ntranscribed, making the evaluation dependent on the availability and quality of\nautomatic speech recognition (ASR) systems. In this paper, we propose a\ntext-free evaluation metric for end-to-end S2ST, named BLASER, to avoid the\ndependency on ASR systems. BLASER leverages a multilingual multimodal encoder\nto directly encode the speech segments for source input, translation output and\nreference into a shared embedding space and computes a score of the translation\nquality that can be used as a proxy to human evaluation. To evaluate our\napproach, we construct training and evaluation sets from more than 40k human\nannotations covering seven language directions. The best results of BLASER are\nachieved by training with supervision from human rating scores. We show that\nwhen evaluated at the sentence level, BLASER correlates significantly better\nwith human judgment compared to ASR-dependent metrics including ASR-SENTBLEU in\nall translation directions and ASR-COMET in five of them. Our analysis shows\ncombining speech and text as inputs to BLASER does not increase the correlation\nwith human scores, but best correlations are achieved when using speech, which\nmotivates the goal of our research. Moreover, we show that using ASR for\nreferences is detrimental for text-based metrics.\n","authors":["Mingda Chen","Paul-Ambroise Duquenne","Pierre Andrews","Justine Kao","Alexandre Mourachko","Holger Schwenk","Marta R. Costa-jussà"],"pdf_url":"https://arxiv.org/pdf/2212.08486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08482v1","updated":"2022-12-16T13:55:22Z","published":"2022-12-16T13:55:22Z","title":"Implementation of general formal translators","summary":"  The general translator formalism and computing specific implementations are\nproposed. The implementation of specific elements necessary to process the\nsource and destination information within the translators are presented. Some\ncommon directives or instructions, such as classes and procedures, were unified\nand generalized in order to allow general translations implementations. In\norder to cover general cases, two levels of processing are required, related to\nthe source and destination information appropriate transformations, with the\nrelated control and processing instructions. The proposed general translator\nelements are useful for processing natural or artificial information described\nthrough any types of languages or systems.\n","authors":["Iosif Iulian Petrila"],"pdf_url":"https://arxiv.org/pdf/2212.08482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08459v1","updated":"2022-12-16T13:07:39Z","published":"2022-12-16T13:07:39Z","title":"Experiments on Generalizability of BERTopic on Multi-Domain Short Text","summary":"  Topic modeling is widely used for analytically evaluating large collections\nof textual data. One of the most popular topic techniques is Latent Dirichlet\nAllocation (LDA), which is flexible and adaptive, but not optimal for e.g.\nshort texts from various domains. We explore how the state-of-the-art BERTopic\nalgorithm performs on short multi-domain text and find that it generalizes\nbetter than LDA in terms of topic coherence and diversity. We further analyze\nthe performance of the HDBSCAN clustering algorithm utilized by BERTopic and\nfind that it classifies a majority of the documents as outliers. This crucial,\nyet overseen problem excludes too many documents from further analysis. When we\nreplace HDBSCAN with k-Means, we achieve similar performance, but without\noutliers.\n","authors":["Muriël de Groot","Mohammad Aliannejadi","Marcel R. Haas"],"pdf_url":"https://arxiv.org/pdf/2212.08459v1.pdf","comment":"Accepted poster presentation at WiNLP 2022, as a part of EMNLP 2022,\n  2 pages"},{"id":"http://arxiv.org/abs/2212.08458v1","updated":"2022-12-16T13:07:09Z","published":"2022-12-16T13:07:09Z","title":"Fast Rule-Based Decoding: Revisiting Syntactic Rules in Neural\n  Constituency Parsing","summary":"  Most recent studies on neural constituency parsing focus on encoder\nstructures, while few developments are devoted to decoders. Previous research\nhas demonstrated that probabilistic statistical methods based on syntactic\nrules are particularly effective in constituency parsing, whereas syntactic\nrules are not used during the training of neural models in prior work probably\ndue to their enormous computation requirements. In this paper, we first\nimplement a fast CKY decoding procedure harnessing GPU acceleration, based on\nwhich we further derive a syntactic rule-based (rule-constrained) CKY decoding.\nIn the experiments, our method obtains 95.89 and 92.52 F1 on the datasets of\nPTB and CTB respectively, which shows significant improvements compared with\nprevious approaches. Besides, our parser achieves strong and competitive\ncross-domain performance in zero-shot settings.\n","authors":["Tianyu Shi","Zhicheng Wang","Liyin Xiao","Cong Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08458v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07127v3","updated":"2022-12-16T12:52:19Z","published":"2022-12-14T09:26:07Z","title":"Towards mapping the contemporary art world with ArtLM: an art-specific\n  NLP model","summary":"  With an increasing amount of data in the art world, discovering artists and\nartworks suitable to collectors' tastes becomes a challenge. It is no longer\nenough to use visual information, as contextual information about the artist\nhas become just as important in contemporary art. In this work, we present a\ngeneric Natural Language Processing framework (called ArtLM) to discover the\nconnections among contemporary artists based on their biographies. In this\napproach, we first continue to pre-train the existing general English language\nmodels with a large amount of unlabelled art-related data. We then fine-tune\nthis new pre-trained model with our biography pair dataset manually annotated\nby a team of professionals in the art industry. With extensive experiments, we\ndemonstrate that our ArtLM achieves 85.6% accuracy and 84.0% F1 score and\noutperforms other baseline models. We also provide a visualisation and a\nqualitative analysis of the artist network built from ArtLM's outputs.\n","authors":["Qinkai Chen","Mohamed El-Mennaoui","Antoine Fosset","Amine Rebei","Haoyang Cao","Philine Bouscasse","Christy Eóin O'Beirne","Sasha Shevchenko","Mathieu Rosenbaum"],"pdf_url":"https://arxiv.org/pdf/2212.07127v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08410v1","updated":"2022-12-16T11:24:42Z","published":"2022-12-16T11:24:42Z","title":"Teaching Small Language Models to Reason","summary":"  Chain of thought prompting successfully improves the reasoning capabilities\nof large language models, achieving state of the art results on a range of\ndatasets. However, these reasoning capabilities only appear to emerge in models\nwith a size of over 100 billion parameters. In this paper, we explore the\ntransfer of such reasoning capabilities to models with less than 100 billion\nparameters via knowledge distillation. Specifically, we finetune a student\nmodel on the chain of thought outputs generated by a larger teacher model. Our\nexperiments show that the proposed method improves task performance across\narithmetic, commonsense and symbolic reasoning datasets. For example, the\naccuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on\nPaLM-540B generated chains of thought.\n","authors":["Lucie Charlotte Magister","Jonathan Mallinson","Jakub Adamek","Eric Malmi","Aliaksei Severyn"],"pdf_url":"https://arxiv.org/pdf/2212.08410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08408v1","updated":"2022-12-16T11:15:39Z","published":"2022-12-16T11:15:39Z","title":"Decoder Tuning: Efficient Language Understanding as Decoding","summary":"  With the evergrowing sizes of pre-trained models (PTMs), it has been an\nemerging practice to only provide the inference APIs for users, namely\nmodel-as-a-service (MaaS) setting. To adapt PTMs with model parameters frozen,\nmost current approaches focus on the input side, seeking for powerful prompts\nto stimulate models for correct answers. However, we argue that input-side\nadaptation could be arduous due to the lack of gradient signals and they\nusually require thousands of API queries, resulting in high computation and\ntime costs. In light of this, we present Decoder Tuning (DecT), which in\ncontrast optimizes task-specific decoder networks on the output side.\nSpecifically, DecT first extracts prompt-stimulated output scores for initial\npredictions. On top of that, we train an additional decoder network on the\noutput representations to incorporate posterior data knowledge. By\ngradient-based optimization, DecT can be trained within several seconds and\nrequires only one PTM query per sample. Empirically, we conduct extensive\nnatural language understanding experiments and show that DecT significantly\noutperforms state-of-the-art algorithms with a $10^3\\times$ speed-up.\n","authors":["Ganqu Cui","Wentao Li","Ning Ding","Longtao Huang","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2212.08408v1.pdf","comment":"Work in progress. 13 pages"},{"id":"http://arxiv.org/abs/2212.08407v1","updated":"2022-12-16T11:06:48Z","published":"2022-12-16T11:06:48Z","title":"Utilizing distilBert transformer model for sentiment classification of\n  COVID-19's Persian open-text responses","summary":"  The COVID-19 pandemic has caused drastic alternations in human life in all\naspects. The government's laws in this regard affected the lifestyle of all\npeople. Due to this fact studying the sentiment of individuals is essential to\nbe aware of the future impacts of the coming pandemics. To contribute to this\naim, we proposed an NLP (Natural Language Processing) model to analyze\nopen-text answers in a survey in Persian and detect positive and negative\nfeelings of the people in Iran. In this study, a distilBert transformer model\nwas applied to take on this task. We deployed three approaches to perform the\ncomparison, and our best model could gain accuracy: 0.824, Precision: 0.824,\nRecall: 0.798, and F1 score: 0.804.\n","authors":["Fatemeh Sadat Masoumi","Mohammad Bahrani"],"pdf_url":"https://arxiv.org/pdf/2212.08407v1.pdf","comment":"The paper is accepted at The 7th International Conference on Science\n  and Technology of Electrical, Computer, and Mechanical Engineering of Iran"},{"id":"http://arxiv.org/abs/2212.08395v1","updated":"2022-12-16T10:39:22Z","published":"2022-12-16T10:39:22Z","title":"Metaphorical Polysemy Detection: Conventional Metaphor meets Word Sense\n  Disambiguation","summary":"  Linguists distinguish between novel and conventional metaphor, a distinction\nwhich the metaphor detection task in NLP does not take into account. Instead,\nmetaphoricity is formulated as a property of a token in a sentence, regardless\nof metaphor type. In this paper, we investigate the limitations of treating\nconventional metaphors in this way, and advocate for an alternative which we\nname 'metaphorical polysemy detection' (MPD). In MPD, only conventional\nmetaphoricity is treated, and it is formulated as a property of word senses in\na lexicon. We develop the first MPD model, which learns to identify\nconventional metaphors in the English WordNet. To train it, we present a novel\ntraining procedure that combines metaphor detection with word sense\ndisambiguation (WSD). For evaluation, we manually annotate metaphor in two\nsubsets of WordNet. Our model significantly outperforms a strong baseline based\non a state-of-the-art metaphor detection model, attaining an ROC-AUC score of\n.78 (compared to .65) on one of the sets. Additionally, when paired with a WSD\nmodel, our approach outperforms a state-of-the-art metaphor detection model at\nidentifying conventional metaphors in text (.659 F1 compared to .626).\n","authors":["Rowan Hall Maudslay","Simone Teufel"],"pdf_url":"https://arxiv.org/pdf/2212.08395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08390v1","updated":"2022-12-16T10:33:38Z","published":"2022-12-16T10:33:38Z","title":"Lessons learned from the evaluation of Spanish Language Models","summary":"  Given the impact of language models on the field of Natural Language\nProcessing, a number of Spanish encoder-only masked language models (aka BERTs)\nhave been trained and released. These models were developed either within large\nprojects using very large private corpora or by means of smaller scale academic\nefforts leveraging freely available data. In this paper we present a\ncomprehensive head-to-head comparison of language models for Spanish with the\nfollowing results: (i) Previously ignored multilingual models from large\ncompanies fare better than monolingual models, substantially changing the\nevaluation landscape of language models in Spanish; (ii) Results across the\nmonolingual models are not conclusive, with supposedly smaller and inferior\nmodels performing competitively. Based on these empirical results, we argue for\nthe need of more research to understand the factors underlying them. In this\nsense, the effect of corpus size, quality and pre-training techniques need to\nbe further investigated to be able to obtain Spanish monolingual models\nsignificantly better than the multilingual ones released by large private\ncompanies, specially in the face of rapid ongoing progress in the field. The\nrecent activity in the development of language technology for Spanish is to be\nwelcomed, but our results show that building language models remains an open,\nresource-heavy problem which requires to marry resources (monetary and/or\ncomputational) with the best research expertise and practice.\n","authors":["Rodrigo Agerri","Eneko Agirre"],"pdf_url":"https://arxiv.org/pdf/2212.08390v1.pdf","comment":"10 pages, three tables"},{"id":"http://arxiv.org/abs/2212.08388v1","updated":"2022-12-16T10:23:26Z","published":"2022-12-16T10:23:26Z","title":"Homonymy Information for English WordNet","summary":"  A widely acknowledged shortcoming of WordNet is that it lacks a distinction\nbetween word meanings which are systematically related (polysemy), and those\nwhich are coincidental (homonymy). Several previous works have attempted to\nfill this gap, by inferring this information using computational methods. We\nrevisit this task, and exploit recent advances in language modelling to\nsynthesise homonymy annotation for Princeton WordNet. Previous approaches treat\nthe problem using clustering methods; by contrast, our method works by linking\nWordNet to the Oxford English Dictionary, which contains the information we\nneed. To perform this alignment, we pair definitions based on their proximity\nin an embedding space produced by a Transformer model. Despite the simplicity\nof this approach, our best model attains an F1 of .97 on an evaluation set that\nwe annotate. The outcome of our work is a high-quality homonymy annotation\nlayer for Princeton WordNet, which we release.\n","authors":["Rowan Hall Maudslay","Simone Teufel"],"pdf_url":"https://arxiv.org/pdf/2212.08388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04800v2","updated":"2022-12-16T09:47:43Z","published":"2022-12-09T12:06:15Z","title":"AUC Maximization for Low-Resource Named Entity Recognition","summary":"  Current work in named entity recognition (NER) uses either cross entropy (CE)\nor conditional random fields (CRF) as the objective/loss functions to optimize\nthe underlying NER model. Both of these traditional objective functions for the\nNER problem generally produce adequate performance when the data distribution\nis balanced and there are sufficient annotated training examples. But since NER\nis inherently an imbalanced tagging problem, the model performance under the\nlow-resource settings could suffer using these standard objective functions.\nBased on recent advances in area under the ROC curve (AUC) maximization, we\npropose to optimize the NER model by maximizing the AUC score. We give evidence\nthat by simply combining two binary-classifiers that maximize the AUC score,\nsignificant performance improvement over traditional loss functions is achieved\nunder low-resource NER settings. We also conduct extensive experiments to\ndemonstrate the advantages of our method under the low-resource and\nhighly-imbalanced data distribution settings. To the best of our knowledge,\nthis is the first work that brings AUC maximization to the NER setting.\nFurthermore, we show that our method is agnostic to different types of NER\nembeddings, models and domains. The code to replicate this work will be\nprovided upon request.\n","authors":["Ngoc Dang Nguyen","Wei Tan","Wray Buntine","Richard Beare","Changyou Chen","Lan Du"],"pdf_url":"https://arxiv.org/pdf/2212.04800v2.pdf","comment":"10 pages, 4 figures, AAAI 2023 accepted paper"},{"id":"http://arxiv.org/abs/2212.08354v1","updated":"2022-12-16T09:01:56Z","published":"2022-12-16T09:01:56Z","title":"FewFedWeight: Few-shot Federated Learning Framework across Multiple NLP\n  Tasks","summary":"  Massively multi-task learning with large language models has recently made\nsubstantial progress on few-shot generalization. However, this is usually\nperformed in a centralized learning fashion, ignoring the privacy sensitivity\nissue of (annotated) data used in multiple tasks. To mitigate this issue, we\npropose FewFedWeight, a few-shot federated learning framework across multiple\ntasks, to achieve the best of both worlds: privacy preservation and cross-task\ngeneralization. FewFedWeight trains client models in isolated devices without\nsharing data. It broadcasts the global model in the server to each client and\nproduces pseudo data for clients so that knowledge from the global model can be\nexplored to enhance few-shot learning of each client model. An energy-based\nalgorithm is further proposed to weight pseudo samples in order to reduce the\nnegative impact of noise from the generated pseudo data. Adaptive model weights\nof client models are also tuned according to their performance. We use these\nmodel weights to dynamically aggregate client models to update the global\nmodel. Experiments on 118 NLP tasks show that FewFedWeight can significantly\nimprove the performance of client models on 61% tasks with an average\nperformance improvement rate of 30.5% over the baseline and substantially\noutperform FedAvg and other decentralized learning methods.\n","authors":["Weilong Dong","Xinwei Wu","Junzhuo Li","Shuangzhi Wu","Chao Bian","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2212.08354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08353v1","updated":"2022-12-16T09:01:19Z","published":"2022-12-16T09:01:19Z","title":"How to disagree well: Investigating the dispute tactics used on\n  Wikipedia","summary":"  Disagreements are frequently studied from the perspective of either detecting\ntoxicity or analysing argument structure. We propose a framework of dispute\ntactics that unifies these two perspectives, as well as other dialogue acts\nwhich play a role in resolving disputes, such as asking questions and providing\nclarification. This framework includes a preferential ordering among\nrebuttal-type tactics, ranging from ad hominem attacks to refuting the central\nargument. Using this framework, we annotate 213 disagreements (3,865\nutterances) from Wikipedia Talk pages. This allows us to investigate research\nquestions around the tactics used in disagreements; for instance, we provide\nempirical validation of the approach to disagreement recommended by Wikipedia.\nWe develop models for multilabel prediction of dispute tactics in an utterance,\nachieving the best performance with a transformer-based label powerset model.\nAdding an auxiliary task to incorporate the ordering of rebuttal tactics\nfurther yields a statistically significant increase. Finally, we show that\nthese annotations can be used to provide useful additional signals to improve\nperformance on the task of predicting escalation.\n","authors":["Christine de Kock","Tom Stafford","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2212.08353v1.pdf","comment":"Accepted to EMNLP 2022 (Long paper)"},{"id":"http://arxiv.org/abs/2212.08335v1","updated":"2022-12-16T08:26:32Z","published":"2022-12-16T08:26:32Z","title":"Law to Binary Tree -- An Formal Interpretation of Legal Natural Language","summary":"  Knowledge representation and reasoning in law are essential to facilitate the\nautomation of legal analysis and decision-making tasks. In this paper, we\npropose a new approach based on legal science, specifically legal taxonomy, for\nrepresenting and reasoning with legal documents. Our approach interprets the\nregulations in legal documents as binary trees, which facilitates legal\nreasoning systems to make decisions and resolve logical contradictions. The\nadvantages of this approach are twofold. First, legal reasoning can be\nperformed on the basis of the binary tree representation of the regulations.\nSecond, the binary tree representation of the regulations is more\nunderstandable than the existing sentence-based representations. We provide an\nexample of how our approach can be used to interpret the regulations in a legal\ndocument.\n","authors":["Ha-Thanh Nguyen","Vu Tran","Ngoc-Cam Le","Thi-Thuy Le","Quang-Huy Nguyen","Le-Minh Nguyen","Ken Satoh"],"pdf_url":"https://arxiv.org/pdf/2212.08335v1.pdf","comment":"LN2FR 2022"},{"id":"http://arxiv.org/abs/2212.08329v1","updated":"2022-12-16T08:14:04Z","published":"2022-12-16T08:14:04Z","title":"Text-to-speech synthesis based on latent variable conversion using\n  diffusion probabilistic model and variational autoencoder","summary":"  Text-to-speech synthesis (TTS) is a task to convert texts into speech. Two of\nthe factors that have been driving TTS are the advancements of probabilistic\nmodels and latent representation learning. We propose a TTS method based on\nlatent variable conversion using a diffusion probabilistic model and the\nvariational autoencoder (VAE). In our TTS method, we use a waveform model based\non VAE, a diffusion model that predicts the distribution of latent variables in\nthe waveform model from texts, and an alignment model that learns alignments\nbetween the text and speech latent sequences. Our method integrates diffusion\nwith VAE by modeling both mean and variance parameters with diffusion, where\nthe target distribution is determined by approximation from VAE. This latent\nvariable conversion framework potentially enables us to flexibly incorporate\nvarious latent feature extractors. Our experiments show that our method is\nrobust to linguistic labels with poor orthography and alignment errors.\n","authors":["Yusuke Yasuda","Tomoki Toda"],"pdf_url":"https://arxiv.org/pdf/2212.08329v1.pdf","comment":"Submitted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2212.08330v1","updated":"2022-12-16T08:14:04Z","published":"2022-12-16T08:14:04Z","title":"Convolution-enhanced Evolving Attention Networks","summary":"  Attention-based neural networks, such as Transformers, have become ubiquitous\nin numerous applications, including computer vision, natural language\nprocessing, and time-series analysis. In all kinds of attention networks, the\nattention maps are crucial as they encode semantic dependencies between input\ntokens. However, most existing attention networks perform modeling or reasoning\nbased on representations, wherein the attention maps of different layers are\nlearned separately without explicit interactions. In this paper, we propose a\nnovel and generic evolving attention mechanism, which directly models the\nevolution of inter-token relationships through a chain of residual\nconvolutional modules. The major motivations are twofold. On the one hand, the\nattention maps in different layers share transferable knowledge, thus adding a\nresidual connection can facilitate the information flow of inter-token\nrelationships across layers. On the other hand, there is naturally an\nevolutionary trend among attention maps at different abstraction levels, so it\nis beneficial to exploit a dedicated convolution-based module to capture this\nprocess. Equipped with the proposed mechanism, the convolution-enhanced\nevolving attention networks achieve superior performance in various\napplications, including time-series representation, natural language\nunderstanding, machine translation, and image classification. Especially on\ntime-series representation tasks, Evolving Attention-enhanced Dilated\nConvolutional (EA-DC-) Transformer outperforms state-of-the-art models\nsignificantly, achieving an average of 17% improvement compared to the best\nSOTA. To the best of our knowledge, this is the first work that explicitly\nmodels the layer-wise evolution of attention maps. Our implementation is\navailable at https://github.com/pkuyym/EvolvingAttention\n","authors":["Yujing Wang","Yaming Yang","Zhuo Li","Jiangang Bai","Mingliang Zhang","Xiangtai Li","Jing Yu","Ce Zhang","Gao Huang","Yunhai Tong"],"pdf_url":"https://arxiv.org/pdf/2212.08330v1.pdf","comment":"Extension of the previous work (arXiv:2102.12895). arXiv admin note:\n  text overlap with arXiv:2102.12895"},{"id":"http://arxiv.org/abs/2212.08322v1","updated":"2022-12-16T07:48:02Z","published":"2022-12-16T07:48:02Z","title":"ReCo: Reliable Causal Chain Reasoning via Structural Causal Recurrent\n  Neural Networks","summary":"  Causal chain reasoning (CCR) is an essential ability for many decision-making\nAI systems, which requires the model to build reliable causal chains by\nconnecting causal pairs. However, CCR suffers from two main transitive\nproblems: threshold effect and scene drift. In other words, the causal pairs to\nbe spliced may have a conflicting threshold boundary or scenario. To address\nthese issues, we propose a novel Reliable Causal chain reasoning\nframework~(ReCo), which introduces exogenous variables to represent the\nthreshold and scene factors of each causal pair within the causal chain, and\nestimates the threshold and scene contradictions across exogenous variables via\nstructural causal recurrent neural networks~(SRNN). Experiments show that ReCo\noutperforms a series of strong baselines on both Chinese and English CCR\ndatasets. Moreover, by injecting reliable causal chain knowledge distilled by\nReCo, BERT can achieve better performances on four downstream causal-related\ntasks than BERT models enhanced by other kinds of knowledge.\n","authors":["Kai Xiong","Xiao Ding","Zhongyang Li","Li Du","Bing Qin","Yi Zheng","Baoxing Huai"],"pdf_url":"https://arxiv.org/pdf/2212.08322v1.pdf","comment":"Accepted by EMNLP 2022"},{"id":"http://arxiv.org/abs/2212.08321v1","updated":"2022-12-16T07:47:03Z","published":"2022-12-16T07:47:03Z","title":"Investigation of Japanese PnG BERT language model in text-to-speech\n  synthesis for pitch accent language","summary":"  End-to-end text-to-speech synthesis (TTS) can generate highly natural\nsynthetic speech from raw text. However, rendering the correct pitch accents is\nstill a challenging problem for end-to-end TTS. To tackle the challenge of\nrendering correct pitch accent in Japanese end-to-end TTS, we adopt PnG~BERT, a\nself-supervised pretrained model in the character and phoneme domain for TTS.\nWe investigate the effects of features captured by PnG~BERT on Japanese TTS by\nmodifying the fine-tuning condition to determine the conditions helpful\ninferring pitch accents. We manipulate content of PnG~BERT features from being\ntext-oriented to speech-oriented by changing the number of fine-tuned layers\nduring TTS. In addition, we teach PnG~BERT pitch accent information by\nfine-tuning with tone prediction as an additional downstream task. Our\nexperimental results show that the features of PnG~BERT captured by pretraining\ncontain information helpful inferring pitch accent, and PnG~BERT outperforms\nbaseline Tacotron on accent correctness in a listening test.\n","authors":["Yusuke Yasuda","Tomoki Toda"],"pdf_url":"https://arxiv.org/pdf/2212.08321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08307v1","updated":"2022-12-16T07:11:18Z","published":"2022-12-16T07:11:18Z","title":"Controllable Text Generation via Probability Density Estimation in the\n  Latent Space","summary":"  Previous work on controllable text generation has explored the idea of\ncontrol from the latent space, such as optimizing a representation with\nattribute-related classifiers or sampling a representation from relevant\ndiscrete samples. However, they are not effective enough in modeling both the\nlatent space and the control, leaving controlled text with low quality and\ndiversity. In this work, we propose a novel control framework using probability\ndensity estimation in the latent space. Our method utilizes an invertible\ntransformation function, the Normalizing Flow, that maps the complex\ndistributions in the latent space to simple Gaussian distributions in the prior\nspace. Thus, we can perform sophisticated and flexible control in the prior\nspace and feed the control effects back into the latent space owing to the\none-one-mapping property of invertible transformations. Experiments on\nsingle-attribute controls and multi-attribute control reveal that our method\noutperforms several strong baselines on attribute relevance and text quality\nand achieves the SOTA. Further analysis of control strength adjustment\ndemonstrates the flexibility of our control strategy.\n","authors":["Yuxuan Gu","Xiaocheng Feng","Sicheng Ma","Lingyuan Zhang","Heng Gong","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2212.08307v1.pdf","comment":"13 pages, 6 figures, Work in progress"},{"id":"http://arxiv.org/abs/2212.08287v1","updated":"2022-12-16T05:17:59Z","published":"2022-12-16T05:17:59Z","title":"Rich Event Modeling for Script Event Prediction","summary":"  Script is a kind of structured knowledge extracted from texts, which contains\na sequence of events. Based on such knowledge, script event prediction aims to\npredict the subsequent event. To do so, two aspects should be considered for\nevents, namely, event description (i.e., what the events should contain) and\nevent encoding (i.e., how they should be encoded). Most existing methods\ndescribe an event by a verb together with only a few core arguments (i.e.,\nsubject, object, and indirect object), which are not precise. In addition,\nexisting event encoders are limited to a fixed number of arguments, which are\nnot flexible to deal with extra information. Thus, in this paper, we propose\nthe Rich Event Prediction (REP) framework for script event prediction.\nFundamentally, it is based on the proposed rich event description, which\nenriches the existing ones with three kinds of important information, namely,\nthe senses of verbs, extra semantic roles, and types of participants. REP\ncontains an event extractor to extract such information from texts. Based on\nthe extracted rich information, a predictor then selects the most probable\nsubsequent event. The core component of the predictor is a transformer-based\nevent encoder to flexibly deal with an arbitrary number of arguments.\nExperimental results on the widely used Gigaword Corpus show the effectiveness\nof the proposed framework.\n","authors":["Long Bai","Saiping Guan","Zixuan Li","Jiafeng Guo","Xiaolong Jin","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2212.08287v1.pdf","comment":"AAAI 2023 (main conference)"},{"id":"http://arxiv.org/abs/2212.08286v1","updated":"2022-12-16T05:15:41Z","published":"2022-12-16T05:15:41Z","title":"ALERT: Adapting Language Models to Reasoning Tasks","summary":"  Current large language models can perform reasonably well on complex tasks\nthat require step-by-step reasoning with few-shot learning. Are these models\napplying reasoning skills they have learnt during pre-training and reason\noutside of their training context, or are they simply memorizing their training\ncorpus at finer granularity and have learnt to better understand their context?\nTo tease apart these possibilities, we introduce ALERT, a benchmark and suite\nof analyses for assessing language models' reasoning ability comparing\npre-trained and finetuned models on complex tasks that require reasoning skills\nto solve. ALERT provides a test bed to asses any language model on fine-grained\nreasoning skills, which spans over 20 datasets and covers 10 different\nreasoning skills. We leverage ALERT to further investigate the role of\nfinetuning. With extensive empirical analysis we find that language models\nlearn more reasoning skills such as textual entailment, abductive reasoning,\nand analogical reasoning during finetuning stage compared to pretraining state.\nWe also find that when language models are finetuned they tend to overfit to\nthe prompt template, which hurts the robustness of models causing\ngeneralization problems.\n","authors":["Ping Yu","Tianlu Wang","Olga Golovneva","Badr Alkhamissy","Gargi Ghosh","Mona Diab","Asli Celikyilmaz"],"pdf_url":"https://arxiv.org/pdf/2212.08286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08283v1","updated":"2022-12-16T05:10:09Z","published":"2022-12-16T05:10:09Z","title":"SceneGATE: Scene-Graph based co-Attention networks for TExt visual\n  question answering","summary":"  Most TextVQA approaches focus on the integration of objects, scene texts and\nquestion words by a simple transformer encoder. But this fails to capture the\nsemantic relations between different modalities. The paper proposes a Scene\nGraph based co-Attention Network (SceneGATE) for TextVQA, which reveals the\nsemantic relations among the objects, Optical Character Recognition (OCR)\ntokens and the question words. It is achieved by a TextVQA-based scene graph\nthat discovers the underlying semantics of an image. We created a\nguided-attention module to capture the intra-modal interplay between the\nlanguage and the vision as a guidance for inter-modal interactions. To make\nexplicit teaching of the relations between the two modalities, we proposed and\nintegrated two attention modules, namely a scene graph-based semantic\nrelation-aware attention and a positional relation-aware attention. We\nconducted extensive experiments on two benchmark datasets, Text-VQA and ST-VQA.\nIt is shown that our SceneGATE method outperformed existing ones because of the\nscene graph and its attention modules.\n","authors":["Siwen Luo","Feiqi Cao","Felipe Nunez","Zean Wen","Josiah Poon","Caren Han"],"pdf_url":"https://arxiv.org/pdf/2212.08283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08279v1","updated":"2022-12-16T04:52:53Z","published":"2022-12-16T04:52:53Z","title":"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion\n  Behaviors in Social Deduction Games","summary":"  Persuasion modeling is a key building block for conversational agents.\nExisting works in this direction are limited to analyzing textual dialogue\ncorpus. We argue that visual signals also play an important role in\nunderstanding human persuasive behaviors. In this paper, we introduce the first\nmultimodal dataset for modeling persuasion behaviors. Our dataset includes 199\ndialogue transcriptions and videos captured in a multi-player social deduction\ngame setting, 26,647 utterance level annotations of persuasion strategy, and\ngame level annotations of deduction game outcomes. We provide extensive\nexperiments to show how dialogue context and visual signals benefit persuasion\nstrategy prediction. We also explore the generalization ability of language\nmodels for persuasion modeling and the role of persuasion strategies in\npredicting social deduction game outcomes. Our dataset, code, and models can be\nfound at https://persuasion-deductiongame.socialai-data.org.\n","authors":["Bolin Lai","Hongxin Zhang","Miao Liu","Aryan Pariani","Fiona Ryan","Wenqi Jia","Shirley Anugrah Hayati","James M. Rehg","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2212.08279v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2212.08216v1","updated":"2022-12-16T01:10:41Z","published":"2022-12-16T01:10:41Z","title":"Azimuth: Systematic Error Analysis for Text Classification","summary":"  We present Azimuth, an open-source and easy-to-use tool to perform error\nanalysis for text classification. Compared to other stages of the ML\ndevelopment cycle, such as model training and hyper-parameter tuning, the\nprocess and tooling for the error analysis stage are less mature. However, this\nstage is critical for the development of reliable and trustworthy AI systems.\nTo make error analysis more systematic, we propose an approach comprising\ndataset analysis and model quality assessment, which Azimuth facilitates. We\naim to help AI practitioners discover and address areas where the model does\nnot generalize by leveraging and integrating a range of ML techniques, such as\nsaliency maps, similarity, uncertainty, and behavioral analyses, all in one\ntool. Our code and documentation are available at\ngithub.com/servicenow/azimuth.\n","authors":["Gabrielle Gauthier-Melançon","Orlando Marquez Ayala","Lindsay Brin","Chris Tyler","Frédéric Branchaud-Charron","Joseph Marinier","Karine Grande","Di Le"],"pdf_url":"https://arxiv.org/pdf/2212.08216v1.pdf","comment":"To be published in Proceedings of the 2022 Conference on Empirical\n  Methods in Natural Language Processing: System Demonstrations. 13 pages and\n  14 figures"},{"id":"http://arxiv.org/abs/2212.08206v1","updated":"2022-12-16T00:21:30Z","published":"2022-12-16T00:21:30Z","title":"Meeting Summarization: A Survey of the State of the Art","summary":"  Information overloading requires the need for summarizers to extract salient\ninformation from the text. Currently, there is an overload of dialogue data due\nto the rise of virtual communication platforms. The rise of Covid-19 has led\npeople to rely on online communication platforms like Zoom, Slack, Microsoft\nTeams, Discord, etc. to conduct their company meetings. Instead of going\nthrough the entire meeting transcripts, people can use meeting summarizers to\nselect useful data. Nevertheless, there is a lack of comprehensive surveys in\nthe field of meeting summarizers. In this survey, we aim to cover recent\nmeeting summarization techniques. Our survey offers a general overview of text\nsummarization along with datasets and evaluation metrics for meeting\nsummarization. We also provide the performance of each summarizer on a\nleaderboard. We conclude our survey with different challenges in this domain\nand potential research opportunities for future researchers.\n","authors":["Lakshmi Prasanna Kumar","Arman Kabiri"],"pdf_url":"https://arxiv.org/pdf/2212.08206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08205v1","updated":"2022-12-16T00:15:45Z","published":"2022-12-16T00:15:45Z","title":"A unified information-theoretic model of EEG signatures of human\n  language processing","summary":"  We advance an information-theoretic model of human language processing in the\nbrain, in which incoming linguistic input is processed at two levels, in terms\nof a heuristic interpretation and in terms of error correction. We propose that\nthese two kinds of information processing have distinct electroencephalographic\nsignatures, corresponding to the well-documented N400 and P600 components of\nlanguage-related event-related potentials (ERPs). Formally, we show that the\ninformation content (surprisal) of a word in context can be decomposed into two\nquantities: (A) heuristic surprise, which signals processing difficulty of word\ngiven its inferred context, and corresponds with the N400 signal; and (B)\ndiscrepancy signal, which reflects divergence between the true context and the\ninferred context, and corresponds to the P600 signal. Both of these quantities\ncan be estimated using modern NLP techniques. We validate our theory by\nsuccessfully simulating ERP patterns elicited by a variety of linguistic\nmanipulations in previously-reported experimental data from Ryskin et al.\n(2021). Our theory is in principle compatible with traditional cognitive\ntheories assuming a `good-enough' heuristic interpretation stage, but with\nprecise information-theoretic formulation.\n","authors":["Jiaxuan Li","Richard Futrell"],"pdf_url":"https://arxiv.org/pdf/2212.08205v1.pdf","comment":"4 pages, 3 figures, accepted InfoCog workshop at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.08204v1","updated":"2022-12-16T00:15:14Z","published":"2022-12-16T00:15:14Z","title":"LegalRelectra: Mixed-domain Language Modeling for Long-range Legal Text\n  Comprehension","summary":"  The application of Natural Language Processing (NLP) to specialized domains,\nsuch as the law, has recently received a surge of interest. As many legal\nservices rely on processing and analyzing large collections of documents,\nautomating such tasks with NLP tools emerges as a key challenge. Many popular\nlanguage models, such as BERT or RoBERTa, are general-purpose models, which\nhave limitations on processing specialized legal terminology and syntax. In\naddition, legal documents may contain specialized vocabulary from other\ndomains, such as medical terminology in personal injury text. Here, we propose\nLegalRelectra, a legal-domain language model that is trained on mixed-domain\nlegal and medical corpora. We show that our model improves over general-domain\nand single-domain medical and legal language models when processing\nmixed-domain (personal injury) text. Our training architecture implements the\nElectra framework, but utilizes Reformer instead of BERT for its generator and\ndiscriminator. We show that this improves the model's performance on processing\nlong passages and results in better long-range text comprehension.\n","authors":["Wenyue Hua","Yuchen Zhang","Zhe Chen","Josie Li","Melanie Weber"],"pdf_url":"https://arxiv.org/pdf/2212.08204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08756v1","updated":"2022-12-16T23:37:44Z","published":"2022-12-16T23:37:44Z","title":"Multi-Scales Data Augmentation Approach In Natural Language Inference\n  For Artifacts Mitigation And Pre-Trained Model Optimization","summary":"  Machine learning models can reach high performance on benchmark natural\nlanguage processing (NLP) datasets but fail in more challenging settings. We\nstudy this issue when a pre-trained model learns dataset artifacts in natural\nlanguage inference (NLI), the topic of studying the logical relationship\nbetween a pair of text sequences. We provide a variety of techniques for\nanalyzing and locating dataset artifacts inside the crowdsourced Stanford\nNatural Language Inference (SNLI) corpus. We study the stylistic pattern of\ndataset artifacts in the SNLI. To mitigate dataset artifacts, we employ a\nunique multi-scale data augmentation technique with two distinct frameworks: a\nbehavioral testing checklist at the sentence level and lexical synonym criteria\nat the word level. Specifically, our combination method enhances our model's\nresistance to perturbation testing, enabling it to continuously outperform the\npre-trained baseline.\n","authors":["Zhenyuan Lu"],"pdf_url":"https://arxiv.org/pdf/2212.08756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05956v2","updated":"2022-12-16T22:25:28Z","published":"2022-12-12T15:09:56Z","title":"Improving Generalization of Pre-trained Language Models via Stochastic\n  Weight Averaging","summary":"  Knowledge Distillation (KD) is a commonly used technique for improving the\ngeneralization of compact Pre-trained Language Models (PLMs) on downstream\ntasks. However, such methods impose the additional burden of training a\nseparate teacher model for every new dataset. Alternatively, one may directly\nwork on the improvement of the optimization procedure of the compact model\ntoward better generalization. Recent works observe that the flatness of the\nlocal minimum correlates well with better generalization. In this work, we\nadapt Stochastic Weight Averaging (SWA), a method encouraging convergence to a\nflatter minimum, to fine-tuning PLMs. We conduct extensive experiments on\nvarious NLP tasks (text classification, question answering, and generation) and\ndifferent model architectures and demonstrate that our adaptation improves the\ngeneralization without extra computation cost. Moreover, we observe that this\nsimple optimization technique is able to outperform the state-of-the-art KD\nmethods for compact models.\n","authors":["Peng Lu","Ivan Kobyzev","Mehdi Rezagholizadeh","Ahmad Rashid","Ali Ghodsi","Philippe Langlais"],"pdf_url":"https://arxiv.org/pdf/2212.05956v2.pdf","comment":"Published at EMNLP 2022 (Findings)"},{"id":"http://arxiv.org/abs/2203.03540v3","updated":"2022-12-16T22:20:33Z","published":"2022-02-02T14:28:51Z","title":"GatorTron: A Large Clinical Language Model to Unlock Patient Information\n  from Unstructured Electronic Health Records","summary":"  There is an increasing interest in developing artificial intelligence (AI)\nsystems to process and interpret electronic health records (EHRs). Natural\nlanguage processing (NLP) powered by pretrained language models is the key\ntechnology for medical AI systems utilizing clinical narratives. However, there\nare few clinical language models, the largest of which trained in the clinical\ndomain is comparatively small at 110 million parameters (compared with billions\nof parameters in the general domain). It is not clear how large clinical\nlanguage models with billions of parameters can help medical AI systems utilize\nunstructured EHRs. In this study, we develop from scratch a large clinical\nlanguage model - GatorTron - using >90 billion words of text (including >82\nbillion words of de-identified clinical text) and systematically evaluate it on\n5 clinical NLP tasks including clinical concept extraction, medical relation\nextraction, semantic textual similarity, natural language inference (NLI), and\nmedical question answering (MQA). We examine how (1) scaling up the number of\nparameters and (2) scaling up the size of the training data could benefit these\nNLP tasks. GatorTron models scale up the clinical language model from 110\nmillion to 8.9 billion parameters and improve 5 clinical NLP tasks (e.g., 9.6%\nand 9.5% improvement in accuracy for NLI and MQA), which can be applied to\nmedical AI systems to improve healthcare delivery. The GatorTron models are\npublicly available at:\nhttps://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/gatortron_og.\n","authors":["Xi Yang","Aokun Chen","Nima PourNejatian","Hoo Chang Shin","Kaleb E Smith","Christopher Parisien","Colin Compas","Cheryl Martin","Mona G Flores","Ying Zhang","Tanja Magoc","Christopher A Harle","Gloria Lipori","Duane A Mitchell","William R Hogan","Elizabeth A Shenkman","Jiang Bian","Yonghui Wu"],"pdf_url":"https://arxiv.org/pdf/2203.03540v3.pdf","comment":"24 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2212.08724v1","updated":"2022-12-16T21:44:34Z","published":"2022-12-16T21:44:34Z","title":"DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text\n  Generation","summary":"  Self-training (ST) has prospered again in language understanding by\naugmenting the fine-tuning of pre-trained language models when labeled data is\ninsufficient. However, it remains challenging to incorporate ST into\nattribute-controllable language generation. Augmented by only self-generated\npseudo text, generation models over-emphasize exploitation of the previously\nlearned space, suffering from a constrained generalization boundary. We revisit\nST and propose a novel method, DuNST to alleviate this problem. DuNST jointly\nmodels text generation and classification with a shared Variational AutoEncoder\nand corrupts the generated pseudo text by two kinds of flexible noise to\ndisturb the space. In this way, our model could construct and utilize both\npseudo text from given labels and pseudo labels from available unlabeled text,\nwhich are gradually refined during the ST process. We theoretically demonstrate\nthat DuNST can be regarded as enhancing exploration towards the potential real\ntext space, providing a guarantee of improved performance. Experiments on three\ncontrollable generation tasks show that DuNST could significantly boost control\naccuracy while maintaining comparable generation fluency and diversity against\nseveral strong baselines.\n","authors":["Yuxi Feng","Xiaoyuan Yi","Xiting Wang","Laks V. S. Lakshmanan","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2212.08724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08718v1","updated":"2022-12-16T21:29:41Z","published":"2022-12-16T21:29:41Z","title":"Neural Story Planning","summary":"  Automated plot generation is the challenge of generating a sequence of events\nthat will be perceived by readers as the plot of a coherent story. Traditional\nsymbolic planners plan a story from a goal state and guarantee logical causal\nplot coherence but rely on a library of hand-crafted actions with their\npreconditions and effects. This closed world setting limits the length and\ndiversity of what symbolic planners can generate. On the other hand,\npre-trained neural language models can generate stories with great diversity,\nwhile being generally incapable of ending a story in a specified manner and can\nhave trouble maintaining coherence. In this paper, we present an approach to\nstory plot generation that unifies causal planning with neural language models.\nWe propose to use commonsense knowledge extracted from large language models to\nrecursively expand a story plot in a backward chaining fashion. Specifically,\nour system infers the preconditions for events in the story and then events\nthat will cause those conditions to become true. We performed automatic\nevaluation to measure narrative coherence as indicated by the ability to answer\nquestions about whether different events in the story are causally related to\nother events. Results indicate that our proposed method produces more coherent\nplotlines than several strong baselines.\n","authors":["Anbang Ye","Christopher Cui","Taiwei Shi","Mark O. Riedl"],"pdf_url":"https://arxiv.org/pdf/2212.08718v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08703v1","updated":"2022-12-16T20:27:40Z","published":"2022-12-16T20:27:40Z","title":"Fast Entropy-Based Methods of Word-Level Confidence Estimation for\n  End-To-End Automatic Speech Recognition","summary":"  This paper presents a class of new fast non-trainable entropy-based\nconfidence estimation methods for automatic speech recognition. We show how\nper-frame entropy values can be normalized and aggregated to obtain a\nconfidence measure per unit and per word for Connectionist Temporal\nClassification (CTC) and Recurrent Neural Network Transducer (RNN-T) models.\nProposed methods have similar computational complexity to the traditional\nmethod based on the maximum per-frame probability, but they are more\nadjustable, have a wider effective threshold range, and better push apart the\nconfidence distributions of correct and incorrect words. We evaluate the\nproposed confidence measures on LibriSpeech test sets, and show that they are\nup to 2 and 4 times better than confidence estimation based on the maximum\nper-frame probability at detecting incorrect words for Conformer-CTC and\nConformer-RNN-T models, respectively.\n","authors":["Aleksandr Laptev","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2212.08703v1.pdf","comment":"To appear in Proc. SLT 2022, Jan 09-12, 2023, Doha, Qatar. 8 pages, 4\n  figures, 4 tables"},{"id":"http://arxiv.org/abs/2212.08700v1","updated":"2022-12-16T20:01:22Z","published":"2022-12-16T20:01:22Z","title":"'Rarely' a problem? Language models exhibit inverse scaling in their\n  predictions following 'few'-type quantifiers","summary":"  Language Models appear to perform poorly on quantification. We ask how badly.\n'Few'-type quantifiers, as in 'few children like vegetables' might pose a\nparticular challenge for Language Models, since the sentence components without\nthe quantifier are likely to co-occur, and because 'few'-type quantifiers are\nrare. We present 960 sentences stimuli from two human neurolinguistic\nexperiments to 22 autoregressive transformer models of differing sizes. Not\nonly do the models perform poorly on 'few'-type quantifiers, but overall the\nlarger the model, the worse its performance. We interpret this inverse scaling\nas suggesting that larger models increasingly reflect online rather than\noffline human processing, and argue that decreasing performance of larger\nmodels may challenge uses of Language Models as the basis for Natural Language\nSystems.\n","authors":["James A. Michaelov","Benjamin K. Bergen"],"pdf_url":"https://arxiv.org/pdf/2212.08700v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2212.08653v1","updated":"2022-12-16T18:59:12Z","published":"2022-12-16T18:59:12Z","title":"Attentive Mask CLIP","summary":"  Image token removal is an efficient augmentation strategy for reducing the\ncost of computing image features. However, this efficient augmentation strategy\nhas been found to adversely affect the accuracy of CLIP-based training. We\nhypothesize that removing a large portion of image tokens may improperly\ndiscard the semantic content associated with a given text description, thus\nconstituting an incorrect pairing target in CLIP training. To address this\nissue, we propose an attentive token removal approach for CLIP training, which\nretains tokens with a high semantic correlation to the text description. The\ncorrelation scores are computed in an online fashion using the EMA version of\nthe visual encoder. Our experiments show that the proposed attentive masking\napproach performs better than the previous method of random token removal for\nCLIP training. The approach also makes it efficient to apply multiple\naugmentation views to the image, as well as introducing instance contrastive\nlearning tasks between these views into the CLIP framework. Compared to other\nCLIP improvements that combine different pre-training targets such as SLIP and\nMaskCLIP, our method is not only more effective, but also much more efficient.\nSpecifically, using ViT-B and YFCC-15M dataset, our approach achieves $43.9\\%$\ntop-1 accuracy on ImageNet-1K zero-shot classification, as well as $62.7/42.1$\nand $38.0/23.2$ I2T/T2I retrieval accuracy on Flickr30K and MS COCO, which are\n$+1.1\\%$, $+5.5/+0.9$, and $+4.4/+1.3$ higher than the SLIP method, while being\n$2.30\\times$ faster. An efficient version of our approach running $1.16\\times$\nfaster than the plain CLIP model achieves significant gains of $+5.3\\%$,\n$+11.3/+8.0$, and $+9.5/+4.9$ on these benchmarks.\n","authors":["Yifan Yang","Weiquan Huang","Yixuan Wei","Houwen Peng","Xinyang Jiang","Huiqiang Jiang","Fangyun Wei","Yin Wang","Han Hu","Lili Qiu","Yuqing Yang"],"pdf_url":"https://arxiv.org/pdf/2212.08653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08650v1","updated":"2022-12-16T18:51:41Z","published":"2022-12-16T18:51:41Z","title":"On Human Visual Contrast Sensitivity and Machine Vision Robustness: A\n  Comparative Study","summary":"  It is well established in neuroscience that color vision plays an essential\npart in the human visual perception system. Meanwhile, many novel designs for\ncomputer vision inspired by human vision have achieved success in a wide range\nof tasks and applications. Nonetheless, how color differences affect machine\nvision has not been well explored. Our work tries to bridge this gap between\nthe human color vision aspect of visual recognition and that of the machine. To\nachieve this, we curate two datasets: CIFAR10-F and CIFAR100-F, which are based\non the foreground colors of the popular CIFAR datasets. Together with CIFAR10-B\nand CIFAR100-B, the existing counterpart datasets with information on the\nbackground colors of CIFAR test sets, we assign each image based on its color\ncontrast level per its foreground and background color labels and use this as a\nproxy to study how color contrast affects machine vision. We first conduct a\nproof-of-concept study, showing the effect of color difference and validate our\ndatasets. Furthermore, on a broader level, an important characteristic of human\nvision is its robustness against ambient changes; therefore, drawing\ninspirations from ophthalmology and the robustness literature, we analogize\ncontrast sensitivity from the human visual aspect to machine vision and\ncomplement the current robustness study using corrupted images with our\nCIFAR-CoCo datasets. In summary, motivated by neuroscience and equipped with\nthe datasets we curate, we devise a new framework in two dimensions to perform\nextensive analyses on the effect of color contrast and corrupted images: (1)\nmodel architecture, (2) model size, to measure the perception ability of\nmachine vision beyond total accuracy. We also explore how task complexity and\ndata augmentation play a role in this setup. Our results call attention to new\nevaluation approaches for human-like machine perception.\n","authors":["Ming-Chang Chiu","Yingfei Wang","Derrick Eui Gyu Kim","Pin-Yu Chen","Xuezhe Ma"],"pdf_url":"https://arxiv.org/pdf/2212.08650v1.pdf","comment":"9 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.08649v1","updated":"2022-12-16T18:51:10Z","published":"2022-12-16T18:51:10Z","title":"Better May Not Be Fairer: Can Data Augmentation Mitigate Subgroup\n  Degradation?","summary":"  It is no secret that deep learning models exhibit undesirable behaviors such\nas learning spurious correlations instead of learning correct relationships\nbetween input/output pairs. Prior works on robustness study datasets that mix\nlow-level features to quantify how spurious correlations affect predictions\ninstead of considering natural semantic factors due to limitations in accessing\nrealistic datasets for comprehensive evaluation. To bridge this gap, in this\npaper we first investigate how natural background colors play a role as\nspurious features in image classification tasks by manually splitting the test\nsets of CIFAR10 and CIFAR100 into subgroups based on the background color of\neach image. We name our datasets CIFAR10-B and CIFAR100-B. We find that while\nstandard CNNs achieve human-level accuracy, the subgroup performances are not\nconsistent, and the phenomenon remains even after data augmentation (DA). To\nalleviate this issue, we propose FlowAug, a semantic DA method that leverages\nthe decoupled semantic representations captured by a pre-trained generative\nflow. Experimental results show that FlowAug achieves more consistent results\nacross subgroups than other types of DA methods on CIFAR10 and CIFAR100.\nAdditionally, it shows better generalization performance. Furthermore, we\npropose a generic metric for studying model robustness to spurious\ncorrelations, where we take a macro average on the weighted standard deviations\nacross different classes. Per our metric, FlowAug demonstrates less reliance on\nspurious correlations. Although this metric is proposed to study our curated\ndatasets, it applies to all datasets that have subgroups or subclasses. Lastly,\naside from less dependence on spurious correlations and better generalization\non in-distribution test sets, we also show superior out-of-distribution results\non CIFAR10.1 and competitive performances on CIFAR10-C and CIFAR100-C.\n","authors":["Ming-Chang Chiu","Pin-Yu Chen","Xuezhe Ma"],"pdf_url":"https://arxiv.org/pdf/2212.08649v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2211.14821v2","updated":"2022-12-16T18:47:57Z","published":"2022-11-27T13:24:28Z","title":"Towards Realistic Underwater Dataset Generation and Color Restoration","summary":"  Recovery of true color from underwater images is an ill-posed problem. This\nis because the wide-band attenuation coefficients for the RGB color channels\ndepend on object range, reflectance, etc. which are difficult to model. Also,\nthere is backscattering due to suspended particles in water. Thus, most\nexisting deep-learning based color restoration methods, which are trained on\nsynthetic underwater datasets, do not perform well on real underwater data.\nThis can be attributed to the fact that synthetic data cannot accurately\nrepresent real conditions. To address this issue, we use an image to image\ntranslation network to bridge the gap between the synthetic and real domains by\ntranslating images from synthetic underwater domain to real underwater domain.\nUsing this multimodal domain adaptation technique, we create a dataset that can\ncapture a diverse array of underwater conditions. We then train a simple but\neffective CNN based network on our domain adapted dataset to perform color\nrestoration. Code and pre-trained models can be accessed at\nhttps://github.com/nehamjain10/TRUDGCR\n","authors":["Neham Jain","Gopi Matta","Kaushik Mitra"],"pdf_url":"https://arxiv.org/pdf/2211.14821v2.pdf","comment":"Published at The Indian Conference on Computer Vision, Graphics and\n  Image Processing (ICVGIP) 2022"},{"id":"http://arxiv.org/abs/2101.11878v3","updated":"2022-12-16T18:45:15Z","published":"2021-01-28T09:16:21Z","title":"CORL: Compositional Representation Learning for Few-Shot Classification","summary":"  Few-shot image classification consists of two consecutive learning processes:\n1) In the meta-learning stage, the model acquires a knowledge base from a set\nof training classes. 2) During meta-testing, the acquired knowledge is used to\nrecognize unseen classes from very few examples. Inspired by the compositional\nrepresentation of objects in humans, we train a neural network architecture\nthat explicitly represents objects as a dictionary of shared components and\ntheir spatial composition. In particular, during meta-learning, we train a\nknowledge base that consists of a dictionary of component representations and a\ndictionary of component activation maps that encode common spatial activation\npatterns of components. The elements of both dictionaries are shared among the\ntraining classes. During meta-testing, the representation of unseen classes is\nlearned using the component representations and the component activation maps\nfrom the knowledge base. Finally, an attention mechanism is used to strengthen\nthose components that are most important for each category. We demonstrate the\nvalue of our interpretable compositional learning framework for a few-shot\nclassification using miniImageNet, tieredImageNet, CIFAR-FS, and FC100, where\nwe achieve comparable performance.\n","authors":["Ju He","Adam Kortylewski","Alan Yuille"],"pdf_url":"https://arxiv.org/pdf/2101.11878v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07555v2","updated":"2022-12-16T18:39:09Z","published":"2022-12-14T23:59:24Z","title":"IMoS: Intent-Driven Full-Body Motion Synthesis for Human-Object\n  Interactions","summary":"  Can we make virtual characters in a scene interact with their surrounding\nobjects through simple instructions? Is it possible to synthesize such motion\nplausibly with a diverse set of objects and instructions? Inspired by these\nquestions, we present the first framework to synthesize the full-body motion of\nvirtual human characters performing specified actions with 3D objects placed\nwithin their reach. Our system takes as input textual instructions specifying\nthe objects and the associated intentions of the virtual characters and outputs\ndiverse sequences of full-body motions. This is in contrast to existing work,\nwhere full-body action synthesis methods generally do not consider object\ninteractions, and human-object interaction methods focus mainly on synthesizing\nhand or finger movements for grasping objects. We accomplish our objective by\ndesigning an intent-driven full-body motion generator, which uses a pair of\ndecoupled conditional variational autoencoders (CVAE) to learn the motion of\nthe body parts in an autoregressive manner. We also optimize for the positions\nof the objects with six degrees of freedom (6DoF) such that they plausibly fit\nwithin the hands of the synthesized characters. We compare our proposed method\nwith the existing methods of motion synthesis and establish a new and stronger\nstate-of-the-art for the task of intent-driven motion synthesis. Through a user\nstudy, we further show that our synthesized full-body motions appear more\nrealistic to the participants in more than 80% of scenarios compared to the\ncurrent state-of-the-art methods, and are perceived to be as good as the ground\ntruth on several occasions.\n","authors":["Anindita Ghosh","Rishabh Dabral","Vladislav Golyanik","Christian Theobalt","Philipp Slusallek"],"pdf_url":"https://arxiv.org/pdf/2212.07555v2.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2212.08641v1","updated":"2022-12-16T18:31:48Z","published":"2022-12-16T18:31:48Z","title":"GFPose: Learning 3D Human Pose Prior with Gradient Fields","summary":"  Learning 3D human pose prior is essential to human-centered AI. Here, we\npresent GFPose, a versatile framework to model plausible 3D human poses for\nvarious applications. At the core of GFPose is a time-dependent score network,\nwhich estimates the gradient on each body joint and progressively denoises the\nperturbed 3D human pose to match a given task specification. During the\ndenoising process, GFPose implicitly incorporates pose priors in gradients and\nunifies various discriminative and generative tasks in an elegant framework.\nDespite the simplicity, GFPose demonstrates great potential in several\ndownstream tasks. Our experiments empirically show that 1) as a\nmulti-hypothesis pose estimator, GFPose outperforms existing SOTAs by 20% on\nHuman3.6M dataset. 2) as a single-hypothesis pose estimator, GFPose achieves\ncomparable results to deterministic SOTAs, even with a vanilla backbone. 3)\nGFPose is able to produce diverse and realistic samples in pose denoising,\ncompletion and generation tasks. Project page\nhttps://sites.google.com/view/gfpose/\n","authors":["Hai Ci","Mingdong Wu","Wentao Zhu","Xiaoxuan Ma","Hao Dong","Fangwei Zhong","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2212.08641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08639v1","updated":"2022-12-16T18:31:23Z","published":"2022-12-16T18:31:23Z","title":"An annotated instance segmentation XXL-CT dataset from a historic\n  airplane","summary":"  The Me 163 was a Second World War fighter airplane and a result of the German\nair force secret developments. One of these airplanes is currently owned and\ndisplayed in the historic aircraft exhibition of the Deutsches Museum in\nMunich, Germany. To gain insights with respect to its history, design and state\nof preservation, a complete CT scan was obtained using an industrial\nXXL-computer tomography scanner.\n  Using the CT data from the Me 163, all its details can visually be examined\nat various levels, ranging from the complete hull down to single sprockets and\nrivets. However, while a trained human observer can identify and interpret the\nvolumetric data with all its parts and connections, a virtual dissection of the\nairplane and all its different parts would be quite desirable. Nevertheless,\nthis means, that an instance segmentation of all components and objects of\ninterest into disjoint entities from the CT data is necessary.\n  As of currently, no adequate computer-assisted tools for automated or\nsemi-automated segmentation of such XXL-airplane data are available, in a first\nstep, an interactive data annotation and object labeling process has been\nestablished. So far, seven 512 x 512 x 512 voxel sub-volumes from the Me 163\nairplane have been annotated and labeled, whose results can potentially be used\nfor various new applications in the field of digital heritage, non-destructive\ntesting, or machine-learning.\n  This work describes the data acquisition process of the airplane using an\nindustrial XXL-CT scanner, outlines the interactive segmentation and labeling\nscheme to annotate sub-volumes of the airplane's CT data, describes and\ndiscusses various challenges with respect to interpreting and handling the\nannotated and labeled data.\n","authors":["Roland Gruber","Nils Reims","Andreas Hempfer","Stefan Gerth","Michael Salamon","Thomas Wittenberg"],"pdf_url":"https://arxiv.org/pdf/2212.08639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05153v2","updated":"2022-12-16T18:18:59Z","published":"2022-12-10T00:18:05Z","title":"Algorithmic progress in computer vision","summary":"  We investigate algorithmic progress in image classification on ImageNet,\nperhaps the most well-known test bed for computer vision. We estimate a model,\ninformed by work on neural scaling laws, and infer a decomposition of progress\ninto the scaling of compute, data, and algorithms. Using Shapley values to\nattribute performance improvements, we find that algorithmic improvements have\nbeen roughly as important as the scaling of compute for progress computer\nvision. Our estimates indicate that algorithmic innovations mostly take the\nform of compute-augmenting algorithmic advances (which enable researchers to\nget better performance from less compute), not data-augmenting algorithmic\nadvances. We find that compute-augmenting algorithmic advances are made at a\npace more than twice as fast as the rate usually associated with Moore's law.\nIn particular, we estimate that compute-augmenting innovations halve compute\nrequirements every nine months (95\\% confidence interval: 4 to 25 months).\n","authors":["Ege Erdil","Tamay Besiroglu"],"pdf_url":"https://arxiv.org/pdf/2212.05153v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08632v1","updated":"2022-12-16T18:12:04Z","published":"2022-12-16T18:12:04Z","title":"Enhancing Multi-modal and Multi-hop Question Answering via Structured\n  Knowledge and Unified Retrieval-Generation","summary":"  Multi-modal and multi-hop question answering aims to answer a question based\non multiple input sources from different modalities. Previous methods retrieve\nthe evidence separately and feed the retrieved evidence to a language model to\ngenerate the corresponding answer. However, these methods fail to build\nconnections between candidates and thus cannot model the inter-dependent\nrelation during retrieval. Moreover, the reasoning process over multi-modality\ncandidates can be unbalanced without building alignments between different\nmodalities. To address this limitation, we propose a Structured Knowledge and\nUnified Retrieval Generation based method (SKURG). We align the sources from\ndifferent modalities via the shared entities and map them into a shared\nsemantic space via structured knowledge. Then, we utilize a unified\nretrieval-generation decoder to integrate intermediate retrieval results for\nanswer generation and adaptively determine the number of retrieval steps. We\nperform experiments on two multi-modal and multi-hop datasets: WebQA and\nMultimodalQA. The results demonstrate that SKURG achieves state-of-the-art\nperformance on both retrieval and answer generation.\n","authors":["Qian Yang","Qian Chen","Wen Wang","Baotian Hu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.08632v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.08624v1","updated":"2022-12-16T17:59:40Z","published":"2022-12-16T17:59:40Z","title":"Development of A Real-time POCUS Image Quality Assessment and\n  Acquisition Guidance System","summary":"  Point-of-care ultrasound (POCUS) is one of the most commonly applied tools\nfor cardiac function imaging in the clinical routine of the emergency\ndepartment and pediatric intensive care unit. The prior studies demonstrate\nthat AI-assisted software can guide nurses or novices without prior sonography\nexperience to acquire POCUS by recognizing the interest region, assessing image\nquality, and providing instructions. However, these AI algorithms cannot simply\nreplace the role of skilled sonographers in acquiring diagnostic-quality POCUS.\nUnlike chest X-ray, CT, and MRI, which have standardized imaging protocols,\nPOCUS can be acquired with high inter-observer variability. Though being with\nvariability, they are usually all clinically acceptable and interpretable. In\nchallenging clinical environments, sonographers employ novel heuristics to\nacquire POCUS in complex scenarios. To help novice learners to expedite the\ntraining process while reducing the dependency on experienced sonographers in\nthe curriculum implementation, We will develop a framework to perform real-time\nAI-assisted quality assessment and probe position guidance to provide training\nprocess for novice learners with less manual intervention.\n","authors":["Zhenge Jia","Yiyu Shi","Jingtong Hu","Lei Yang","Benjamin Nti"],"pdf_url":"https://arxiv.org/pdf/2212.08624v1.pdf","comment":"4 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2212.08613v1","updated":"2022-12-16T17:42:38Z","published":"2022-12-16T17:42:38Z","title":"Atrous Space Bender U-Net (ASBU-Net/LogiNet)","summary":"  $ $With recent advances in CNNs, exceptional improvements have been made in\nsemantic segmentation of high resolution images in terms of accuracy and\nlatency. However, challenges still remain in detecting objects in crowded\nscenes, large scale variations, partial occlusion, and distortions, while still\nmaintaining mobility and latency. We introduce a fast and efficient\nconvolutional neural network, ASBU-Net, for semantic segmentation of high\nresolution images that addresses these problems and uses no novelty layers for\nease of quantization and embedded hardware support. ASBU-Net is based on a new\nfeature extraction module, atrous space bender layer (ASBL), which is efficient\nin terms of computation and memory. The ASB layers form a building block that\nis used to make ASBNet. Since this network does not use any special layers it\ncan be easily implemented, quantized and deployed on FPGAs and other hardware\nwith limited memory. We present experiments on resource and accuracy trade-offs\nand show strong performance compared to other popular models.\n","authors":["Anurag Bansal","Oleg Ostap","Miguel Maestre Trueba","Kristopher Perry"],"pdf_url":"https://arxiv.org/pdf/2212.08613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08610v1","updated":"2022-12-16T17:39:32Z","published":"2022-12-16T17:39:32Z","title":"Huruf: An Application for Arabic Handwritten Character Recognition Using\n  Deep Learning","summary":"  Handwriting Recognition has been a field of great interest in the Artificial\nIntelligence domain. Due to its broad use cases in real life, research has been\nconducted widely on it. Prominent work has been done in this field focusing\nmainly on Latin characters. However, the domain of Arabic handwritten character\nrecognition is still relatively unexplored. The inherent cursive nature of the\nArabic characters and variations in writing styles across individuals makes the\ntask even more challenging. We identified some probable reasons behind this and\nproposed a lightweight Convolutional Neural Network-based architecture for\nrecognizing Arabic characters and digits. The proposed pipeline consists of a\ntotal of 18 layers containing four layers each for convolution, pooling, batch\nnormalization, dropout, and finally one Global average pooling and a Dense\nlayer. Furthermore, we thoroughly investigated the different choices of\nhyperparameters such as the choice of the optimizer, kernel initializer,\nactivation function, etc. Evaluating the proposed architecture on the publicly\navailable 'Arabic Handwritten Character Dataset (AHCD)' and 'Modified Arabic\nhandwritten digits Database (MadBase)' datasets, the proposed model\nrespectively achieved an accuracy of 96.93% and 99.35% which is comparable to\nthe state-of-the-art and makes it a suitable solution for real-life end-level\napplications.\n","authors":["Minhaz Kamal","Fairuz Shaiara","Chowdhury Mohammad Abdullah","Sabbir Ahmed","Tasnim Ahmed","Md. Hasanul Kabir"],"pdf_url":"https://arxiv.org/pdf/2212.08610v1.pdf","comment":"Accepted in 25th ICCIT (6 pages, 4 tables, 4 figures)"},{"id":"http://arxiv.org/abs/2212.08596v1","updated":"2022-12-16T17:22:51Z","published":"2022-12-16T17:22:51Z","title":"De-risking Carbon Capture and Sequestration with Explainable CO2 Leakage\n  Detection in Time-lapse Seismic Monitoring Images","summary":"  With the growing global deployment of carbon capture and sequestration\ntechnology to combat climate change, monitoring and detection of potential CO2\nleakage through existing or storage induced faults are critical to the safe and\nlong-term viability of the technology. Recent work on time-lapse seismic\nmonitoring of CO2 storage has shown promising results in its ability to monitor\nthe growth of the CO2 plume from surface recorded seismic data. However, due to\nthe low sensitivity of seismic imaging to CO2 concentration, additional\ndevelopments are required to efficiently interpret the seismic images for\nleakage. In this work, we introduce a binary classification of time-lapse\nseismic images to delineate CO2 plumes (leakage) using state-of-the-art deep\nlearning models. Additionally, we localize the leakage region of CO2 plumes by\nleveraging Class Activation Mapping methods.\n","authors":["Huseyin Tuna Erdinc","Abhinav Prakash Gahlot","Ziyi Yin","Mathias Louboutin","Felix J. Herrmann"],"pdf_url":"https://arxiv.org/pdf/2212.08596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.13240v2","updated":"2022-12-16T17:15:54Z","published":"2022-07-27T01:49:26Z","title":"Contrastive Image Synthesis and Self-supervised Feature Adaptation for\n  Cross-Modality Biomedical Image Segmentation","summary":"  This work presents a novel framework CISFA (Contrastive Image synthesis and\nSelf-supervised Feature Adaptation)that builds on image domain translation and\nunsupervised feature adaptation for cross-modality biomedical image\nsegmentation. Different from existing works, we use a one-sided generative\nmodel and add a weighted patch-wise contrastive loss between sampled patches of\nthe input image and the corresponding synthetic image, which serves as shape\nconstraints. Moreover, we notice that the generated images and input images\nshare similar structural information but are in different modalities. As such,\nwe enforce contrastive losses on the generated images and the input images to\ntrain the encoder of a segmentation model to minimize the discrepancy between\npaired images in the learned embedding space. Compared with existing works that\nrely on adversarial learning for feature adaptation, such a method enables the\nencoder to learn domain-independent features in a more explicit way. We\nextensively evaluate our methods on segmentation tasks containing CT and MRI\nimages for abdominal cavities and whole hearts. Experimental results show that\nthe proposed framework not only outputs synthetic images with less distortion\nof organ shapes, but also outperforms state-of-the-art domain adaptation\nmethods by a large margin.\n","authors":["Xinrong Hu","Corey Wang","Yiyu Shi"],"pdf_url":"https://arxiv.org/pdf/2207.13240v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08586v1","updated":"2022-12-16T17:06:28Z","published":"2022-12-16T17:06:28Z","title":"Rethinking Cooking State Recognition with Vision Transformers","summary":"  To ensure proper knowledge representation of the kitchen environment, it is\nvital for kitchen robots to recognize the states of the food items that are\nbeing cooked. Although the domain of object detection and recognition has been\nextensively studied, the task of object state classification has remained\nrelatively unexplored. The high intra-class similarity of ingredients during\ndifferent states of cooking makes the task even more challenging. Researchers\nhave proposed adopting Deep Learning based strategies in recent times, however,\nthey are yet to achieve high performance. In this study, we utilized the\nself-attention mechanism of the Vision Transformer (ViT) architecture for the\nCooking State Recognition task. The proposed approach encapsulates the globally\nsalient features from images, while also exploiting the weights learned from a\nlarger dataset. This global attention allows the model to withstand the\nsimilarities between samples of different cooking objects, while the employment\nof transfer learning helps to overcome the lack of inductive bias by utilizing\npretrained weights. To improve recognition accuracy, several augmentation\ntechniques have been employed as well. Evaluation of our proposed framework on\nthe `Cooking State Recognition Challenge Dataset' has achieved an accuracy of\n94.3%, which significantly outperforms the state-of-the-art.\n","authors":["Akib Mohammed Khan","Alif Ashrafee","Reeshoon Sayera","Shahriar Ivan","Sabbir Ahmed"],"pdf_url":"https://arxiv.org/pdf/2212.08586v1.pdf","comment":"Accepted in 25th ICCIT (6 pages, 5 Figures, 5 Tables)"},{"id":"http://arxiv.org/abs/2212.08583v1","updated":"2022-12-16T17:02:55Z","published":"2022-12-16T17:02:55Z","title":"Semi-Siamese Network for Robust Change Detection Across Different\n  Domains with Applications to 3D Printing","summary":"  Automatic defect detection for 3D printing processes, which shares many\ncharacteristics with change detection problems, is a vital step for quality\ncontrol of 3D printed products. However, there are some critical challenges in\nthe current state of practice. First, existing methods for computer\nvision-based process monitoring typically work well only under specific camera\nviewpoints and lighting situations, requiring expensive pre-processing,\nalignment, and camera setups. Second, many defect detection techniques are\nspecific to pre-defined defect patterns and/or print schematics. In this work,\nwe approach the automatic defect detection problem differently using a novel\nSemi-Siamese deep learning model that directly compares a reference schematic\nof the desired print and a camera image of the achieved print. The model then\nsolves an image segmentation problem, identifying the locations of defects with\nrespect to the reference frame. Unlike most change detection problems, our\nmodel is specially developed to handle images coming from different domains and\nis robust against perturbations in the imaging setup such as camera angle and\nillumination. Defect localization predictions were made in 2.75 seconds per\nlayer using a standard MacBookPro, which is comparable to the typical tens of\nseconds or less for printing a single layer on an inkjet-based 3D printer,\nwhile achieving an F1-score of more than 0.9.\n","authors":["Yushuo Niu","Ethan Chadwick","Anson W. K. Ma","Qian Yang"],"pdf_url":"https://arxiv.org/pdf/2212.08583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12065v2","updated":"2022-12-16T16:46:04Z","published":"2022-07-25T11:18:48Z","title":"Dynamic Channel Selection in Self-Supervised Learning","summary":"  Whilst computer vision models built using self-supervised approaches are now\ncommonplace, some important questions remain. Do self-supervised models learn\nhighly redundant channel features? What if a self-supervised network could\ndynamically select the important channels and get rid of the unnecessary ones?\nCurrently, convnets pre-trained with self-supervision have obtained comparable\nperformance on downstream tasks in comparison to their supervised counterparts\nin computer vision. However, there are drawbacks to self-supervised models\nincluding their large numbers of parameters, computationally expensive training\nstrategies and a clear need for faster inference on downstream tasks. In this\nwork, our goal is to address the latter by studying how a standard channel\nselection method developed for supervised learning can be applied to networks\ntrained with self-supervision. We validate our findings on a range of target\nbudgets $t_{d}$ for channel computation on image classification task across\ndifferent datasets, specifically CIFAR-10, CIFAR-100, and ImageNet-100,\nobtaining comparable performance to that of the original network when selecting\nall channels but at a significant reduction in computation reported in terms of\nFLOPs.\n","authors":["Tarun Krishna","Ayush K. Rai","Yasser A. D. Djilali","Alan F. Smeaton","Kevin McGuinness","Noel E. O'Connor"],"pdf_url":"https://arxiv.org/pdf/2207.12065v2.pdf","comment":"Accepted in Irish Machine Vision and Image Processing Conference 2022"},{"id":"http://arxiv.org/abs/2212.08568v1","updated":"2022-12-16T16:44:46Z","published":"2022-12-16T16:44:46Z","title":"Biomedical image analysis competitions: The state of current\n  participation practice","summary":"  The number of international benchmarking competitions is steadily increasing\nin various fields of machine learning (ML) research and practice. So far,\nhowever, little is known about the common practice as well as bottlenecks faced\nby the community in tackling the research questions posed. To shed light on the\nstatus quo of algorithm development in the specific field of biomedical imaging\nanalysis, we designed an international survey that was issued to all\nparticipants of challenges conducted in conjunction with the IEEE ISBI 2021 and\nMICCAI 2021 conferences (80 competitions in total). The survey covered\nparticipants' expertise and working environments, their chosen strategies, as\nwell as algorithm characteristics. A median of 72% challenge participants took\npart in the survey. According to our results, knowledge exchange was the\nprimary incentive (70%) for participation, while the reception of prize money\nplayed only a minor role (16%). While a median of 80 working hours was spent on\nmethod development, a large portion of participants stated that they did not\nhave enough time for method development (32%). 25% perceived the infrastructure\nto be a bottleneck. Overall, 94% of all solutions were deep learning-based. Of\nthese, 84% were based on standard architectures. 43% of the respondents\nreported that the data samples (e.g., images) were too large to be processed at\nonce. This was most commonly addressed by patch-based training (69%),\ndownsampling (37%), and solving 3D analysis tasks as a series of 2D tasks.\nK-fold cross-validation on the training set was performed by only 37% of the\nparticipants and only 50% of the participants performed ensembling based on\nmultiple identical models (61%) or heterogeneous models (39%). 48% of the\nrespondents applied postprocessing steps.\n","authors":["Matthias Eisenmann","Annika Reinke","Vivienn Weru","Minu Dietlinde Tizabi","Fabian Isensee","Tim J. Adler","Patrick Godau","Veronika Cheplygina","Michal Kozubek","Sharib Ali","Anubha Gupta","Jan Kybic","Alison Noble","Carlos Ortiz de Solórzano","Samiksha Pachade","Caroline Petitjean","Daniel Sage","Donglai Wei","Elizabeth Wilden","Deepak Alapatt","Vincent Andrearczyk","Ujjwal Baid","Spyridon Bakas","Niranjan Balu","Sophia Bano","Vivek Singh Bawa","Jorge Bernal","Sebastian Bodenstedt","Alessandro Casella","Jinwook Choi","Olivier Commowick","Marie Daum","Adrien Depeursinge","Reuben Dorent","Jan Egger","Hannah Eichhorn","Sandy Engelhardt","Melanie Ganz","Gabriel Girard","Lasse Hansen","Mattias Heinrich","Nicholas Heller","Alessa Hering","Arnaud Huaulmé","Hyunjeong Kim","Bennett Landman","Hongwei Bran Li","Jianning Li","Jun Ma","Anne Martel","Carlos Martín-Isla","Bjoern Menze","Chinedu Innocent Nwoye","Valentin Oreiller","Nicolas Padoy","Sarthak Pati","Kelly Payette","Carole Sudre","Kimberlin van Wijnen","Armine Vardazaryan","Tom Vercauteren","Martin Wagner","Chuanbo Wang","Moi Hoon Yap","Zeyun Yu","Chun Yuan","Maximilian Zenk","Aneeq Zia","David Zimmerer","Rina Bao","Chanyeol Choi","Andrew Cohen","Oleh Dzyubachyk","Adrian Galdran","Tianyuan Gan","Tianqi Guo","Pradyumna Gupta","Mahmood Haithami","Edward Ho","Ikbeom Jang","Zhili Li","Zhengbo Luo","Filip Lux","Sokratis Makrogiannis","Dominik Müller","Young-tack Oh","Subeen Pang","Constantin Pape","Gorkem Polat","Charlotte Rosalie Reed","Kanghyun Ryu","Tim Scherr","Vajira Thambawita","Haoyu Wang","Xinliang Wang","Kele Xu","Hung Yeh","Doyeob Yeo","Yixuan Yuan","Yan Zeng","Xin Zhao","Julian Abbing","Jannes Adam","Nagesh Adluru","Niklas Agethen","Salman Ahmed","Yasmina Al Khalil","Mireia Alenyà","Esa Alhoniemi","Chengyang An","Talha Anwar","Tewodros Weldebirhan Arega","Netanell Avisdris","Dogu Baran Aydogan","Yingbin Bai","Maria Baldeon Calisto","Berke Doga Basaran","Marcel Beetz","Cheng Bian","Hao Bian","Kevin Blansit","Louise Bloch","Robert Bohnsack","Sara Bosticardo","Jack Breen","Mikael Brudfors","Raphael Brüngel","Mariano Cabezas","Alberto Cacciola","Zhiwei Chen","Yucong Chen","Daniel Tianming Chen","Minjeong Cho","Min-Kook Choi","Chuantao Xie Chuantao Xie","Dana Cobzas","Julien Cohen-Adad","Jorge Corral Acero","Sujit Kumar Das","Marcela de Oliveira","Hanqiu Deng","Guiming Dong","Lars Doorenbos","Cory Efird","Di Fan","Mehdi Fatan Serj","Alexandre Fenneteau","Lucas Fidon","Patryk Filipiak","René Finzel","Nuno R. Freitas","Christoph M. Friedrich","Mitchell Fulton","Finn Gaida","Francesco Galati","Christoforos Galazis","Chang Hee Gan","Zheyao Gao","Shengbo Gao","Matej Gazda","Beerend Gerats","Neil Getty","Adam Gibicar","Ryan Gifford","Sajan Gohil","Maria Grammatikopoulou","Daniel Grzech","Orhun Güley","Timo Günnemann","Chunxu Guo","Sylvain Guy","Heonjin Ha","Luyi Han","Il Song Han","Ali Hatamizadeh","Tian He","Jimin Heo","Sebastian Hitziger","SeulGi Hong","SeungBum Hong","Rian Huang","Ziyan Huang","Markus Huellebrand","Stephan Huschauer","Mustaffa Hussain","Tomoo Inubushi","Ece Isik Polat","Mojtaba Jafaritadi","SeongHun Jeong","Bailiang Jian","Yuanhong Jiang","Zhifan Jiang","Yueming Jin","Smriti Joshi","Abdolrahim Kadkhodamohammadi","Reda Abdellah Kamraoui","Inha Kang","Junghwa Kang","Davood Karimi","April Khademi","Muhammad Irfan Khan","Suleiman A. Khan","Rishab Khantwal","Kwang-Ju Kim","Timothy Kline","Satoshi Kondo","Elina Kontio","Adrian Krenzer","Artem Kroviakov","Hugo Kuijf","Satyadwyoom Kumar","Francesco La Rosa","Abhi Lad","Doohee Lee","Minho Lee","Chiara Lena","Hao Li","Ling Li","Xingyu Li","Fuyuan Liao","KuanLun Liao","Arlindo Limede Oliveira","Chaonan Lin","Shan Lin","Akis Linardos","Marius George Linguraru","Han Liu","Tao Liu","Di Liu","Yanling Liu","João Lourenço-Silva","Jingpei Lu","Jiangshan Lu","Imanol Luengo","Christina B. Lund","Huan Minh Luu","Yi Lv","Yi Lv","Uzay Macar","Leon Maechler","Sina Mansour L.","Kenji Marshall","Moona Mazher","Richard McKinley","Alfonso Medela","Felix Meissen","Mingyuan Meng","Dylan Miller","Seyed Hossein Mirjahanmardi","Arnab Mishra","Samir Mitha","Hassan Mohy-ud-Din","Tony Chi Wing Mok","Gowtham Krishnan Murugesan","Enamundram Naga Karthik","Sahil Nalawade","Jakub Nalepa","Mohamed Naser","Ramin Nateghi","Hammad Naveed","Quang-Minh Nguyen","Cuong Nguyen Quoc","Brennan Nichyporuk","Bruno Oliveira","David Owen","Jimut Bahan Pal","Junwen Pan","Wentao Pan","Winnie Pang","Bogyu Park","Vivek Pawar","Kamlesh Pawar","Michael Peven","Lena Philipp","Tomasz Pieciak","Szymon Plotka","Marcel Plutat","Fattaneh Pourakpour","Domen Preložnik","Kumaradevan Punithakumar","Abdul Qayyum","Sandro Queirós","Arman Rahmim","Salar Razavi","Jintao Ren","Mina Rezaei","Jonathan Adam Rico","ZunHyan Rieu","Markus Rink","Johannes Roth","Yusely Ruiz-Gonzalez","Numan Saeed","Anindo Saha","Mostafa Salem","Ricardo Sanchez-Matilla","Kurt Schilling","Wei Shao","Zhiqiang Shen","Ruize Shi","Pengcheng Shi","Daniel Sobotka","Théodore Soulier","Bella Specktor Fadida","Danail Stoyanov","Timothy Sum Hon Mun","Xiaowu Sun","Rong Tao","Franz Thaler","Antoine Théberge","Felix Thielke","Helena Torres","Kareem A. Wahid","Jiacheng Wang","YiFei Wang","Wei Wang","Xiong Wang","Jianhui Wen","Ning Wen","Marek Wodzinski","Ye Wu","Fangfang Xia","Tianqi Xiang","Chen Xiaofei","Lizhan Xu","Tingting Xue","Yuxuan Yang","Lin Yang","Kai Yao","Huifeng Yao","Amirsaeed Yazdani","Michael Yip","Hwanseung Yoo","Fereshteh Yousefirizi","Shunkai Yu","Lei Yu","Jonathan Zamora","Ramy Ashraf Zeineldin","Dewen Zeng","Jianpeng Zhang","Bokai Zhang","Jiapeng Zhang","Fan Zhang","Huahong Zhang","Zhongchen Zhao","Zixuan Zhao","Jiachen Zhao","Can Zhao","Qingshuo Zheng","Yuheng Zhi","Ziqi Zhou","Baosheng Zou","Klaus Maier-Hein","Paul F. Jäger","Annette Kopp-Schneider","Lena Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2212.08568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08558v1","updated":"2022-12-16T16:25:36Z","published":"2022-12-16T16:25:36Z","title":"Simulating Road Spray Effects in Automotive Lidar Sensor Models","summary":"  Modeling perception sensors is key for simulation based testing of automated\ndriving functions. Beyond weather conditions themselves, sensors are also\nsubjected to object dependent environmental influences like tire spray caused\nby vehicles moving on wet pavement. In this work, a novel modeling approach for\nspray in lidar data is introduced. The model conforms to the Open Simulation\nInterface (OSI) standard and is based on the formation of detection clusters\nwithin a spray plume. The detections are rendered with a simple custom ray\ncasting algorithm without the need of a fluid dynamics simulation or physics\nengine. The model is subsequently used to generate training data for object\ndetection algorithms. It is shown that the model helps to improve detection in\nreal-world spray scenarios significantly. Furthermore, a systematic real-world\ndata set is recorded and published for analysis, model calibration and\nvalidation of spray effects in active perception sensors. Experiments are\nconducted on a test track by driving over artificially watered pavement with\nvarying vehicle speeds, vehicle types and levels of pavement wetness. All\nmodels and data of this work are available open source.\n","authors":["Clemens Linnhoff","Dominik Scheuble","Mario Bijelic","Lukas Elster","Philipp Rosenberger","Werner Ritter","Dengxin Dai","Hermann Winner"],"pdf_url":"https://arxiv.org/pdf/2212.08558v1.pdf","comment":"Submitted to IEEE Sensors Journal"},{"id":"http://arxiv.org/abs/2110.03905v3","updated":"2022-12-16T15:45:18Z","published":"2021-10-08T05:57:30Z","title":"COVID-19 Monitoring System using Social Distancing and Face Mask\n  Detection on Surveillance video datasets","summary":"  In the current times, the fear and danger of COVID-19 virus still stands\nlarge. Manual monitoring of social distancing norms is impractical with a large\npopulation moving about and with insufficient task force and resources to\nadminister them. There is a need for a lightweight, robust and 24X7\nvideo-monitoring system that automates this process. This paper proposes a\ncomprehensive and effective solution to perform person detection, social\ndistancing violation detection, face detection and face mask classification\nusing object detection, clustering and Convolution Neural Network (CNN) based\nbinary classifier. For this, YOLOv3, Density-based spatial clustering of\napplications with noise (DBSCAN), Dual Shot Face Detector (DSFD) and\nMobileNetV2 based binary classifier have been employed on surveillance video\ndatasets. This paper also provides a comparative study of different face\ndetection and face mask classification models. Finally, a video dataset\nlabelling method is proposed along with the labelled video dataset to\ncompensate for the lack of dataset in the community and is used for evaluation\nof the system. The system performance is evaluated in terms of accuracy, F1\nscore as well as the prediction time, which has to be low for practical\napplicability. The system performs with an accuracy of 91.2% and F1 score of\n90.79% on the labelled video dataset and has an average prediction time of 7.12\nseconds for 78 frames of a video.\n","authors":["Sahana Srinivasan","Rujula Singh R","Ruchita R Biradar","Revathi SA"],"pdf_url":"https://arxiv.org/pdf/2110.03905v3.pdf","comment":"I, Rujula Singh R, would like to apologize to the research community\n  for the confusion caused by the inconsistency in author lists between\n  multiple versions of this paper. I take full responsibility for this error\n  and will be more diligent in the future to ensure the accuracy and\n  consistency of our research publications"},{"id":"http://arxiv.org/abs/2212.08536v1","updated":"2022-12-16T15:35:34Z","published":"2022-12-16T15:35:34Z","title":"Detection-aware multi-object tracking evaluation","summary":"  How would you fairly evaluate two multi-object tracking algorithms (i.e.\ntrackers), each one employing a different object detector? Detectors keep\nimproving, thus trackers can make less effort to estimate object states over\ntime. Is it then fair to compare a new tracker employing a new detector with\nanother tracker using an old detector? In this paper, we propose a novel\nperformance measure, named Tracking Effort Measure (TEM), to evaluate trackers\nthat use different detectors. TEM estimates the improvement that the tracker\ndoes with respect to its input data (i.e. detections) at frame level\n(intra-frame complexity) and sequence level (inter-frame complexity). We\nevaluate TEM over well-known datasets, four trackers and eight detection sets.\nResults show that, unlike conventional tracking evaluation measures, TEM can\nquantify the effort done by the tracker with a reduced correlation on the input\ndetections. Its implementation is publicly available online at\nhttps://github.com/vpulab/MOT-evaluation.\n","authors":["Juan C. SanMiguel","Jorge Muñoz","Fabio Poiesi"],"pdf_url":"https://arxiv.org/pdf/2212.08536v1.pdf","comment":"This paper was accepted at IEEE International Conference on Advanced\n  Video and Signal Based Surveillance (AVSS)"},{"id":"http://arxiv.org/abs/2212.08526v1","updated":"2022-12-16T15:15:34Z","published":"2022-12-16T15:15:34Z","title":"Unifying Human Motion Synthesis and Style Transfer with Denoising\n  Diffusion Probabilistic Models","summary":"  Generating realistic motions for digital humans is a core but challenging\npart of computer animations and games, as human motions are both diverse in\ncontent and rich in styles. While the latest deep learning approaches have made\nsignificant advancements in this domain, they mostly consider motion synthesis\nand style manipulation as two separate problems. This is mainly due to the\nchallenge of learning both motion contents that account for the inter-class\nbehaviour and styles that account for the intra-class behaviour effectively in\na common representation. To tackle this challenge, we propose a denoising\ndiffusion probabilistic model solution for styled motion synthesis. As\ndiffusion models have a high capacity brought by the injection of\nstochasticity, we can represent both inter-class motion content and intra-class\nstyle behaviour in the same latent. This results in an integrated, end-to-end\ntrained pipeline that facilitates the generation of optimal motion and\nexploration of content-style coupled latent space. To achieve high-quality\nresults, we design a multi-task architecture of diffusion model that\nstrategically generates aspects of human motions for local guidance. We also\ndesign adversarial and physical regulations for global guidance. We demonstrate\nsuperior performance with quantitative and qualitative results and validate the\neffectiveness of our multi-task architecture.\n","authors":["Ziyi Chang","Edmund J. C. Findlay","Haozheng Zhang","Hubert P. H. Shum"],"pdf_url":"https://arxiv.org/pdf/2212.08526v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16161v2","updated":"2022-12-16T14:52:08Z","published":"2022-11-29T12:44:45Z","title":"Artifact Removal in Histopathology Images","summary":"  In the clinical setting of histopathology, whole-slide image (WSI) artifacts\nfrequently arise, distorting regions of interest, and having a pernicious\nimpact on WSI analysis. Image-to-image translation networks such as CycleGANs\nare in principle capable of learning an artifact removal function from unpaired\ndata. However, we identify a surjection problem with artifact removal, and\npropose an weakly-supervised extension to CycleGAN to address this. We assemble\na pan-cancer dataset comprising artifact and clean tiles from the TCGA\ndatabase. Promising results highlight the soundness of our method.\n","authors":["Cameron Dahan","Stergios Christodoulidis","Maria Vakalopoulou","Joseph Boyd"],"pdf_url":"https://arxiv.org/pdf/2211.16161v2.pdf","comment":"Corrected typos, small modification of Figure 1 (+ reflected in\n  Section 2.1), results unchanged"},{"id":"http://arxiv.org/abs/2212.08511v1","updated":"2022-12-16T14:49:27Z","published":"2022-12-16T14:49:27Z","title":"Road Detection in Snowy Forest Environment using RGB Camera","summary":"  Automated driving technology has gained a lot of momentum in the last few\nyears. For the exploration field, navigation is the important key for\nautonomous operation. In difficult scenarios such as snowy environment, the\nroad is covered with snow and road detection is impossible in this situation\nusing only basic techniques. This paper introduces detection of snowy road in\nforest environment using RGB camera. The method combines noise filtering\ntechnique with morphological operation to classify the image component. By\nusing the assumption that all road is covered by snow and the snow part is\ndefined as road area. From the perspective image of road, the vanishing point\nof road is one of factor to scope the region of road. This vanishing point is\nfound with fitting triangle technique. The performance of algorithm is\nevaluated by two error value: False Negative Rate and False Positive Rate. The\nerror shows that the method has high efficiency for detect road with straight\nroad but low performance for curved road. This road region will be applied with\ndepth information from camera to detect for obstacle in the future work.\n","authors":["Sirawich Vachmanus","Takanori Emaru","Ankit A. Ravankar","Yukinori Kobayashi"],"pdf_url":"https://arxiv.org/pdf/2212.08511v1.pdf","comment":"5 pages, 9 figures, conference proceeding"},{"id":"http://arxiv.org/abs/2212.08506v1","updated":"2022-12-16T14:38:30Z","published":"2022-12-16T14:38:30Z","title":"Weakly Supervised Video Anomaly Detection Based on Cross-Batch\n  Clustering Guidance","summary":"  Weakly supervised video anomaly detection (WSVAD) is a challenging task since\nonly video-level labels are available for training. In previous studies, the\ndiscriminative power of the learned features is not strong enough, and the data\nimbalance resulting from the mini-batch training strategy is ignored. To\naddress these two issues, we propose a novel WSVAD method based on cross-batch\nclustering guidance. To enhance the discriminative power of features, we\npropose a batch clustering based loss to encourage a clustering branch to\ngenerate distinct normal and abnormal clusters based on a batch of data.\nMeanwhile, we design a cross-batch learning strategy by introducing clustering\nresults from previous mini-batches to reduce the impact of data imbalance. In\naddition, we propose to generate more accurate segment-level anomaly scores\nbased on batch clustering guidance further improving the performance of WSVAD.\nExtensive experiments on two public datasets demonstrate the effectiveness of\nour approach.\n","authors":["Congqi Cao","Xin Zhang","Shizhou Zhang","Peng Wang","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.08506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.10521v2","updated":"2022-12-16T14:05:11Z","published":"2022-08-22T18:01:49Z","title":"Estimation Contracts for Outlier-Robust Geometric Perception","summary":"  Outlier-robust estimation is a fundamental problem and has been extensively\ninvestigated by statisticians and practitioners. The last few years have seen a\nconvergence across research fields towards \"algorithmic robust statistics\",\nwhich focuses on developing tractable outlier-robust techniques for\nhigh-dimensional estimation problems. Despite this convergence, research\nefforts across fields have been mostly disconnected from one another. This\nmonograph bridges recent work on certifiable outlier-robust estimation for\ngeometric perception in robotics and computer vision with parallel work in\nrobust statistics. In particular, we adapt and extend recent results on robust\nlinear regression (applicable to the low-outlier regime with << 50% outliers)\nand list-decodable regression (applicable to the high-outlier regime with >>\n50% outliers) to the setup commonly found in robotics and vision, where (i)\nvariables (e.g., rotations, poses) belong to a non-convex domain, (ii)\nmeasurements are vector-valued, and (iii) the number of outliers is not known a\npriori. The emphasis here is on performance guarantees: rather than proposing\nradically new algorithms, we provide conditions on the input measurements under\nwhich modern estimation algorithms (possibly after small modifications) are\nguaranteed to recover an estimate close to the ground truth in the presence of\noutliers. These conditions are what we call an \"estimation contract\". Besides\nthe proposed extensions of existing results, we believe the main contributions\nof this monograph are (i) to unify parallel research lines by pointing out\ncommonalities and differences, (ii) to introduce advanced material (e.g.,\nsum-of-squares proofs) in an accessible and self-contained presentation for the\npractitioner, and (iii) to point out a few immediate opportunities and open\nquestions in outlier-robust geometric perception.\n","authors":["Luca Carlone"],"pdf_url":"https://arxiv.org/pdf/2208.10521v2.pdf","comment":"95 pages, 12 figures"},{"id":"http://arxiv.org/abs/2212.08490v1","updated":"2022-12-16T14:02:12Z","published":"2022-12-16T14:02:12Z","title":"LEDCNet: A Lightweight and Efficient Semantic Segmentation Algorithm\n  Using Dual Context Module for Extracting Ground Objects from UAV Aerial\n  Remote Sensing Images","summary":"  Semantic segmentation of UAV aerial remote sensing images provides a more\nefficient and convenient surveying and mapping method for traditional surveying\nand mapping. In order to make the model lightweight and improve a certain\naccuracy, this research developed a new lightweight and efficient network for\nthe extraction of ground features from UAV aerial remote sensing images, called\nLDMCNet. Meanwhile, this research develops a powerful lightweight backbone\nnetwork for the proposed semantic segmentation model. It is called LDCNet, and\nit is hoped that it can become the backbone network of a new generation of\nlightweight semantic segmentation algorithms. The proposed model uses dual\nmulti-scale context modules, namely the Atrous Space Pyramid Pooling module\n(ASPP) and the Object Context Representation module (OCR). In addition, this\nresearch constructs a private dataset for semantic segmentation of aerial\nremote sensing images from drones. This data set contains 2431 training sets,\n945 validation sets, and 475 test sets. The proposed model performs well on\nthis dataset, with only 1.4M parameters and 5.48G floating-point operations\n(FLOPs), achieving an average intersection-over-union ratio (mIoU) of 71.12%.\n7.88% higher than the baseline model. In order to verify the effectiveness of\nthe proposed model, training on the public datasets \"LoveDA\" and \"CITY-OSM\"\nalso achieved excellent results, achieving mIoU of 65.27% and 74.39%,\nrespectively.\n","authors":["Xiaoxiang Han","Yiman Liu","Gang Liu","Qiaohong Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08490v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2212.08479v1","updated":"2022-12-16T13:46:17Z","published":"2022-12-16T13:46:17Z","title":"Neural Implicit k-Space for Binning-free Non-Cartesian Cardiac MR\n  Imaging","summary":"  In this work, we propose a novel image reconstruction framework that directly\nlearns a neural implicit representation in k-space for ECG-triggered\nnon-Cartesian Cardiac Magnetic Resonance Imaging (CMR). While existing methods\nbin acquired data from neighboring time points to reconstruct one phase of the\ncardiac motion, our framework allows for a continuous, binning-free, and\nsubject-specific k-space representation.We assign a unique coordinate that\nconsists of time, coil index, and frequency domain location to each sampled\nk-space point. We then learn the subject-specific mapping from these unique\ncoordinates to k-space intensities using a multi-layer perceptron with\nfrequency domain regularization. During inference, we obtain a complete k-space\nfor Cartesian coordinates and an arbitrary temporal resolution. A simple\ninverse Fourier transform recovers the image, eliminating the need for density\ncompensation and costly non-uniform Fourier transforms for non-Cartesian data.\nThis novel imaging framework was tested on 42 radially sampled datasets from 6\nsubjects. The proposed method outperforms other techniques qualitatively and\nquantitatively using data from four and one heartbeat(s) and 30 cardiac phases.\nOur results for one heartbeat reconstruction of 50 cardiac phases show improved\nartifact removal and spatio-temporal resolution, leveraging the potential for\nreal-time CMR.\n","authors":["Wenqi Huang","Hongwei Li","Gastao Cruz","Jiazhen Pan","Daniel Rueckert","Kerstin Hammernik"],"pdf_url":"https://arxiv.org/pdf/2212.08479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.02541v3","updated":"2022-12-16T13:42:24Z","published":"2022-08-04T09:17:30Z","title":"MVSFormer: Multi-View Stereo by Learning Robust Image Features and\n  Temperature-based Depth","summary":"  Feature representation learning is the key recipe for learning-based\nMulti-View Stereo (MVS). As the common feature extractor of learning-based MVS,\nvanilla Feature Pyramid Networks (FPNs) suffer from discouraged feature\nrepresentations for reflection and texture-less areas, which limits the\ngeneralization of MVS. Even FPNs worked with pre-trained Convolutional Neural\nNetworks (CNNs) fail to tackle these issues. On the other hand, Vision\nTransformers (ViTs) have achieved prominent success in many 2D vision tasks.\nThus we ask whether ViTs can facilitate feature learning in MVS? In this paper,\nwe propose a pre-trained ViT enhanced MVS network called MVSFormer, which can\nlearn more reliable feature representations benefited by informative priors\nfrom ViT. The finetuned MVSFormer with hierarchical ViTs of efficient attention\nmechanisms can achieve prominent improvement based on FPNs. Besides, the\nalternative MVSFormer with frozen ViT weights is further proposed. This largely\nalleviates the training cost with competitive performance strengthened by the\nattention map from the self-distillation pre-training. MVSFormer can be\ngeneralized to various input resolutions with efficient multi-scale training\nstrengthened by gradient accumulation. Moreover, we discuss the merits and\ndrawbacks of classification and regression-based MVS methods, and further\npropose to unify them with a temperature-based strategy. MVSFormer achieves\nstate-of-the-art performance on the DTU dataset. Particularly, MVSFormer ranks\nas Top-1 on both intermediate and advanced sets of the highly competitive\nTanks-and-Temples leaderboard.\n","authors":["Chenjie Cao","Xinlin Ren","Yanwei Fu"],"pdf_url":"https://arxiv.org/pdf/2208.02541v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08472v1","updated":"2022-12-16T13:37:23Z","published":"2022-12-16T13:37:23Z","title":"One-Stage Cascade Refinement Networks for Infrared Small Target\n  Detection","summary":"  Single-frame InfraRed Small Target (SIRST) detection has been a challenging\ntask due to a lack of inherent characteristics, imprecise bounding box\nregression, a scarcity of real-world datasets, and sensitive localization\nevaluation. In this paper, we propose a comprehensive solution to these\nchallenges. First, we find that the existing anchor-free label assignment\nmethod is prone to mislabeling small targets as background, leading to their\nomission by detectors. To overcome this issue, we propose an all-scale\npseudo-box-based label assignment scheme that relaxes the constraints on scale\nand decouples the spatial assignment from the size of the ground-truth target.\nSecond, motivated by the structured prior of feature pyramids, we introduce the\none-stage cascade refinement network (OSCAR), which uses the high-level head as\nsoft proposals for the low-level refinement head. This allows OSCAR to process\nthe same target in a cascade coarse-to-fine manner. Finally, we present a new\nresearch benchmark for infrared small target detection, consisting of the\nSIRST-V2 dataset of real-world, high-resolution single-frame targets, the\nnormalized contrast evaluation metric, and the DeepInfrared toolkit for\ndetection. We conduct extensive ablation studies to evaluate the components of\nOSCAR and compare its performance to state-of-the-art model-driven and\ndata-driven methods on the SIRST-V2 benchmark. Our results demonstrate that a\ntop-down cascade refinement framework can improve the accuracy of infrared\nsmall target detection without sacrificing efficiency. The DeepInfrared\ntoolkit, dataset, and trained models are available at\nhttps://github.com/YimianDai/open-deepinfrared to advance further research in\nthis field.\n","authors":["Yimian Dai","Xiang Li","Fei Zhou","Yulei Qian","Yaohong Chen","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2212.08472v1.pdf","comment":"Submitted to TGRS, Major Revision"},{"id":"http://arxiv.org/abs/2212.05729v2","updated":"2022-12-16T13:33:27Z","published":"2022-12-12T06:38:35Z","title":"ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient\n  Self-Supervised Monocular Depth Estimation","summary":"  The exploration of mutual-benefit cross-domains has shown great potential\ntoward accurate self-supervised depth estimation. In this work, we revisit\nfeature fusion between depth and semantic information and propose an efficient\nlocal adaptive attention method for geometric aware representation enhancement.\nInstead of building global connections or deforming attention across the\nfeature space without restraint, we bound the spatial interaction within a\nlearnable region of interest. In particular, we leverage geometric cues from\nsemantic information to learn local adaptive bounding boxes to guide\nunsupervised feature aggregation. The local areas preclude most irrelevant\nreference points from attention space, yielding more selective feature learning\nand faster convergence. We naturally extend the paradigm into a multi-head and\nhierarchic way to enable the information distillation in different semantic\nlevels and improve the feature discriminative ability for fine-grained depth\nestimation. Extensive experiments on the KITTI dataset show that our proposed\nmethod establishes a new state-of-the-art in self-supervised monocular depth\nestimation task, demonstrating the effectiveness of our approach over former\nTransformer variants.\n","authors":["Daitao Xing","Jinglin Shen","Chiuman Ho","Anthony Tzes"],"pdf_url":"https://arxiv.org/pdf/2212.05729v2.pdf","comment":"9 Pages, AAAI 2023"},{"id":"http://arxiv.org/abs/2212.08464v1","updated":"2022-12-16T13:20:31Z","published":"2022-12-16T13:20:31Z","title":"Free-form 3D Scene Inpainting with Dual-stream GAN","summary":"  Nowadays, the need for user editing in a 3D scene has rapidly increased due\nto the development of AR and VR technology. However, the existing 3D scene\ncompletion task (and datasets) cannot suit the need because the missing regions\nin scenes are generated by the sensor limitation or object occlusion. Thus, we\npresent a novel task named free-form 3D scene inpainting. Unlike scenes in\nprevious 3D completion datasets preserving most of the main structures and\nhints of detailed shapes around missing regions, the proposed inpainting\ndataset, FF-Matterport, contains large and diverse missing regions formed by\nour free-form 3D mask generation algorithm that can mimic human drawing\ntrajectories in 3D space. Moreover, prior 3D completion methods cannot perform\nwell on this challenging yet practical task, simply interpolating nearby\ngeometry and color context. Thus, a tailored dual-stream GAN method is\nproposed. First, our dual-stream generator, fusing both geometry and color\ninformation, produces distinct semantic boundaries and solves the interpolation\nissue. To further enhance the details, our lightweight dual-stream\ndiscriminator regularizes the geometry and color edges of the predicted scenes\nto be realistic and sharp. We conducted experiments with the proposed\nFF-Matterport dataset. Qualitative and quantitative results validate the\nsuperiority of our approach over existing scene completion methods and the\nefficacy of all proposed components.\n","authors":["Ru-Fen Jheng","Tsung-Han Wu","Jia-Fong Yeh","Winston H. Hsu"],"pdf_url":"https://arxiv.org/pdf/2212.08464v1.pdf","comment":"BMVC 2022"},{"id":"http://arxiv.org/abs/2212.08448v1","updated":"2022-12-16T12:46:21Z","published":"2022-12-16T12:46:21Z","title":"From Xception to NEXcepTion: New Design Decisions and Neural\n  Architecture Search","summary":"  In this paper, we present a modified Xception architecture, the NEXcepTion\nnetwork. Our network has significantly better performance than the original\nXception, achieving top-1 accuracy of 81.5% on the ImageNet validation dataset\n(an improvement of 2.5%) as well as a 28% higher throughput. Another variant of\nour model, NEXcepTion-TP, reaches 81.8% top-1 accuracy, similar to ConvNeXt\n(82.1%), while having a 27% higher throughput. Our model is the result of\napplying improved training procedures and new design decisions combined with an\napplication of Neural Architecture Search (NAS) on a smaller dataset. These\nfindings call for revisiting older architectures and reassessing their\npotential when combined with the latest enhancements.\n","authors":["Hadar Shavit","Filip Jatelnicki","Pol Mor-Puigventós","Wojtek Kowalczyk"],"pdf_url":"https://arxiv.org/pdf/2212.08448v1.pdf","comment":"Accepted at ICPRAM 2023"},{"id":"http://arxiv.org/abs/2212.08423v1","updated":"2022-12-16T11:52:15Z","published":"2022-12-16T11:52:15Z","title":"Context Label Learning: Improving Background Class Representations in\n  Semantic Segmentation","summary":"  Background samples provide key contextual information for segmenting regions\nof interest (ROIs). However, they always cover a diverse set of structures,\ncausing difficulties for the segmentation model to learn good decision\nboundaries with high sensitivity and precision. The issue concerns the highly\nheterogeneous nature of the background class, resulting in multi-modal\ndistributions. Empirically, we find that neural networks trained with\nheterogeneous background struggle to map the corresponding contextual samples\nto compact clusters in feature space. As a result, the distribution over\nbackground logit activations may shift across the decision boundary, leading to\nsystematic over-segmentation across different datasets and tasks. In this\nstudy, we propose context label learning (CoLab) to improve the context\nrepresentations by decomposing the background class into several subclasses.\nSpecifically, we train an auxiliary network as a task generator, along with the\nprimary segmentation model, to automatically generate context labels that\npositively affect the ROI segmentation accuracy. Extensive experiments are\nconducted on several challenging segmentation tasks and datasets. The results\ndemonstrate that CoLab can guide the segmentation model to map the logits of\nbackground samples away from the decision boundary, resulting in significantly\nimproved segmentation accuracy. Code is available.\n","authors":["Zeju Li","Konstantinos Kamnitsas","Cheng Ouyang","Chen Chen","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2212.08423v1.pdf","comment":"Provisionally accepted to IEEE Transactions on Medical Imaging"},{"id":"http://arxiv.org/abs/2212.08420v1","updated":"2022-12-16T11:44:01Z","published":"2022-12-16T11:44:01Z","title":"Fake it till you make it: Learning(s) from a synthetic ImageNet clone","summary":"  Recent large-scale image generation models such as Stable Diffusion have\nexhibited an impressive ability to generate fairly realistic images starting\nfrom a very simple text prompt. Could such models render real images obsolete\nfor training image prediction models? In this paper, we answer part of this\nprovocative question by questioning the need for real images when training\nmodels for ImageNet classification. More precisely, provided only with the\nclass names that have been used to build the dataset, we explore the ability of\nStable Diffusion to generate synthetic clones of ImageNet and measure how\nuseful they are for training classification models from scratch. We show that\nwith minimal and class-agnostic prompt engineering those ImageNet clones we\ndenote as ImageNet-SD are able to close a large part of the gap between models\nproduced by synthetic images and models trained with real images for the\nseveral standard classification benchmarks that we consider in this study. More\nimportantly, we show that models trained on synthetic images exhibit strong\ngeneralization properties and perform on par with models trained on real data.\n","authors":["Mert Bulent Sariyildiz","Karteek Alahari","Diane Larlus","Yannis Kalantidis"],"pdf_url":"https://arxiv.org/pdf/2212.08420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12592v2","updated":"2022-12-16T11:33:17Z","published":"2022-01-29T13:58:03Z","title":"Exact Decomposition of Joint Low Rankness and Local Smoothness Plus\n  Sparse Matrices","summary":"  It is known that the decomposition in low-rank and sparse matrices\n(\\textbf{L+S} for short) can be achieved by several Robust PCA techniques.\nBesides the low rankness, the local smoothness (\\textbf{LSS}) is a vitally\nessential prior for many real-world matrix data such as hyperspectral images\nand surveillance videos, which makes such matrices have low-rankness and local\nsmoothness properties at the same time. This poses an interesting question: Can\nwe make a matrix decomposition in terms of \\textbf{L\\&LSS +S } form exactly? To\naddress this issue, we propose in this paper a new RPCA model based on\nthree-dimensional correlated total variation regularization (3DCTV-RPCA for\nshort) by fully exploiting and encoding the prior expression underlying such\njoint low-rank and local smoothness matrices. Specifically, using a\nmodification of Golfing scheme, we prove that under some mild assumptions, the\nproposed 3DCTV-RPCA model can decompose both components exactly, which should\nbe the first theoretical guarantee among all such related methods combining low\nrankness and local smoothness. In addition, by utilizing Fast Fourier Transform\n(FFT), we propose an efficient ADMM algorithm with a solid convergence\nguarantee for solving the resulting optimization problem. Finally, a series of\nexperiments on both simulations and real applications are carried out to\ndemonstrate the general validity of the proposed 3DCTV-RPCA model.\n","authors":["Jiangjun Peng","Yao Wang","Hongying Zhang","Jianjun Wang","Deyu Meng"],"pdf_url":"https://arxiv.org/pdf/2201.12592v2.pdf","comment":"15 pages, 14 figures, 4 tables"},{"id":"http://arxiv.org/abs/2212.08415v1","updated":"2022-12-16T11:27:50Z","published":"2022-12-16T11:27:50Z","title":"Person Detection Using an Ultra Low-resolution Thermal Imager on a\n  Low-cost MCU","summary":"  Detecting persons in images or video with neural networks is a well-studied\nsubject in literature. However, such works usually assume the availability of a\ncamera of decent resolution and a high-performance processor or GPU to run the\ndetection algorithm, which significantly increases the cost of a complete\ndetection system. However, many applications require low-cost solutions,\ncomposed of cheap sensors and simple microcontrollers. In this paper, we\ndemonstrate that even on such hardware we are not condemned to simple classic\nimage processing techniques. We propose a novel ultra-lightweight CNN-based\nperson detector that processes thermal video from a low-cost 32x24 pixel static\nimager. Trained and compressed on our own recorded dataset, our model achieves\nup to 91.62% accuracy (F1-score), has less than 10k parameters, and runs as\nfast as 87ms and 46ms on low-cost microcontrollers STM32F407 and STM32F746,\nrespectively.\n","authors":["Maarten Vandersteegen","Wouter Reusen","Kristof Van Beeck","Toon Goedemé"],"pdf_url":"https://arxiv.org/pdf/2212.08415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08414v1","updated":"2022-12-16T11:27:44Z","published":"2022-12-16T11:27:44Z","title":"Deep Learning Methods for Calibrated Photometric Stereo and Beyond: A\n  Survey","summary":"  Photometric stereo recovers the surface normals of an object from multiple\nimages with varying shading cues, i.e., modeling the relationship between\nsurface orientation and intensity at each pixel. Photometric stereo prevails in\nsuperior per-pixel resolution and fine reconstruction details. However, it is a\ncomplicated problem because of the non-linear relationship caused by\nnon-Lambertian surface reflectance. Recently, various deep learning methods\nhave shown a powerful ability in the context of photometric stereo against\nnon-Lambertian surfaces. This paper provides a comprehensive review of existing\ndeep learning-based calibrated photometric stereo methods. We first analyze\nthese methods from different perspectives, including input processing,\nsupervision, and network architecture. We summarize the performance of deep\nlearning photometric stereo models on the most widely-used benchmark data set.\nThis demonstrates the advanced performance of deep learning-based photometric\nstereo methods. Finally, we give suggestions and propose future research trends\nbased on the limitations of existing models.\n","authors":["Yakun Ju","Kin-Man Lam","Wuyuan Xie","Huiyu Zhou","Junyu Dong","Boxin Shi"],"pdf_url":"https://arxiv.org/pdf/2212.08414v1.pdf","comment":"16 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2207.12080v3","updated":"2022-12-16T10:47:34Z","published":"2022-07-25T11:57:01Z","title":"Intention-Conditioned Long-Term Human Egocentric Action Forecasting","summary":"  To anticipate how a human would act in the future, it is essential to\nunderstand the human intention since it guides the human towards a certain\ngoal. In this paper, we propose a hierarchical architecture which assumes a\nsequence of human action (low-level) can be driven from the human intention\n(high-level). Based on this, we deal with Long-Term Action Anticipation task in\negocentric videos. Our framework first extracts two level of human information\nover the N observed videos human actions through a Hierarchical Multi-task MLP\nMixer (H3M). Then, we condition the uncertainty of the future through an\nIntention-Conditioned Variational Auto-Encoder (I-CVAE) that generates K stable\npredictions of the next Z=20 actions that the observed human might perform. By\nleveraging human intention as high-level information, we claim that our model\nis able to anticipate more time-consistent actions in the long-term, thus\nimproving the results over baseline methods in EGO4D Challenge. This work\nranked first in both CVPR@2022 and ECVV@2022 EGO4D LTA Challenge by providing\nmore plausible anticipated sequences, improving the anticipation of nouns and\noverall actions. The code is available at\nhttps://github.com/Evm7/ego4dlta-icvae.\n","authors":["Esteve Valls Mascaro","Hyemin Ahn","Dongheui Lee"],"pdf_url":"https://arxiv.org/pdf/2207.12080v3.pdf","comment":"Validation report Winner of CVPR@2022 and ECCV@2022 EGO4D LTA\n  Challenge Accepted in IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV), 2023 More info\n  https://sites.google.com/view/estevevallsmascaro/publications/wacv2023"},{"id":"http://arxiv.org/abs/2212.08387v1","updated":"2022-12-16T10:21:29Z","published":"2022-12-16T10:21:29Z","title":"Traffic sign detection and recognition using event camera image\n  reconstruction","summary":"  This paper presents a method for detection and recognition of traffic signs\nbased on information extracted from an event camera. The solution used a\nFireNet deep convolutional neural network to reconstruct events into greyscale\nframes. Two YOLOv4 network models were trained, one based on greyscale images\nand the other on colour images. The best result was achieved for the model\ntrained on the basis of greyscale images, achieving an efficiency of 87.03%.\n","authors":["Kamil Jeziorek","Tomasz Kryjak"],"pdf_url":"https://arxiv.org/pdf/2212.08387v1.pdf","comment":"Paper accepted for publication in: Zeszyty Studenckiego Towarzystwa\n  Naukowego, 59. Hutnicza Konferencja Studenckich Kol Naukowych AGH,ISSN\n  1732-0925, 2022 nr 38, pp. 127-134. (original manuscript in Polish)"},{"id":"http://arxiv.org/abs/2212.08384v1","updated":"2022-12-16T10:16:42Z","published":"2022-12-16T10:16:42Z","title":"Fast-moving object counting with an event camera","summary":"  This paper proposes the use of an event camera as a component of a vision\nsystem that enables counting of fast-moving objects - in this case, falling\ncorn grains. These type of cameras transmit information about the change in\nbrightness of individual pixels and are characterised by low latency, no motion\nblur, correct operation in different lighting conditions, as well as very low\npower consumption. The proposed counting algorithm processes events in real\ntime. The operation of the solution was demonstrated on a stand consisting of a\nchute with a vibrating feeder, which allowed the number of grains falling to be\nadjusted. The objective of the control system with a PID controller was to\nmaintain a constant average number of falling objects. The proposed solution\nwas subjected to a series of tests to determine the correctness of the\ndeveloped method operation. On their basis, the validity of using an event\ncamera to count small, fast-moving objects and the associated wide range of\npotential industrial applications can be confirmed.\n","authors":["Kamil Bialik","Marcin Kowalczyk","Krzysztof Blachut","Tomasz Kryjak"],"pdf_url":"https://arxiv.org/pdf/2212.08384v1.pdf","comment":"Paper accepted for the Automation 2023 (7-9 March 2023, Warsaw,\n  Poland) conference and PAR journal (original manuscript in Polish)"},{"id":"http://arxiv.org/abs/2212.08380v1","updated":"2022-12-16T10:13:25Z","published":"2022-12-16T10:13:25Z","title":"Instance-specific Label Distribution Regularization for Learning with\n  Label Noise","summary":"  Modeling noise transition matrix is a kind of promising method for learning\nwith label noise. Based on the estimated noise transition matrix and the noisy\nposterior probabilities, the clean posterior probabilities, which are jointly\ncalled Label Distribution (LD) in this paper, can be calculated as the\nsupervision. To reliably estimate the noise transition matrix, some methods\nassume that anchor points are available during training. Nonetheless, if anchor\npoints are invalid, the noise transition matrix might be poorly learned,\nresulting in poor performance. Consequently, other methods treat reliable data\npoints, extracted from training data, as pseudo anchor points. However, from a\nstatistical point of view, the noise transition matrix can be inferred from\ndata with noisy labels under the clean-label-domination assumption. Therefore,\nwe aim to estimate the noise transition matrix without (pseudo) anchor points.\nThere is evidence showing that samples are more likely to be mislabeled as\nother similar class labels, which means the mislabeling probability is highly\ncorrelated with the inter-class correlation. Inspired by this observation, we\npropose an instance-specific Label Distribution Regularization (LDR), in which\nthe instance-specific LD is estimated as the supervision, to prevent DCNNs from\nmemorizing noisy labels. Specifically, we estimate the noisy posterior under\nthe supervision of noisy labels, and approximate the batch-level noise\ntransition matrix by estimating the inter-class correlation matrix with neither\nanchor points nor pseudo anchor points. Experimental results on two synthetic\nnoisy datasets and two real-world noisy datasets demonstrate that our LDR\noutperforms existing methods.\n","authors":["Zehui Liao","Shishuai Hu","Yutong Xie","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2212.08380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08378v1","updated":"2022-12-16T10:08:38Z","published":"2022-12-16T10:08:38Z","title":"Feature Dropout: Revisiting the Role of Augmentations in Contrastive\n  Learning","summary":"  What role do augmentations play in contrastive learning? Recent work suggests\nthat good augmentations are label-preserving with respect to a specific\ndownstream task. We complicate this picture by showing that label-destroying\naugmentations can be useful in the foundation model setting, where the goal is\nto learn diverse, general-purpose representations for multiple downstream\ntasks. We perform contrastive learning experiments on a range of image and\naudio datasets with multiple downstream tasks (e.g. for digits superimposed on\nphotographs, predicting the class of one vs. the other). We find that Viewmaker\nNetworks, a recently proposed model for learning augmentations for contrastive\nlearning, produce label-destroying augmentations that stochastically destroy\nfeatures needed for different downstream tasks. These augmentations are\ninterpretable (e.g. altering shapes, digits, or letters added to images) and\nsurprisingly often result in better performance compared to expert-designed\naugmentations, despite not preserving label information. To support our\nempirical results, we theoretically analyze a simple contrastive learning\nsetting with a linear model. In this setting, label-destroying augmentations\nare crucial for preventing one set of features from suppressing the learning of\nfeatures useful for another downstream task. Our results highlight the need for\nanalyzing the interaction between multiple downstream tasks when trying to\nexplain the success of foundation models.\n","authors":["Alex Tamkin","Margalit Glasgow","Xiluo He","Noah Goodman"],"pdf_url":"https://arxiv.org/pdf/2212.08378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08377v1","updated":"2022-12-16T10:05:31Z","published":"2022-12-16T10:05:31Z","title":"PointAvatar: Deformable Point-based Head Avatars from Videos","summary":"  The ability to create realistic, animatable and relightable head avatars from\ncasual video sequences would open up wide ranging applications in communication\nand entertainment. Current methods either build on explicit 3D morphable meshes\n(3DMM) or exploit neural implicit representations. The former are limited by\nfixed topology, while the latter are non-trivial to deform and inefficient to\nrender. Furthermore, existing approaches entangle lighting in the color\nestimation, thus they are limited in re-rendering the avatar in new\nenvironments. In contrast, we propose PointAvatar, a deformable point-based\nrepresentation that disentangles the source color into intrinsic albedo and\nnormal-dependent shading. We demonstrate that PointAvatar bridges the gap\nbetween existing mesh- and implicit representations, combining high-quality\ngeometry and appearance with topological flexibility, ease of deformation and\nrendering efficiency. We show that our method is able to generate animatable 3D\navatars using monocular videos from multiple sources including hand-held\nsmartphones, laptop webcams and internet videos, achieving state-of-the-art\nquality in challenging cases where previous methods fail, e.g., thin hair\nstrands, while being significantly more efficient in training than competing\nmethods.\n","authors":["Yufeng Zheng","Wang Yifan","Gordon Wetzstein","Michael J. Black","Otmar Hilliges"],"pdf_url":"https://arxiv.org/pdf/2212.08377v1.pdf","comment":"Project page: https://zhengyuf.github.io/pointavatar/"},{"id":"http://arxiv.org/abs/2211.06108v2","updated":"2022-12-16T09:40:57Z","published":"2022-11-11T10:24:42Z","title":"RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object\n  Detection System","summary":"  In autonomous driving systems, LiDAR and radar play important roles in the\nperception of the surrounding environment.LiDAR provides accurate 3D spatial\nsensing information but cannot work in adverse weather like fog. On the other\nhand, the radar signal can be diffracted when encountering raindrops or mist\nparticles thanks to its wavelength, but it suffers from large noise. Recent\nstate-of-the-art works reveal that fusion of radar and LiDAR can lead to robust\ndetection in adverse weather. The existing works adopt convolutional neural\nnetwork architecture to extract features from each sensor data stream, then\nalign and aggregate the two branch features to predict object detection\nresults. However, these methods have low accuracy of bounding box estimations\ndue to a simple design of label assignment and fusion strategies. In this\npaper, we propose a bird's-eye view fusion learning-based anchor box-free\nobject detection system, which fuses the feature derived from the radar\nrange-azimuth heatmap and the LiDAR point cloud to estimate the possible\nobjects. Different label assignment strategies have been designed to facilitate\nthe consistency between the classification of foreground or background anchor\npoints and the corresponding bounding box regressions. In addition, the\nperformance of the proposed object detector is further enhanced by employing a\nnovel interactive transformer module. The superior performance of the proposed\nmethods in this paper has been demonstrated using the recently published Oxford\nradar robotCar dataset, showing that the average precision of our system\nsignificantly outperforms the best state-of-the-art method by 14.4% and 20.5%\nat IoU equals 0.8 in clear and foggy weather testing, respectively.\n","authors":["Yanlong Yang","Jianan Liu","Tao Huang","Qing-Long Han","Gang Ma","Bing Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.06108v2.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.08365v1","updated":"2022-12-16T09:33:31Z","published":"2022-12-16T09:33:31Z","title":"Geometric Rectification of Creased Document Images based on Isometric\n  Mapping","summary":"  Geometric rectification of images of distorted documents finds wide\napplications in document digitization and Optical Character Recognition (OCR).\nAlthough smoothly curved deformations have been widely investigated by many\nworks, the most challenging distortions, e.g. complex creases and large\nfoldings, have not been studied in particular. The performance of existing\napproaches, when applied to largely creased or folded documents, is far from\nsatisfying, leaving substantial room for improvement. To tackle this task,\nknowledge about document rectification should be incorporated into the\ncomputation, among which the developability of 3D document models and\nparticular textural features in the images, such as straight lines, are the\nmost essential ones. For this purpose, we propose a general framework of\ndocument image rectification in which a computational isometric mapping model\nis utilized for expressing a 3D document model and its flattening in the plane.\nBased on this framework, both model developability and textural features are\nconsidered in the computation. The experiments and comparisons to the\nstate-of-the-art approaches demonstrated the effectiveness and outstanding\nperformance of the proposed method. Our method is also flexible in that the\nrectification results can be enhanced by any other methods that extract\nhigh-quality feature lines in the images.\n","authors":["Dong Luo","Pengbo Bo"],"pdf_url":"https://arxiv.org/pdf/2212.08365v1.pdf","comment":"23 pages,17 figures"},{"id":"http://arxiv.org/abs/2212.08363v1","updated":"2022-12-16T09:31:15Z","published":"2022-12-16T09:31:15Z","title":"Fast Learning of Dynamic Hand Gesture Recognition with Few-Shot Learning\n  Models","summary":"  We develop Few-Shot Learning models trained to recognize five or ten\ndifferent dynamic hand gestures, respectively, which are arbitrarily\ninterchangeable by providing the model with one, two, or five examples per hand\ngesture. All models were built in the Few-Shot Learning architecture of the\nRelation Network (RN), in which Long-Short-Term Memory cells form the backbone.\nThe models use hand reference points extracted from RGB-video sequences of the\nJester dataset which was modified to contain 190 different types of hand\ngestures. Result show accuracy of up to 88.8% for recognition of five and up to\n81.2% for ten dynamic hand gestures. The research also sheds light on the\npotential effort savings of using a Few-Shot Learning approach instead of a\ntraditional Deep Learning approach to detect dynamic hand gestures. Savings\nwere defined as the number of additional observations required when a Deep\nLearning model is trained on new hand gestures instead of a Few Shot Learning\nmodel. The difference with respect to the total number of observations required\nto achieve approximately the same accuracy indicates potential savings of up to\n630 observations for five and up to 1260 observations for ten hand gestures to\nbe recognized. Since labeling video recordings of hand gestures implies\nsignificant effort, these savings can be considered substantial.\n","authors":["Niels Schlüsener","Michael Bücker"],"pdf_url":"https://arxiv.org/pdf/2212.08363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.12570v3","updated":"2022-12-16T09:29:56Z","published":"2021-06-23T17:54:35Z","title":"Learning Multimodal VAEs through Mutual Supervision","summary":"  Multimodal VAEs seek to model the joint distribution over heterogeneous data\n(e.g.\\ vision, language), whilst also capturing a shared representation across\nsuch modalities. Prior work has typically combined information from the\nmodalities by reconciling idiosyncratic representations directly in the\nrecognition model through explicit products, mixtures, or other such\nfactorisations. Here we introduce a novel alternative, the MEME, that avoids\nsuch explicit combinations by repurposing semi-supervised VAEs to combine\ninformation between modalities implicitly through mutual supervision. This\nformulation naturally allows learning from partially-observed data where some\nmodalities can be entirely missing -- something that most existing approaches\neither cannot handle, or do so to a limited extent. We demonstrate that MEME\noutperforms baselines on standard metrics across both partial and complete\nobservation schemes on the MNIST-SVHN (image-image) and CUB (image-text)\ndatasets. We also contrast the quality of the representations learnt by mutual\nsupervision against standard approaches and observe interesting trends in its\nability to capture relatedness between data.\n","authors":["Tom Joy","Yuge Shi","Philip H. S. Torr","Tom Rainforth","Sebastian M. Schmon","N. Siddharth"],"pdf_url":"https://arxiv.org/pdf/2106.12570v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.10779v4","updated":"2022-12-16T09:04:36Z","published":"2022-04-18T04:51:08Z","title":"CgAT: Center-Guided Adversarial Training for Deep Hashing-Based\n  Retrieval","summary":"  Deep hashing has been extensively utilized in massive image retrieval because\nof its efficiency and effectiveness. However, deep hashing models are\nvulnerable to adversarial examples, making it essential to develop adversarial\ndefense methods for image retrieval. Existing solutions achieved limited\ndefense performance because of using weak adversarial samples for training and\nlacking discriminative optimization objectives to learn robust features. In\nthis paper, we present a min-max based Center-guided Adversarial Training,\nnamely CgAT, to improve the robustness of deep hashing networks through worst\nadversarial examples. Specifically, we first formulate the center code as a\nsemantically-discriminative representative of the input image content, which\npreserves the semantic similarity with positive samples and dissimilarity with\nnegative examples. We prove that a mathematical formula can calculate the\ncenter code immediately. After obtaining the center codes in each optimization\niteration of the deep hashing network, they are adopted to guide the\nadversarial training process. On the one hand, CgAT generates the worst\nadversarial examples as augmented data by maximizing the Hamming distance\nbetween the hash codes of the adversarial examples and the center codes. On the\nother hand, CgAT learns to mitigate the effects of adversarial samples by\nminimizing the Hamming distance to the center codes. Extensive experiments on\nthe benchmark datasets demonstrate the effectiveness of our adversarial\ntraining algorithm in defending against adversarial attacks for deep\nhashing-based retrieval. Compared with the current state-of-the-art defense\nmethod, we significantly improve the defense performance by an average of\n18.61%, 12.35%, and 11.56% on FLICKR-25K, NUS-WIDE, and MS-COCO, respectively.\n","authors":["Xunguang Wang","Yinqun Lin","Xiaomeng Li"],"pdf_url":"https://arxiv.org/pdf/2204.10779v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08356v1","updated":"2022-12-16T09:02:01Z","published":"2022-12-16T09:02:01Z","title":"CD-TTA: Compound Domain Test-time Adaptation for Semantic Segmentation","summary":"  Test-time adaptation (TTA) has attracted significant attention due to its\npractical properties which enable the adaptation of a pre-trained model to a\nnew domain with only target dataset during the inference stage. Prior works on\nTTA assume that the target dataset comes from the same distribution and thus\nconstitutes a single homogeneous domain. In practice, however, the target\ndomain can contain multiple homogeneous domains which are sufficiently\ndistinctive from each other and those multiple domains might occur cyclically.\nOur preliminary investigation shows that domain-specific TTA outperforms\nvanilla TTA treating compound domain (CD) as a single one. However, domain\nlabels are not available for CD, which makes domain-specific TTA not\npracticable. To this end, we propose an online clustering algorithm for finding\npseudo-domain labels to obtain similar benefits as domain-specific\nconfiguration and accumulating knowledge of cyclic domains effectively.\nMoreover, we observe that there is a significant discrepancy in terms of\nprediction quality among samples, especially in the CD context. This further\nmotivates us to boost its performance with gradient denoising by considering\nthe image-wise similarity with the source distribution. Overall, the key\ncontribution of our work lies in proposing a highly significant new task\ncompound domain test-time adaptation (CD-TTA) on semantic segmentation as well\nas providing a strong baseline to facilitate future works to benchmark.\n","authors":["Junha Song","Kwanyong Park","Inkyu Shin","Sanghyun Woo","In So Kweon"],"pdf_url":"https://arxiv.org/pdf/2212.08356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08355v1","updated":"2022-12-16T09:01:57Z","published":"2022-12-16T09:01:57Z","title":"Learning Classifiers of Prototypes and Reciprocal Points for Universal\n  Domain Adaptation","summary":"  Universal Domain Adaptation aims to transfer the knowledge between the\ndatasets by handling two shifts: domain-shift and category-shift. The main\nchallenge is correctly distinguishing the unknown target samples while adapting\nthe distribution of known class knowledge from source to target. Most existing\nmethods approach this problem by first training the target adapted known\nclassifier and then relying on the single threshold to distinguish unknown\ntarget samples. However, this simple threshold-based approach prevents the\nmodel from considering the underlying complexities existing between the known\nand unknown samples in the high-dimensional feature space. In this paper, we\npropose a new approach in which we use two sets of feature points, namely dual\nClassifiers for Prototypes and Reciprocals (CPR). Our key idea is to associate\neach prototype with corresponding known class features while pushing the\nreciprocals apart from these prototypes to locate them in the potential unknown\nfeature space. The target samples are then classified as unknown if they fall\nnear any reciprocals at test time. To successfully train our framework, we\ncollect the partial, confident target samples that are classified as known or\nunknown through on our proposed multi-criteria selection. We then additionally\napply the entropy loss regularization to them. For further adaptation, we also\napply standard consistency regularization that matches the predictions of two\ndifferent views of the input to make more compact target feature space. We\nevaluate our proposal, CPR, on three standard benchmarks and achieve comparable\nor new state-of-the-art results. We also provide extensive ablation experiments\nto verify our main design choices in our framework.\n","authors":["Sungsu Hur","Inkyu Shin","Kwanyong Park","Sanghyun Woo","In So Kweon"],"pdf_url":"https://arxiv.org/pdf/2212.08355v1.pdf","comment":"Accepted at WACV 2023"},{"id":"http://arxiv.org/abs/2210.16810v3","updated":"2022-12-16T08:57:41Z","published":"2022-10-30T11:08:25Z","title":"SL3D: Self-supervised-Self-labeled 3D Recognition","summary":"  Deep learning has attained remarkable success in many 3D visual recognition\ntasks, including shape classification, object detection, and semantic\nsegmentation. However, many of these results rely on manually collecting\ndensely annotated real-world 3D data, which is highly time-consuming and\nexpensive to obtain, limiting the scalability of 3D recognition tasks. Thus, we\nstudy unsupervised 3D recognition and propose a Self-supervised-Self-Labeled 3D\nRecognition (SL3D) framework. SL3D simultaneously solves two coupled\nobjectives, i.e., clustering and learning feature representation to generate\npseudo-labeled data for unsupervised 3D recognition. SL3D is a generic\nframework and can be applied to solve different 3D recognition tasks, including\nclassification, object detection, and semantic segmentation. Extensive\nexperiments demonstrate its effectiveness. Code is available at\nhttps://github.com/fcendra/sl3d.\n","authors":["Fernando Julio Cendra","Lan Ma","Jiajun Shen","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2210.16810v3.pdf","comment":"This paper has already been accepted by Neural Information Processing\n  Systems (NeurIPS 2022) Workshop on Self-Supervised Learning: Theory and\n  Practice"},{"id":"http://arxiv.org/abs/2212.07648v2","updated":"2022-12-16T08:51:53Z","published":"2022-12-15T08:06:03Z","title":"Relightable Neural Human Assets from Multi-view Gradient Illuminations","summary":"  Human modeling and relighting are two fundamental problems in computer vision\nand graphics, where high-quality datasets can largely facilitate related\nresearch. However, most existing human datasets only provide multi-view human\nimages captured under the same illumination. Although valuable for modeling\ntasks, they are not readily used in relighting problems. To promote research in\nboth fields, in this paper, we present UltraStage, a new 3D human dataset that\ncontains more than 2K high-quality human assets captured under both multi-view\nand multi-illumination settings. Specifically, for each example, we provide 32\nsurrounding views illuminated with one white light and two gradient\nilluminations. In addition to regular multi-view images, gradient illuminations\nhelp recover detailed surface normal and spatially-varying material maps,\nenabling various relighting applications. Inspired by recent advances in neural\nrepresentation, we further interpret each example into a neural human asset\nwhich allows novel view synthesis under arbitrary lighting conditions. We show\nour neural human assets can achieve extremely high capture performance and are\ncapable of representing fine details such as facial wrinkles and cloth folds.\nWe also validate UltraStage in single image relighting tasks, training neural\nnetworks with virtual relighted data from neural assets and demonstrating\nrealistic rendering improvements over prior arts. UltraStage will be publicly\navailable to the community to stimulate significant future developments in\nvarious human modeling and rendering tasks.\n","authors":["Taotao Zhou","Kai He","Di Wu","Teng Xu","Qixuan Zhang","Kuixiang Shao","Wenzheng Chen","Lan Xu","Jingyi Yu"],"pdf_url":"https://arxiv.org/pdf/2212.07648v2.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2212.08341v1","updated":"2022-12-16T08:35:21Z","published":"2022-12-16T08:35:21Z","title":"Adversarial Example Defense via Perturbation Grading Strategy","summary":"  Deep Neural Networks have been widely used in many fields. However, studies\nhave shown that DNNs are easily attacked by adversarial examples, which have\ntiny perturbations and greatly mislead the correct judgment of DNNs.\nFurthermore, even if malicious attackers cannot obtain all the underlying model\nparameters, they can use adversarial examples to attack various DNN-based task\nsystems. Researchers have proposed various defense methods to protect DNNs,\nsuch as reducing the aggressiveness of adversarial examples by preprocessing or\nimproving the robustness of the model by adding modules. However, some defense\nmethods are only effective for small-scale examples or small perturbations but\nhave limited defense effects for adversarial examples with large perturbations.\nThis paper assigns different defense strategies to adversarial perturbations of\ndifferent strengths by grading the perturbations on the input examples.\nExperimental results show that the proposed method effectively improves defense\nperformance. In addition, the proposed method does not modify any task model,\nwhich can be used as a preprocessing module, which significantly reduces the\ndeployment cost in practical applications.\n","authors":["Shaowei Zhu","Wanli Lyu","Bin Li","Zhaoxia Yin","Bin Luo"],"pdf_url":"https://arxiv.org/pdf/2212.08341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08340v1","updated":"2022-12-16T08:31:07Z","published":"2022-12-16T08:31:07Z","title":"Neural Enhanced Belief Propagation for Multiobject Tracking","summary":"  Algorithmic solutions for multi-object tracking (MOT) are a key enabler for\napplications in autonomous navigation and applied ocean sciences.\nState-of-the-art MOT methods fully rely on a statistical model and typically\nuse preprocessed sensor data as measurements. In particular, measurements are\nproduced by a detector that extracts potential object locations from the raw\nsensor data collected for a discrete time step. This preparatory processing\nstep reduces data flow and computational complexity but may result in a loss of\ninformation. State-of-the-art Bayesian MOT methods that are based on belief\npropagation (BP) systematically exploit graph structures of the statistical\nmodel to reduce computational complexity and improve scalability. However, as a\nfully model-based approach, BP can only provide suboptimal estimates when there\nis a mismatch between the statistical model and the true data-generating\nprocess. Existing BP-based MOT methods can further only make use of\npreprocessed measurements. In this paper, we introduce a variant of BP that\ncombines model-based with data-driven MOT. The proposed neural enhanced belief\npropagation (NEBP) method complements the statistical model of BP by\ninformation learned from raw sensor data. This approach conjectures that the\nlearned information can reduce model mismatch and thus improve data association\nand false alarm rejection. Our NEBP method improves tracking performance\ncompared to model-based methods. At the same time, it inherits the advantages\nof BP-based MOT, i.e., it scales only quadratically in the number of objects,\nand it can thus generate and maintain a large number of object tracks. We\nevaluate the performance of our NEBP approach for MOT on the nuScenes\nautonomous driving dataset and demonstrate that it has state-of-the-art\nperformance.\n","authors":["Mingchao Liang","Florian Meyer"],"pdf_url":"https://arxiv.org/pdf/2212.08340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08334v1","updated":"2022-12-16T08:22:55Z","published":"2022-12-16T08:22:55Z","title":"Lightweight integration of 3D features to improve 2D image segmentation","summary":"  Scene understanding is a major challenge of today's computer vision. Center\nto this task is image segmentation, since scenes are often provided as a set of\npictures. Nowadays, many such datasets also provide 3D geometry information\ngiven as a 3D point cloud acquired by a laser scanner or a depth camera. To\nexploit this geometric information, many current approaches rely on both a 2D\nloss and 3D loss, requiring not only 2D per pixel labels but also 3D per point\nlabels. However obtaining a 3D groundtruth is challenging, time-consuming and\nerror-prone. In this paper, we show that image segmentation can benefit from 3D\ngeometric information without requiring any 3D groundtruth, by training the\ngeometric feature extraction with a 2D segmentation loss in an end-to-end\nfashion. Our method starts by extracting a map of 3D features directly from the\npoint cloud by using a lightweight and simple 3D encoder neural network. The 3D\nfeature map is then used as an additional input to a classical image\nsegmentation network. During training, the 3D features extraction is optimized\nfor the segmentation task by back-propagation through the entire pipeline. Our\nmethod exhibits state-of-the-art performance with much lighter input dataset\nrequirements, since no 3D groundtruth is required.\n","authors":["Olivier Pradelle","Raphaelle Chaine","David Wendland","Julie Digne"],"pdf_url":"https://arxiv.org/pdf/2212.08334v1.pdf","comment":"main : 7 pages, 4 figures; supplementary : 4 pages, 3 figures;\n  submitted to CVIU"},{"id":"http://arxiv.org/abs/2212.08330v1","updated":"2022-12-16T08:14:04Z","published":"2022-12-16T08:14:04Z","title":"Convolution-enhanced Evolving Attention Networks","summary":"  Attention-based neural networks, such as Transformers, have become ubiquitous\nin numerous applications, including computer vision, natural language\nprocessing, and time-series analysis. In all kinds of attention networks, the\nattention maps are crucial as they encode semantic dependencies between input\ntokens. However, most existing attention networks perform modeling or reasoning\nbased on representations, wherein the attention maps of different layers are\nlearned separately without explicit interactions. In this paper, we propose a\nnovel and generic evolving attention mechanism, which directly models the\nevolution of inter-token relationships through a chain of residual\nconvolutional modules. The major motivations are twofold. On the one hand, the\nattention maps in different layers share transferable knowledge, thus adding a\nresidual connection can facilitate the information flow of inter-token\nrelationships across layers. On the other hand, there is naturally an\nevolutionary trend among attention maps at different abstraction levels, so it\nis beneficial to exploit a dedicated convolution-based module to capture this\nprocess. Equipped with the proposed mechanism, the convolution-enhanced\nevolving attention networks achieve superior performance in various\napplications, including time-series representation, natural language\nunderstanding, machine translation, and image classification. Especially on\ntime-series representation tasks, Evolving Attention-enhanced Dilated\nConvolutional (EA-DC-) Transformer outperforms state-of-the-art models\nsignificantly, achieving an average of 17% improvement compared to the best\nSOTA. To the best of our knowledge, this is the first work that explicitly\nmodels the layer-wise evolution of attention maps. Our implementation is\navailable at https://github.com/pkuyym/EvolvingAttention\n","authors":["Yujing Wang","Yaming Yang","Zhuo Li","Jiangang Bai","Mingliang Zhang","Xiangtai Li","Jing Yu","Ce Zhang","Gao Huang","Yunhai Tong"],"pdf_url":"https://arxiv.org/pdf/2212.08330v1.pdf","comment":"Extension of the previous work (arXiv:2102.12895). arXiv admin note:\n  text overlap with arXiv:2102.12895"},{"id":"http://arxiv.org/abs/2212.08328v1","updated":"2022-12-16T08:04:56Z","published":"2022-12-16T08:04:56Z","title":"MEIL-NeRF: Memory-Efficient Incremental Learning of Neural Radiance\n  Fields","summary":"  Hinged on the representation power of neural networks, neural radiance fields\n(NeRF) have recently emerged as one of the promising and widely applicable\nmethods for 3D object and scene representation. However, NeRF faces challenges\nin practical applications, such as large-scale scenes and edge devices with a\nlimited amount of memory, where data needs to be processed sequentially. Under\nsuch incremental learning scenarios, neural networks are known to suffer\ncatastrophic forgetting: easily forgetting previously seen data after training\nwith new data. We observe that previous incremental learning algorithms are\nlimited by either low performance or memory scalability issues. As such, we\ndevelop a Memory-Efficient Incremental Learning algorithm for NeRF (MEIL-NeRF).\nMEIL-NeRF takes inspiration from NeRF itself in that a neural network can serve\nas a memory that provides the pixel RGB values, given rays as queries. Upon the\nmotivation, our framework learns which rays to query NeRF to extract previous\npixel values. The extracted pixel values are then used to train NeRF in a\nself-distillation manner to prevent catastrophic forgetting. As a result,\nMEIL-NeRF demonstrates constant memory consumption and competitive performance.\n","authors":["Jaeyoung Chung","Kanggeon Lee","Sungyong Baik","Kyoung Mu Lee"],"pdf_url":"https://arxiv.org/pdf/2212.08328v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2212.08327v1","updated":"2022-12-16T08:00:54Z","published":"2022-12-16T08:00:54Z","title":"WavEnhancer: Unifying Wavelet and Transformer for Image Enhancement","summary":"  Image enhancement is a technique that frequently utilized in digital image\nprocessing. In recent years, the popularity of learning-based techniques for\nenhancing the aesthetic performance of photographs has increased. However, the\nmajority of current works do not optimize an image from different frequency\ndomains and typically focus on either pixel-level or global-level enhancements.\nIn this paper, we propose a transformer-based model in the wavelet domain to\nrefine different frequency bands of an image. Our method focuses both on local\ndetails and high-level features for enhancement, which can generate superior\nresults. On the basis of comprehensive benchmark evaluations, our method\noutperforms the state-of-the-art methods.\n","authors":["Zinuo Li","Xuhang Chen","Chi-Man Pun","Shuqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.08327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.11291v2","updated":"2022-12-16T07:48:13Z","published":"2022-10-20T14:23:40Z","title":"Cyclical Self-Supervision for Semi-Supervised Ejection Fraction\n  Prediction from Echocardiogram Videos","summary":"  Left-ventricular ejection fraction (LVEF) is an important indicator of heart\nfailure. Existing methods for LVEF estimation from video require large amounts\nof annotated data to achieve high performance, e.g. using 10,030 labeled\nechocardiogram videos to achieve mean absolute error (MAE) of 4.10. Labeling\nthese videos is time-consuming however and limits potential downstream\napplications to other heart diseases. This paper presents the first\nsemi-supervised approach for LVEF prediction. Unlike general video prediction\ntasks, LVEF prediction is specifically related to changes in the left ventricle\n(LV) in echocardiogram videos. By incorporating knowledge learned from\npredicting LV segmentations into LVEF regression, we can provide additional\ncontext to the model for better predictions. To this end, we propose a novel\nCyclical Self-Supervision (CSS) method for learning video-based LV\nsegmentation, which is motivated by the observation that the heartbeat is a\ncyclical process with temporal repetition. Prediction masks from our\nsegmentation model can then be used as additional input for LVEF regression to\nprovide spatial context for the LV region. We also introduce teacher-student\ndistillation to distill the information from LV segmentation masks into an\nend-to-end LVEF regression model that only requires video inputs. Results show\nour method outperforms alternative semi-supervised methods and can achieve MAE\nof 4.17, which is competitive with state-of-the-art supervised performance,\nusing half the number of labels. Validation on an external dataset also shows\nimproved generalization ability from using our method. Our code is available at\nhttps://github.com/xmed-lab/CSS-SemiVideo.\n","authors":["Weihang Dai","Xiaomeng Li","Xinpeng Ding","Kwang-Ting Cheng"],"pdf_url":"https://arxiv.org/pdf/2210.11291v2.pdf","comment":"Accepted in IEEE Transactions on Medical Imaging"},{"id":"http://arxiv.org/abs/2212.08320v1","updated":"2022-12-16T07:46:53Z","published":"2022-12-16T07:46:53Z","title":"Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image\n  Transformers Help 3D Representation Learning?","summary":"  The success of deep learning heavily relies on large-scale data with\ncomprehensive labels, which is more expensive and time-consuming to fetch in 3D\ncompared to 2D images or natural languages. This promotes the potential of\nutilizing models pretrained with data more than 3D as teachers for cross-modal\nknowledge transferring. In this paper, we revisit masked modeling in a unified\nfashion of knowledge distillation, and we show that foundational Transformers\npretrained with 2D images or natural languages can help self-supervised 3D\nrepresentation learning through training Autoencoders as Cross-Modal Teachers\n(ACT). The pretrained Transformers are transferred as cross-modal 3D teachers\nusing discrete variational autoencoding self-supervision, during which the\nTransformers are frozen with prompt tuning for better knowledge inheritance.\nThe latent features encoded by the 3D teachers are used as the target of masked\npoint modeling, wherein the dark knowledge is distilled to the 3D Transformer\nstudents as foundational geometry understanding. Our ACT pretrained 3D learner\nachieves state-of-the-art generalization capacity across various downstream\nbenchmarks, e.g., 88.21% overall accuracy on ScanObjectNN. Codes will be\nreleased at https://github.com/RunpeiDong/ACT.\n","authors":["Runpei Dong","Zekun Qi","Linfeng Zhang","Junbo Zhang","Jianjian Sun","Zheng Ge","Li Yi","Kaisheng Ma"],"pdf_url":"https://arxiv.org/pdf/2212.08320v1.pdf","comment":"Tech report"},{"id":"http://arxiv.org/abs/2205.04948v2","updated":"2022-12-16T07:22:56Z","published":"2022-05-10T15:03:00Z","title":"Transformer-based Cross-Modal Recipe Embeddings with Large Batch\n  Training","summary":"  In this paper, we present a cross-modal recipe retrieval framework,\nTransformer-based Network for Large Batch Training (TNLBT), which is inspired\nby ACME~(Adversarial Cross-Modal Embedding) and H-T~(Hierarchical Transformer).\nTNLBT aims to accomplish retrieval tasks while generating images from recipe\nembeddings. We apply the Hierarchical Transformer-based recipe text encoder,\nthe Vision Transformer~(ViT)-based recipe image encoder, and an adversarial\nnetwork architecture to enable better cross-modal embedding learning for recipe\ntexts and images. In addition, we use self-supervised learning to exploit the\nrich information in the recipe texts having no corresponding images. Since\ncontrastive learning could benefit from a larger batch size according to the\nrecent literature on self-supervised learning, we adopt a large batch size\nduring training and have validated its effectiveness. In the experiments, the\nproposed framework significantly outperformed the current state-of-the-art\nframeworks in both cross-modal recipe retrieval and image generation tasks on\nthe benchmark Recipe1M. This is the first work which confirmed the\neffectiveness of large batch training on cross-modal recipe embeddings.\n","authors":["Jing Yang","Junwen Chen","Keiji Yanai"],"pdf_url":"https://arxiv.org/pdf/2205.04948v2.pdf","comment":"Accepted at MMM2023"},{"id":"http://arxiv.org/abs/2212.08311v1","updated":"2022-12-16T07:20:28Z","published":"2022-12-16T07:20:28Z","title":"Can We Find Strong Lottery Tickets in Generative Models?","summary":"  Yes. In this paper, we investigate strong lottery tickets in generative\nmodels, the subnetworks that achieve good generative performance without any\nweight update. Neural network pruning is considered the main cornerstone of\nmodel compression for reducing the costs of computation and memory.\nUnfortunately, pruning a generative model has not been extensively explored,\nand all existing pruning algorithms suffer from excessive weight-training\ncosts, performance degradation, limited generalizability, or complicated\ntraining. To address these problems, we propose to find a strong lottery ticket\nvia moment-matching scores. Our experimental results show that the discovered\nsubnetwork can perform similarly or better than the trained dense model even\nwhen only 10% of the weights remain. To the best of our knowledge, we are the\nfirst to show the existence of strong lottery tickets in generative models and\nprovide an algorithm to find it stably. Our code and supplementary materials\nare publicly available.\n","authors":["Sangyeop Yeo","Yoojin Jang","Jy-yong Sohn","Dongyoon Han","Jaejun Yoo"],"pdf_url":"https://arxiv.org/pdf/2212.08311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12268v2","updated":"2022-12-16T06:43:23Z","published":"2022-11-22T13:37:34Z","title":"Out-of-Candidate Rectification for Weakly Supervised Semantic\n  Segmentation","summary":"  Weakly supervised semantic segmentation is typically inspired by class\nactivation maps, which serve as pseudo masks with class-discriminative regions\nhighlighted. Although tremendous efforts have been made to recall precise and\ncomplete locations for each class, existing methods still commonly suffer from\nthe unsolicited Out-of-Candidate (OC) error predictions that not belongs to the\nlabel candidates, which could be avoidable since the contradiction with\nimage-level class tags is easy to be detected. In this paper, we develop a\ngroup ranking-based Out-of-Candidate Rectification (OCR) mechanism in a\nplug-and-play fashion. Firstly, we adaptively split the semantic categories\ninto In-Candidate (IC) and OC groups for each OC pixel according to their prior\nannotation correlation and posterior prediction correlation. Then, we derive a\ndifferentiable rectification loss to force OC pixels to shift to the IC group.\nIncorporating our OCR with seminal baselines (e.g., AffinityNet, SEAM,\nMCTformer), we can achieve remarkable performance gains on both Pascal VOC\n(+3.2%, +3.3%, +0.8% mIoU) and MS COCO (+1.0%, +1.3%, +0.5% mIoU) datasets with\nnegligible extra training overhead, which justifies the effectiveness and\ngenerality of our OCR.\n","authors":["Zesen Cheng","Pengchong Qiao","Kehan Li","Siheng Li","Pengxu Wei","Xiangyang Ji","Li Yuan","Chang Liu","Jie Chen"],"pdf_url":"https://arxiv.org/pdf/2211.12268v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12194v3","updated":"2022-12-16T06:41:05Z","published":"2022-07-25T13:33:53Z","title":"Domain Decorrelation with Potential Energy Ranking","summary":"  Machine learning systems, especially the methods based on deep learning,\nenjoy great success in modern computer vision tasks under experimental\nsettings. Generally, these classic deep learning methods are built on the\n\\emph{i.i.d.} assumption, supposing the training and test data are drawn from a\nsimilar distribution independently and identically. However, the aforementioned\n\\emph{i.i.d.} assumption is in general unavailable in the real-world scenario,\nand as a result, leads to sharp performance decay of deep learning algorithms.\nBehind this, domain shift is one of the primary factors to be blamed. In order\nto tackle this problem, we propose using \\textbf{Po}tential \\textbf{E}nergy\n\\textbf{R}anking (PoER) to decouple the object feature and the domain feature\n(\\emph{i.e.,} appearance feature) in given images, promoting the learning of\nlabel-discriminative features while filtering out the irrelevant correlations\nbetween the objects and the background. PoER helps the neural networks to\ncapture label-related features which contain the domain information first in\nshallow layers and then distills the label-discriminative representations out\nprogressively, enforcing the neural networks to be aware of the characteristic\nof objects and background which is vital to the generation of domain-invariant\nfeatures. PoER reports superior performance on domain generalization\nbenchmarks, improving the average top-1 accuracy by at least 1.20\\% compared to\nthe existing methods. Moreover, we use PoER in the ECCV 2022 NICO\nChallenge\\footnote{https://nicochallenge.com}, achieving top place with only a\nvanilla ResNet-18. The code has been made available at\nhttps://github.com/ForeverPs/PoER.\n","authors":["Sen Pei","Jiaxi Sun","Richard Yi Da Xu","Shiming Xiang","Gaofeng Meng"],"pdf_url":"https://arxiv.org/pdf/2207.12194v3.pdf","comment":"2022 ECCV jury award, accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2209.05166v3","updated":"2022-12-16T06:30:21Z","published":"2022-09-12T11:51:08Z","title":"Global Prototype Encoding for Incremental Video Highlights Detection","summary":"  Video highlights detection has been long researched as a topic in computer\nvision tasks, digging the user-appealing clips out given unexposed raw video\ninputs. However, in most case, the mainstream methods in this line of research\nare built on the closed world assumption, where a fixed number of highlight\ncategories is defined properly in advance and need all training data to be\navailable at the same time, and as a result, leads to poor scalability with\nrespect to both the highlight categories and the size of the dataset. To tackle\nthe problem mentioned above, we propose a video highlights detector that is\nable to learn incrementally, namely \\textbf{G}lobal \\textbf{P}rototype\n\\textbf{E}ncoding (GPE), capturing newly defined video highlights in the\nextended dataset via their corresponding prototypes. Alongside, we present a\nwell annotated and costly dataset termed \\emph{ByteFood}, including more than\n5.1k gourmet videos belongs to four different domains which are \\emph{cooking},\n\\emph{eating}, \\emph{food material}, and \\emph{presentation} respectively. To\nthe best of our knowledge, this is the first time the incremental learning\nsettings are introduced to video highlights detection, which in turn relieves\nthe burden of training video inputs and promotes the scalability of\nconventional neural networks in proportion to both the size of the dataset and\nthe quantity of domains. Moreover, the proposed GPE surpasses current\nincremental learning methods on \\emph{ByteFood}, reporting an improvement of\n1.57\\% mAP at least. The code and dataset will be made available sooner.\n","authors":["Sen Pei","Shixiong Xu","Ye Yuan","Jiashi Feng","Xiaohui Shen","Xiaojie Jin"],"pdf_url":"https://arxiv.org/pdf/2209.05166v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08296v1","updated":"2022-12-16T06:23:58Z","published":"2022-12-16T06:23:58Z","title":"DQnet: Cross-Model Detail Querying for Camouflaged Object Detection","summary":"  Camouflaged objects are seamlessly blended in with their surroundings, which\nbrings a challenging detection task in computer vision. Optimizing a\nconvolutional neural network (CNN) for camouflaged object detection (COD) tends\nto activate local discriminative regions while ignoring complete object extent,\ncausing the partial activation issue which inevitably leads to missing or\nredundant regions of objects. In this paper, we argue that partial activation\nis caused by the intrinsic characteristics of CNN, where the convolution\noperations produce local receptive fields and experience difficulty to capture\nlong-range feature dependency among image regions. In order to obtain feature\nmaps that could activate full object extent, keeping the segmental results from\nbeing overwhelmed by noisy features, a novel framework termed Cross-Model\nDetail Querying network (DQnet) is proposed. It reasons the relations between\nlong-range-aware representations and multi-scale local details to make the\nenhanced representation fully highlight the object regions and eliminate noise\non non-object regions. Specifically, a vanilla ViT pretrained with\nself-supervised learning (SSL) is employed to model long-range dependencies\namong image regions. A ResNet is employed to enable learning fine-grained\nspatial local details in multiple scales. Then, to effectively retrieve\nobject-related details, a Relation-Based Querying (RBQ) module is proposed to\nexplore window-based interactions between the global representations and the\nmulti-scale local details. Extensive experiments are conducted on the widely\nused COD datasets and show that our DQnet outperforms the current\nstate-of-the-arts.\n","authors":["Wei Sun","Chengao Liu","Linyan Zhang","Yu Li","Pengxu Wei","Chang Liu","Jialing Zou","Jianbin Jiao","Qixiang Ye"],"pdf_url":"https://arxiv.org/pdf/2212.08296v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08290v1","updated":"2022-12-16T05:51:52Z","published":"2022-12-16T05:51:52Z","title":"Robust Learning Protocol for Federated Tumor Segmentation Challenge","summary":"  In this work, we devise robust and efficient learning protocols for\norchestrating a Federated Learning (FL) process for the Federated Tumor\nSegmentation Challenge (FeTS 2022). Enabling FL for FeTS setup is challenging\nmainly due to data heterogeneity among collaborators and communication cost of\ntraining. To tackle these challenges, we propose Robust Learning Protocol\n(RoLePRO) which is a combination of server-side adaptive optimisation (e.g.,\nserver-side Adam) and judicious parameter (weights) aggregation schemes (e.g.,\nadaptive weighted aggregation). RoLePRO takes a two-phase approach, where the\nfirst phase consists of vanilla Federated Averaging, while the second phase\nconsists of a judicious aggregation scheme that uses a sophisticated\nreweighting, all in the presence of an adaptive optimisation algorithm at the\nserver. We draw insights from extensive experimentation to tune learning rates\nfor the two phases.\n","authors":["Ambrish Rawat","Giulio Zizzo","Swanand Kadhe","Jonathan P. Epperlein","Stefano Braghin"],"pdf_url":"https://arxiv.org/pdf/2212.08290v1.pdf","comment":"14 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2212.08283v1","updated":"2022-12-16T05:10:09Z","published":"2022-12-16T05:10:09Z","title":"SceneGATE: Scene-Graph based co-Attention networks for TExt visual\n  question answering","summary":"  Most TextVQA approaches focus on the integration of objects, scene texts and\nquestion words by a simple transformer encoder. But this fails to capture the\nsemantic relations between different modalities. The paper proposes a Scene\nGraph based co-Attention Network (SceneGATE) for TextVQA, which reveals the\nsemantic relations among the objects, Optical Character Recognition (OCR)\ntokens and the question words. It is achieved by a TextVQA-based scene graph\nthat discovers the underlying semantics of an image. We created a\nguided-attention module to capture the intra-modal interplay between the\nlanguage and the vision as a guidance for inter-modal interactions. To make\nexplicit teaching of the relations between the two modalities, we proposed and\nintegrated two attention modules, namely a scene graph-based semantic\nrelation-aware attention and a positional relation-aware attention. We\nconducted extensive experiments on two benchmark datasets, Text-VQA and ST-VQA.\nIt is shown that our SceneGATE method outperformed existing ones because of the\nscene graph and its attention modules.\n","authors":["Siwen Luo","Feiqi Cao","Felipe Nunez","Zean Wen","Josiah Poon","Caren Han"],"pdf_url":"https://arxiv.org/pdf/2212.08283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08281v1","updated":"2022-12-16T05:08:52Z","published":"2022-12-16T05:08:52Z","title":"HGAN: Hierarchical Graph Alignment Network for Image-Text Retrieval","summary":"  Image-text retrieval (ITR) is a challenging task in the field of multimodal\ninformation processing due to the semantic gap between different modalities. In\nrecent years, researchers have made great progress in exploring the accurate\nalignment between image and text. However, existing works mainly focus on the\nfine-grained alignment between image regions and sentence fragments, which\nignores the guiding significance of context background information. Actually,\nintegrating the local fine-grained information and global context background\ninformation can provide more semantic clues for retrieval. In this paper, we\npropose a novel Hierarchical Graph Alignment Network (HGAN) for image-text\nretrieval. First, to capture the comprehensive multimodal features, we\nconstruct the feature graphs for the image and text modality respectively.\nThen, a multi-granularity shared space is established with a designed\nMulti-granularity Feature Aggregation and Rearrangement (MFAR) module, which\nenhances the semantic corresponding relations between the local and global\ninformation, and obtains more accurate feature representations for the image\nand text modalities. Finally, the ultimate image and text features are further\nrefined through three-level similarity functions to achieve the hierarchical\nalignment. To justify the proposed model, we perform extensive experiments on\nMS-COCO and Flickr30K datasets. Experimental results show that the proposed\nHGAN outperforms the state-of-the-art methods on both datasets, which\ndemonstrates the effectiveness and superiority of our model.\n","authors":["Jie Guo","Meiting Wang","Yan Zhou","Bin Song","Yuhao Chi","Wei Fan","Jianglong Chang"],"pdf_url":"https://arxiv.org/pdf/2212.08281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08279v1","updated":"2022-12-16T04:52:53Z","published":"2022-12-16T04:52:53Z","title":"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion\n  Behaviors in Social Deduction Games","summary":"  Persuasion modeling is a key building block for conversational agents.\nExisting works in this direction are limited to analyzing textual dialogue\ncorpus. We argue that visual signals also play an important role in\nunderstanding human persuasive behaviors. In this paper, we introduce the first\nmultimodal dataset for modeling persuasion behaviors. Our dataset includes 199\ndialogue transcriptions and videos captured in a multi-player social deduction\ngame setting, 26,647 utterance level annotations of persuasion strategy, and\ngame level annotations of deduction game outcomes. We provide extensive\nexperiments to show how dialogue context and visual signals benefit persuasion\nstrategy prediction. We also explore the generalization ability of language\nmodels for persuasion modeling and the role of persuasion strategies in\npredicting social deduction game outcomes. Our dataset, code, and models can be\nfound at https://persuasion-deductiongame.socialai-data.org.\n","authors":["Bolin Lai","Hongxin Zhang","Miao Liu","Aryan Pariani","Fiona Ryan","Wenqi Jia","Shirley Anugrah Hayati","James M. Rehg","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2212.08279v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2212.08277v1","updated":"2022-12-16T04:25:43Z","published":"2022-12-16T04:25:43Z","title":"Improving self-supervised representation learning via sequential\n  adversarial masking","summary":"  Recent methods in self-supervised learning have demonstrated that\nmasking-based pretext tasks extend beyond NLP, serving as useful pretraining\nobjectives in computer vision. However, existing approaches apply random or ad\nhoc masking strategies that limit the difficulty of the reconstruction task\nand, consequently, the strength of the learnt representations. We improve upon\ncurrent state-of-the-art work in learning adversarial masks by proposing a new\nframework that generates masks in a sequential fashion with different\nconstraints on the adversary. This leads to improvements in performance on\nvarious downstream tasks, such as classification on ImageNet100, STL10, and\nCIFAR10/100 and segmentation on Pascal VOC. Our results further demonstrate the\npromising capabilities of masking-based approaches for SSL in computer vision.\n","authors":["Dylan Sam","Min Bai","Tristan McKinney","Li Erran Li"],"pdf_url":"https://arxiv.org/pdf/2212.08277v1.pdf","comment":"9 pages, 2 figures, Presented at NeurIPS 2022 SSL: Theory and\n  Practice Workshop"},{"id":"http://arxiv.org/abs/2212.08273v1","updated":"2022-12-16T04:18:47Z","published":"2022-12-16T04:18:47Z","title":"Learning for Vehicle-to-Vehicle Cooperative Perception under Lossy\n  Communication","summary":"  Deep learning has been widely used in the perception (e.g., 3D object\ndetection) of intelligent vehicle driving. Due to the beneficial\nVehicle-to-Vehicle (V2V) communication, the deep learning based features from\nother agents can be shared to the ego vehicle so as to improve the perception\nof the ego vehicle. It is named as Cooperative Perception in the V2V research,\nwhose algorithms have been dramatically advanced recently. However, all the\nexisting cooperative perception algorithms assume the ideal V2V communication\nwithout considering the possible lossy shared features because of the Lossy\nCommunication (LC) which is common in the complex real-world driving scenarios.\nIn this paper, we first study the side effect (e.g., detection performance\ndrop) by the lossy communication in the V2V Cooperative Perception, and then we\npropose a novel intermediate LC-aware feature fusion method to relieve the side\neffect of lossy communication by a LC-aware Repair Network (LCRN) and enhance\nthe interaction between the ego vehicle and other vehicles by a specially\ndesigned V2V Attention Module (V2VAM) including intra-vehicle attention of ego\nvehicle and uncertainty-aware inter-vehicle attention. The extensive experiment\non the public cooperative perception dataset OPV2V (based on digital-twin CARLA\nsimulator) demonstrates that the proposed method is quite effective for the\ncooperative point cloud based 3D object detection under lossy V2V\ncommunication.\n","authors":["Jinlong Li","Runsheng Xu","Xinyu Liu","Jin Ma","Zicheng Chi","Jiaqi Ma","Hongkai Yu"],"pdf_url":"https://arxiv.org/pdf/2212.08273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.02062v2","updated":"2022-12-16T03:51:02Z","published":"2022-07-05T14:13:22Z","title":"Image Amodal Completion: A Survey","summary":"  Existing computer vision systems can compete with humans in understanding the\nvisible parts of objects, but still fall far short of humans when it comes to\ndepicting the invisible parts of partially occluded objects. Image amodal\ncompletion aims to equip computers with human-like amodal completion functions\nto understand an intact object despite it being partially occluded. The main\npurpose of this survey is to provide an intuitive understanding of the research\nhotspots, key technologies and future trends in the field of image amodal\ncompletion. Firstly, we present a comprehensive review of the latest literature\nin this emerging field, exploring three key tasks in image amodal completion,\nincluding amodal shape completion, amodal appearance completion, and order\nperception. Then we examine popular datasets related to image amodal completion\nalong with their common data collection methods and evaluation metrics.\nFinally, we discuss real-world applications and future research directions for\nimage amodal completion, facilitating the reader's understanding of the\nchallenges of existing technologies and upcoming research trends.\n","authors":["Jiayang Ao","Qiuhong Ke","Krista A. Ehinger"],"pdf_url":"https://arxiv.org/pdf/2207.02062v2.pdf","comment":"The manuscript is under consideration at Computer Vision and Image\n  Understanding"},{"id":"http://arxiv.org/abs/2212.08254v1","updated":"2022-12-16T02:52:37Z","published":"2022-12-16T02:52:37Z","title":"RepQ-ViT: Scale Reparameterization for Post-Training Quantization of\n  Vision Transformers","summary":"  Post-training quantization (PTQ), which only requires a tiny dataset for\ncalibration without end-to-end retraining, is a light and practical model\ncompression technique. Recently, several PTQ schemes for vision transformers\n(ViTs) have been presented; unfortunately, they typically suffer from\nnon-trivial accuracy degradation, especially in low-bit cases. In this paper,\nwe propose RepQ-ViT, a novel PTQ framework for ViTs based on quantization scale\nreparameterization, to address the above issues. RepQ-ViT decouples the\nquantization and inference processes, where the former employs complex\nquantizers and the latter employs scale-reparameterized simplified quantizers.\nThis ensures both accurate quantization and efficient inference, which\ndistinguishes it from existing approaches that sacrifice quantization\nperformance to meet the target hardware. More specifically, we focus on two\ncomponents with extreme distributions: post-LayerNorm activations with severe\ninter-channel variation and post-Softmax activations with power-law features,\nand initially apply channel-wise quantization and log$\\sqrt{2}$ quantization,\nrespectively. Then, we reparameterize the scales to hardware-friendly\nlayer-wise quantization and log2 quantization for inference, with only slight\naccuracy or computational costs. Extensive experiments are conducted on\nmultiple vision tasks with different model variants, proving that RepQ-ViT,\nwithout hyperparameters and expensive reconstruction procedures, can outperform\nexisting strong baselines and encouragingly improve the accuracy of 4-bit PTQ\nof ViTs to a usable level.\n","authors":["Zhikai Li","Junrui Xiao","Lianwei Yang","Qingyi Gu"],"pdf_url":"https://arxiv.org/pdf/2212.08254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08251v1","updated":"2022-12-16T02:43:52Z","published":"2022-12-16T02:43:52Z","title":"Robust Saliency Guidance for Data-free Class Incremental Learning","summary":"  Data-Free Class Incremental Learning (DFCIL) aims to sequentially learn tasks\nwith access only to data from the current one. DFCIL is of interest because it\nmitigates concerns about privacy and long-term storage of data, while at the\nsame time alleviating the problem of catastrophic forgetting in incremental\nlearning. In this work, we introduce robust saliency guidance for DFCIL and\npropose a new framework, which we call RObust Saliency Supervision (ROSS), for\nmitigating the negative effect of saliency drift. Firstly, we use a\nteacher-student architecture leveraging low-level tasks to supervise the model\nwith global saliency. We also apply boundary-guided saliency to protect it from\ndrifting across object boundaries at intermediate layers. Finally, we introduce\na module for injecting and recovering saliency noise to increase robustness of\nsaliency preservation. Our experiments demonstrate that our method can retain\nbetter saliency maps across tasks and achieve state-of-the-art results on the\nCIFAR-100, Tiny-ImageNet and ImageNet-Subset DFCIL benchmarks. Code will be\nmade publicly available.\n","authors":["Xialei Liu","Jiang-Tian Zhai","Andrew D. Bagdanov","Ke Li","Ming-Ming Cheng"],"pdf_url":"https://arxiv.org/pdf/2212.08251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08244v1","updated":"2022-12-16T02:23:50Z","published":"2022-12-16T02:23:50Z","title":"Offline Reinforcement Learning for Visual Navigation","summary":"  Reinforcement learning can enable robots to navigate to distant goals while\noptimizing user-specified reward functions, including preferences for following\nlanes, staying on paved paths, or avoiding freshly mowed grass. However, online\nlearning from trial-and-error for real-world robots is logistically\nchallenging, and methods that instead can utilize existing datasets of robotic\nnavigation data could be significantly more scalable and enable broader\ngeneralization. In this paper, we present ReViND, the first offline RL system\nfor robotic navigation that can leverage previously collected data to optimize\nuser-specified reward functions in the real-world. We evaluate our system for\noff-road navigation without any additional data collection or fine-tuning, and\nshow that it can navigate to distant goals using only offline training from\nthis dataset, and exhibit behaviors that qualitatively differ based on the\nuser-specified reward function.\n","authors":["Dhruv Shah","Arjun Bhorkar","Hrish Leen","Ilya Kostrikov","Nick Rhinehart","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2212.08244v1.pdf","comment":"Project page https://sites.google.com/view/revind/home"},{"id":"http://arxiv.org/abs/2212.08228v1","updated":"2022-12-16T01:35:27Z","published":"2022-12-16T01:35:27Z","title":"SADM: Sequence-Aware Diffusion Model for Longitudinal Medical Image\n  Generation","summary":"  Human organs constantly undergo anatomical changes due to a complex mix of\nshort-term (e.g., heartbeat) and long-term (e.g., aging) factors. Evidently,\nprior knowledge of these factors will be beneficial when modeling their future\nstate, i.e., via image generation. However, most of the medical image\ngeneration tasks only rely on the input from a single image, thus ignoring the\nsequential dependency even when longitudinal data is available. Sequence-aware\ndeep generative models, where model input is a sequence of ordered and\ntimestamped images, are still underexplored in the medical imaging domain that\nis featured by several unique challenges: 1) Sequences with various lengths; 2)\nMissing data or frame, and 3) High dimensionality. To this end, we propose a\nsequence-aware diffusion model (SADM) for the generation of longitudinal\nmedical images. Recently, diffusion models have shown promising results on\nhigh-fidelity image generation. Our method extends this new technique by\nintroducing a sequence-aware transformer as the conditional module in a\ndiffusion model. The novel design enables learning longitudinal dependency even\nwith missing data during training and allows autoregressive generation of a\nsequence of images during inference. Our extensive experiments on 3D\nlongitudinal medical images demonstrate the effectiveness of SADM compared with\nbaselines and alternative methods.\n","authors":["Jee Seok Yoon","Chenghao Zhang","Heung-Il Suk","Jia Guo","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2212.08228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14670v3","updated":"2022-12-16T01:23:13Z","published":"2022-10-26T12:47:29Z","title":"Boosting Semi-Supervised Semantic Segmentation with Probabilistic\n  Representations","summary":"  Recent breakthroughs in semi-supervised semantic segmentation have been\ndeveloped through contrastive learning. In prevalent pixel-wise contrastive\nlearning solutions, the model maps pixels to deterministic representations and\nregularizes them in the latent space. However, there exist inaccurate\npseudo-labels which map the ambiguous representations of pixels to the wrong\nclasses due to the limited cognitive ability of the model. In this paper, we\ndefine pixel-wise representations from a new perspective of probability theory\nand propose a Probabilistic Representation Contrastive Learning (PRCL)\nframework that improves representation quality by taking its probability into\nconsideration. Through modelling the mapping from pixels to representations as\nthe probability via multivariate Gaussian distributions, we can tune the\ncontribution of the ambiguous representations to tolerate the risk of\ninaccurate pseudo-labels. Furthermore, we define prototypes in the form of\ndistributions, which indicates the confidence of a class, while the point\nprototype cannot. Moreover, we propose to regularize the distribution variance\nto enhance the reliability of representations. Taking advantage of these\nbenefits, high-quality feature representations can be derived in the latent\nspace, thereby the performance of semantic segmentation can be further\nimproved. We conduct sufficient experiment to evaluate PRCL on Pascal VOC and\nCityScapes to demonstrate its superiority. The code is available at\nhttps://github.com/Haoyu-Xie/PRCL.\n","authors":["Haoyu Xie","Changqi Wang","Mingkai Zheng","Minjing Dong","Shan You","Chong Fu","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2210.14670v3.pdf","comment":"Accepted to AAAI 2023"},{"id":"http://arxiv.org/abs/2212.08208v1","updated":"2022-12-16T00:32:38Z","published":"2022-12-16T00:32:38Z","title":"Location-aware Adaptive Denormalization: A Deep Learning Approach For\n  Wildfire Danger Forecasting","summary":"  Climate change is expected to intensify and increase extreme events in the\nweather cycle. Since this has a significant impact on various sectors of our\nlife, recent works are concerned with identifying and predicting such extreme\nevents from Earth observations. This paper proposes a 2D/3D two-branch\nconvolutional neural network (CNN) for wildfire danger forecasting. To use a\nunified framework, previous approaches duplicate static variables along the\ntime dimension and neglect the intrinsic differences between static and dynamic\nvariables. Furthermore, most existing multi-branch architectures lose the\ninterconnections between the branches during the feature learning stage. To\naddress these issues, we propose a two-branch architecture with a\nLocation-aware Adaptive Denormalization layer (LOADE). Using LOADE as a\nbuilding block, we can modulate the dynamic features conditional on their\ngeographical location. Thus, our approach considers feature properties as a\nunified yet compound 2D/3D model. Besides, we propose using an absolute\ntemporal encoding for time-related forecasting problems. Our experimental\nresults show a better performance of our approach than other baselines on the\nchallenging FireCube dataset.\n","authors":["Mohamad Hakam Shams Eddin","Ribana Roscher","Juergen Gall"],"pdf_url":"https://arxiv.org/pdf/2212.08208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.02879v2","updated":"2022-12-16T00:31:44Z","published":"2022-08-04T20:31:46Z","title":"PointConvFormer: Revenge of the Point-based Convolution","summary":"  We introduce PointConvFormer, a novel building block for point cloud based\ndeep network architectures. Inspired by generalization theory, PointConvFormer\ncombines ideas from point convolution, where filter weights are only based on\nrelative position, and Transformers which utilize feature-based attention. In\nPointConvFormer, attention computed from feature difference between neighboring\npoints is used to modify the convolutional weights at each point. Hence,\ninvariances from point convolution are preserved, whereas attention helps to\nselect relevant points in the neighborhood. PointConvFormer is suitable for\nmultiple tasks that require details at the point level, such as segmentation\nand scene flow estimation tasks. We experiment on both tasks with multiple\ndatasets including ScanNet, SemanticKitti, FlyingThings3D and KITTI. Our\nresults show that PointConvFormer substantially outperforms classic\nconvolutions, regular transformers, and voxelized sparse convolution approaches\nwith much smaller and faster networks. Visualizations show that PointConvFormer\nperforms similarly to convolution on flat areas, whereas the neighborhood\nselection effect is stronger on object boundaries, showing that it has got the\nbest of both worlds.\n","authors":["Wenxuan Wu","Qi Shan","Li Fuxin"],"pdf_url":"https://arxiv.org/pdf/2208.02879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.06997v4","updated":"2022-12-16T00:14:00Z","published":"2022-02-14T19:29:08Z","title":"Cross-Modality Neuroimage Synthesis: A Survey","summary":"  The existence of completely aligned and paired multi-modal neuroimaging data\nhas proved its effectiveness in diagnosis of brain diseases. However,\ncollecting the full set of well-aligned and paired data is expensive or even\nimpractical, since the practical difficulties may include high cost, long time\nacquisition, image corruption, and privacy issues. A realistic solution is to\nexplore either an unsupervised learning or a semi-supervised learning to\nsynthesize the absent neuroimaging data. In this paper, we are the first one to\ncomprehensively approach cross-modality neuroimage synthesis task from\ndifferent perspectives, which include the level of the supervision (especially\nfor weakly-supervised and unsupervised), loss function, evaluation metrics, the\nrange of modality synthesis, datasets (aligned, private and public) and the\nsynthesis-based downstream tasks. To begin with, we highlight several opening\nchallenges for cross-modality neuroimage sysnthesis. Then we summarize the\narchitecture of cross-modality synthesis under various of supervision level. In\naddition, we provide in-depth analysis of how cross-modality neuroimage\nsynthesis can improve the performance of different downstream tasks. Finally,\nwe re-evaluate the open challenges and point out the future directions for the\nremaining challenges. All resources are available at\nhttps://github.com/M-3LAB/awesome-multimodal-brain-image-systhesis\n","authors":["Guoyang Xie","Jinbao Wang","Yawen Huang","Jiayi Lyu","Feng Zheng","Yefeng Zheng","Yaochu Jin"],"pdf_url":"https://arxiv.org/pdf/2202.06997v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08751v1","updated":"2022-12-16T23:22:59Z","published":"2022-12-16T23:22:59Z","title":"Point-E: A System for Generating 3D Point Clouds from Complex Prompts","summary":"  While recent work on text-conditional 3D object generation has shown\npromising results, the state-of-the-art methods typically require multiple\nGPU-hours to produce a single sample. This is in stark contrast to\nstate-of-the-art generative image models, which produce samples in a number of\nseconds or minutes. In this paper, we explore an alternative method for 3D\nobject generation which produces 3D models in only 1-2 minutes on a single GPU.\nOur method first generates a single synthetic view using a text-to-image\ndiffusion model, and then produces a 3D point cloud using a second diffusion\nmodel which conditions on the generated image. While our method still falls\nshort of the state-of-the-art in terms of sample quality, it is one to two\norders of magnitude faster to sample from, offering a practical trade-off for\nsome use cases. We release our pre-trained point cloud diffusion models, as\nwell as evaluation code and models, at https://github.com/openai/point-e.\n","authors":["Alex Nichol","Heewoo Jun","Prafulla Dhariwal","Pamela Mishkin","Mark Chen"],"pdf_url":"https://arxiv.org/pdf/2212.08751v1.pdf","comment":"8 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.08749v1","updated":"2022-12-16T23:19:44Z","published":"2022-12-16T23:19:44Z","title":"Analysis and application of multispectral data for water segmentation\n  using machine learning","summary":"  Monitoring water is a complex task due to its dynamic nature, added\npollutants, and land build-up. The availability of high-resolu-tion data by\nSentinel-2 multispectral products makes implementing remote sensing\napplications feasible. However, overutilizing or underutilizing multispectral\nbands of the product can lead to inferior performance. In this work, we compare\nthe performances of ten out of the thirteen bands available in a Sentinel-2\nproduct for water segmentation using eight machine learning algorithms. We find\nthat the shortwave infrared bands (B11 and B12) are the most superior for\nsegmenting water bodies. B11 achieves an overall accuracy of $71\\%$ while B12\nachieves $69\\%$ across all algorithms on the test site. We also find that the\nSupport Vector Machine (SVM) algorithm is the most favourable for single-band\nwater segmentation. The SVM achieves an overall accuracy of $69\\%$ across the\ntested bands over the given test site. Finally, to demonstrate the\neffectiveness of choosing the right amount of data, we use only B11 reflectance\ndata to train an artificial neural network, BandNet. Even with a basic\narchitecture, BandNet is proportionate to known architectures for semantic and\nwater segmentation, achieving a $92.47$ mIOU on the test site. BandNet requires\nonly a fraction of the time and resources to train and run inference, making it\nsuitable to be deployed on web applications to run and monitor water bodies in\nlocalized regions. Our codebase is available at\nhttps://github.com/IamShubhamGupto/BandNet.\n","authors":["Shubham Gupta","Uma D.","Ramachandra Hebbar"],"pdf_url":"https://arxiv.org/pdf/2212.08749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08740v1","updated":"2022-12-16T22:29:21Z","published":"2022-12-16T22:29:21Z","title":"Lateral Strain Imaging using Self-supervised and Physically Inspired\n  Constraints in Unsupervised Regularized Elastography","summary":"  Convolutional Neural Networks (CNN) have shown promising results for\ndisplacement estimation in UltraSound Elastography (USE). Many modifications\nhave been proposed to improve the displacement estimation of CNNs for USE in\nthe axial direction. However, the lateral strain, which is essential in several\ndownstream tasks such as the inverse problem of elasticity imaging, remains a\nchallenge. The lateral strain estimation is complicated since the motion and\nthe sampling frequency in this direction are substantially lower than the axial\none, and a lack of carrier signal in this direction. In computer vision\napplications, the axial and the lateral motions are independent. In contrast,\nthe tissue motion pattern in USE is governed by laws of physics which link the\naxial and lateral displacements. In this paper, inspired by Hooke's law, we\nfirst propose Physically Inspired ConsTraint for Unsupervised Regularized\nElastography (PICTURE), where we impose a constraint on the Effective Poisson's\nratio (EPR) to improve the lateral strain estimation. In the next step, we\npropose self-supervised PICTURE (sPICTURE) to further enhance the strain image\nestimation. Extensive experiments on simulation, experimental phantom and in\nvivo data demonstrate that the proposed methods estimate accurate axial and\nlateral strain maps.\n","authors":["Ali K. Z. Tehrani","Md Ashikuzzaman","Hassan Rivaz"],"pdf_url":"https://arxiv.org/pdf/2212.08740v1.pdf","comment":"Accepted in IEEE Transactions on Medical Imaging (TMI)"},{"id":"http://arxiv.org/abs/2212.08733v1","updated":"2022-12-16T22:05:38Z","published":"2022-12-16T22:05:38Z","title":"Counterfactual Explanations for Misclassified Images: How Human and\n  Machine Explanations Differ","summary":"  Counterfactual explanations have emerged as a popular solution for the\neXplainable AI (XAI) problem of elucidating the predictions of black-box\ndeep-learning systems due to their psychological validity, flexibility across\nproblem domains and proposed legal compliance. While over 100 counterfactual\nmethods exist, claiming to generate plausible explanations akin to those\npreferred by people, few have actually been tested on users ($\\sim7\\%$). So,\nthe psychological validity of these counterfactual algorithms for effective XAI\nfor image data is not established. This issue is addressed here using a novel\nmethodology that (i) gathers ground truth human-generated counterfactual\nexplanations for misclassified images, in two user studies and, then, (ii)\ncompares these human-generated ground-truth explanations to\ncomputationally-generated explanations for the same misclassifications. Results\nindicate that humans do not \"minimally edit\" images when generating\ncounterfactual explanations. Instead, they make larger, \"meaningful\" edits that\nbetter approximate prototypes in the counterfactual class.\n","authors":["Eoin Delaney","Arjun Pakrashi","Derek Greene","Mark T. Keane"],"pdf_url":"https://arxiv.org/pdf/2212.08733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08731v1","updated":"2022-12-16T22:03:37Z","published":"2022-12-16T22:03:37Z","title":"Multi-person 3D pose estimation from unlabelled data","summary":"  Its numerous applications make multi-human 3D pose estimation a remarkably\nimpactful area of research. Nevertheless, assuming a multiple-view system\ncomposed of several regular RGB cameras, 3D multi-pose estimation presents\nseveral challenges. First of all, each person must be uniquely identified in\nthe different views to separate the 2D information provided by the cameras.\nSecondly, the 3D pose estimation process from the multi-view 2D information of\neach person must be robust against noise and potential occlusions in the\nscenario. In this work, we address these two challenges with the help of deep\nlearning. Specifically, we present a model based on Graph Neural Networks\ncapable of predicting the cross-view correspondence of the people in the\nscenario along with a Multilayer Perceptron that takes the 2D points to yield\nthe 3D poses of each person. These two models are trained in a self-supervised\nmanner, thus avoiding the need for large datasets with 3D annotations.\n","authors":["Daniel Rodriguez-Criado","Pilar Bachiller","George Vogiatzis","Luis J. Manso"],"pdf_url":"https://arxiv.org/pdf/2212.08731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08729v1","updated":"2022-12-16T21:51:51Z","published":"2022-12-16T21:51:51Z","title":"Distribution-aware Goal Prediction and Conformant Model-based Planning\n  for Safe Autonomous Driving","summary":"  The feasibility of collecting a large amount of expert demonstrations has\ninspired growing research interests in learning-to-drive settings, where models\nlearn by imitating the driving behaviour from experts. However, exclusively\nrelying on imitation can limit agents' generalisability to novel scenarios that\nare outside the support of the training data. In this paper, we address this\nchallenge by factorising the driving task, based on the intuition that modular\narchitectures are more generalisable and more robust to changes in the\nenvironment compared to monolithic, end-to-end frameworks. Specifically, we\ndraw inspiration from the trajectory forecasting community and reformulate the\nlearning-to-drive task as obstacle-aware perception and grounding,\ndistribution-aware goal prediction, and model-based planning. Firstly, we train\nthe obstacle-aware perception module to extract salient representation of the\nvisual context. Then, we learn a multi-modal goal distribution by performing\nconditional density-estimation using normalising flow. Finally, we ground\ncandidate trajectory predictions road geometry, and plan the actions based on\non vehicle dynamics. Under the CARLA simulator, we report state-of-the-art\nresults on the CARNOVEL benchmark.\n","authors":["Jonathan Francis","Bingqing Chen","Weiran Yao","Eric Nyberg","Jean Oh"],"pdf_url":"https://arxiv.org/pdf/2212.08729v1.pdf","comment":"Accepted: 1st Workshop on Safe Learning for Autonomous Driving, at\n  the International Conference on Machine Learning (ICML 2022); Best Paper\n  Award"},{"id":"http://arxiv.org/abs/2206.05398v2","updated":"2022-12-16T21:20:30Z","published":"2022-06-11T02:15:46Z","title":"E2PN: Efficient SE(3)-Equivariant Point Network","summary":"  This paper proposes a convolution structure for learning SE(3)-equivariant\nfeatures from 3D point clouds. It can be viewed as an equivariant version of\nkernel point convolutions (KPConv), a widely used convolution form to process\npoint cloud data. Compared with existing equivariant networks, our design is\nsimple, lightweight, fast, and easy to be integrated with existing\ntask-specific point cloud learning pipelines. We achieve these desirable\nproperties by combining group convolutions and quotient representations. More\nspecifically, we discretize SO(3) to finite groups for their simplicity while\nusing SO(2) as the stabilizer subgroup to form spherical quotient feature\nfields to save computations. We also propose a permutation layer to recover\nSO(3) features from spherical features to preserve the capacity to distinguish\nrotations. Experiments show that our method achieves comparable or superior\nperformance in various tasks while consuming much less memory and running\nfaster than existing work. The proposed method can foster the adoption of\nequivariant feature learning in practical applications based on point clouds\nand inspire future developments of equivariant feature learning for real-world\napplications.\n","authors":["Minghan Zhu","Maani Ghaffari","William A. Clark","Huei Peng"],"pdf_url":"https://arxiv.org/pdf/2206.05398v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11801v3","updated":"2022-12-16T20:15:53Z","published":"2022-11-21T19:09:52Z","title":"Self-Supervised Pre-training of 3D Point Cloud Networks with Image Data","summary":"  Reducing the quantity of annotations required for supervised training is\nvital when labels are scarce and costly. This reduction is especially important\nfor semantic segmentation tasks involving 3D datasets that are often\nsignificantly smaller and more challenging to annotate than their image-based\ncounterparts. Self-supervised pre-training on large unlabelled datasets is one\nway to reduce the amount of manual annotations needed. Previous work has\nfocused on pre-training with point cloud data exclusively; this approach often\nrequires two or more registered views. In the present work, we combine image\nand point cloud modalities, by first learning self-supervised image features\nand then using these features to train a 3D model. By incorporating image data,\nwhich is often included in many 3D datasets, our pre-training method only\nrequires a single scan of a scene. We demonstrate that our pre-training\napproach, despite using single scans, achieves comparable performance to other\nmulti-scan, point cloud-only methods.\n","authors":["Andrej Janda","Brandon Wagstaff","Edwin G. Ng","Jonathan Kelly"],"pdf_url":"https://arxiv.org/pdf/2211.11801v3.pdf","comment":"In Proceedings of the Conference on Robot Learning (CoRL'22) Workshop\n  on Pre-Training Robot Learning, Auckland, New Zealand, December 15, 2022"},{"id":"http://arxiv.org/abs/2212.08698v1","updated":"2022-12-16T19:58:52Z","published":"2022-12-16T19:58:52Z","title":"Uncovering the Disentanglement Capability in Text-to-Image Diffusion\n  Models","summary":"  Generative models have been widely studied in computer vision. Recently,\ndiffusion models have drawn substantial attention due to the high quality of\ntheir generated images. A key desired property of image generative models is\nthe ability to disentangle different attributes, which should enable\nmodification towards a style without changing the semantic content, and the\nmodification parameters should generalize to different images. Previous studies\nhave found that generative adversarial networks (GANs) are inherently endowed\nwith such disentanglement capability, so they can perform disentangled image\nediting without re-training or fine-tuning the network. In this work, we\nexplore whether diffusion models are also inherently equipped with such a\ncapability. Our finding is that for stable diffusion models, by partially\nchanging the input text embedding from a neutral description (e.g., \"a photo of\nperson\") to one with style (e.g., \"a photo of person with smile\") while fixing\nall the Gaussian random noises introduced during the denoising process, the\ngenerated images can be modified towards the target style without changing the\nsemantic content. Based on this finding, we further propose a simple,\nlight-weight image editing algorithm where the mixing weights of the two text\nembeddings are optimized for style matching and content preservation. This\nentire process only involves optimizing over around 50 parameters and does not\nfine-tune the diffusion model itself. Experiments show that the proposed method\ncan modify a wide range of attributes, with the performance outperforming\ndiffusion-model-based image-editing algorithms that require fine-tuning. The\noptimized weights generalize well to different images. Our code is publicly\navailable at https://github.com/UCSB-NLP-Chang/DiffusionDisentanglement.\n","authors":["Qiucheng Wu","Yujian Liu","Handong Zhao","Ajinkya Kale","Trung Bui","Tong Yu","Zhe Lin","Yang Zhang","Shiyu Chang"],"pdf_url":"https://arxiv.org/pdf/2212.08698v1.pdf","comment":"23 pages, 18 figures"},{"id":"http://arxiv.org/abs/2112.00933v3","updated":"2022-12-16T19:18:33Z","published":"2021-12-02T02:12:03Z","title":"PartImageNet: A Large, High-Quality Dataset of Parts","summary":"  It is natural to represent objects in terms of their parts. This has the\npotential to improve the performance of algorithms for object recognition and\nsegmentation but can also help for downstream tasks like activity recognition.\nResearch on part-based models, however, is hindered by the lack of datasets\nwith per-pixel part annotations. This is partly due to the difficulty and high\ncost of annotating object parts so it has rarely been done except for humans\n(where there exists a big literature on part-based models). To help address\nthis problem, we propose PartImageNet, a large, high-quality dataset with part\nsegmentation annotations. It consists of $158$ classes from ImageNet with\napproximately $24,000$ images. PartImageNet is unique because it offers\npart-level annotations on a general set of classes including non-rigid,\narticulated objects, while having an order of magnitude larger size compared to\nexisting part datasets (excluding datasets of humans). It can be utilized for\nmany vision tasks including Object Segmentation, Semantic Part Segmentation,\nFew-shot Learning and Part Discovery. We conduct comprehensive experiments\nwhich study these tasks and set up a set of baselines. The dataset and scripts\nare released at https://github.com/TACJu/PartImageNet.\n","authors":["Ju He","Shuo Yang","Shaokang Yang","Adam Kortylewski","Xiaoding Yuan","Jie-Neng Chen","Shuai Liu","Cheng Yang","Qihang Yu","Alan Yuille"],"pdf_url":"https://arxiv.org/pdf/2112.00933v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.05529v2","updated":"2022-12-16T19:07:45Z","published":"2021-03-09T16:15:47Z","title":"Deep and Statistical Learning in Biomedical Imaging: State of the Art in\n  3D MRI Brain Tumor Segmentation","summary":"  Clinical diagnostic and treatment decisions rely upon the integration of\npatient-specific data with clinical reasoning. Cancer presents a unique context\nthat influence treatment decisions, given its diverse forms of disease\nevolution. Biomedical imaging allows noninvasive assessment of disease based on\nvisual evaluations leading to better clinical outcome prediction and\ntherapeutic planning. Early methods of brain cancer characterization\npredominantly relied upon statistical modeling of neuroimaging data. Driven by\nthe breakthroughs in computer vision, deep learning became the de facto\nstandard in the domain of medical imaging. Integrated statistical and deep\nlearning methods have recently emerged as a new direction in the automation of\nthe medical practice unifying multi-disciplinary knowledge in medicine,\nstatistics, and artificial intelligence. In this study, we critically review\nmajor statistical and deep learning models and their applications in brain\nimaging research with a focus on MRI-based brain tumor segmentation. The\nresults do highlight that model-driven classical statistics and data-driven\ndeep learning is a potent combination for developing automated systems in\nclinical oncology.\n","authors":["K. Ruwani M. Fernando","Chris P. Tsokos"],"pdf_url":"https://arxiv.org/pdf/2103.05529v2.pdf","comment":"21 pages, 7 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.08262v1","updated":"2022-12-16T03:13:43Z","published":"2022-12-16T03:13:43Z","title":"Uniform Sequence Better: Time Interval Aware Data Augmentation for\n  Sequential Recommendation","summary":"  Sequential recommendation is an important task to predict the next-item to\naccess based on a sequence of interacted items. Most existing works learn user\npreference as the transition pattern from the previous item to the next one,\nignoring the time interval between these two items. However, we observe that\nthe time interval in a sequence may vary significantly different, and thus\nresult in the ineffectiveness of user modeling due to the issue of\n\\emph{preference drift}. In fact, we conducted an empirical study to validate\nthis observation, and found that a sequence with uniformly distributed time\ninterval (denoted as uniform sequence) is more beneficial for performance\nimprovement than that with greatly varying time interval. Therefore, we propose\nto augment sequence data from the perspective of time interval, which is not\nstudied in the literature. Specifically, we design five operators (Ti-Crop,\nTi-Reorder, Ti-Mask, Ti-Substitute, Ti-Insert) to transform the original\nnon-uniform sequence to uniform sequence with the consideration of variance of\ntime intervals. Then, we devise a control strategy to execute data augmentation\non item sequences in different lengths. Finally, we implement these\nimprovements on a state-of-the-art model CoSeRec and validate our approach on\nfour real datasets. The experimental results show that our approach reaches\nsignificantly better performance than the other 11 competing methods. Our\nimplementation is available: https://github.com/KingGugu/TiCoSeRec.\n","authors":["Yizhou Dang","Enneng Yang","Guibing Guo","Linying Jiang","Xingwei Wang","Xiaoxiao Xu","Qinghui Sun","Hong Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08262v1.pdf","comment":"9 pages, 4 figures, AAAI-2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2209.00626v3","updated":"2022-12-16T18:50:31Z","published":"2022-08-30T02:12:47Z","title":"The alignment problem from a deep learning perspective","summary":"  Within the coming decades, artificial general intelligence (AGI) may surpass\nhuman capabilities at a wide range of important tasks. We outline a case for\nexpecting that, without substantial effort to prevent it, AGIs could learn to\npursue goals which are very undesirable (in other words, misaligned) from a\nhuman perspective. We argue that AGIs trained in similar ways as today's most\ncapable models could learn to act deceptively to receive higher reward; learn\ninternally-represented goals which generalize beyond their training\ndistributions; and pursue those goals using power-seeking strategies. We\noutline how the deployment of misaligned AGIs might irreversibly undermine\nhuman control over the world, and briefly review research directions aimed at\npreventing these problems.\n","authors":["Richard Ngo","Lawrence Chan","Sören Mindermann"],"pdf_url":"https://arxiv.org/pdf/2209.00626v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08648v1","updated":"2022-12-16T18:48:54Z","published":"2022-12-16T18:48:54Z","title":"Connecting Permutation Equivariant Neural Networks and Partition\n  Diagrams","summary":"  We show how the Schur-Weyl duality that exists between the partition algebra\nand the symmetric group results in a stronger theoretical foundation for\ncharacterising all of the possible permutation equivariant neural networks\nwhose layers are some tensor power of the permutation representation $M_n$ of\nthe symmetric group $S_n$. In doing so, we unify two separate bodies of\nliterature, and we correct some of the major results that are now widely quoted\nby the machine learning community. In particular, we find a basis of matrices\nfor the learnable, linear, permutation equivariant layer functions between such\ntensor power spaces in the standard basis of $M_n$ by using an elegant\ngraphical representation of a basis of set partitions for the partition algebra\nand its related vector spaces. Also, we show how we can calculate the number of\nweights that must appear in these layer functions by looking at certain paths\nthrough the McKay quiver for $M_n$. Finally, we describe how our approach\ngeneralises to the construction of neural networks that are equivariant to\nlocal symmetries.\n","authors":["Edward Pearce-Crump"],"pdf_url":"https://arxiv.org/pdf/2212.08648v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2212.08645v1","updated":"2022-12-16T18:39:32Z","published":"2022-12-16T18:39:32Z","title":"Efficient Conditionally Invariant Representation Learning","summary":"  We introduce the Conditional Independence Regression CovariancE (CIRCE), a\nmeasure of conditional independence for multivariate continuous-valued\nvariables. CIRCE applies as a regularizer in settings where we wish to learn\nneural features $\\varphi(X)$ of data $X$ to estimate a target $Y$, while being\nconditionally independent of a distractor $Z$ given $Y$. Both $Z$ and $Y$ are\nassumed to be continuous-valued but relatively low dimensional, whereas $X$ and\nits features may be complex and high dimensional. Relevant settings include\ndomain-invariant learning, fairness, and causal learning. The procedure\nrequires just a single ridge regression from $Y$ to kernelized features of $Z$,\nwhich can be done in advance. It is then only necessary to enforce independence\nof $\\varphi(X)$ from residuals of this regression, which is possible with\nattractive estimation properties and consistency guarantees. By contrast,\nearlier measures of conditional feature dependence require multiple regressions\nfor each step of feature learning, resulting in more severe bias and variance,\nand greater computational cost. When sufficiently rich features are used, we\nestablish that CIRCE is zero if and only if $\\varphi(X) \\perp \\!\\!\\! \\perp Z\n\\mid Y$. In experiments, we show superior performance to previous methods on\nchallenging benchmarks, including learning conditionally invariant image\nfeatures.\n","authors":["Roman Pogodin","Namrata Deka","Yazhe Li","Danica J. Sutherland","Victor Veitch","Arthur Gretton"],"pdf_url":"https://arxiv.org/pdf/2212.08645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07555v2","updated":"2022-12-16T18:39:09Z","published":"2022-12-14T23:59:24Z","title":"IMoS: Intent-Driven Full-Body Motion Synthesis for Human-Object\n  Interactions","summary":"  Can we make virtual characters in a scene interact with their surrounding\nobjects through simple instructions? Is it possible to synthesize such motion\nplausibly with a diverse set of objects and instructions? Inspired by these\nquestions, we present the first framework to synthesize the full-body motion of\nvirtual human characters performing specified actions with 3D objects placed\nwithin their reach. Our system takes as input textual instructions specifying\nthe objects and the associated intentions of the virtual characters and outputs\ndiverse sequences of full-body motions. This is in contrast to existing work,\nwhere full-body action synthesis methods generally do not consider object\ninteractions, and human-object interaction methods focus mainly on synthesizing\nhand or finger movements for grasping objects. We accomplish our objective by\ndesigning an intent-driven full-body motion generator, which uses a pair of\ndecoupled conditional variational autoencoders (CVAE) to learn the motion of\nthe body parts in an autoregressive manner. We also optimize for the positions\nof the objects with six degrees of freedom (6DoF) such that they plausibly fit\nwithin the hands of the synthesized characters. We compare our proposed method\nwith the existing methods of motion synthesis and establish a new and stronger\nstate-of-the-art for the task of intent-driven motion synthesis. Through a user\nstudy, we further show that our synthesized full-body motions appear more\nrealistic to the participants in more than 80% of scenarios compared to the\ncurrent state-of-the-art methods, and are perceived to be as good as the ground\ntruth on several occasions.\n","authors":["Anindita Ghosh","Rishabh Dabral","Vladislav Golyanik","Christian Theobalt","Philipp Slusallek"],"pdf_url":"https://arxiv.org/pdf/2212.07555v2.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2212.01688v2","updated":"2022-12-16T18:21:16Z","published":"2022-12-03T20:55:10Z","title":"LDL: A Defense for Label-Based Membership Inference Attacks","summary":"  The data used to train deep neural network (DNN) models in applications such\nas healthcare and finance typically contain sensitive information. A DNN model\nmay suffer from overfitting. Overfitted models have been shown to be\nsusceptible to query-based attacks such as membership inference attacks (MIAs).\nMIAs aim to determine whether a sample belongs to the dataset used to train a\nclassifier (members) or not (nonmembers). Recently, a new class of label based\nMIAs (LAB MIAs) was proposed, where an adversary was only required to have\nknowledge of predicted labels of samples. Developing a defense against an\nadversary carrying out a LAB MIA on DNN models that cannot be retrained remains\nan open problem. We present LDL, a light weight defense against LAB MIAs. LDL\nworks by constructing a high-dimensional sphere around queried samples such\nthat the model decision is unchanged for (noisy) variants of the sample within\nthe sphere. This sphere of label-invariance creates ambiguity and prevents a\nquerying adversary from correctly determining whether a sample is a member or a\nnonmember. We analytically characterize the success rate of an adversary\ncarrying out a LAB MIA when LDL is deployed, and show that the formulation is\nconsistent with experimental observations. We evaluate LDL on seven datasets --\nCIFAR-10, CIFAR-100, GTSRB, Face, Purchase, Location, and Texas -- with varying\nsizes of training data. All of these datasets have been used by SOTA LAB MIAs.\nOur experiments demonstrate that LDL reduces the success rate of an adversary\ncarrying out a LAB MIA in each case. We empirically compare LDL with defenses\nagainst LAB MIAs that require retraining of DNN models, and show that LDL\nperforms favorably despite not needing to retrain the DNNs.\n","authors":["Arezoo Rajabi","Dinuka Sahabandu","Luyao Niu","Bhaskar Ramasubramanian","Radha Poovendran"],"pdf_url":"https://arxiv.org/pdf/2212.01688v2.pdf","comment":"to appear in ACM ASIA Conference on Computer and Communications\n  Security (ACM ASIACCS 2023)"},{"id":"http://arxiv.org/abs/2212.05153v2","updated":"2022-12-16T18:18:59Z","published":"2022-12-10T00:18:05Z","title":"Algorithmic progress in computer vision","summary":"  We investigate algorithmic progress in image classification on ImageNet,\nperhaps the most well-known test bed for computer vision. We estimate a model,\ninformed by work on neural scaling laws, and infer a decomposition of progress\ninto the scaling of compute, data, and algorithms. Using Shapley values to\nattribute performance improvements, we find that algorithmic improvements have\nbeen roughly as important as the scaling of compute for progress computer\nvision. Our estimates indicate that algorithmic innovations mostly take the\nform of compute-augmenting algorithmic advances (which enable researchers to\nget better performance from less compute), not data-augmenting algorithmic\nadvances. We find that compute-augmenting algorithmic advances are made at a\npace more than twice as fast as the rate usually associated with Moore's law.\nIn particular, we estimate that compute-augmenting innovations halve compute\nrequirements every nine months (95\\% confidence interval: 4 to 25 months).\n","authors":["Ege Erdil","Tamay Besiroglu"],"pdf_url":"https://arxiv.org/pdf/2212.05153v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08630v1","updated":"2022-12-16T18:08:51Z","published":"2022-12-16T18:08:51Z","title":"Brauer's Group Equivariant Neural Networks","summary":"  We provide a full characterisation of all of the possible group equivariant\nneural networks whose layers are some tensor power of $\\mathbb{R}^{n}$ for\nthree symmetry groups that are missing from the machine learning literature:\n$O(n)$, the orthogonal group; $SO(n)$, the special orthogonal group; and\n$Sp(n)$, the symplectic group. In particular, we find a spanning set of\nmatrices for the learnable, linear, equivariant layer functions between such\ntensor power spaces in the standard basis of $\\mathbb{R}^{n}$ when the group is\n$O(n)$ or $SO(n)$, and in the symplectic basis of $\\mathbb{R}^{n}$ when the\ngroup is $Sp(n)$. The neural networks that we characterise are simple to\nimplement since our method circumvents the typical requirement when building\ngroup equivariant neural networks of having to decompose the tensor power\nspaces of $\\mathbb{R}^{n}$ into irreducible representations. We also describe\nhow our approach generalises to the construction of neural networks that are\nequivariant to local symmetries.\n  The theoretical background for our results comes from the Schur-Weyl\ndualities that were established by Brauer in his 1937 paper \"On Algebras Which\nare Connected with the Semisimple Continuous Groups\" for each of the three\ngroups in question. We suggest that Schur-Weyl duality is a powerful\nmathematical concept that could be used to understand the structure of neural\nnetworks that are equivariant to groups beyond those considered in this paper.\n","authors":["Edward Pearce-Crump"],"pdf_url":"https://arxiv.org/pdf/2212.08630v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2212.08624v1","updated":"2022-12-16T17:59:40Z","published":"2022-12-16T17:59:40Z","title":"Development of A Real-time POCUS Image Quality Assessment and\n  Acquisition Guidance System","summary":"  Point-of-care ultrasound (POCUS) is one of the most commonly applied tools\nfor cardiac function imaging in the clinical routine of the emergency\ndepartment and pediatric intensive care unit. The prior studies demonstrate\nthat AI-assisted software can guide nurses or novices without prior sonography\nexperience to acquire POCUS by recognizing the interest region, assessing image\nquality, and providing instructions. However, these AI algorithms cannot simply\nreplace the role of skilled sonographers in acquiring diagnostic-quality POCUS.\nUnlike chest X-ray, CT, and MRI, which have standardized imaging protocols,\nPOCUS can be acquired with high inter-observer variability. Though being with\nvariability, they are usually all clinically acceptable and interpretable. In\nchallenging clinical environments, sonographers employ novel heuristics to\nacquire POCUS in complex scenarios. To help novice learners to expedite the\ntraining process while reducing the dependency on experienced sonographers in\nthe curriculum implementation, We will develop a framework to perform real-time\nAI-assisted quality assessment and probe position guidance to provide training\nprocess for novice learners with less manual intervention.\n","authors":["Zhenge Jia","Yiyu Shi","Jingtong Hu","Lei Yang","Benjamin Nti"],"pdf_url":"https://arxiv.org/pdf/2212.08624v1.pdf","comment":"4 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2212.08620v1","updated":"2022-12-16T17:57:41Z","published":"2022-12-16T17:57:41Z","title":"POTATO: The Portable Text Annotation Tool","summary":"  We present POTATO, the Portable text annotation tool, a free, fully\nopen-sourced annotation system that 1) supports labeling many types of text and\nmultimodal data; 2) offers easy-to-configure features to maximize the\nproductivity of both deployers and annotators (convenient templates for common\nML/NLP tasks, active learning, keypress shortcuts, keyword highlights,\ntooltips); and 3) supports a high degree of customization (editable UI,\ninserting pre-screening questions, attention and qualification tests).\nExperiments over two annotation tasks suggest that POTATO improves labeling\nspeed through its specially-designed productivity features, especially for long\ndocuments and complex tasks. POTATO is available at\nhttps://github.com/davidjurgens/potato and will continue to be updated.\n","authors":["Jiaxin Pei","Aparna Ananthasubramaniam","Xingyao Wang","Naitian Zhou","Jackson Sargent","Apostolos Dedeloudis","David Jurgens"],"pdf_url":"https://arxiv.org/pdf/2212.08620v1.pdf","comment":"EMNLP 2022 DEMO"},{"id":"http://arxiv.org/abs/2212.08607v1","updated":"2022-12-16T17:36:23Z","published":"2022-12-16T17:36:23Z","title":"MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text\n  Generation","summary":"  Prompting large language models has enabled significant recent progress in\nmulti-step reasoning over text. However, when applied to text generation from\nsemi-structured data (e.g., graphs or tables), these methods typically suffer\nfrom low semantic coverage, hallucination, and logical inconsistency. We\npropose MURMUR, a neuro-symbolic modular approach to text generation from\nsemi-structured data with multi-step reasoning. MURMUR is a best-first search\nmethod that generates reasoning paths using: (1) neural and symbolic modules\nwith specific linguistic and logical skills, (2) a grammar whose production\nrules define valid compositions of modules, and (3) value functions that assess\nthe quality of each reasoning step. We conduct experiments on two diverse\ndata-to-text generation tasks like WebNLG and LogicNLG. These tasks differ in\ntheir data representations (graphs and tables) and span multiple linguistic and\nlogical skills. MURMUR obtains significant improvements over recent few-shot\nbaselines like direct prompting and chain-of-thought prompting, while also\nachieving comparable performance to fine-tuned GPT-2 on out-of-domain data.\nMoreover, human evaluation shows that MURMUR generates highly faithful and\ncorrect reasoning paths that lead to 26% more logically consistent summaries on\nLogicNLG, compared to direct prompting.\n","authors":["Swarnadeep Saha","Xinyan Velocity Yu","Mohit Bansal","Ramakanth Pasunuru","Asli Celikyilmaz"],"pdf_url":"https://arxiv.org/pdf/2212.08607v1.pdf","comment":"22 pages (9 figures, 18 tables)"},{"id":"http://arxiv.org/abs/2212.08604v1","updated":"2022-12-16T17:32:56Z","published":"2022-12-16T17:32:56Z","title":"Planning Visual-Tactile Precision Grasps via Complementary Use of Vision\n  and Touch","summary":"  Reliably planning fingertip grasps for multi-fingered hands lies as a key\nchallenge for many tasks including tool use, insertion, and dexterous in-hand\nmanipulation. This task becomes even more difficult when the robot lacks an\naccurate model of the object to be grasped. Tactile sensing offers a promising\napproach to account for uncertainties in object shape. However, current robotic\nhands tend to lack full tactile coverage. As such, a problem arises of how to\nplan and execute grasps for multi-fingered hands such that contact is made with\nthe area covered by the tactile sensors. To address this issue, we propose an\napproach to grasp planning that explicitly reasons about where the fingertips\nshould contact the estimated object surface while maximizing the probability of\ngrasp success. Key to our method's success is the use of visual surface\nestimation for initial planning to encode the contact constraint. The robot\nthen executes this plan using a tactile-feedback controller that enables the\nrobot to adapt to online estimates of the object's surface to correct for\nerrors in the initial plan. Importantly, the robot never explicitly integrates\nobject pose or surface estimates between visual and tactile sensing, instead it\nuses the two modalities in complementary ways. Vision guides the robots motion\nprior to contact; touch updates the plan when contact occurs differently than\npredicted from vision. We show that our method successfully synthesises and\nexecutes precision grasps for previously unseen objects using surface estimates\nfrom a single camera view. Further, our approach outperforms a state of the art\nmulti-fingered grasp planner, while also beating several baselines we propose.\n","authors":["Martin Matak","Tucker Hermans"],"pdf_url":"https://arxiv.org/pdf/2212.08604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12584v2","updated":"2022-12-16T17:08:46Z","published":"2022-01-29T13:13:57Z","title":"Convolutional Filtering in Simplicial Complexes","summary":"  This paper proposes convolutional filtering for data whose structure can be\nmodeled by a simplicial complex (SC). SCs are mathematical tools that not only\ncapture pairwise relationships as graphs but account also for higher-order\nnetwork structures. These filters are built by following the shift-and-sum\nprinciple of the convolution operation and rely on the Hodge-Laplacians to\nshift the signal within the simplex. But since in SCs we have also\ninter-simplex coupling, we use the incidence matrices to transfer the signal in\nadjacent simplices and build a filter bank to jointly filter signals from\ndifferent levels. We prove some interesting properties for the proposed filter\nbank, including permutation and orientation equivariance, a computational\ncomplexity that is linear in the SC dimension, and a spectral interpretation\nusing the simplicial Fourier transform. We illustrate the proposed approach\nwith numerical experiments.\n","authors":["Elvin Isufi","Maosheng Yang"],"pdf_url":"https://arxiv.org/pdf/2201.12584v2.pdf","comment":"5 pages, 2 figures, accepted in ICASSP 2022 (The first version has\n  some errors and we fixed them in the second version)"},{"id":"http://arxiv.org/abs/1910.02519v4","updated":"2022-12-16T17:01:59Z","published":"2019-10-06T20:34:52Z","title":"FIS-GAN: GAN with Flow-based Importance Sampling","summary":"  Generative Adversarial Networks (GAN) training process, in most cases, apply\nUniform or Gaussian sampling methods in the latent space, which probably spends\nmost of the computation on examples that can be properly handled and easy to\ngenerate. Theoretically, importance sampling speeds up stochastic optimization\nin supervised learning by prioritizing training examples. In this paper, we\nexplore the possibility of adapting importance sampling into adversarial\nlearning. We use importance sampling to replace Uniform and Gaussian sampling\nmethods in the latent space and employ normalizing flow to approximate latent\nspace posterior distribution by density estimation. Empirically, results on\nMNIST and Fashion-MNIST demonstrate that our method significantly accelerates\nGAN's optimization while retaining visual fidelity in generated samples.\n","authors":["Shiyu Yi","Donglin Zhan","Wenqing Zhang","Denglin Jiang","Kang An","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/1910.02519v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08578v1","updated":"2022-12-16T16:54:37Z","published":"2022-12-16T16:54:37Z","title":"Provable Fairness for Neural Network Models using Formal Verification","summary":"  Machine learning models are increasingly deployed for critical\ndecision-making tasks, making it important to verify that they do not contain\ngender or racial biases picked up from training data. Typical approaches to\nachieve fairness revolve around efforts to clean or curate training data, with\npost-hoc statistical evaluation of the fairness of the model on evaluation\ndata. In contrast, we propose techniques to \\emph{prove} fairness using\nrecently developed formal methods that verify properties of neural network\nmodels.Beyond the strength of guarantee implied by a formal proof, our methods\nhave the advantage that we do not need explicit training or evaluation data\n(which is often proprietary) in order to analyze a given trained model. In\nexperiments on two familiar datasets in the fairness literature (COMPAS and\nADULTS), we show that through proper training, we can reduce unfairness by an\naverage of 65.4\\% at a cost of less than 1\\% in AUC score.\n","authors":["Giorgian Borca-Tasciuc","Xingzhi Guo","Stanley Bak","Steven Skiena"],"pdf_url":"https://arxiv.org/pdf/2212.08578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08568v1","updated":"2022-12-16T16:44:46Z","published":"2022-12-16T16:44:46Z","title":"Biomedical image analysis competitions: The state of current\n  participation practice","summary":"  The number of international benchmarking competitions is steadily increasing\nin various fields of machine learning (ML) research and practice. So far,\nhowever, little is known about the common practice as well as bottlenecks faced\nby the community in tackling the research questions posed. To shed light on the\nstatus quo of algorithm development in the specific field of biomedical imaging\nanalysis, we designed an international survey that was issued to all\nparticipants of challenges conducted in conjunction with the IEEE ISBI 2021 and\nMICCAI 2021 conferences (80 competitions in total). The survey covered\nparticipants' expertise and working environments, their chosen strategies, as\nwell as algorithm characteristics. A median of 72% challenge participants took\npart in the survey. According to our results, knowledge exchange was the\nprimary incentive (70%) for participation, while the reception of prize money\nplayed only a minor role (16%). While a median of 80 working hours was spent on\nmethod development, a large portion of participants stated that they did not\nhave enough time for method development (32%). 25% perceived the infrastructure\nto be a bottleneck. Overall, 94% of all solutions were deep learning-based. Of\nthese, 84% were based on standard architectures. 43% of the respondents\nreported that the data samples (e.g., images) were too large to be processed at\nonce. This was most commonly addressed by patch-based training (69%),\ndownsampling (37%), and solving 3D analysis tasks as a series of 2D tasks.\nK-fold cross-validation on the training set was performed by only 37% of the\nparticipants and only 50% of the participants performed ensembling based on\nmultiple identical models (61%) or heterogeneous models (39%). 48% of the\nrespondents applied postprocessing steps.\n","authors":["Matthias Eisenmann","Annika Reinke","Vivienn Weru","Minu Dietlinde Tizabi","Fabian Isensee","Tim J. Adler","Patrick Godau","Veronika Cheplygina","Michal Kozubek","Sharib Ali","Anubha Gupta","Jan Kybic","Alison Noble","Carlos Ortiz de Solórzano","Samiksha Pachade","Caroline Petitjean","Daniel Sage","Donglai Wei","Elizabeth Wilden","Deepak Alapatt","Vincent Andrearczyk","Ujjwal Baid","Spyridon Bakas","Niranjan Balu","Sophia Bano","Vivek Singh Bawa","Jorge Bernal","Sebastian Bodenstedt","Alessandro Casella","Jinwook Choi","Olivier Commowick","Marie Daum","Adrien Depeursinge","Reuben Dorent","Jan Egger","Hannah Eichhorn","Sandy Engelhardt","Melanie Ganz","Gabriel Girard","Lasse Hansen","Mattias Heinrich","Nicholas Heller","Alessa Hering","Arnaud Huaulmé","Hyunjeong Kim","Bennett Landman","Hongwei Bran Li","Jianning Li","Jun Ma","Anne Martel","Carlos Martín-Isla","Bjoern Menze","Chinedu Innocent Nwoye","Valentin Oreiller","Nicolas Padoy","Sarthak Pati","Kelly Payette","Carole Sudre","Kimberlin van Wijnen","Armine Vardazaryan","Tom Vercauteren","Martin Wagner","Chuanbo Wang","Moi Hoon Yap","Zeyun Yu","Chun Yuan","Maximilian Zenk","Aneeq Zia","David Zimmerer","Rina Bao","Chanyeol Choi","Andrew Cohen","Oleh Dzyubachyk","Adrian Galdran","Tianyuan Gan","Tianqi Guo","Pradyumna Gupta","Mahmood Haithami","Edward Ho","Ikbeom Jang","Zhili Li","Zhengbo Luo","Filip Lux","Sokratis Makrogiannis","Dominik Müller","Young-tack Oh","Subeen Pang","Constantin Pape","Gorkem Polat","Charlotte Rosalie Reed","Kanghyun Ryu","Tim Scherr","Vajira Thambawita","Haoyu Wang","Xinliang Wang","Kele Xu","Hung Yeh","Doyeob Yeo","Yixuan Yuan","Yan Zeng","Xin Zhao","Julian Abbing","Jannes Adam","Nagesh Adluru","Niklas Agethen","Salman Ahmed","Yasmina Al Khalil","Mireia Alenyà","Esa Alhoniemi","Chengyang An","Talha Anwar","Tewodros Weldebirhan Arega","Netanell Avisdris","Dogu Baran Aydogan","Yingbin Bai","Maria Baldeon Calisto","Berke Doga Basaran","Marcel Beetz","Cheng Bian","Hao Bian","Kevin Blansit","Louise Bloch","Robert Bohnsack","Sara Bosticardo","Jack Breen","Mikael Brudfors","Raphael Brüngel","Mariano Cabezas","Alberto Cacciola","Zhiwei Chen","Yucong Chen","Daniel Tianming Chen","Minjeong Cho","Min-Kook Choi","Chuantao Xie Chuantao Xie","Dana Cobzas","Julien Cohen-Adad","Jorge Corral Acero","Sujit Kumar Das","Marcela de Oliveira","Hanqiu Deng","Guiming Dong","Lars Doorenbos","Cory Efird","Di Fan","Mehdi Fatan Serj","Alexandre Fenneteau","Lucas Fidon","Patryk Filipiak","René Finzel","Nuno R. Freitas","Christoph M. Friedrich","Mitchell Fulton","Finn Gaida","Francesco Galati","Christoforos Galazis","Chang Hee Gan","Zheyao Gao","Shengbo Gao","Matej Gazda","Beerend Gerats","Neil Getty","Adam Gibicar","Ryan Gifford","Sajan Gohil","Maria Grammatikopoulou","Daniel Grzech","Orhun Güley","Timo Günnemann","Chunxu Guo","Sylvain Guy","Heonjin Ha","Luyi Han","Il Song Han","Ali Hatamizadeh","Tian He","Jimin Heo","Sebastian Hitziger","SeulGi Hong","SeungBum Hong","Rian Huang","Ziyan Huang","Markus Huellebrand","Stephan Huschauer","Mustaffa Hussain","Tomoo Inubushi","Ece Isik Polat","Mojtaba Jafaritadi","SeongHun Jeong","Bailiang Jian","Yuanhong Jiang","Zhifan Jiang","Yueming Jin","Smriti Joshi","Abdolrahim Kadkhodamohammadi","Reda Abdellah Kamraoui","Inha Kang","Junghwa Kang","Davood Karimi","April Khademi","Muhammad Irfan Khan","Suleiman A. Khan","Rishab Khantwal","Kwang-Ju Kim","Timothy Kline","Satoshi Kondo","Elina Kontio","Adrian Krenzer","Artem Kroviakov","Hugo Kuijf","Satyadwyoom Kumar","Francesco La Rosa","Abhi Lad","Doohee Lee","Minho Lee","Chiara Lena","Hao Li","Ling Li","Xingyu Li","Fuyuan Liao","KuanLun Liao","Arlindo Limede Oliveira","Chaonan Lin","Shan Lin","Akis Linardos","Marius George Linguraru","Han Liu","Tao Liu","Di Liu","Yanling Liu","João Lourenço-Silva","Jingpei Lu","Jiangshan Lu","Imanol Luengo","Christina B. Lund","Huan Minh Luu","Yi Lv","Yi Lv","Uzay Macar","Leon Maechler","Sina Mansour L.","Kenji Marshall","Moona Mazher","Richard McKinley","Alfonso Medela","Felix Meissen","Mingyuan Meng","Dylan Miller","Seyed Hossein Mirjahanmardi","Arnab Mishra","Samir Mitha","Hassan Mohy-ud-Din","Tony Chi Wing Mok","Gowtham Krishnan Murugesan","Enamundram Naga Karthik","Sahil Nalawade","Jakub Nalepa","Mohamed Naser","Ramin Nateghi","Hammad Naveed","Quang-Minh Nguyen","Cuong Nguyen Quoc","Brennan Nichyporuk","Bruno Oliveira","David Owen","Jimut Bahan Pal","Junwen Pan","Wentao Pan","Winnie Pang","Bogyu Park","Vivek Pawar","Kamlesh Pawar","Michael Peven","Lena Philipp","Tomasz Pieciak","Szymon Plotka","Marcel Plutat","Fattaneh Pourakpour","Domen Preložnik","Kumaradevan Punithakumar","Abdul Qayyum","Sandro Queirós","Arman Rahmim","Salar Razavi","Jintao Ren","Mina Rezaei","Jonathan Adam Rico","ZunHyan Rieu","Markus Rink","Johannes Roth","Yusely Ruiz-Gonzalez","Numan Saeed","Anindo Saha","Mostafa Salem","Ricardo Sanchez-Matilla","Kurt Schilling","Wei Shao","Zhiqiang Shen","Ruize Shi","Pengcheng Shi","Daniel Sobotka","Théodore Soulier","Bella Specktor Fadida","Danail Stoyanov","Timothy Sum Hon Mun","Xiaowu Sun","Rong Tao","Franz Thaler","Antoine Théberge","Felix Thielke","Helena Torres","Kareem A. Wahid","Jiacheng Wang","YiFei Wang","Wei Wang","Xiong Wang","Jianhui Wen","Ning Wen","Marek Wodzinski","Ye Wu","Fangfang Xia","Tianqi Xiang","Chen Xiaofei","Lizhan Xu","Tingting Xue","Yuxuan Yang","Lin Yang","Kai Yao","Huifeng Yao","Amirsaeed Yazdani","Michael Yip","Hwanseung Yoo","Fereshteh Yousefirizi","Shunkai Yu","Lei Yu","Jonathan Zamora","Ramy Ashraf Zeineldin","Dewen Zeng","Jianpeng Zhang","Bokai Zhang","Jiapeng Zhang","Fan Zhang","Huahong Zhang","Zhongchen Zhao","Zixuan Zhao","Jiachen Zhao","Can Zhao","Qingshuo Zheng","Yuheng Zhi","Ziqi Zhou","Baosheng Zou","Klaus Maier-Hein","Paul F. Jäger","Annette Kopp-Schneider","Lena Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2212.08568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08554v1","updated":"2022-12-16T16:12:51Z","published":"2022-12-16T16:12:51Z","title":"An automated parameter domain decomposition approach for gravitational\n  wave surrogates using hp-greedy refinement","summary":"  We introduce hp-greedy, a refinement approach for building gravitational wave\nsurrogates as an extension of the standard reduced basis framework. Our\nproposal is data-driven, with a domain decomposition of the parameter space,\nlocal reduced basis, and a binary tree as the resulting structure, which are\nobtained in an automated way. When compared to the standard global reduced\nbasis approach, the numerical simulations of our proposal show three salient\nfeatures: i) representations of lower dimension with no loss of accuracy, ii) a\nsignificantly higher accuracy for a fixed maximum dimensionality of the basis,\nin some cases by orders of magnitude, and iii) results that depend on the\nreduced basis seed choice used by the refinement algorithm. We first illustrate\nthe key parts of our approach with a toy model and then present a more\nrealistic use case of gravitational waves emitted by the collision of two\nspinning, non-precessing black holes. We discuss performance aspects of\nhp-greedy, such as overfitting with respect to the depth of the tree structure,\nand other hyperparameter dependences. As two direct applications of the\nproposed hp-greedy refinement, we envision: i) a further acceleration of\nstatistical inference, which might be complementary to focused reduced-order\nquadratures, and ii) the search of gravitational waves through clustering and\nnearest neighbors.\n","authors":["Franco Cerino","J. Andrés Diaz-Pace","Manuel Tiglio"],"pdf_url":"https://arxiv.org/pdf/2212.08554v1.pdf","comment":"16 pages, code available from authors upon request"},{"id":"http://arxiv.org/abs/2212.08546v1","updated":"2022-12-16T15:55:16Z","published":"2022-12-16T15:55:16Z","title":"Estimating truncation effects of quantum bosonic systems using sampling\n  algorithms","summary":"  To simulate bosons on a qubit- or qudit-based quantum computer, one has to\nregularize the theory by truncating infinite-dimensional local Hilbert spaces\nto finite dimensions. In the search for practical quantum applications, it is\nimportant to know how big the truncation errors can be. In general, it is not\neasy to estimate errors unless we have a good quantum computer. In this paper\nwe show that traditional sampling methods on classical devices, specifically\nMarkov Chain Monte Carlo, can address this issue with a reasonable amount of\ncomputational resources available today. As a demonstration, we apply this idea\nto the scalar field theory on a two-dimensional lattice, with a size that goes\nbeyond what is achievable using exact diagonalization methods. This method can\nbe used to estimate the resources needed for realistic quantum simulations of\nbosonic theories, and also, to check the validity of the results of the\ncorresponding quantum simulations.\n","authors":["Masanori Hanada","Junyu Liu","Enrico Rinaldi","Masaki Tezuka"],"pdf_url":"https://arxiv.org/pdf/2212.08546v1.pdf","comment":"19 pages, 3 figures"},{"id":"http://arxiv.org/abs/2110.03905v3","updated":"2022-12-16T15:45:18Z","published":"2021-10-08T05:57:30Z","title":"COVID-19 Monitoring System using Social Distancing and Face Mask\n  Detection on Surveillance video datasets","summary":"  In the current times, the fear and danger of COVID-19 virus still stands\nlarge. Manual monitoring of social distancing norms is impractical with a large\npopulation moving about and with insufficient task force and resources to\nadminister them. There is a need for a lightweight, robust and 24X7\nvideo-monitoring system that automates this process. This paper proposes a\ncomprehensive and effective solution to perform person detection, social\ndistancing violation detection, face detection and face mask classification\nusing object detection, clustering and Convolution Neural Network (CNN) based\nbinary classifier. For this, YOLOv3, Density-based spatial clustering of\napplications with noise (DBSCAN), Dual Shot Face Detector (DSFD) and\nMobileNetV2 based binary classifier have been employed on surveillance video\ndatasets. This paper also provides a comparative study of different face\ndetection and face mask classification models. Finally, a video dataset\nlabelling method is proposed along with the labelled video dataset to\ncompensate for the lack of dataset in the community and is used for evaluation\nof the system. The system performance is evaluated in terms of accuracy, F1\nscore as well as the prediction time, which has to be low for practical\napplicability. The system performs with an accuracy of 91.2% and F1 score of\n90.79% on the labelled video dataset and has an average prediction time of 7.12\nseconds for 78 frames of a video.\n","authors":["Sahana Srinivasan","Rujula Singh R","Ruchita R Biradar","Revathi SA"],"pdf_url":"https://arxiv.org/pdf/2110.03905v3.pdf","comment":"I, Rujula Singh R, would like to apologize to the research community\n  for the confusion caused by the inconsistency in author lists between\n  multiple versions of this paper. I take full responsibility for this error\n  and will be more diligent in the future to ensure the accuracy and\n  consistency of our research publications"},{"id":"http://arxiv.org/abs/2212.08541v1","updated":"2022-12-16T15:43:41Z","published":"2022-12-16T15:43:41Z","title":"Learnable Commutative Monoids for Graph Neural Networks","summary":"  Graph neural networks (GNNs) have been shown to be highly sensitive to the\nchoice of aggregation function. While summing over a node's neighbours can\napproximate any permutation-invariant function over discrete inputs,\nCohen-Karlik et al. [2020] proved there are set-aggregation problems for which\nsumming cannot generalise to unbounded inputs, proposing recurrent neural\nnetworks regularised towards permutation-invariance as a more expressive\naggregator. We show that these results carry over to the graph domain: GNNs\nequipped with recurrent aggregators are competitive with state-of-the-art\npermutation-invariant aggregators, on both synthetic benchmarks and real-world\nproblems. However, despite the benefits of recurrent aggregators, their $O(V)$\ndepth makes them both difficult to parallelise and harder to train on large\ngraphs. Inspired by the observation that a well-behaved aggregator for a GNN is\na commutative monoid over its latent space, we propose a framework for\nconstructing learnable, commutative, associative binary operators. And with\nthis, we construct an aggregator of $O(\\log V)$ depth, yielding exponential\nimprovements for both parallelism and dependency length while achieving\nperformance competitive with recurrent aggregators. Based on our empirical\nobservations, our proposed learnable commutative monoid (LCM) aggregator\nrepresents a favourable tradeoff between efficient and expressive aggregators.\n","authors":["Euan Ong","Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2212.08541v1.pdf","comment":"Accepted to the proceedings of the First Learning on Graphs\n  Conference (LoG 2022)"},{"id":"http://arxiv.org/abs/2212.07428v2","updated":"2022-12-16T15:35:37Z","published":"2022-12-14T10:50:13Z","title":"Towards Linguistically Informed Multi-Objective Pre-Training for Natural\n  Language Inference","summary":"  We introduce a linguistically enhanced combination of pre-training methods\nfor transformers. The pre-training objectives include POS-tagging, synset\nprediction based on semantic knowledge graphs, and parent prediction based on\ndependency parse trees. Our approach achieves competitive results on the\nNatural Language Inference task, compared to the state of the art. Specifically\nfor smaller models, the method results in a significant performance boost,\nemphasizing the fact that intelligent pre-training can make up for fewer\nparameters and help building more efficient models. Combining POS-tagging and\nsynset prediction yields the overall best results.\n","authors":["Maren Pielka","Svetlana Schmidt","Lisa Pucknat","Rafet Sifa"],"pdf_url":"https://arxiv.org/pdf/2212.07428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08532v1","updated":"2022-12-16T15:32:49Z","published":"2022-12-16T15:32:49Z","title":"Do Not Trust a Model Because It is Confident: Uncovering and\n  Characterizing Unknown Unknowns to Student Success Predictors in Online-Based\n  Learning","summary":"  Student success models might be prone to develop weak spots, i.e., examples\nhard to accurately classify due to insufficient representation during model\ncreation. This weakness is one of the main factors undermining users' trust,\nsince model predictions could for instance lead an instructor to not intervene\non a student in need. In this paper, we unveil the need of detecting and\ncharacterizing unknown unknowns in student success prediction in order to\nbetter understand when models may fail. Unknown unknowns include the students\nfor which the model is highly confident in its predictions, but is actually\nwrong. Therefore, we cannot solely rely on the model's confidence when\nevaluating the predictions quality. We first introduce a framework for the\nidentification and characterization of unknown unknowns. We then assess its\ninformativeness on log data collected from flipped courses and online courses\nusing quantitative analyses and interviews with instructors. Our results show\nthat unknown unknowns are a critical issue in this domain and that our\nframework can be applied to support their detection. The source code is\navailable at https://github.com/epfl-ml4ed/unknown-unknowns.\n","authors":["Roberta Galici","Tanja Käser","Gianni Fenu","Mirko Marras"],"pdf_url":"https://arxiv.org/pdf/2212.08532v1.pdf","comment":"Accepted as a full paper at the International Conference on Learning\n  Analytics & Knowledge (LAK23)"},{"id":"http://arxiv.org/abs/2206.08871v2","updated":"2022-12-16T15:18:22Z","published":"2022-06-17T16:18:28Z","title":"How Robust is Unsupervised Representation Learning to Distribution\n  Shift?","summary":"  The robustness of machine learning algorithms to distributions shift is\nprimarily discussed in the context of supervised learning (SL). As such, there\nis a lack of insight on the robustness of the representations learned from\nunsupervised methods, such as self-supervised learning (SSL) and auto-encoder\nbased algorithms (AE), to distribution shift. We posit that the input-driven\nobjectives of unsupervised algorithms lead to representations that are more\nrobust to distribution shift than the target-driven objective of SL. We verify\nthis by extensively evaluating the performance of SSL and AE on both synthetic\nand realistic distribution shift datasets. Following observations that the\nlinear layer used for classification itself can be susceptible to spurious\ncorrelations, we evaluate the representations using a linear head trained on a\nsmall amount of out-of-distribution (OOD) data, to isolate the robustness of\nthe learned representations from that of the linear head. We also develop\n\"controllable\" versions of existing realistic domain generalisation datasets\nwith adjustable degrees of distribution shifts. This allows us to study the\nrobustness of different learning algorithms under versatile yet realistic\ndistribution shift conditions. Our experiments show that representations\nlearned from unsupervised learning algorithms generalise better than SL under a\nwide variety of extreme as well as realistic distribution shifts.\n","authors":["Yuge Shi","Imant Daunhawer","Julia E. Vogt","Philip H. S. Torr","Amartya Sanyal"],"pdf_url":"https://arxiv.org/pdf/2206.08871v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07282v2","updated":"2022-12-16T15:11:16Z","published":"2022-12-14T15:30:56Z","title":"Directional Direct Feedback Alignment: Estimating Backpropagation Paths\n  for Efficient Learning on Neural Processors","summary":"  The error Backpropagation algorithm (BP) is a key method for training deep\nneural networks. While performant, it is also resource-demanding in terms of\ncomputation, memory usage and energy. This makes it unsuitable for online\nlearning on edge devices that require a high processing rate and low energy\nconsumption. More importantly, BP does not take advantage of the parallelism\nand local characteristics offered by dedicated neural processors. There is\ntherefore a demand for alternative algorithms to BP that could improve the\nlatency, memory requirements, and energy footprint of neural networks on\nhardware. In this work, we propose a novel method based on Direct Feedback\nAlignment (DFA) which uses Forward-Mode Automatic Differentiation to estimate\nbackpropagation paths and learn feedback connections in an online manner. We\nexperimentally show that Directional DFA achieves performances that are closer\nto BP than other feedback methods on several benchmark datasets and\narchitectures while benefiting from the locality and parallelization\ncharacteristics of DFA. Moreover, we show that, unlike other feedback learning\nalgorithms, our method provides stable learning for convolution layers.\n","authors":["Florian Bacho","Dominique Chu"],"pdf_url":"https://arxiv.org/pdf/2212.07282v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.05957v2","updated":"2022-12-16T15:03:15Z","published":"2022-09-13T12:46:57Z","title":"Adversarial Inter-Group Link Injection Degrades the Fairness of Graph\n  Neural Networks","summary":"  We present evidence for the existence and effectiveness of adversarial\nattacks on graph neural networks (GNNs) that aim to degrade fairness. These\nattacks can disadvantage a particular subgroup of nodes in GNN-based node\nclassification, where nodes of the underlying network have sensitive\nattributes, such as race or gender. We conduct qualitative and experimental\nanalyses explaining how adversarial link injection impairs the fairness of GNN\npredictions. For example, an attacker can compromise the fairness of GNN-based\nnode classification by injecting adversarial links between nodes belonging to\nopposite subgroups and opposite class labels. Our experiments on empirical\ndatasets demonstrate that adversarial fairness attacks can significantly\ndegrade the fairness of GNN predictions (attacks are effective) with a low\nperturbation rate (attacks are efficient) and without a significant drop in\naccuracy (attacks are deceptive). This work demonstrates the vulnerability of\nGNN models to adversarial fairness attacks. We hope our findings raise\nawareness about this issue in our community and lay a foundation for the future\ndevelopment of GNN models that are more robust to such attacks.\n","authors":["Hussain Hussain","Meng Cao","Sandipan Sikdar","Denis Helic","Elisabeth Lex","Markus Strohmaier","Roman Kern"],"pdf_url":"https://arxiv.org/pdf/2209.05957v2.pdf","comment":"A shorter version of this work has been accepted by IEEE ICDM 2022"},{"id":"http://arxiv.org/abs/2209.15154v2","updated":"2022-12-16T15:01:34Z","published":"2022-09-30T00:49:31Z","title":"Variable-Based Calibration for Machine Learning Classifiers","summary":"  The deployment of machine learning classifiers in high-stakes domains\nrequires well-calibrated confidence scores for model predictions. In this paper\nwe introduce the notion of variable-based calibration to characterize\ncalibration properties of a model with respect to a variable of interest,\ngeneralizing traditional score-based calibration and metrics such as expected\ncalibration error (ECE). In particular, we find that models with near-perfect\nECE can exhibit significant variable-based calibration error as a function of\nfeatures of the data. We demonstrate this phenomenon both theoretically and in\npractice on multiple well-known datasets, and show that it can persist after\nthe application of existing recalibration methods. To mitigate this issue, we\npropose strategies for detection, visualization, and quantification of\nvariable-based calibration error. We then examine the limitations of current\nscore-based recalibration methods and explore potential modifications. Finally,\nwe discuss the implications of these findings, emphasizing that an\nunderstanding of calibration beyond simple aggregate measures is crucial for\nendeavors such as fairness and model interpretability.\n","authors":["Markelle Kelly","Padhraic Smyth"],"pdf_url":"https://arxiv.org/pdf/2209.15154v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07011v2","updated":"2022-12-16T14:59:17Z","published":"2022-10-13T13:19:51Z","title":"Variational Graph Generator for Multi-View Graph Clustering","summary":"  Multi-view graph clustering (MGC) methods are increasingly being studied due\nto the explosion of multi-view data with graph structural information. The\ncritical point of MGC is to better utilize the view-specific and view-common\ninformation in features and graphs of multiple views. However, existing works\nhave an inherent limitation that they are unable to concurrently utilize the\nconsensus graph information across multiple graphs and the view-specific\nfeature information. To address this issue, we propose Variational Graph\nGenerator for Multi-View Graph Clustering (VGMGC). Specifically, a novel\nvariational graph generator is proposed to extract common information among\nmultiple graphs. This generator infers a reliable variational consensus graph\nbased on a priori assumption over multiple graphs. Then a simple yet effective\ngraph encoder in conjunction with the multi-view clustering objective is\npresented to learn the desired graph embeddings for clustering, which embeds\nthe inferred view-common graph and view-specific graphs together with features.\nFinally, theoretical results illustrate the rationality of VGMGC by analyzing\nthe uncertainty of the inferred consensus graph with information bottleneck\nprinciple. Extensive experiments demonstrate the superior performance of our\nVGMGC over SOTAs.\n","authors":["Jianpeng Chen","Yawen Ling","Jie Xu","Yazhou Ren","Shudong Huang","Xiaorong Pu","Zhifeng Hao","Philip S. Yu","Lifang He"],"pdf_url":"https://arxiv.org/pdf/2210.07011v2.pdf","comment":"submitted to TNNLS"},{"id":"http://arxiv.org/abs/2212.08507v1","updated":"2022-12-16T14:40:25Z","published":"2022-12-16T14:40:25Z","title":"Robust Explanation Constraints for Neural Networks","summary":"  Post-hoc explanation methods are used with the intent of providing insights\nabout neural networks and are sometimes said to help engender trust in their\noutputs. However, popular explanations methods have been found to be fragile to\nminor perturbations of input features or model parameters. Relying on\nconstraint relaxation techniques from non-convex optimization, we develop a\nmethod that upper-bounds the largest change an adversary can make to a\ngradient-based explanation via bounded manipulation of either the input\nfeatures or model parameters. By propagating a compact input or parameter set\nas symbolic intervals through the forwards and backwards computations of the\nneural network we can formally certify the robustness of gradient-based\nexplanations. Our bounds are differentiable, hence we can incorporate provable\nexplanation robustness into neural network training. Empirically, our method\nsurpasses the robustness provided by previous heuristic approaches. We find\nthat our training method is the only method able to learn neural networks with\ncertificates of explanation robustness across all six datasets tested.\n","authors":["Matthew Wicker","Juyeon Heo","Luca Costabello","Adrian Weller"],"pdf_url":"https://arxiv.org/pdf/2212.08507v1.pdf","comment":"23 pages, 12 figures"},{"id":"http://arxiv.org/abs/2212.08496v1","updated":"2022-12-16T14:21:29Z","published":"2022-12-16T14:21:29Z","title":"Federated Learning with Flexible Control","summary":"  Federated learning (FL) enables distributed model training from local data\ncollected by users. In distributed systems with constrained resources and\npotentially high dynamics, e.g., mobile edge networks, the efficiency of FL is\nan important problem. Existing works have separately considered different\nconfigurations to make FL more efficient, such as infrequent transmission of\nmodel updates, client subsampling, and compression of update vectors. However,\nan important open problem is how to jointly apply and tune these control knobs\nin a single FL algorithm, to achieve the best performance by allowing a high\ndegree of freedom in control decisions. In this paper, we address this problem\nand propose FlexFL - an FL algorithm with multiple options that can be adjusted\nflexibly. Our FlexFL algorithm allows both arbitrary rates of local computation\nat clients and arbitrary amounts of communication between clients and the\nserver, making both the computation and communication resource consumption\nadjustable. We prove a convergence upper bound of this algorithm. Based on this\nresult, we further propose a stochastic optimization formulation and algorithm\nto determine the control decisions that (approximately) minimize the\nconvergence bound, while conforming to constraints related to resource\nconsumption. The advantage of our approach is also verified using experiments.\n","authors":["Shiqiang Wang","Jake Perazzone","Mingyue Ji","Kevin S. Chan"],"pdf_url":"https://arxiv.org/pdf/2212.08496v1.pdf","comment":"Accepted to IEEE INFOCOM 2023"},{"id":"http://arxiv.org/abs/2212.01199v3","updated":"2022-12-16T14:12:08Z","published":"2022-12-02T14:25:58Z","title":"Gibbs-Helmholtz Graph Neural Network: capturing the temperature\n  dependency of activity coefficients at infinite dilution","summary":"  The accurate prediction of physicochemical properties of chemical compounds\nin mixtures (such as the activity coefficient at infinite dilution\n$\\gamma_{ij}^\\infty$) is essential for developing novel and more sustainable\nchemical processes. In this work, we analyze the performance of\npreviously-proposed GNN-based models for the prediction of\n$\\gamma_{ij}^\\infty$, and compare them with several mechanistic models in a\nseries of 9 isothermal studies. Moreover, we develop the Gibbs-Helmholtz Graph\nNeural Network (GH-GNN) model for predicting $\\ln \\gamma_{ij}^\\infty$ of\nmolecular systems at different temperatures. Our method combines the simplicity\nof a Gibbs-Helmholtz-derived expression with a series of graph neural networks\nthat incorporate explicit molecular and intermolecular descriptors for\ncapturing dispersion and hydrogen bonding effects. We have trained this model\nusing experimentally determined $\\ln \\gamma_{ij}^\\infty$ data of 40,219\nbinary-systems involving 1032 solutes and 866 solvents, overall showing\nsuperior performance compared to the popular UNIFAC-Dortmund model. We analyze\nthe performance of GH-GNN for continuous and discrete inter/extrapolation and\ngive indications for the model's applicability domain and expected accuracy. In\ngeneral, GH-GNN is able to produce accurate predictions for extrapolated\nbinary-systems if at least 25 systems with the same combination of\nsolute-solvent chemical classes are contained in the training set and a\nsimilarity indicator above 0.35 is also present. This model and its\napplicability domain recommendations have been made open-source at\nhttps://github.com/edgarsmdn/GH-GNN.\n","authors":["Edgar Ivan Sanchez Medina","Steffen Linke","Martin Stoll","Kai Sundmacher"],"pdf_url":"https://arxiv.org/pdf/2212.01199v3.pdf","comment":"Code available at: https://github.com/edgarsmdn/GH-GNN"},{"id":"http://arxiv.org/abs/2208.10521v2","updated":"2022-12-16T14:05:11Z","published":"2022-08-22T18:01:49Z","title":"Estimation Contracts for Outlier-Robust Geometric Perception","summary":"  Outlier-robust estimation is a fundamental problem and has been extensively\ninvestigated by statisticians and practitioners. The last few years have seen a\nconvergence across research fields towards \"algorithmic robust statistics\",\nwhich focuses on developing tractable outlier-robust techniques for\nhigh-dimensional estimation problems. Despite this convergence, research\nefforts across fields have been mostly disconnected from one another. This\nmonograph bridges recent work on certifiable outlier-robust estimation for\ngeometric perception in robotics and computer vision with parallel work in\nrobust statistics. In particular, we adapt and extend recent results on robust\nlinear regression (applicable to the low-outlier regime with << 50% outliers)\nand list-decodable regression (applicable to the high-outlier regime with >>\n50% outliers) to the setup commonly found in robotics and vision, where (i)\nvariables (e.g., rotations, poses) belong to a non-convex domain, (ii)\nmeasurements are vector-valued, and (iii) the number of outliers is not known a\npriori. The emphasis here is on performance guarantees: rather than proposing\nradically new algorithms, we provide conditions on the input measurements under\nwhich modern estimation algorithms (possibly after small modifications) are\nguaranteed to recover an estimate close to the ground truth in the presence of\noutliers. These conditions are what we call an \"estimation contract\". Besides\nthe proposed extensions of existing results, we believe the main contributions\nof this monograph are (i) to unify parallel research lines by pointing out\ncommonalities and differences, (ii) to introduce advanced material (e.g.,\nsum-of-squares proofs) in an accessible and self-contained presentation for the\npractitioner, and (iii) to point out a few immediate opportunities and open\nquestions in outlier-robust geometric perception.\n","authors":["Luca Carlone"],"pdf_url":"https://arxiv.org/pdf/2208.10521v2.pdf","comment":"95 pages, 12 figures"},{"id":"http://arxiv.org/abs/2212.08479v1","updated":"2022-12-16T13:46:17Z","published":"2022-12-16T13:46:17Z","title":"Neural Implicit k-Space for Binning-free Non-Cartesian Cardiac MR\n  Imaging","summary":"  In this work, we propose a novel image reconstruction framework that directly\nlearns a neural implicit representation in k-space for ECG-triggered\nnon-Cartesian Cardiac Magnetic Resonance Imaging (CMR). While existing methods\nbin acquired data from neighboring time points to reconstruct one phase of the\ncardiac motion, our framework allows for a continuous, binning-free, and\nsubject-specific k-space representation.We assign a unique coordinate that\nconsists of time, coil index, and frequency domain location to each sampled\nk-space point. We then learn the subject-specific mapping from these unique\ncoordinates to k-space intensities using a multi-layer perceptron with\nfrequency domain regularization. During inference, we obtain a complete k-space\nfor Cartesian coordinates and an arbitrary temporal resolution. A simple\ninverse Fourier transform recovers the image, eliminating the need for density\ncompensation and costly non-uniform Fourier transforms for non-Cartesian data.\nThis novel imaging framework was tested on 42 radially sampled datasets from 6\nsubjects. The proposed method outperforms other techniques qualitatively and\nquantitatively using data from four and one heartbeat(s) and 30 cardiac phases.\nOur results for one heartbeat reconstruction of 50 cardiac phases show improved\nartifact removal and spatio-temporal resolution, leveraging the potential for\nreal-time CMR.\n","authors":["Wenqi Huang","Hongwei Li","Gastao Cruz","Jiazhen Pan","Daniel Rueckert","Kerstin Hammernik"],"pdf_url":"https://arxiv.org/pdf/2212.08479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08458v1","updated":"2022-12-16T13:07:09Z","published":"2022-12-16T13:07:09Z","title":"Fast Rule-Based Decoding: Revisiting Syntactic Rules in Neural\n  Constituency Parsing","summary":"  Most recent studies on neural constituency parsing focus on encoder\nstructures, while few developments are devoted to decoders. Previous research\nhas demonstrated that probabilistic statistical methods based on syntactic\nrules are particularly effective in constituency parsing, whereas syntactic\nrules are not used during the training of neural models in prior work probably\ndue to their enormous computation requirements. In this paper, we first\nimplement a fast CKY decoding procedure harnessing GPU acceleration, based on\nwhich we further derive a syntactic rule-based (rule-constrained) CKY decoding.\nIn the experiments, our method obtains 95.89 and 92.52 F1 on the datasets of\nPTB and CTB respectively, which shows significant improvements compared with\nprevious approaches. Besides, our parser achieves strong and competitive\ncross-domain performance in zero-shot settings.\n","authors":["Tianyu Shi","Zhicheng Wang","Liyin Xiao","Cong Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08458v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07127v3","updated":"2022-12-16T12:52:19Z","published":"2022-12-14T09:26:07Z","title":"Towards mapping the contemporary art world with ArtLM: an art-specific\n  NLP model","summary":"  With an increasing amount of data in the art world, discovering artists and\nartworks suitable to collectors' tastes becomes a challenge. It is no longer\nenough to use visual information, as contextual information about the artist\nhas become just as important in contemporary art. In this work, we present a\ngeneric Natural Language Processing framework (called ArtLM) to discover the\nconnections among contemporary artists based on their biographies. In this\napproach, we first continue to pre-train the existing general English language\nmodels with a large amount of unlabelled art-related data. We then fine-tune\nthis new pre-trained model with our biography pair dataset manually annotated\nby a team of professionals in the art industry. With extensive experiments, we\ndemonstrate that our ArtLM achieves 85.6% accuracy and 84.0% F1 score and\noutperforms other baseline models. We also provide a visualisation and a\nqualitative analysis of the artist network built from ArtLM's outputs.\n","authors":["Qinkai Chen","Mohamed El-Mennaoui","Antoine Fosset","Amine Rebei","Haoyang Cao","Philine Bouscasse","Christy Eóin O'Beirne","Sasha Shevchenko","Mathieu Rosenbaum"],"pdf_url":"https://arxiv.org/pdf/2212.07127v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14990v2","updated":"2022-12-16T12:52:07Z","published":"2022-09-29T17:51:51Z","title":"Partially Observable RL with B-Stability: Unified Structural Condition\n  and Sharp Sample-Efficient Algorithms","summary":"  Partial Observability -- where agents can only observe partial information\nabout the true underlying state of the system -- is ubiquitous in real-world\napplications of Reinforcement Learning (RL). Theoretically, learning a\nnear-optimal policy under partial observability is known to be hard in the\nworst case due to an exponential sample complexity lower bound. Recent work has\nidentified several tractable subclasses that are learnable with polynomial\nsamples, such as Partially Observable Markov Decision Processes (POMDPs) with\ncertain revealing or decodability conditions. However, this line of research is\nstill in its infancy, where (1) unified structural conditions enabling\nsample-efficient learning are lacking; (2) existing sample complexities for\nknown tractable subclasses are far from sharp; and (3) fewer sample-efficient\nalgorithms are available than in fully observable RL.\n  This paper advances all three aspects above for Partially Observable RL in\nthe general setting of Predictive State Representations (PSRs). First, we\npropose a natural and unified structural condition for PSRs called\n\\emph{B-stability}. B-stable PSRs encompasses the vast majority of known\ntractable subclasses such as weakly revealing POMDPs, low-rank\nfuture-sufficient POMDPs, decodable POMDPs, and regular PSRs. Next, we show\nthat any B-stable PSR can be learned with polynomial samples in relevant\nproblem parameters. When instantiated in the aforementioned subclasses, our\nsample complexities improve substantially over the current best ones. Finally,\nour results are achieved by three algorithms simultaneously: Optimistic Maximum\nLikelihood Estimation, Estimation-to-Decisions, and Model-Based Optimistic\nPosterior Sampling. The latter two algorithms are new for sample-efficient\nlearning of POMDPs/PSRs.\n","authors":["Fan Chen","Yu Bai","Song Mei"],"pdf_url":"https://arxiv.org/pdf/2209.14990v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08445v1","updated":"2022-12-16T12:45:16Z","published":"2022-12-16T12:45:16Z","title":"Conditional Generative Adversarial Network for keystroke presentation\n  attack","summary":"  Cybersecurity is a crucial step in data protection to ensure user security\nand personal data privacy. In this sense, many companies have started to\ncontrol and restrict access to their data using authentication systems.\nHowever, these traditional authentication methods, are not enough for ensuring\ndata protection, and for this reason, behavioral biometrics have gained\nimportance. Despite their promising results and the wide range of applications,\nbiometric systems have shown to be vulnerable to malicious attacks, such as\nPresentation Attacks. For this reason, in this work, we propose to study a new\napproach aiming to deploy a presentation attack towards a keystroke\nauthentication system. Our idea is to use Conditional Generative Adversarial\nNetworks (cGAN) for generating synthetic keystroke data that can be used for\nimpersonating an authorized user. These synthetic data are generated following\ntwo different real use cases, one in which the order of the typed words is\nknown (ordered dynamic) and the other in which this order is unknown\n(no-ordered dynamic). Finally, both keystroke dynamics (ordered and no-ordered)\nare validated using an external keystroke authentication system. Results\nindicate that the cGAN can effectively generate keystroke dynamics patterns\nthat can be used for deceiving keystroke authentication systems.\n","authors":["Idoia Eizaguirre-Peral","Lander Segurola-Gil","Francesco Zola"],"pdf_url":"https://arxiv.org/pdf/2212.08445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.07859v2","updated":"2022-12-16T12:44:36Z","published":"2022-07-16T07:23:45Z","title":"Deep Learning and Its Applications to WiFi Human Sensing: A Benchmark\n  and A Tutorial","summary":"  WiFi sensing has been evolving rapidly in recent years. Empowered by\npropagation models and deep learning methods, many challenging applications are\nrealized such as WiFi-based human activity recognition and gesture recognition.\nHowever, in contrast to deep learning for visual recognition and natural\nlanguage processing, no sufficiently comprehensive public benchmark exists. In\nthis paper, we highlight the recent progress on deep learning enabled WiFi\nsensing, and then propose a benchmark, SenseFi, to study the effectiveness of\nvarious deep learning models for WiFi sensing. These advanced models are\ncompared in terms of distinct sensing tasks, WiFi platforms, recognition\naccuracy, model size, computational complexity, feature transferability, and\nadaptability of unsupervised learning. It is also regarded as a tutorial for\ndeep learning based WiFi sensing, starting from CSI hardware platform to\nsensing algorithms. The extensive experiments provide us with experiences in\ndeep model design, learning strategy skills and training techniques for\nreal-world applications. To the best of our knowledge, this is the first\nbenchmark with an open-source library for deep learning in WiFi sensing\nresearch. The benchmark codes are available at\nhttps://github.com/CHENXINYAN-sg/WiFi-CSI-Sensing-Benchmark.\n","authors":["Jianfei Yang","Xinyan Chen","Dazhuo Wang","Han Zou","Chris Xiaoxuan Lu","Sumei Sun","Lihua Xie"],"pdf_url":"https://arxiv.org/pdf/2207.07859v2.pdf","comment":"A benchmark and tutorial for WiFi CSI Human sensing based on deep\n  learning methods"},{"id":"http://arxiv.org/abs/2211.07915v4","updated":"2022-12-16T12:30:00Z","published":"2022-11-15T06:00:28Z","title":"Backdoor Attacks on Time Series: A Generative Approach","summary":"  Backdoor attacks have emerged as one of the major security threats to deep\nlearning models as they can easily control the model's test-time predictions by\npre-injecting a backdoor trigger into the model at training time. While\nbackdoor attacks have been extensively studied on images, few works have\ninvestigated the threat of backdoor attacks on time series data. To fill this\ngap, in this paper we present a novel generative approach for time series\nbackdoor attacks against deep learning based time series classifiers. Backdoor\nattacks have two main goals: high stealthiness and high attack success rate. We\nfind that, compared to images, it can be more challenging to achieve the two\ngoals on time series. This is because time series have fewer input dimensions\nand lower degrees of freedom, making it hard to achieve a high attack success\nrate without compromising stealthiness. Our generative approach addresses this\nchallenge by generating trigger patterns that are as realistic as real-time\nseries patterns while achieving a high attack success rate without causing a\nsignificant drop in clean accuracy. We also show that our proposed attack is\nresistant to potential backdoor defenses. Furthermore, we propose a novel\nuniversal generator that can poison any type of time series with a single\ngenerator that allows universal attacks without the need to fine-tune the\ngenerative model for new time series datasets.\n","authors":["Yujing Jiang","Xingjun Ma","Sarah Monazam Erfani","James Bailey"],"pdf_url":"https://arxiv.org/pdf/2211.07915v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05781v2","updated":"2022-12-16T12:06:16Z","published":"2022-12-12T09:07:37Z","title":"Robust Recurrent Neural Network to Identify Ship Motion in Open Water\n  with Performance Guarantees -- Technical Report","summary":"  Recurrent neural networks are capable of learning the dynamics of an unknown\nnonlinear system purely from input-output measurements. However, the resulting\nmodels do not provide any stability guarantees on the input-output mapping. In\nthis work, we represent a recurrent neural network as a linear time-invariant\nsystem with nonlinear disturbances. By introducing constraints on the\nparameters, we can guarantee finite gain stability and incremental finite gain\nstability. We apply this identification method to learn the motion of a\nfour-degrees-of-freedom ship that is moving in open water and compare it\nagainst other purely learning-based approaches with unconstrained parameters.\nOur analysis shows that the constrained recurrent neural network has a lower\nprediction accuracy on the test set, but it achieves comparable results on an\nout-of-distribution set and respects stability conditions.\n","authors":["Daniel Frank","Decky Aspandi Latif","Michael Muehlebach","Benjamin Unger","Steffen Staab"],"pdf_url":"https://arxiv.org/pdf/2212.05781v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.01955v2","updated":"2022-12-16T11:55:00Z","published":"2021-12-03T15:01:52Z","title":"Revisiting Neuron Coverage for DNN Testing: A Layer-Wise and\n  Distribution-Aware Criterion","summary":"  Various deep neural network (DNN) coverage criteria have been proposed to\nassess DNN test inputs and steer input mutations. The coverage is characterized\nvia neurons having certain outputs, or the discrepancy between neuron outputs.\nNevertheless, recent research indicates that neuron coverage criteria show\nlittle correlation with test suite quality.\n  In general, DNNs approximate distributions, by incorporating hierarchical\nlayers, to make predictions for inputs. Thus, we champion to deduce DNN\nbehaviors based on its approximated distributions from a layer perspective. A\ntest suite should be assessed using its induced layer output distributions.\nAccordingly, to fully examine DNN behaviors, input mutation should be directed\ntoward diversifying the approximated distributions.\n  This paper summarizes eight design requirements for DNN coverage criteria,\ntaking into account distribution properties and practical concerns. We then\npropose a new criterion, NeuraL Coverage (NLC), that satisfies all design\nrequirements. NLC treats a single DNN layer as the basic computational unit\n(rather than a single neuron) and captures four critical properties of neuron\noutput distributions. Thus, NLC accurately describes how DNNs comprehend inputs\nvia approximated distributions. We demonstrate that NLC is significantly\ncorrelated with the diversity of a test suite across a number of tasks\n(classification and generation) and data formats (image and text). Its capacity\nto discover DNN prediction errors is promising. Test input mutation guided by\nNLC results in a greater quality and diversity of exposed erroneous behaviors.\n","authors":["Yuanyuan Yuan","Qi Pang","Shuai Wang"],"pdf_url":"https://arxiv.org/pdf/2112.01955v2.pdf","comment":"The extended version of a paper to appear in the Proceedings of the\n  45th IEEE/ACM International Conference on Software Engineering, 2023, (ICSE\n  '23), 14 pages"},{"id":"http://arxiv.org/abs/2212.08423v1","updated":"2022-12-16T11:52:15Z","published":"2022-12-16T11:52:15Z","title":"Context Label Learning: Improving Background Class Representations in\n  Semantic Segmentation","summary":"  Background samples provide key contextual information for segmenting regions\nof interest (ROIs). However, they always cover a diverse set of structures,\ncausing difficulties for the segmentation model to learn good decision\nboundaries with high sensitivity and precision. The issue concerns the highly\nheterogeneous nature of the background class, resulting in multi-modal\ndistributions. Empirically, we find that neural networks trained with\nheterogeneous background struggle to map the corresponding contextual samples\nto compact clusters in feature space. As a result, the distribution over\nbackground logit activations may shift across the decision boundary, leading to\nsystematic over-segmentation across different datasets and tasks. In this\nstudy, we propose context label learning (CoLab) to improve the context\nrepresentations by decomposing the background class into several subclasses.\nSpecifically, we train an auxiliary network as a task generator, along with the\nprimary segmentation model, to automatically generate context labels that\npositively affect the ROI segmentation accuracy. Extensive experiments are\nconducted on several challenging segmentation tasks and datasets. The results\ndemonstrate that CoLab can guide the segmentation model to map the logits of\nbackground samples away from the decision boundary, resulting in significantly\nimproved segmentation accuracy. Code is available.\n","authors":["Zeju Li","Konstantinos Kamnitsas","Cheng Ouyang","Chen Chen","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2212.08423v1.pdf","comment":"Provisionally accepted to IEEE Transactions on Medical Imaging"},{"id":"http://arxiv.org/abs/2212.08420v1","updated":"2022-12-16T11:44:01Z","published":"2022-12-16T11:44:01Z","title":"Fake it till you make it: Learning(s) from a synthetic ImageNet clone","summary":"  Recent large-scale image generation models such as Stable Diffusion have\nexhibited an impressive ability to generate fairly realistic images starting\nfrom a very simple text prompt. Could such models render real images obsolete\nfor training image prediction models? In this paper, we answer part of this\nprovocative question by questioning the need for real images when training\nmodels for ImageNet classification. More precisely, provided only with the\nclass names that have been used to build the dataset, we explore the ability of\nStable Diffusion to generate synthetic clones of ImageNet and measure how\nuseful they are for training classification models from scratch. We show that\nwith minimal and class-agnostic prompt engineering those ImageNet clones we\ndenote as ImageNet-SD are able to close a large part of the gap between models\nproduced by synthetic images and models trained with real images for the\nseveral standard classification benchmarks that we consider in this study. More\nimportantly, we show that models trained on synthetic images exhibit strong\ngeneralization properties and perform on par with models trained on real data.\n","authors":["Mert Bulent Sariyildiz","Karteek Alahari","Diane Larlus","Yannis Kalantidis"],"pdf_url":"https://arxiv.org/pdf/2212.08420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08415v1","updated":"2022-12-16T11:27:50Z","published":"2022-12-16T11:27:50Z","title":"Person Detection Using an Ultra Low-resolution Thermal Imager on a\n  Low-cost MCU","summary":"  Detecting persons in images or video with neural networks is a well-studied\nsubject in literature. However, such works usually assume the availability of a\ncamera of decent resolution and a high-performance processor or GPU to run the\ndetection algorithm, which significantly increases the cost of a complete\ndetection system. However, many applications require low-cost solutions,\ncomposed of cheap sensors and simple microcontrollers. In this paper, we\ndemonstrate that even on such hardware we are not condemned to simple classic\nimage processing techniques. We propose a novel ultra-lightweight CNN-based\nperson detector that processes thermal video from a low-cost 32x24 pixel static\nimager. Trained and compressed on our own recorded dataset, our model achieves\nup to 91.62% accuracy (F1-score), has less than 10k parameters, and runs as\nfast as 87ms and 46ms on low-cost microcontrollers STM32F407 and STM32F746,\nrespectively.\n","authors":["Maarten Vandersteegen","Wouter Reusen","Kristof Van Beeck","Toon Goedemé"],"pdf_url":"https://arxiv.org/pdf/2212.08415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08410v1","updated":"2022-12-16T11:24:42Z","published":"2022-12-16T11:24:42Z","title":"Teaching Small Language Models to Reason","summary":"  Chain of thought prompting successfully improves the reasoning capabilities\nof large language models, achieving state of the art results on a range of\ndatasets. However, these reasoning capabilities only appear to emerge in models\nwith a size of over 100 billion parameters. In this paper, we explore the\ntransfer of such reasoning capabilities to models with less than 100 billion\nparameters via knowledge distillation. Specifically, we finetune a student\nmodel on the chain of thought outputs generated by a larger teacher model. Our\nexperiments show that the proposed method improves task performance across\narithmetic, commonsense and symbolic reasoning datasets. For example, the\naccuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on\nPaLM-540B generated chains of thought.\n","authors":["Lucie Charlotte Magister","Jonathan Mallinson","Jakub Adamek","Eric Malmi","Aliaksei Severyn"],"pdf_url":"https://arxiv.org/pdf/2212.08410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.02704v2","updated":"2022-12-16T11:24:24Z","published":"2022-04-06T10:00:33Z","title":"Fundamental limits to learning closed-form mathematical models from data","summary":"  Given a finite and noisy dataset generated with a closed-form mathematical\nmodel, when is it possible to learn the true generating model from the data\nalone? This is the question we investigate here. We show that this\nmodel-learning problem displays a transition from a low-noise phase in which\nthe true model can be learned, to a phase in which the observation noise is too\nhigh for the true model to be learned by any method. Both in the low-noise\nphase and in the high-noise phase, probabilistic model selection leads to\noptimal generalization to unseen data. This is in contrast to standard machine\nlearning approaches, including artificial neural networks, which in this\nparticular problem are limited, in the low-noise phase, by their ability to\ninterpolate. In the transition region between the learnable and unlearnable\nphases, generalization is hard for all approaches including probabilistic model\nselection.\n","authors":["Oscar Fajardo-Fontiveros","Ignasi Reichardt","Harry R. De Los Rios","Jordi Duch","Marta Sales-Pardo","Roger Guimera"],"pdf_url":"https://arxiv.org/pdf/2204.02704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08408v1","updated":"2022-12-16T11:15:39Z","published":"2022-12-16T11:15:39Z","title":"Decoder Tuning: Efficient Language Understanding as Decoding","summary":"  With the evergrowing sizes of pre-trained models (PTMs), it has been an\nemerging practice to only provide the inference APIs for users, namely\nmodel-as-a-service (MaaS) setting. To adapt PTMs with model parameters frozen,\nmost current approaches focus on the input side, seeking for powerful prompts\nto stimulate models for correct answers. However, we argue that input-side\nadaptation could be arduous due to the lack of gradient signals and they\nusually require thousands of API queries, resulting in high computation and\ntime costs. In light of this, we present Decoder Tuning (DecT), which in\ncontrast optimizes task-specific decoder networks on the output side.\nSpecifically, DecT first extracts prompt-stimulated output scores for initial\npredictions. On top of that, we train an additional decoder network on the\noutput representations to incorporate posterior data knowledge. By\ngradient-based optimization, DecT can be trained within several seconds and\nrequires only one PTM query per sample. Empirically, we conduct extensive\nnatural language understanding experiments and show that DecT significantly\noutperforms state-of-the-art algorithms with a $10^3\\times$ speed-up.\n","authors":["Ganqu Cui","Wentao Li","Ning Ding","Longtao Huang","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2212.08408v1.pdf","comment":"Work in progress. 13 pages"},{"id":"http://arxiv.org/abs/2212.08403v1","updated":"2022-12-16T10:59:03Z","published":"2022-12-16T10:59:03Z","title":"LiFe-net: Data-driven Modelling of Time-dependent Temperatures and\n  Charging Statistics Of Tesla's LiFePo4 EV Battery","summary":"  Modelling the temperature of Electric Vehicle (EV) batteries is a fundamental\ntask of EV manufacturing. Extreme temperatures in the battery packs can affect\ntheir longevity and power output. Although theoretical models exist for\ndescribing heat transfer in battery packs, they are computationally expensive\nto simulate. Furthermore, it is difficult to acquire data measurements from\nwithin the battery cell. In this work, we propose a data-driven surrogate model\n(LiFe-net) that uses readily accessible driving diagnostics for battery\ntemperature estimation to overcome these limitations. This model incorporates\nNeural Operators with a traditional numerical integration scheme to estimate\nthe temperature evolution. Moreover, we propose two further variations of the\nbaseline model: LiFe-net trained with a regulariser and LiFe-net trained with\ntime stability loss. We compared these models in terms of generalization error\non test data. The results showed that LiFe-net trained with time stability loss\noutperforms the other two models and can estimate the temperature evolution on\nunseen data with a relative error of 2.77 % on average.\n","authors":["Jeyhun Rustamov","Luisa Fennert","Nico Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2212.08403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.14311v3","updated":"2022-12-16T10:54:24Z","published":"2022-08-30T14:50:25Z","title":"Modeling Volatility and Dependence of European Carbon and Energy Prices","summary":"  We study the prices of European Emission Allowances (EUA), whereby we analyze\ntheir uncertainty and dependencies on related energy prices (natural gas, coal,\nand oil). We propose a probabilistic multivariate conditional time series model\nwith a VECM-Copula-GARCH structure which exploits key characteristics of the\ndata. Data are normalized with respect to inflation and carbon emissions to\nallow for proper cross-series evaluation. The forecasting performance is\nevaluated in an extensive rolling-window forecasting study, covering eight\nyears out-of-sample. We discuss our findings for both levels- and\nlog-transformed data, focusing on time-varying correlations, and in view of the\nRussian invasion of Ukraine.\n","authors":["Jonathan Berrisch","Sven Pappert","Florian Ziel","Antonia Arsova"],"pdf_url":"https://arxiv.org/pdf/2208.14311v3.pdf","comment":"Accepted for publication in Finance Research Letters"},{"id":"http://arxiv.org/abs/2212.08399v1","updated":"2022-12-16T10:46:20Z","published":"2022-12-16T10:46:20Z","title":"Reducing Sequence Length Learning Impacts on Transformer Models","summary":"  Classification algorithms using Transformer architectures can be affected by\nthe sequence length learning problem whenever observations from different\nclasses have a different length distribution. This problem brings models to use\nsequence length as a predictive feature instead of relying on important textual\ninformation. Even if most public datasets are not affected by this problem,\nprivately corpora for fields such as medicine and insurance may carry this data\nbias. This poses challenges throughout the value chain given their usage in a\nmachine learning application. In this paper, we empirically expose this problem\nand present approaches to minimize its impacts.\n","authors":["Jean-Thomas Baillargeon","Luc Lamontagne"],"pdf_url":"https://arxiv.org/pdf/2212.08399v1.pdf","comment":"10 pages, 8 content - 2 appendix, 2 figures"},{"id":"http://arxiv.org/abs/2212.08379v1","updated":"2022-12-16T10:12:54Z","published":"2022-12-16T10:12:54Z","title":"GeneFormer: Learned Gene Compression using Transformer-based Context\n  Modeling","summary":"  With the development of gene sequencing technology, an explosive growth of\ngene data has been witnessed. And the storage of gene data has become an\nimportant issue. Traditional gene data compression methods rely on general\nsoftware like G-zip, which fails to utilize the interrelation of nucleotide\nsequence. Recently, many researchers begin to investigate deep learning based\ngene data compression method. In this paper, we propose a transformer-based\ngene compression method named GeneFormer. Specifically, we first introduce a\nmodified transformer structure to fully explore the nucleotide sequence\ndependency. Then, we propose fixed-length parallel grouping to accelerate the\ndecoding speed of our autoregressive model. Experimental results on real-world\ndatasets show that our method saves 29.7% bit rate compared with the\nstate-of-the-art method, and the decoding speed is significantly faster than\nall existing learning-based gene compression methods.\n","authors":["Zhanbei Cui","Yu Liao","Tongda Xu","Yan Wang"],"pdf_url":"https://arxiv.org/pdf/2212.08379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.15701v3","updated":"2022-12-16T10:11:53Z","published":"2021-10-29T12:01:48Z","title":"Successor Feature Representations","summary":"  Transfer in Reinforcement Learning aims to improve learning performance on\ntarget tasks using knowledge from experienced source tasks. Successor\nRepresentations (SR) and their extension Successor Features (SF) are prominent\ntransfer mechanisms in domains where reward functions change between tasks.\nThey reevaluate the expected return of previously learned policies in a new\ntarget task to transfer their knowledge. The SF framework extended SR by\nlinearly decomposing rewards into successor features and a reward weight vector\nallowing their application in high-dimensional tasks. But this came with the\ncost of having a linear relationship between reward functions and successor\nfeatures, limiting its application to such tasks. We propose a novel\nformulation of SR based on learning the cumulative discounted probability of\nsuccessor features, called Successor Feature Representations (SFR). Crucially,\nSFR allows to reevaluate the expected return of policies for general reward\nfunctions. We introduce different SFR variations, prove its convergence, and\nprovide a guarantee on its transfer performance. Experimental evaluations based\non SFR with function approximation demonstrate its advantage over SF not only\nfor general reward functions but also in the case of linearly decomposable\nreward functions.\n","authors":["Chris Reinke","Xavier Alameda-Pineda"],"pdf_url":"https://arxiv.org/pdf/2110.15701v3.pdf","comment":"source code available at\n  https://gitlab.inria.fr/robotlearn/sfr_learning [v2] added experiments with\n  learned features [v3] renamed paper and changed scope"},{"id":"http://arxiv.org/abs/2212.08378v1","updated":"2022-12-16T10:08:38Z","published":"2022-12-16T10:08:38Z","title":"Feature Dropout: Revisiting the Role of Augmentations in Contrastive\n  Learning","summary":"  What role do augmentations play in contrastive learning? Recent work suggests\nthat good augmentations are label-preserving with respect to a specific\ndownstream task. We complicate this picture by showing that label-destroying\naugmentations can be useful in the foundation model setting, where the goal is\nto learn diverse, general-purpose representations for multiple downstream\ntasks. We perform contrastive learning experiments on a range of image and\naudio datasets with multiple downstream tasks (e.g. for digits superimposed on\nphotographs, predicting the class of one vs. the other). We find that Viewmaker\nNetworks, a recently proposed model for learning augmentations for contrastive\nlearning, produce label-destroying augmentations that stochastically destroy\nfeatures needed for different downstream tasks. These augmentations are\ninterpretable (e.g. altering shapes, digits, or letters added to images) and\nsurprisingly often result in better performance compared to expert-designed\naugmentations, despite not preserving label information. To support our\nempirical results, we theoretically analyze a simple contrastive learning\nsetting with a linear model. In this setting, label-destroying augmentations\nare crucial for preventing one set of features from suppressing the learning of\nfeatures useful for another downstream task. Our results highlight the need for\nanalyzing the interaction between multiple downstream tasks when trying to\nexplain the success of foundation models.\n","authors":["Alex Tamkin","Margalit Glasgow","Xiluo He","Noah Goodman"],"pdf_url":"https://arxiv.org/pdf/2212.08378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.10102v3","updated":"2022-12-16T09:52:47Z","published":"2020-06-17T18:54:03Z","title":"Capturing Label Characteristics in VAEs","summary":"  We present a principled approach to incorporating labels in VAEs that\ncaptures the rich characteristic information associated with those labels.\nWhile prior work has typically conflated these by learning latent variables\nthat directly correspond to label values, we argue this is contrary to the\nintended effect of supervision in VAEs-capturing rich label characteristics\nwith the latents. For example, we may want to capture the characteristics of a\nface that make it look young, rather than just the age of the person. To this\nend, we develop the CCVAE, a novel VAE model and concomitant variational\nobjective which captures label characteristics explicitly in the latent space,\neschewing direct correspondences between label values and latents. Through\njudicious structuring of mappings between such characteristic latents and\nlabels, we show that the CCVAE can effectively learn meaningful representations\nof the characteristics of interest across a variety of supervision schemes. In\nparticular, we show that the CCVAE allows for more effective and more general\ninterventions to be performed, such as smooth traversals within the\ncharacteristics for a given label, diverse conditional generation, and\ntransferring characteristics across datapoints.\n","authors":["Tom Joy","Sebastian M. Schmon","Philip H. S. Torr","N. Siddharth","Tom Rainforth"],"pdf_url":"https://arxiv.org/pdf/2006.10102v3.pdf","comment":"Accepted to ICLR 2021"},{"id":"http://arxiv.org/abs/2212.04800v2","updated":"2022-12-16T09:47:43Z","published":"2022-12-09T12:06:15Z","title":"AUC Maximization for Low-Resource Named Entity Recognition","summary":"  Current work in named entity recognition (NER) uses either cross entropy (CE)\nor conditional random fields (CRF) as the objective/loss functions to optimize\nthe underlying NER model. Both of these traditional objective functions for the\nNER problem generally produce adequate performance when the data distribution\nis balanced and there are sufficient annotated training examples. But since NER\nis inherently an imbalanced tagging problem, the model performance under the\nlow-resource settings could suffer using these standard objective functions.\nBased on recent advances in area under the ROC curve (AUC) maximization, we\npropose to optimize the NER model by maximizing the AUC score. We give evidence\nthat by simply combining two binary-classifiers that maximize the AUC score,\nsignificant performance improvement over traditional loss functions is achieved\nunder low-resource NER settings. We also conduct extensive experiments to\ndemonstrate the advantages of our method under the low-resource and\nhighly-imbalanced data distribution settings. To the best of our knowledge,\nthis is the first work that brings AUC maximization to the NER setting.\nFurthermore, we show that our method is agnostic to different types of NER\nembeddings, models and domains. The code to replicate this work will be\nprovided upon request.\n","authors":["Ngoc Dang Nguyen","Wei Tan","Wray Buntine","Richard Beare","Changyou Chen","Lan Du"],"pdf_url":"https://arxiv.org/pdf/2212.04800v2.pdf","comment":"10 pages, 4 figures, AAAI 2023 accepted paper"},{"id":"http://arxiv.org/abs/2212.08370v1","updated":"2022-12-16T09:45:22Z","published":"2022-12-16T09:45:22Z","title":"Shapley variable importance cloud for machine learning models","summary":"  Current practice in interpretable machine learning often focuses on\nexplaining the final model trained from data, e.g., by using the Shapley\nadditive explanations (SHAP) method. The recently developed Shapley variable\nimportance cloud (ShapleyVIC) extends the current practice to a group of\n\"nearly optimal models\" to provide comprehensive and robust variable importance\nassessments, with estimated uncertainty intervals for a more complete\nunderstanding of variable contributions to predictions. ShapleyVIC was\ninitially developed for applications with traditional regression models, and\nthe benefits of ShapleyVIC inference have been demonstrated in real-life\nprediction tasks using the logistic regression model. However, as a\nmodel-agnostic approach, ShapleyVIC application is not limited to such\nscenarios. In this work, we extend ShapleyVIC implementation for machine\nlearning models to enable wider applications, and propose it as a useful\ncomplement to the current SHAP analysis to enable more trustworthy applications\nof these black-box models.\n","authors":["Yilin Ning","Mingxuan Liu","Nan Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06108v2","updated":"2022-12-16T09:40:57Z","published":"2022-11-11T10:24:42Z","title":"RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object\n  Detection System","summary":"  In autonomous driving systems, LiDAR and radar play important roles in the\nperception of the surrounding environment.LiDAR provides accurate 3D spatial\nsensing information but cannot work in adverse weather like fog. On the other\nhand, the radar signal can be diffracted when encountering raindrops or mist\nparticles thanks to its wavelength, but it suffers from large noise. Recent\nstate-of-the-art works reveal that fusion of radar and LiDAR can lead to robust\ndetection in adverse weather. The existing works adopt convolutional neural\nnetwork architecture to extract features from each sensor data stream, then\nalign and aggregate the two branch features to predict object detection\nresults. However, these methods have low accuracy of bounding box estimations\ndue to a simple design of label assignment and fusion strategies. In this\npaper, we propose a bird's-eye view fusion learning-based anchor box-free\nobject detection system, which fuses the feature derived from the radar\nrange-azimuth heatmap and the LiDAR point cloud to estimate the possible\nobjects. Different label assignment strategies have been designed to facilitate\nthe consistency between the classification of foreground or background anchor\npoints and the corresponding bounding box regressions. In addition, the\nperformance of the proposed object detector is further enhanced by employing a\nnovel interactive transformer module. The superior performance of the proposed\nmethods in this paper has been demonstrated using the recently published Oxford\nradar robotCar dataset, showing that the average precision of our system\nsignificantly outperforms the best state-of-the-art method by 14.4% and 20.5%\nat IoU equals 0.8 in clear and foggy weather testing, respectively.\n","authors":["Yanlong Yang","Jianan Liu","Tao Huang","Qing-Long Han","Gang Ma","Bing Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.06108v2.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2106.12570v3","updated":"2022-12-16T09:29:56Z","published":"2021-06-23T17:54:35Z","title":"Learning Multimodal VAEs through Mutual Supervision","summary":"  Multimodal VAEs seek to model the joint distribution over heterogeneous data\n(e.g.\\ vision, language), whilst also capturing a shared representation across\nsuch modalities. Prior work has typically combined information from the\nmodalities by reconciling idiosyncratic representations directly in the\nrecognition model through explicit products, mixtures, or other such\nfactorisations. Here we introduce a novel alternative, the MEME, that avoids\nsuch explicit combinations by repurposing semi-supervised VAEs to combine\ninformation between modalities implicitly through mutual supervision. This\nformulation naturally allows learning from partially-observed data where some\nmodalities can be entirely missing -- something that most existing approaches\neither cannot handle, or do so to a limited extent. We demonstrate that MEME\noutperforms baselines on standard metrics across both partial and complete\nobservation schemes on the MNIST-SVHN (image-image) and CUB (image-text)\ndatasets. We also contrast the quality of the representations learnt by mutual\nsupervision against standard approaches and observe interesting trends in its\nability to capture relatedness between data.\n","authors":["Tom Joy","Yuge Shi","Philip H. S. Torr","Tom Rainforth","Sebastian M. Schmon","N. Siddharth"],"pdf_url":"https://arxiv.org/pdf/2106.12570v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.10779v4","updated":"2022-12-16T09:04:36Z","published":"2022-04-18T04:51:08Z","title":"CgAT: Center-Guided Adversarial Training for Deep Hashing-Based\n  Retrieval","summary":"  Deep hashing has been extensively utilized in massive image retrieval because\nof its efficiency and effectiveness. However, deep hashing models are\nvulnerable to adversarial examples, making it essential to develop adversarial\ndefense methods for image retrieval. Existing solutions achieved limited\ndefense performance because of using weak adversarial samples for training and\nlacking discriminative optimization objectives to learn robust features. In\nthis paper, we present a min-max based Center-guided Adversarial Training,\nnamely CgAT, to improve the robustness of deep hashing networks through worst\nadversarial examples. Specifically, we first formulate the center code as a\nsemantically-discriminative representative of the input image content, which\npreserves the semantic similarity with positive samples and dissimilarity with\nnegative examples. We prove that a mathematical formula can calculate the\ncenter code immediately. After obtaining the center codes in each optimization\niteration of the deep hashing network, they are adopted to guide the\nadversarial training process. On the one hand, CgAT generates the worst\nadversarial examples as augmented data by maximizing the Hamming distance\nbetween the hash codes of the adversarial examples and the center codes. On the\nother hand, CgAT learns to mitigate the effects of adversarial samples by\nminimizing the Hamming distance to the center codes. Extensive experiments on\nthe benchmark datasets demonstrate the effectiveness of our adversarial\ntraining algorithm in defending against adversarial attacks for deep\nhashing-based retrieval. Compared with the current state-of-the-art defense\nmethod, we significantly improve the defense performance by an average of\n18.61%, 12.35%, and 11.56% on FLICKR-25K, NUS-WIDE, and MS-COCO, respectively.\n","authors":["Xunguang Wang","Yinqun Lin","Xiaomeng Li"],"pdf_url":"https://arxiv.org/pdf/2204.10779v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08349v1","updated":"2022-12-16T08:57:18Z","published":"2022-12-16T08:57:18Z","title":"Swing Distillation: A Privacy-Preserving Knowledge Distillation\n  Framework","summary":"  Knowledge distillation (KD) has been widely used for model compression and\nknowledge transfer. Typically, a big teacher model trained on sufficient data\ntransfers knowledge to a small student model. However, despite the success of\nKD, little effort has been made to study whether KD leaks the training data of\nthe teacher model. In this paper, we experimentally reveal that KD suffers from\nthe risk of privacy leakage. To alleviate this issue, we propose a novel\nknowledge distillation method, swing distillation, which can effectively\nprotect the private information of the teacher model from flowing to the\nstudent model. In our framework, the temperature coefficient is dynamically and\nadaptively adjusted according to the degree of private information contained in\nthe data, rather than a predefined constant hyperparameter. It assigns\ndifferent temperatures to tokens according to the likelihood that a token in a\nposition contains private information. In addition, we inject noise into soft\ntargets provided to the student model, in order to avoid unshielded knowledge\ntransfer. Experiments on multiple datasets and tasks demonstrate that the\nproposed swing distillation can significantly reduce (by over 80% in terms of\ncanary exposure) the risk of privacy leakage in comparison to KD with\ncompetitive or better performance. Furthermore, swing distillation is robust\nagainst the increasing privacy budget.\n","authors":["Junzhuo Li","Xinwei Wu","Weilong Dong","Shuangzhi Wu","Chao Bian","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2212.08349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.05075v4","updated":"2022-12-16T08:49:08Z","published":"2021-08-11T07:37:03Z","title":"Jujutsu: A Two-stage Defense against Adversarial Patch Attacks on Deep\n  Neural Networks","summary":"  Adversarial patch attacks create adversarial examples by injecting arbitrary\ndistortions within a bounded region of the input to fool deep neural networks\n(DNNs). These attacks are robust (i.e., physically-realizable) and universally\nmalicious, and hence represent a severe security threat to real-world DNN-based\nsystems.\n  We propose Jujutsu, a two-stage technique to detect and mitigate robust and\nuniversal adversarial patch attacks. We first observe that adversarial patches\nare crafted as localized features that yield large influence on the prediction\noutput, and continue to dominate the prediction on any input. Jujutsu leverages\nthis observation for accurate attack detection with low false positives. Patch\nattacks corrupt only a localized region of the input, while the majority of the\ninput remains unperturbed. Therefore, Jujutsu leverages generative adversarial\nnetworks (GAN) to perform localized attack recovery by synthesizing the\nsemantic contents of the input that are corrupted by the attacks, and\nreconstructs a ``clean'' input for correct prediction.\n  We evaluate Jujutsu on four diverse datasets spanning 8 different DNN models,\nand find that it achieves superior performance and significantly outperforms\nfour existing defenses. We further evaluate Jujutsu against physical-world\nattacks, as well as adaptive attacks.\n","authors":["Zitao Chen","Pritam Dash","Karthik Pattabiraman"],"pdf_url":"https://arxiv.org/pdf/2108.05075v4.pdf","comment":"To appear in AsiaCCS'23"},{"id":"http://arxiv.org/abs/2210.08349v2","updated":"2022-12-16T08:41:45Z","published":"2022-10-15T17:57:43Z","title":"When to Update Your Model: Constrained Model-based Reinforcement\n  Learning","summary":"  Designing and analyzing model-based RL (MBRL) algorithms with guaranteed\nmonotonic improvement has been challenging, mainly due to the interdependence\nbetween policy optimization and model learning. Existing discrepancy bounds\ngenerally ignore the impacts of model shifts, and their corresponding\nalgorithms are prone to degrade performance by drastic model updating. In this\nwork, we first propose a novel and general theoretical scheme for a\nnon-decreasing performance guarantee of MBRL. Our follow-up derived bounds\nreveal the relationship between model shifts and performance improvement. These\ndiscoveries encourage us to formulate a constrained lower-bound optimization\nproblem to permit the monotonicity of MBRL. A further example demonstrates that\nlearning models from a dynamically-varying number of explorations benefit the\neventual returns. Motivated by these analyses, we design a simple but effective\nalgorithm CMLO (Constrained Model-shift Lower-bound Optimization), by\nintroducing an event-triggered mechanism that flexibly determines when to\nupdate the model. Experiments show that CMLO surpasses other state-of-the-art\nmethods and produces a boost when various policy optimization methods are\nemployed.\n","authors":["Tianying Ji","Yu Luo","Fuchun Sun","Mingxuan Jing","Fengxiang He","Wenbing Huang"],"pdf_url":"https://arxiv.org/pdf/2210.08349v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2105.04187v3","updated":"2022-12-16T08:37:34Z","published":"2021-05-10T08:33:10Z","title":"A Rigorous Information-Theoretic Definition of Redundancy and Relevancy\n  in Feature Selection Based on (Partial) Information Decomposition","summary":"  Selecting a minimal feature set that is maximally informative about a target\nvariable is a central task in machine learning and statistics. Information\ntheory provides a powerful framework for formulating feature selection\nalgorithms -- yet, a rigorous, information-theoretic definition of feature\nrelevancy, which accounts for feature interactions such as redundant and\nsynergistic contributions, is still missing. We argue that this lack is\ninherent to classical information theory which does not provide measures to\ndecompose the information a set of variables provides about a target into\nunique, redundant, and synergistic contributions. Such a decomposition has been\nintroduced only recently by the partial information decomposition (PID)\nframework. Using PID, we clarify why feature selection is a conceptually\ndifficult problem when approached using information theory and provide a novel\ndefinition of feature relevancy and redundancy in PID terms. From this\ndefinition, we show that the conditional mutual information (CMI) maximizes\nrelevancy while minimizing redundancy and propose an iterative, CMI-based\nalgorithm for practical feature selection. We demonstrate the power of our\nCMI-based algorithm in comparison to the unconditional mutual information on\nbenchmark examples and provide corresponding PID estimates to highlight how PID\nallows to quantify information contribution of features and their interactions\nin feature-selection problems.\n","authors":["Patricia Wollstadt","Sebastian Schmitt","Michael Wibral"],"pdf_url":"https://arxiv.org/pdf/2105.04187v3.pdf","comment":"43 pages, 12 figures. Reorganization and shortening of manuscript,\n  added Appendix with theoretical guarantees, background information on the\n  algorithm used, and an additional example application on a larger problem"},{"id":"http://arxiv.org/abs/2212.08343v1","updated":"2022-12-16T08:37:24Z","published":"2022-12-16T08:37:24Z","title":"SplitGP: Achieving Both Generalization and Personalization in Federated\n  Learning","summary":"  A fundamental challenge to providing edge-AI services is the need for a\nmachine learning (ML) model that achieves personalization (i.e., to individual\nclients) and generalization (i.e., to unseen data) properties concurrently.\nExisting techniques in federated learning (FL) have encountered a steep\ntradeoff between these objectives and impose large computational requirements\non edge devices during training and inference. In this paper, we propose\nSplitGP, a new split learning solution that can simultaneously capture\ngeneralization and personalization capabilities for efficient inference across\nresource-constrained clients (e.g., mobile/IoT devices). Our key idea is to\nsplit the full ML model into client-side and server-side components, and impose\ndifferent roles to them: the client-side model is trained to have strong\npersonalization capability optimized to each client's main task, while the\nserver-side model is trained to have strong generalization capability for\nhandling all clients' out-of-distribution tasks. We analytically characterize\nthe convergence behavior of SplitGP, revealing that all client models approach\nstationary points asymptotically. Further, we analyze the inference time in\nSplitGP and provide bounds for determining model split ratios. Experimental\nresults show that SplitGP outperforms existing baselines by wide margins in\ninference time and test accuracy for varying amounts of out-of-distribution\nsamples.\n","authors":["Dong-Jun Han","Do-Yeon Kim","Minseok Choi","Christopher G. Brinton","Jaekyun Moon"],"pdf_url":"https://arxiv.org/pdf/2212.08343v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2209.12590v2","updated":"2022-12-16T08:37:14Z","published":"2022-09-26T11:21:19Z","title":"Learning to Drop Out: An Adversarial Approach to Training Sequence VAEs","summary":"  In principle, applying variational autoencoders (VAEs) to sequential data\noffers a method for controlled sequence generation, manipulation, and\nstructured representation learning. However, training sequence VAEs is\nchallenging: autoregressive decoders can often explain the data without\nutilizing the latent space, known as posterior collapse. To mitigate this,\nstate-of-the-art models weaken the powerful decoder by applying uniformly\nrandom dropout to the decoder input. We show theoretically that this removes\npointwise mutual information provided by the decoder input, which is\ncompensated for by utilizing the latent space. We then propose an adversarial\ntraining strategy to achieve information-based stochastic dropout. Compared to\nuniform dropout on standard text benchmark datasets, our targeted approach\nincreases both sequence modeling performance and the information captured in\nthe latent space.\n","authors":["Đorđe Miladinović","Kumar Shridhar","Kushal Jain","Max B. Paulus","Joachim M. Buhmann","Mrinmaya Sachan","Carl Allen"],"pdf_url":"https://arxiv.org/pdf/2209.12590v2.pdf","comment":"Accepted at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.08341v1","updated":"2022-12-16T08:35:21Z","published":"2022-12-16T08:35:21Z","title":"Adversarial Example Defense via Perturbation Grading Strategy","summary":"  Deep Neural Networks have been widely used in many fields. However, studies\nhave shown that DNNs are easily attacked by adversarial examples, which have\ntiny perturbations and greatly mislead the correct judgment of DNNs.\nFurthermore, even if malicious attackers cannot obtain all the underlying model\nparameters, they can use adversarial examples to attack various DNN-based task\nsystems. Researchers have proposed various defense methods to protect DNNs,\nsuch as reducing the aggressiveness of adversarial examples by preprocessing or\nimproving the robustness of the model by adding modules. However, some defense\nmethods are only effective for small-scale examples or small perturbations but\nhave limited defense effects for adversarial examples with large perturbations.\nThis paper assigns different defense strategies to adversarial perturbations of\ndifferent strengths by grading the perturbations on the input examples.\nExperimental results show that the proposed method effectively improves defense\nperformance. In addition, the proposed method does not modify any task model,\nwhich can be used as a preprocessing module, which significantly reduces the\ndeployment cost in practical applications.\n","authors":["Shaowei Zhu","Wanli Lyu","Bin Li","Zhaoxia Yin","Bin Luo"],"pdf_url":"https://arxiv.org/pdf/2212.08341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08340v1","updated":"2022-12-16T08:31:07Z","published":"2022-12-16T08:31:07Z","title":"Neural Enhanced Belief Propagation for Multiobject Tracking","summary":"  Algorithmic solutions for multi-object tracking (MOT) are a key enabler for\napplications in autonomous navigation and applied ocean sciences.\nState-of-the-art MOT methods fully rely on a statistical model and typically\nuse preprocessed sensor data as measurements. In particular, measurements are\nproduced by a detector that extracts potential object locations from the raw\nsensor data collected for a discrete time step. This preparatory processing\nstep reduces data flow and computational complexity but may result in a loss of\ninformation. State-of-the-art Bayesian MOT methods that are based on belief\npropagation (BP) systematically exploit graph structures of the statistical\nmodel to reduce computational complexity and improve scalability. However, as a\nfully model-based approach, BP can only provide suboptimal estimates when there\nis a mismatch between the statistical model and the true data-generating\nprocess. Existing BP-based MOT methods can further only make use of\npreprocessed measurements. In this paper, we introduce a variant of BP that\ncombines model-based with data-driven MOT. The proposed neural enhanced belief\npropagation (NEBP) method complements the statistical model of BP by\ninformation learned from raw sensor data. This approach conjectures that the\nlearned information can reduce model mismatch and thus improve data association\nand false alarm rejection. Our NEBP method improves tracking performance\ncompared to model-based methods. At the same time, it inherits the advantages\nof BP-based MOT, i.e., it scales only quadratically in the number of objects,\nand it can thus generate and maintain a large number of object tracks. We\nevaluate the performance of our NEBP approach for MOT on the nuScenes\nautonomous driving dataset and demonstrate that it has state-of-the-art\nperformance.\n","authors":["Mingchao Liang","Florian Meyer"],"pdf_url":"https://arxiv.org/pdf/2212.08340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08339v1","updated":"2022-12-16T08:30:41Z","published":"2022-12-16T08:30:41Z","title":"Generalization Bounds for Inductive Matrix Completion in Low-noise\n  Settings","summary":"  We study inductive matrix completion (matrix completion with side\ninformation) under an i.i.d. subgaussian noise assumption at a low noise\nregime, with uniform sampling of the entries. We obtain for the first time\ngeneralization bounds with the following three properties: (1) they scale like\nthe standard deviation of the noise and in particular approach zero in the\nexact recovery case; (2) even in the presence of noise, they converge to zero\nwhen the sample size approaches infinity; and (3) for a fixed dimension of the\nside information, they only have a logarithmic dependence on the size of the\nmatrix. Differently from many works in approximate recovery, we present results\nboth for bounded Lipschitz losses and for the absolute loss, with the latter\nrelying on Talagrand-type inequalities. The proofs create a bridge between two\napproaches to the theoretical analysis of matrix completion, since they consist\nin a combination of techniques from both the exact recovery literature and the\napproximate recovery literature.\n","authors":["Antoine Ledent","Rodrigo Alves","Yunwen Lei","Yann Guermeur","Marius Kloft"],"pdf_url":"https://arxiv.org/pdf/2212.08339v1.pdf","comment":"30 Pages, 1 figure; Accepted for publication at AAAI 2023"},{"id":"http://arxiv.org/abs/2209.08037v2","updated":"2022-12-16T08:23:09Z","published":"2022-09-16T16:31:27Z","title":"DAGMA: Learning DAGs via M-matrices and a Log-Determinant Acyclicity\n  Characterization","summary":"  The combinatorial problem of learning directed acyclic graphs (DAGs) from\ndata was recently framed as a purely continuous optimization problem by\nleveraging a differentiable acyclicity characterization of DAGs based on the\ntrace of a matrix exponential function. Existing acyclicity characterizations\nare based on the idea that powers of an adjacency matrix contain information\nabout walks and cycles. In this work, we propose a new acyclicity\ncharacterization based on the log-determinant (log-det) function, which\nleverages the nilpotency property of DAGs. To deal with the inherent\nasymmetries of a DAG, we relate the domain of our log-det characterization to\nthe set of $\\textit{M-matrices}$, which is a key difference to the classical\nlog-det function defined over the cone of positive definite matrices. Similar\nto acyclicity functions previously proposed, our characterization is also exact\nand differentiable. However, when compared to existing characterizations, our\nlog-det function: (1) Is better at detecting large cycles; (2) Has\nbetter-behaved gradients; and (3) Its runtime is in practice about an order of\nmagnitude faster. From the optimization side, we drop the typically used\naugmented Lagrangian scheme and propose DAGMA ($\\textit{DAGs via M-matrices for\nAcyclicity}$), a method that resembles the central path for barrier methods.\nEach point in the central path of DAGMA is a solution to an unconstrained\nproblem regularized by our log-det function, then we show that at the limit of\nthe central path the solution is guaranteed to be a DAG. Finally, we provide\nextensive experiments for $\\textit{linear}$ and $\\textit{nonlinear}$ SEMs and\nshow that our approach can reach large speed-ups and smaller structural Hamming\ndistances against state-of-the-art methods. Code implementing the proposed\nmethod is open-source and publicly available at\nhttps://github.com/kevinsbello/dagma.\n","authors":["Kevin Bello","Bryon Aragam","Pradeep Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2209.08037v2.pdf","comment":"28 pages, 13 figures, published at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.08330v1","updated":"2022-12-16T08:14:04Z","published":"2022-12-16T08:14:04Z","title":"Convolution-enhanced Evolving Attention Networks","summary":"  Attention-based neural networks, such as Transformers, have become ubiquitous\nin numerous applications, including computer vision, natural language\nprocessing, and time-series analysis. In all kinds of attention networks, the\nattention maps are crucial as they encode semantic dependencies between input\ntokens. However, most existing attention networks perform modeling or reasoning\nbased on representations, wherein the attention maps of different layers are\nlearned separately without explicit interactions. In this paper, we propose a\nnovel and generic evolving attention mechanism, which directly models the\nevolution of inter-token relationships through a chain of residual\nconvolutional modules. The major motivations are twofold. On the one hand, the\nattention maps in different layers share transferable knowledge, thus adding a\nresidual connection can facilitate the information flow of inter-token\nrelationships across layers. On the other hand, there is naturally an\nevolutionary trend among attention maps at different abstraction levels, so it\nis beneficial to exploit a dedicated convolution-based module to capture this\nprocess. Equipped with the proposed mechanism, the convolution-enhanced\nevolving attention networks achieve superior performance in various\napplications, including time-series representation, natural language\nunderstanding, machine translation, and image classification. Especially on\ntime-series representation tasks, Evolving Attention-enhanced Dilated\nConvolutional (EA-DC-) Transformer outperforms state-of-the-art models\nsignificantly, achieving an average of 17% improvement compared to the best\nSOTA. To the best of our knowledge, this is the first work that explicitly\nmodels the layer-wise evolution of attention maps. Our implementation is\navailable at https://github.com/pkuyym/EvolvingAttention\n","authors":["Yujing Wang","Yaming Yang","Zhuo Li","Jiangang Bai","Mingliang Zhang","Xiangtai Li","Jing Yu","Ce Zhang","Gao Huang","Yunhai Tong"],"pdf_url":"https://arxiv.org/pdf/2212.08330v1.pdf","comment":"Extension of the previous work (arXiv:2102.12895). arXiv admin note:\n  text overlap with arXiv:2102.12895"},{"id":"http://arxiv.org/abs/2212.08324v1","updated":"2022-12-16T07:53:05Z","published":"2022-12-16T07:53:05Z","title":"Mobile Augmented Reality with Federated Learning in the Metaverse","summary":"  The Metaverse is deemed the next evolution of the Internet and has received\nmuch attention recently. Metaverse applications via mobile augmented reality\n(MAR) require rapid and accurate object detection to mix digital data with the\nreal world. As mobile devices evolve, they become more potent in computing.\nHence, their computational resources can be leveraged to train machine learning\nmodels. In light of the increasing concerns of user privacy and data security,\nfederated learning (FL) has become a promising distributed learning framework\nfor privacy-preserving analytics. In this article, FL and MAR are brought\ntogether in the Metaverse. We discuss the necessity and rationality of the\ncombination of FL and MAR. The prospective technologies that power FL and MAR\nin the Metaverse are also identified. In addition, existing challenges that\nprevent the fulfilment of FL and MAR in the Metaverse and several application\nscenarios are presented. Finally, two case studies of Metaverse FL-MAR systems\nare demonstrated.\n","authors":["Xinyu Zhou","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2212.08324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08323v1","updated":"2022-12-16T07:49:15Z","published":"2022-12-16T07:49:15Z","title":"An ensemble neural network approach to forecast Dengue outbreak based on\n  climatic condition","summary":"  Dengue fever is a virulent disease spreading over 100 tropical and\nsubtropical countries in Africa, the Americas, and Asia. This arboviral disease\naffects around 400 million people globally, severely distressing the healthcare\nsystems. The unavailability of a specific drug and ready-to-use vaccine makes\nthe situation worse. Hence, policymakers must rely on early warning systems to\ncontrol intervention-related decisions. Forecasts routinely provide critical\ninformation for dangerous epidemic events. However, the available forecasting\nmodels (e.g., weather-driven mechanistic, statistical time series, and machine\nlearning models) lack a clear understanding of different components to improve\nprediction accuracy and often provide unstable and unreliable forecasts. This\nstudy proposes an ensemble wavelet neural network with exogenous factor(s)\n(XEWNet) model that can produce reliable estimates for dengue outbreak\nprediction for three geographical regions, namely San Juan, Iquitos, and\nAhmedabad. The proposed XEWNet model is flexible and can easily incorporate\nexogenous climate variable(s) confirmed by statistical causality tests in its\nscalable framework. The proposed model is an integrated approach that uses\nwavelet transformation into an ensemble neural network framework that helps in\ngenerating more reliable long-term forecasts. The proposed XEWNet allows\ncomplex non-linear relationships between the dengue incidence cases and\nrainfall; however, mathematically interpretable, fast in execution, and easily\ncomprehensible. The proposal's competitiveness is measured using computational\nexperiments based on various statistical metrics and several statistical\ncomparison tests. In comparison with statistical, machine learning, and deep\nlearning methods, our proposed XEWNet performs better in 75% of the cases for\nshort-term and long-term forecasting of dengue incidence.\n","authors":["Madhurima Panja","Tanujit Chakraborty","Sk Shahid Nadim","Indrajit Ghosh","Uttam Kumar","Nan Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08312v1","updated":"2022-12-16T07:24:58Z","published":"2022-12-16T07:24:58Z","title":"An Efficient Framework for Monitoring Subgroup Performance of Machine\n  Learning Systems","summary":"  Monitoring machine learning systems post deployment is critical to ensure the\nreliability of the systems. Particularly importance is the problem of\nmonitoring the performance of machine learning systems across all the data\nsubgroups (subpopulations). In practice, this process could be prohibitively\nexpensive as the number of data subgroups grows exponentially with the number\nof input features, and the process of labelling data to evaluate each\nsubgroup's performance is costly. In this paper, we propose an efficient\nframework for monitoring subgroup performance of machine learning systems.\nSpecifically, we aim to find the data subgroup with the worst performance using\na limited number of labeled data. We mathematically formulate this problem as\nan optimization problem with an expensive black-box objective function, and\nthen suggest to use Bayesian optimization to solve this problem. Our\nexperimental results on various real-world datasets and machine learning\nsystems show that our proposed framework can retrieve the worst-performing data\nsubgroup effectively and efficiently.\n","authors":["Huong Ha"],"pdf_url":"https://arxiv.org/pdf/2212.08312v1.pdf","comment":"Accepted to the ML Safety Workshop at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.08311v1","updated":"2022-12-16T07:20:28Z","published":"2022-12-16T07:20:28Z","title":"Can We Find Strong Lottery Tickets in Generative Models?","summary":"  Yes. In this paper, we investigate strong lottery tickets in generative\nmodels, the subnetworks that achieve good generative performance without any\nweight update. Neural network pruning is considered the main cornerstone of\nmodel compression for reducing the costs of computation and memory.\nUnfortunately, pruning a generative model has not been extensively explored,\nand all existing pruning algorithms suffer from excessive weight-training\ncosts, performance degradation, limited generalizability, or complicated\ntraining. To address these problems, we propose to find a strong lottery ticket\nvia moment-matching scores. Our experimental results show that the discovered\nsubnetwork can perform similarly or better than the trained dense model even\nwhen only 10% of the weights remain. To the best of our knowledge, we are the\nfirst to show the existence of strong lottery tickets in generative models and\nprovide an algorithm to find it stably. Our code and supplementary materials\nare publicly available.\n","authors":["Sangyeop Yeo","Yoojin Jang","Jy-yong Sohn","Dongyoon Han","Jaejun Yoo"],"pdf_url":"https://arxiv.org/pdf/2212.08311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05833v2","updated":"2022-12-16T07:14:59Z","published":"2022-10-11T23:26:47Z","title":"Parameter estimation of the homodyned K distribution based on neural\n  networks and trainable fractional-order moments","summary":"  Homodyned K (HK) distribution has been widely used to describe the scattering\nphenomena arising in various research fields, such as ultrasound imaging or\noptics. In this work, we propose a machine learning based approach to the\nestimation of the HK distribution parameters. We develop neural networks that\ncan estimate the HK distribution parameters based on the signal-to-noise ratio,\nskewness and kurtosis calculated using fractional-order moments. Compared to\nthe previous approaches, we consider the orders of the moments as trainable\nvariables that can be optimized along with the network weights using the\nback-propagation algorithm. Networks are trained based on samples generated\nfrom the HK distribution. Obtained results demonstrate that the proposed method\ncan be used to accurately estimate the HK distribution parameters.\n","authors":["Michal Byra","Ziemowit Klimonda","Piotr Jarosik"],"pdf_url":"https://arxiv.org/pdf/2210.05833v2.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.08302v1","updated":"2022-12-16T06:43:16Z","published":"2022-12-16T06:43:16Z","title":"Safe Evaluation For Offline Learning: Are We Ready To Deploy?","summary":"  The world currently offers an abundance of data in multiple domains, from\nwhich we can learn reinforcement learning (RL) policies without further\ninteraction with the environment. RL agents learning offline from such data is\npossible but deploying them while learning might be dangerous in domains where\nsafety is critical. Therefore, it is essential to find a way to estimate how a\nnewly-learned agent will perform if deployed in the target environment before\nactually deploying it and without the risk of overestimating its true\nperformance. To achieve this, we introduce a framework for safe evaluation of\noffline learning using approximate high-confidence off-policy evaluation\n(HCOPE) to estimate the performance of offline policies during learning. In our\nsetting, we assume a source of data, which we split into a train-set, to learn\nan offline policy, and a test-set, to estimate a lower-bound on the offline\npolicy using off-policy evaluation with bootstrapping. A lower-bound estimate\ntells us how good a newly-learned target policy would perform before it is\ndeployed in the real environment, and therefore allows us to decide when to\ndeploy our learned policy.\n","authors":["Hager Radi","Josiah P. Hanna","Peter Stone","Matthew E. Taylor"],"pdf_url":"https://arxiv.org/pdf/2212.08302v1.pdf","comment":"NeurIPS 2021 Workshop on Deployable Decision Making in Embodied\n  Systems [Spotlight]"},{"id":"http://arxiv.org/abs/2212.08299v1","updated":"2022-12-16T06:31:18Z","published":"2022-12-16T06:31:18Z","title":"Metaheuristic for Hub-Spoke Facility Location Problem: Application to\n  Indian E-commerce Industry","summary":"  Indian e-commerce industry has evolved over the last decade and is expected\nto grow over the next few years. The focus has now shifted to turnaround time\n(TAT) due to the emergence of many third-party logistics providers and higher\ncustomer expectations. The key consideration for delivery providers is to\nbalance their overall operating costs while meeting the promised TAT to their\ncustomers. E-commerce delivery partners operate through a network of facilities\nwhose strategic locations help to run the operations efficiently. In this work,\nwe identify the locations of hubs throughout the country and their\ncorresponding mapping with the distribution centers. The objective is to\nminimize the total network costs with TAT adherence. We use Genetic Algorithm\nand leverage business constraints to reduce the solution search space and hence\nthe solution time. The results indicate an improvement of 9.73% in TAT\ncompliance compared with the current scenario.\n","authors":["Aakash Sachdeva","Bhupinder Singh","Rahul Prasad","Nakshatra Goel","Ronit Mondal","Jatin Munjal","Abhishek Bhatnagar","Manjeet Dahiya"],"pdf_url":"https://arxiv.org/pdf/2212.08299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08295v1","updated":"2022-12-16T06:20:19Z","published":"2022-12-16T06:20:19Z","title":"Learning on Persistence Diagrams as Radon Measures","summary":"  Persistence diagrams are common descriptors of the topological structure of\ndata appearing in various classification and regression tasks. They can be\ngeneralized to Radon measures supported on the birth-death plane and endowed\nwith an optimal transport distance. Examples of such measures are expectations\nof probability distributions on the space of persistence diagrams. In this\npaper, we develop methods for approximating continuous functions on the space\nof Radon measures supported on the birth-death plane, as well as their\nutilization in supervised learning tasks. Indeed, we show that any continuous\nfunction defined on a compact subset of the space of such measures (e.g., a\nclassifier or regressor) can be approximated arbitrarily well by polynomial\ncombinations of features computed using a continuous compactly supported\nfunction on the birth-death plane (a template). We provide insights into the\nstructure of relatively compact subsets of the space of Radon measures, and\ntest our approximation methodology on various data sets and supervised learning\ntasks.\n","authors":["Alex Elchesen","Iryna Hartsock","Jose A. Perea","Tatum Rask"],"pdf_url":"https://arxiv.org/pdf/2212.08295v1.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2212.08290v1","updated":"2022-12-16T05:51:52Z","published":"2022-12-16T05:51:52Z","title":"Robust Learning Protocol for Federated Tumor Segmentation Challenge","summary":"  In this work, we devise robust and efficient learning protocols for\norchestrating a Federated Learning (FL) process for the Federated Tumor\nSegmentation Challenge (FeTS 2022). Enabling FL for FeTS setup is challenging\nmainly due to data heterogeneity among collaborators and communication cost of\ntraining. To tackle these challenges, we propose Robust Learning Protocol\n(RoLePRO) which is a combination of server-side adaptive optimisation (e.g.,\nserver-side Adam) and judicious parameter (weights) aggregation schemes (e.g.,\nadaptive weighted aggregation). RoLePRO takes a two-phase approach, where the\nfirst phase consists of vanilla Federated Averaging, while the second phase\nconsists of a judicious aggregation scheme that uses a sophisticated\nreweighting, all in the presence of an adaptive optimisation algorithm at the\nserver. We draw insights from extensive experimentation to tune learning rates\nfor the two phases.\n","authors":["Ambrish Rawat","Giulio Zizzo","Swanand Kadhe","Jonathan P. Epperlein","Stefano Braghin"],"pdf_url":"https://arxiv.org/pdf/2212.08290v1.pdf","comment":"14 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2212.08279v1","updated":"2022-12-16T04:52:53Z","published":"2022-12-16T04:52:53Z","title":"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion\n  Behaviors in Social Deduction Games","summary":"  Persuasion modeling is a key building block for conversational agents.\nExisting works in this direction are limited to analyzing textual dialogue\ncorpus. We argue that visual signals also play an important role in\nunderstanding human persuasive behaviors. In this paper, we introduce the first\nmultimodal dataset for modeling persuasion behaviors. Our dataset includes 199\ndialogue transcriptions and videos captured in a multi-player social deduction\ngame setting, 26,647 utterance level annotations of persuasion strategy, and\ngame level annotations of deduction game outcomes. We provide extensive\nexperiments to show how dialogue context and visual signals benefit persuasion\nstrategy prediction. We also explore the generalization ability of language\nmodels for persuasion modeling and the role of persuasion strategies in\npredicting social deduction game outcomes. Our dataset, code, and models can be\nfound at https://persuasion-deductiongame.socialai-data.org.\n","authors":["Bolin Lai","Hongxin Zhang","Miao Liu","Aryan Pariani","Fiona Ryan","Wenqi Jia","Shirley Anugrah Hayati","James M. Rehg","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2212.08279v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2212.08277v1","updated":"2022-12-16T04:25:43Z","published":"2022-12-16T04:25:43Z","title":"Improving self-supervised representation learning via sequential\n  adversarial masking","summary":"  Recent methods in self-supervised learning have demonstrated that\nmasking-based pretext tasks extend beyond NLP, serving as useful pretraining\nobjectives in computer vision. However, existing approaches apply random or ad\nhoc masking strategies that limit the difficulty of the reconstruction task\nand, consequently, the strength of the learnt representations. We improve upon\ncurrent state-of-the-art work in learning adversarial masks by proposing a new\nframework that generates masks in a sequential fashion with different\nconstraints on the adversary. This leads to improvements in performance on\nvarious downstream tasks, such as classification on ImageNet100, STL10, and\nCIFAR10/100 and segmentation on Pascal VOC. Our results further demonstrate the\npromising capabilities of masking-based approaches for SSL in computer vision.\n","authors":["Dylan Sam","Min Bai","Tristan McKinney","Li Erran Li"],"pdf_url":"https://arxiv.org/pdf/2212.08277v1.pdf","comment":"9 pages, 2 figures, Presented at NeurIPS 2022 SSL: Theory and\n  Practice Workshop"},{"id":"http://arxiv.org/abs/2212.08276v1","updated":"2022-12-16T04:23:36Z","published":"2022-12-16T04:23:36Z","title":"Preventing RNN from Using Sequence Length as a Feature","summary":"  Recurrent neural networks are deep learning topologies that can be trained to\nclassify long documents. However, in our recent work, we found a critical\nproblem with these cells: they can use the length differences between texts of\ndifferent classes as a prominent classification feature. This has the effect of\nproducing models that are brittle and fragile to concept drift, can provide\nmisleading performances and are trivially explainable regardless of text\ncontent. This paper illustrates the problem using synthetic and real-world data\nand provides a simple solution using weight decay regularization.\n","authors":["Jean-Thomas Baillargeon","Hélène Cossette","Luc Lamontagne"],"pdf_url":"https://arxiv.org/pdf/2212.08276v1.pdf","comment":"6 pages, but my overleaf generrates 5 pages. I have no error, the\n  font size seems different"},{"id":"http://arxiv.org/abs/2212.08273v1","updated":"2022-12-16T04:18:47Z","published":"2022-12-16T04:18:47Z","title":"Learning for Vehicle-to-Vehicle Cooperative Perception under Lossy\n  Communication","summary":"  Deep learning has been widely used in the perception (e.g., 3D object\ndetection) of intelligent vehicle driving. Due to the beneficial\nVehicle-to-Vehicle (V2V) communication, the deep learning based features from\nother agents can be shared to the ego vehicle so as to improve the perception\nof the ego vehicle. It is named as Cooperative Perception in the V2V research,\nwhose algorithms have been dramatically advanced recently. However, all the\nexisting cooperative perception algorithms assume the ideal V2V communication\nwithout considering the possible lossy shared features because of the Lossy\nCommunication (LC) which is common in the complex real-world driving scenarios.\nIn this paper, we first study the side effect (e.g., detection performance\ndrop) by the lossy communication in the V2V Cooperative Perception, and then we\npropose a novel intermediate LC-aware feature fusion method to relieve the side\neffect of lossy communication by a LC-aware Repair Network (LCRN) and enhance\nthe interaction between the ego vehicle and other vehicles by a specially\ndesigned V2V Attention Module (V2VAM) including intra-vehicle attention of ego\nvehicle and uncertainty-aware inter-vehicle attention. The extensive experiment\non the public cooperative perception dataset OPV2V (based on digital-twin CARLA\nsimulator) demonstrates that the proposed method is quite effective for the\ncooperative point cloud based 3D object detection under lossy V2V\ncommunication.\n","authors":["Jinlong Li","Runsheng Xu","Xinyu Liu","Jin Ma","Zicheng Chi","Jiaqi Ma","Hongkai Yu"],"pdf_url":"https://arxiv.org/pdf/2212.08273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.02062v2","updated":"2022-12-16T03:51:02Z","published":"2022-07-05T14:13:22Z","title":"Image Amodal Completion: A Survey","summary":"  Existing computer vision systems can compete with humans in understanding the\nvisible parts of objects, but still fall far short of humans when it comes to\ndepicting the invisible parts of partially occluded objects. Image amodal\ncompletion aims to equip computers with human-like amodal completion functions\nto understand an intact object despite it being partially occluded. The main\npurpose of this survey is to provide an intuitive understanding of the research\nhotspots, key technologies and future trends in the field of image amodal\ncompletion. Firstly, we present a comprehensive review of the latest literature\nin this emerging field, exploring three key tasks in image amodal completion,\nincluding amodal shape completion, amodal appearance completion, and order\nperception. Then we examine popular datasets related to image amodal completion\nalong with their common data collection methods and evaluation metrics.\nFinally, we discuss real-world applications and future research directions for\nimage amodal completion, facilitating the reader's understanding of the\nchallenges of existing technologies and upcoming research trends.\n","authors":["Jiayang Ao","Qiuhong Ke","Krista A. Ehinger"],"pdf_url":"https://arxiv.org/pdf/2207.02062v2.pdf","comment":"The manuscript is under consideration at Computer Vision and Image\n  Understanding"},{"id":"http://arxiv.org/abs/2212.08262v1","updated":"2022-12-16T03:13:43Z","published":"2022-12-16T03:13:43Z","title":"Uniform Sequence Better: Time Interval Aware Data Augmentation for\n  Sequential Recommendation","summary":"  Sequential recommendation is an important task to predict the next-item to\naccess based on a sequence of interacted items. Most existing works learn user\npreference as the transition pattern from the previous item to the next one,\nignoring the time interval between these two items. However, we observe that\nthe time interval in a sequence may vary significantly different, and thus\nresult in the ineffectiveness of user modeling due to the issue of\n\\emph{preference drift}. In fact, we conducted an empirical study to validate\nthis observation, and found that a sequence with uniformly distributed time\ninterval (denoted as uniform sequence) is more beneficial for performance\nimprovement than that with greatly varying time interval. Therefore, we propose\nto augment sequence data from the perspective of time interval, which is not\nstudied in the literature. Specifically, we design five operators (Ti-Crop,\nTi-Reorder, Ti-Mask, Ti-Substitute, Ti-Insert) to transform the original\nnon-uniform sequence to uniform sequence with the consideration of variance of\ntime intervals. Then, we devise a control strategy to execute data augmentation\non item sequences in different lengths. Finally, we implement these\nimprovements on a state-of-the-art model CoSeRec and validate our approach on\nfour real datasets. The experimental results show that our approach reaches\nsignificantly better performance than the other 11 competing methods. Our\nimplementation is available: https://github.com/KingGugu/TiCoSeRec.\n","authors":["Yizhou Dang","Enneng Yang","Guibing Guo","Linying Jiang","Xingwei Wang","Xiaoxiao Xu","Qinghui Sun","Hong Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08262v1.pdf","comment":"9 pages, 4 figures, AAAI-2023"},{"id":"http://arxiv.org/abs/2212.08254v1","updated":"2022-12-16T02:52:37Z","published":"2022-12-16T02:52:37Z","title":"RepQ-ViT: Scale Reparameterization for Post-Training Quantization of\n  Vision Transformers","summary":"  Post-training quantization (PTQ), which only requires a tiny dataset for\ncalibration without end-to-end retraining, is a light and practical model\ncompression technique. Recently, several PTQ schemes for vision transformers\n(ViTs) have been presented; unfortunately, they typically suffer from\nnon-trivial accuracy degradation, especially in low-bit cases. In this paper,\nwe propose RepQ-ViT, a novel PTQ framework for ViTs based on quantization scale\nreparameterization, to address the above issues. RepQ-ViT decouples the\nquantization and inference processes, where the former employs complex\nquantizers and the latter employs scale-reparameterized simplified quantizers.\nThis ensures both accurate quantization and efficient inference, which\ndistinguishes it from existing approaches that sacrifice quantization\nperformance to meet the target hardware. More specifically, we focus on two\ncomponents with extreme distributions: post-LayerNorm activations with severe\ninter-channel variation and post-Softmax activations with power-law features,\nand initially apply channel-wise quantization and log$\\sqrt{2}$ quantization,\nrespectively. Then, we reparameterize the scales to hardware-friendly\nlayer-wise quantization and log2 quantization for inference, with only slight\naccuracy or computational costs. Extensive experiments are conducted on\nmultiple vision tasks with different model variants, proving that RepQ-ViT,\nwithout hyperparameters and expensive reconstruction procedures, can outperform\nexisting strong baselines and encouragingly improve the accuracy of 4-bit PTQ\nof ViTs to a usable level.\n","authors":["Zhikai Li","Junrui Xiao","Lianwei Yang","Qingyi Gu"],"pdf_url":"https://arxiv.org/pdf/2212.08254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.12134v3","updated":"2022-12-16T02:31:25Z","published":"2022-05-24T15:10:50Z","title":"Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box\n  Score-Based Query Attacks","summary":"  The score-based query attacks (SQAs) pose practical threats to deep neural\nnetworks by crafting adversarial perturbations within dozens of queries, only\nusing the model's output scores. Nonetheless, we note that if the loss trend of\nthe outputs is slightly perturbed, SQAs could be easily misled and thereby\nbecome much less effective. Following this idea, we propose a novel defense,\nnamely Adversarial Attack on Attackers (AAA), to confound SQAs towards\nincorrect attack directions by slightly modifying the output logits. In this\nway, (1) SQAs are prevented regardless of the model's worst-case robustness;\n(2) the original model predictions are hardly changed, i.e., no degradation on\nclean accuracy; (3) the calibration of confidence scores can be improved\nsimultaneously. Extensive experiments are provided to verify the above\nadvantages. For example, by setting $\\ell_\\infty=8/255$ on CIFAR-10, our\nproposed AAA helps WideResNet-28 secure 80.59% accuracy under Square attack\n(2500 queries), while the best prior defense (i.e., adversarial training) only\nattains 67.44%. Since AAA attacks SQA's general greedy strategy, such\nadvantages of AAA over 8 defenses can be consistently observed on 8\nCIFAR-10/ImageNet models under 6 SQAs, using different attack targets, bounds,\nnorms, losses, and strategies. Moreover, AAA calibrates better without hurting\nthe accuracy. Our code is available at https://github.com/Sizhe-Chen/AAA.\n","authors":["Sizhe Chen","Zhehao Huang","Qinghua Tao","Yingwen Wu","Cihang Xie","Xiaolin Huang"],"pdf_url":"https://arxiv.org/pdf/2205.12134v3.pdf","comment":"accepted by NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.08244v1","updated":"2022-12-16T02:23:50Z","published":"2022-12-16T02:23:50Z","title":"Offline Reinforcement Learning for Visual Navigation","summary":"  Reinforcement learning can enable robots to navigate to distant goals while\noptimizing user-specified reward functions, including preferences for following\nlanes, staying on paved paths, or avoiding freshly mowed grass. However, online\nlearning from trial-and-error for real-world robots is logistically\nchallenging, and methods that instead can utilize existing datasets of robotic\nnavigation data could be significantly more scalable and enable broader\ngeneralization. In this paper, we present ReViND, the first offline RL system\nfor robotic navigation that can leverage previously collected data to optimize\nuser-specified reward functions in the real-world. We evaluate our system for\noff-road navigation without any additional data collection or fine-tuning, and\nshow that it can navigate to distant goals using only offline training from\nthis dataset, and exhibit behaviors that qualitatively differ based on the\nuser-specified reward function.\n","authors":["Dhruv Shah","Arjun Bhorkar","Hrish Leen","Ilya Kostrikov","Nick Rhinehart","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2212.08244v1.pdf","comment":"Project page https://sites.google.com/view/revind/home"},{"id":"http://arxiv.org/abs/2106.02735v3","updated":"2022-12-16T02:05:34Z","published":"2021-06-04T22:00:53Z","title":"Learning particle swarming models from data with Gaussian processes","summary":"  Interacting particle or agent systems that display a rich variety of swarming\nbehaviours are ubiquitous in science and engineering. A fundamental and\nchallenging goal is to understand the link between individual interaction rules\nand swarming. In this paper, we study the data-driven discovery of a\nsecond-order particle swarming model that describes the evolution of $N$\nparticles in $\\mathbb{R}^d$ under radial interactions. We propose a learning\napproach that models the latent radial interaction function as Gaussian\nprocesses, which can simultaneously fulfill two inference goals: one is the\nnonparametric inference of {the} interaction function with pointwise\nuncertainty quantification, and the other one is the inference of unknown\nscalar parameters in the non-collective friction forces of the system. We\nformulate the learning problem as a statistical inverse problem and provide a\ndetailed analysis of recoverability conditions, establishing that a coercivity\ncondition is sufficient for recoverability. Given data collected from $M$ i.i.d\ntrajectories with independent Gaussian observational noise, we provide a\nfinite-sample analysis, showing that our posterior mean estimator converges in\na Reproducing kernel Hilbert space norm, at an optimal rate in $M$ equal to the\none in the classical 1-dimensional Kernel Ridge regression. As a byproduct, we\nshow we can obtain a parametric learning rate in $M$ for the posterior marginal\nvariance using $L^{\\infty}$ norm, and the rate could also involve $N$ and $L$\n(the number of observation time instances for each trajectory), depending on\nthe condition number of the inverse problem. Numerical results on systems that\nexhibit different swarming behaviors demonstrate efficient learning of our\napproach from scarce noisy trajectory data.\n","authors":["Jinchao Feng","Charles Kulick","Yunxiang Ren","Sui Tang"],"pdf_url":"https://arxiv.org/pdf/2106.02735v3.pdf","comment":"44 pages; Appendix 5 pages"},{"id":"http://arxiv.org/abs/2212.08235v1","updated":"2022-12-16T02:00:55Z","published":"2022-12-16T02:00:55Z","title":"A Simple Decentralized Cross-Entropy Method","summary":"  Cross-Entropy Method (CEM) is commonly used for planning in model-based\nreinforcement learning (MBRL) where a centralized approach is typically\nutilized to update the sampling distribution based on only the top-$k$\noperation's results on samples. In this paper, we show that such a centralized\napproach makes CEM vulnerable to local optima, thus impairing its sample\nefficiency. To tackle this issue, we propose Decentralized CEM (DecentCEM), a\nsimple but effective improvement over classical CEM, by using an ensemble of\nCEM instances running independently from one another, and each performing a\nlocal improvement of its own sampling distribution. We provide both theoretical\nand empirical analysis to demonstrate the effectiveness of this simple\ndecentralized approach. We empirically show that, compared to the classical\ncentralized approach using either a single or even a mixture of Gaussian\ndistributions, our DecentCEM finds the global optimum much more consistently\nthus improves the sample efficiency. Furthermore, we plug in our DecentCEM in\nthe planning problem of MBRL, and evaluate our approach in several continuous\ncontrol environments, with comparison to the state-of-art CEM based MBRL\napproaches (PETS and POPLIN). Results show sample efficiency improvement by\nsimply replacing the classical CEM module with our DecentCEM module, while only\nsacrificing a reasonable amount of computational cost. Lastly, we conduct\nablation studies for more in-depth analysis. Code is available at\nhttps://github.com/vincentzhang/decentCEM\n","authors":["Zichen Zhang","Jun Jin","Martin Jagersand","Jun Luo","Dale Schuurmans"],"pdf_url":"https://arxiv.org/pdf/2212.08235v1.pdf","comment":"NeurIPS 2022. The last two authors advised equally"},{"id":"http://arxiv.org/abs/2212.08233v1","updated":"2022-12-16T01:45:17Z","published":"2022-12-16T01:45:17Z","title":"Geometry-aware Autoregressive Models for Calorimeter Shower Simulations","summary":"  Calorimeter shower simulations are often the bottleneck in simulation time\nfor particle physics detectors. A lot of effort is currently spent on\noptimizing generative architectures for specific detector geometries, which\ngeneralize poorly. We develop a geometry-aware autoregressive model on a range\nof calorimeter geometries such that the model learns to adapt its energy\ndeposition depending on the size and position of the cells. This is a key\nproof-of-concept step towards building a model that can generalize to new\nunseen calorimeter geometries with little to no additional training. Such a\nmodel can replace the hundreds of generative models used for calorimeter\nsimulation in a Large Hadron Collider experiment. For the study of future\ndetectors, such a model will dramatically reduce the large upfront investment\nusually needed to generate simulations.\n","authors":["Junze Liu","Aishik Ghosh","Dylan Smith","Pierre Baldi","Daniel Whiteson"],"pdf_url":"https://arxiv.org/pdf/2212.08233v1.pdf","comment":"This paper was submitted to NeurIPS Machine Learning and the Physical\n  Sciences Workshop 2022"},{"id":"http://arxiv.org/abs/2212.08232v1","updated":"2022-12-16T01:41:59Z","published":"2022-12-16T01:41:59Z","title":"Offline Robot Reinforcement Learning with Uncertainty-Guided Human\n  Expert Sampling","summary":"  Recent advances in batch (offline) reinforcement learning have shown\npromising results in learning from available offline data and proved offline\nreinforcement learning to be an essential toolkit in learning control policies\nin a model-free setting. An offline reinforcement learning algorithm applied to\na dataset collected by a suboptimal non-learning-based algorithm can result in\na policy that outperforms the behavior agent used to collect the data. Such a\nscenario is frequent in robotics, where existing automation is collecting\noperational data. Although offline learning techniques can learn from data\ngenerated by a sub-optimal behavior agent, there is still an opportunity to\nimprove the sample complexity of existing offline reinforcement learning\nalgorithms by strategically introducing human demonstration data into the\ntraining process. To this end, we propose a novel approach that uses\nuncertainty estimation to trigger the injection of human demonstration data and\nguide policy training towards optimal behavior while reducing overall sample\ncomplexity. Our experiments show that this approach is more sample efficient\nwhen compared to a naive way of combining expert data with data collected from\na sub-optimal agent. We augmented an existing offline reinforcement learning\nalgorithm Conservative Q-Learning with our approach and performed experiments\non data collected from MuJoCo and OffWorld Gym learning environments.\n","authors":["Ashish Kumar","Ilya Kuzovkin"],"pdf_url":"https://arxiv.org/pdf/2212.08232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08230v1","updated":"2022-12-16T01:38:35Z","published":"2022-12-16T01:38:35Z","title":"Multi-Agent Patrolling with Battery Constraints through Deep\n  Reinforcement Learning","summary":"  Autonomous vehicles are suited for continuous area patrolling problems.\nHowever, finding an optimal patrolling strategy can be challenging for many\nreasons. Firstly, patrolling environments are often complex and can include\nunknown and evolving environmental factors. Secondly, autonomous vehicles can\nhave failures or hardware constraints such as limited battery lives.\nImportantly, patrolling large areas often requires multiple agents that need to\ncollectively coordinate their actions. In this work, we consider these\nlimitations and propose an approach based on a distributed, model-free deep\nreinforcement learning based multi-agent patrolling strategy. In this approach,\nagents make decisions locally based on their own environmental observations and\non shared information. In addition, agents are trained to automatically\nrecharge themselves when required to support continuous collective patrolling.\nA homogeneous multi-agent architecture is proposed, where all patrolling agents\nhave an identical policy. This architecture provides a robust patrolling system\nthat can tolerate agent failures and allow supplementary agents to be added to\nreplace failed agents or to increase the overall patrol performance. This\nperformance is validated through experiments from multiple perspectives,\nincluding the overall patrol performance, the efficiency of the battery\nrecharging strategy, the overall robustness of the system, and the agents'\nability to adapt to environment dynamics.\n","authors":["Chenhao Tong","Aaron Harwood","Maria A. Rodriguez","Richard O. Sinnott"],"pdf_url":"https://arxiv.org/pdf/2212.08230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08228v1","updated":"2022-12-16T01:35:27Z","published":"2022-12-16T01:35:27Z","title":"SADM: Sequence-Aware Diffusion Model for Longitudinal Medical Image\n  Generation","summary":"  Human organs constantly undergo anatomical changes due to a complex mix of\nshort-term (e.g., heartbeat) and long-term (e.g., aging) factors. Evidently,\nprior knowledge of these factors will be beneficial when modeling their future\nstate, i.e., via image generation. However, most of the medical image\ngeneration tasks only rely on the input from a single image, thus ignoring the\nsequential dependency even when longitudinal data is available. Sequence-aware\ndeep generative models, where model input is a sequence of ordered and\ntimestamped images, are still underexplored in the medical imaging domain that\nis featured by several unique challenges: 1) Sequences with various lengths; 2)\nMissing data or frame, and 3) High dimensionality. To this end, we propose a\nsequence-aware diffusion model (SADM) for the generation of longitudinal\nmedical images. Recently, diffusion models have shown promising results on\nhigh-fidelity image generation. Our method extends this new technique by\nintroducing a sequence-aware transformer as the conditional module in a\ndiffusion model. The novel design enables learning longitudinal dependency even\nwith missing data during training and allows autoregressive generation of a\nsequence of images during inference. Our extensive experiments on 3D\nlongitudinal medical images demonstrate the effectiveness of SADM compared with\nbaselines and alternative methods.\n","authors":["Jee Seok Yoon","Chenghao Zhang","Heung-Il Suk","Jia Guo","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2212.08228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08225v1","updated":"2022-12-16T01:27:42Z","published":"2022-12-16T01:27:42Z","title":"Materials Discovery using Max K-Armed Bandit","summary":"  Search algorithms for the bandit problems are applicable in materials\ndiscovery. However, the objectives of the conventional bandit problem are\ndifferent from those of materials discovery. The conventional bandit problem\naims to maximize the total rewards, whereas materials discovery aims to achieve\nbreakthroughs in material properties. The max K-armed bandit (MKB) problem,\nwhich aims to acquire the single best reward, matches with the discovery tasks\nbetter than the conventional bandit. Thus, here, we propose a search algorithm\nfor materials discovery based on the MKB problem using a pseudo-value of the\nupper confidence bound of expected improvement of the best reward. This\napproach is pseudo-guaranteed to be asymptotic oracles that do not depends on\nthe time horizon. In addition, compared with other MKB algorithms, the proposed\nalgorithm has only one hyperparameter, which is advantageous in materials\ndiscovery. We applied the proposed algorithm to synthetic problems and\nmolecular-design demonstrations using a Monte Carlo tree search. According to\nthe results, the proposed algorithm stably outperformed other bandit algorithms\nin the late stage of the search process when the optimal arm of the MKB could\nnot be determined based on its expectation reward.\n","authors":["Nobuaki Kikkawa","Hiroshi Ohno"],"pdf_url":"https://arxiv.org/pdf/2212.08225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08217v1","updated":"2022-12-16T01:10:49Z","published":"2022-12-16T01:10:49Z","title":"Toward Improved Generalization: Meta Transfer of Self-supervised\n  Knowledge on Graphs","summary":"  Despite the remarkable success achieved by graph convolutional networks for\nfunctional brain activity analysis, the heterogeneity of functional patterns\nand the scarcity of imaging data still pose challenges in many tasks.\nTransferring knowledge from a source domain with abundant training data to a\ntarget domain is effective for improving representation learning on scarce\ntraining data. However, traditional transfer learning methods often fail to\ngeneralize the pre-trained knowledge to the target task due to domain\ndiscrepancy. Self-supervised learning on graphs can increase the\ngeneralizability of graph features since self-supervision concentrates on\ninherent graph properties that are not limited to a particular supervised task.\nWe propose a novel knowledge transfer strategy by integrating meta-learning\nwith self-supervised learning to deal with the heterogeneity and scarcity of\nfMRI data. Specifically, we perform a self-supervised task on the source domain\nand apply meta-learning, which strongly improves the generalizability of the\nmodel using the bi-level optimization, to transfer the self-supervised\nknowledge to the target domain. Through experiments on a neurological disorder\nclassification task, we demonstrate that the proposed strategy significantly\nimproves target task performance by increasing the generalizability and\ntransferability of graph-based knowledge.\n","authors":["Wenhui Cui","Haleh Akrami","Anand A. Joshi","Richard M. Leahy"],"pdf_url":"https://arxiv.org/pdf/2212.08217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08216v1","updated":"2022-12-16T01:10:41Z","published":"2022-12-16T01:10:41Z","title":"Azimuth: Systematic Error Analysis for Text Classification","summary":"  We present Azimuth, an open-source and easy-to-use tool to perform error\nanalysis for text classification. Compared to other stages of the ML\ndevelopment cycle, such as model training and hyper-parameter tuning, the\nprocess and tooling for the error analysis stage are less mature. However, this\nstage is critical for the development of reliable and trustworthy AI systems.\nTo make error analysis more systematic, we propose an approach comprising\ndataset analysis and model quality assessment, which Azimuth facilitates. We\naim to help AI practitioners discover and address areas where the model does\nnot generalize by leveraging and integrating a range of ML techniques, such as\nsaliency maps, similarity, uncertainty, and behavioral analyses, all in one\ntool. Our code and documentation are available at\ngithub.com/servicenow/azimuth.\n","authors":["Gabrielle Gauthier-Melançon","Orlando Marquez Ayala","Lindsay Brin","Chris Tyler","Frédéric Branchaud-Charron","Joseph Marinier","Karine Grande","Di Le"],"pdf_url":"https://arxiv.org/pdf/2212.08216v1.pdf","comment":"To be published in Proceedings of the 2022 Conference on Empirical\n  Methods in Natural Language Processing: System Demonstrations. 13 pages and\n  14 figures"},{"id":"http://arxiv.org/abs/2208.02879v2","updated":"2022-12-16T00:31:44Z","published":"2022-08-04T20:31:46Z","title":"PointConvFormer: Revenge of the Point-based Convolution","summary":"  We introduce PointConvFormer, a novel building block for point cloud based\ndeep network architectures. Inspired by generalization theory, PointConvFormer\ncombines ideas from point convolution, where filter weights are only based on\nrelative position, and Transformers which utilize feature-based attention. In\nPointConvFormer, attention computed from feature difference between neighboring\npoints is used to modify the convolutional weights at each point. Hence,\ninvariances from point convolution are preserved, whereas attention helps to\nselect relevant points in the neighborhood. PointConvFormer is suitable for\nmultiple tasks that require details at the point level, such as segmentation\nand scene flow estimation tasks. We experiment on both tasks with multiple\ndatasets including ScanNet, SemanticKitti, FlyingThings3D and KITTI. Our\nresults show that PointConvFormer substantially outperforms classic\nconvolutions, regular transformers, and voxelized sparse convolution approaches\nwith much smaller and faster networks. Visualizations show that PointConvFormer\nperforms similarly to convolution on flat areas, whereas the neighborhood\nselection effect is stronger on object boundaries, showing that it has got the\nbest of both worlds.\n","authors":["Wenxuan Wu","Qi Shan","Li Fuxin"],"pdf_url":"https://arxiv.org/pdf/2208.02879v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2212.08281v1","updated":"2022-12-16T05:08:52Z","published":"2022-12-16T05:08:52Z","title":"HGAN: Hierarchical Graph Alignment Network for Image-Text Retrieval","summary":"  Image-text retrieval (ITR) is a challenging task in the field of multimodal\ninformation processing due to the semantic gap between different modalities. In\nrecent years, researchers have made great progress in exploring the accurate\nalignment between image and text. However, existing works mainly focus on the\nfine-grained alignment between image regions and sentence fragments, which\nignores the guiding significance of context background information. Actually,\nintegrating the local fine-grained information and global context background\ninformation can provide more semantic clues for retrieval. In this paper, we\npropose a novel Hierarchical Graph Alignment Network (HGAN) for image-text\nretrieval. First, to capture the comprehensive multimodal features, we\nconstruct the feature graphs for the image and text modality respectively.\nThen, a multi-granularity shared space is established with a designed\nMulti-granularity Feature Aggregation and Rearrangement (MFAR) module, which\nenhances the semantic corresponding relations between the local and global\ninformation, and obtains more accurate feature representations for the image\nand text modalities. Finally, the ultimate image and text features are further\nrefined through three-level similarity functions to achieve the hierarchical\nalignment. To justify the proposed model, we perform extensive experiments on\nMS-COCO and Flickr30K datasets. Experimental results show that the proposed\nHGAN outperforms the state-of-the-art methods on both datasets, which\ndemonstrates the effectiveness and superiority of our model.\n","authors":["Jie Guo","Meiting Wang","Yan Zhou","Bin Song","Yuhao Chi","Wei Fan","Jianglong Chang"],"pdf_url":"https://arxiv.org/pdf/2212.08281v1.pdf","comment":null}]},"2022-12-19T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2212.09747v1","updated":"2022-12-19T18:59:56Z","published":"2022-12-19T18:59:56Z","title":"Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?","summary":"  Named Entity Recognition (NER) is an important and well-studied task in\nnatural language processing. The classic CoNLL-2003 English dataset, published\nalmost 20 years ago, is commonly used to train and evaluate named entity\ntaggers. The age of this dataset raises the question of how well these models\nperform when applied to modern data. In this paper, we present CoNLL++, a new\nannotated test set that mimics the process used to create the original\nCoNLL-2003 test set as closely as possible, except with data collected from\n2020. Using CoNLL++, we evaluate the generalization of 20+ different models to\nmodern data. We observe that different models have very different\ngeneralization behavior. F\\textsubscript{1} scores of large transformer-based\nmodels which are pre-trained on recent data dropped much less than models using\nstatic word embeddings, and RoBERTa-based and T5 models achieve comparable\nF\\textsubscript{1} scores on both CoNLL-2003 and CoNLL++. Our experiments show\nthat achieving good generalizability requires a combined effort of developing\nlarger models and continuing pre-training with in-domain and recent data. These\nresults suggest standard evaluation methodology may have under-estimated\nprogress on named entity recognition over the past 20 years; in addition to\nimproving performance on the original CoNLL-2003 dataset, we have also improved\nthe ability of our models to generalize to modern data.\n","authors":["Shuheng Liu","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2212.09747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09746v1","updated":"2022-12-19T18:59:45Z","published":"2022-12-19T18:59:45Z","title":"Evaluating Human-Language Model Interaction","summary":"  Many real-world applications of language models (LMs), such as code\nautocomplete and writing assistance, involve human-LM interaction, but the main\nLM benchmarks are non-interactive, where a system produces output without human\nintervention. To evaluate human-LM interaction, we develop a framework,\nHuman-AI Language-based Interaction Evaluation (H-LINE), that expands\nnon-interactive evaluation along three dimensions, capturing (i) the\ninteractive process, not only the final output; (ii) the first-person\nsubjective experience, not just a third-party assessment; and (iii) notions of\npreference beyond quality. We then design five tasks ranging from goal-oriented\nto open-ended to capture different forms of interaction. On four\nstate-of-the-art LMs (three variants of OpenAI's GPT-3 and AI21's J1-Jumbo), we\nfind that non-interactive performance does not always result in better human-LM\ninteraction and that first-person and third-party metrics can diverge,\nsuggesting the importance of examining the nuances of human-LM interaction.\n","authors":["Mina Lee","Megha Srivastava","Amelia Hardy","John Thickstun","Esin Durmus","Ashwin Paranjape","Ines Gerard-Ursin","Xiang Lisa Li","Faisal Ladhak","Frieda Rong","Rose E. Wang","Minae Kwon","Joon Sung Park","Hancheng Cao","Tony Lee","Rishi Bommasani","Michael Bernstein","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2212.09746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09744v1","updated":"2022-12-19T18:59:34Z","published":"2022-12-19T18:59:34Z","title":"DSI++: Updating Transformer Memory with New Documents","summary":"  Differentiable Search Indices (DSIs) encode a corpus of documents in the\nparameters of a model and use the same model to map queries directly to\nrelevant document identifiers. Despite the strong performance of DSI models,\ndeploying them in situations where the corpus changes over time is\ncomputationally expensive because reindexing the corpus requires re-training\nthe model. In this work, we introduce DSI++, a continual learning challenge for\nDSI to incrementally index new documents while being able to answer queries\nrelated to both previously and newly indexed documents. Across different model\nscales and document identifier representations, we show that continual indexing\nof new documents leads to considerable forgetting of previously indexed\ndocuments. We also hypothesize and verify that the model experiences forgetting\nevents during training, leading to unstable learning. To mitigate these issues,\nwe investigate two approaches. The first focuses on modifying the training\ndynamics. Flatter minima implicitly alleviate forgetting, so we optimize for\nflatter loss basins and show that the model stably memorizes more documents\n(+12\\%). Next, we introduce a generative memory to sample pseudo-queries for\ndocuments and supplement them during continual indexing to prevent forgetting\nfor the retrieval task. Extensive experiments on novel continual indexing\nbenchmarks based on Natural Questions (NQ) and MS MARCO demonstrate that our\nproposed solution mitigates forgetting by a significant margin. Concretely, it\nimproves the average Hits@10 by $+21.1\\%$ over competitive baselines for NQ and\nrequires $6$ times fewer model updates compared to re-training the DSI model\nfor incrementally indexing five corpora in a sequence.\n","authors":["Sanket Vaibhav Mehta","Jai Gupta","Yi Tay","Mostafa Dehghani","Vinh Q. Tran","Jinfeng Rao","Marc Najork","Emma Strubell","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2212.09744v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2212.09741v1","updated":"2022-12-19T18:57:05Z","published":"2022-12-19T18:57:05Z","title":"One Embedder, Any Task: Instruction-Finetuned Text Embeddings","summary":"  We introduce INSTRUCTOR, a new method for computing text embeddings given\ntask instructions: every text input is embedded together with instructions\nexplaining the use case (e.g., task and domain descriptions). Unlike encoders\nfrom prior work that are more specialized, INSTRUCTOR is a single embedder that\ncan generate text embeddings tailored to different downstream tasks and\ndomains, without any further training. We first annotate instructions for 330\ndiverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive\nloss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are\nunseen during training), ranging from classification and information retrieval\nto semantic textual similarity and text generation evaluation. INSTRUCTOR,\nwhile having an order of magnitude fewer parameters than the previous best\nmodel, achieves state-of-the-art performance, with an average improvement of\n3.4% compared to the previous best results on the 70 diverse datasets. Our\nanalysis suggests that INSTRUCTOR is robust to changes in instructions, and\nthat instruction finetuning mitigates the challenge of training a single model\non diverse datasets.\n","authors":["Hongjin Su","Weijia Shi*","Jungo Kasai","Yizhong Wang","Yushi Hu","Mari Ostendorf","Wen-tau Yih","Noah A. Smith","Luke Zettlemoyer","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2212.09741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09739v1","updated":"2022-12-19T18:56:52Z","published":"2022-12-19T18:56:52Z","title":"LENS: A Learnable Evaluation Metric for Text Simplification","summary":"  Training learnable metrics using modern language models has recently emerged\nas a promising method for the automatic evaluation of machine translation.\nHowever, existing human evaluation datasets in text simplification are limited\nby a lack of annotations, unitary simplification types, and outdated models,\nmaking them unsuitable for this approach. To address these issues, we introduce\nthe SIMPEVAL corpus that contains: SIMPEVAL_ASSET, comprising 12K human ratings\non 2.4K simplifications of 24 systems, and SIMPEVAL_2022, a challenging\nsimplification benchmark consisting of over 1K human ratings of 360\nsimplifications including generations from GPT-3.5. Training on SIMPEVAL_ASSET,\nwe present LENS, a Learnable Evaluation Metric for Text Simplification.\nExtensive empirical results show that LENS correlates better with human\njudgment than existing metrics, paving the way for future progress in the\nevaluation of text simplification. To create the SIMPEVAL datasets, we\nintroduce RANK & RATE, a human evaluation framework that rates simplifications\nfrom several models in a list-wise manner by leveraging an interactive\ninterface, which ensures both consistency and accuracy in the evaluation\nprocess. Our metric, dataset, and annotation toolkit are available at\nhttps://github.com/Yao-Dou/LENS.\n","authors":["Mounica Maddela","Yao Dou","David Heineman","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09739v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09736v1","updated":"2022-12-19T18:55:21Z","published":"2022-12-19T18:55:21Z","title":"Don't Generate, Discriminate: A Proposal for Grounding Language Models\n  to Real-World Environments","summary":"  A key missing ability of current language models (LMs) is grounding to\nreal-world environments. Most existing work for grounded language understanding\nuses LMs to directly generate plans that can be executed in the environment to\nachieve the desired effects. It casts the burden of ensuring grammaticality,\nfaithfulness, and controllability all on the LMs. We propose Pangu, a generic\nframework for grounded language understanding that capitalizes on the\ndiscriminative ability of LMs instead of their generative ability. Pangu\nconsists of a symbolic agent and a neural LM working in a concerted fashion:\nthe agent explores the environment to incrementally construct valid candidate\nplans, and the LM evaluates the plausibility of the candidate plans to guide\nthe search process. A case study on the challenging problem of knowledge base\nquestion answering (KBQA), which features a massive environment, demonstrates\nthe remarkable effectiveness and flexibility of Pangu: A BERT-base LM is\nsufficient for achieving a new state of the art on standard KBQA datasets, and\nlarger LMs further improve the performance by a large margin. Pangu also\nenables, for the first time, effective few-shot in-context learning for KBQA\nwith large LMs such as Codex.\n","authors":["Yu Gu","Xiang Deng","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2212.09736v1.pdf","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.09730v1","updated":"2022-12-19T18:53:04Z","published":"2022-12-19T18:53:04Z","title":"Speaking Style Conversion With Discrete Self-Supervised Units","summary":"  Voice Conversion (VC) is the task of making a spoken utterance by one speaker\nsound as if uttered by a different speaker, while keeping other aspects like\ncontent unchanged. Current VC methods, focus primarily on spectral features\nlike timbre, while ignoring the unique speaking style of people which often\nimpacts prosody. In this study, we introduce a method for converting not only\nthe timbre, but also prosodic information (i.e., rhythm and pitch changes) to\nthose of the target speaker. The proposed approach is based on a pretrained,\nself-supervised, model for encoding speech to discrete units, which make it\nsimple, effective, and easy to optimise. We consider the many-to-many setting\nwith no paired data. We introduce a suite of quantitative and qualitative\nevaluation metrics for this setup, and empirically demonstrate the proposed\napproach is significantly superior to the evaluated baselines. Code and samples\ncan be found under https://pages.cs.huji.ac.il/adiyoss-lab/dissc/ .\n","authors":["Gallil Maimon","Yossi Adi"],"pdf_url":"https://arxiv.org/pdf/2212.09730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09726v1","updated":"2022-12-19T18:51:06Z","published":"2022-12-19T18:51:06Z","title":"Improving Faithfulness of Abstractive Summarization by Controlling\n  Confounding Effect of Irrelevant Sentences","summary":"  Lack of factual correctness is an issue that still plagues state-of-the-art\nsummarization systems despite their impressive progress on generating seemingly\nfluent summaries. In this paper, we show that factual inconsistency can be\ncaused by irrelevant parts of the input text, which act as confounders. To that\nend, we leverage information-theoretic measures of causal effects to quantify\nthe amount of confounding and precisely quantify how they affect the\nsummarization performance. Based on insights derived from our theoretical\nresults, we design a simple multi-task model to control such confounding by\nleveraging human-annotated relevant sentences when available. Crucially, we\ngive a principled characterization of data distributions where such confounding\ncan be large thereby necessitating the use of human annotated relevant\nsentences to generate factual summaries. Our approach improves faithfulness\nscores by 20\\% over strong baselines on AnswerSumm\n\\citep{fabbri2021answersumm}, a conversation summarization dataset where lack\nof faithfulness is a significant issue due to the subjective nature of the\ntask. Our best method achieves the highest faithfulness score while also\nachieving state-of-the-art results on standard metrics like ROUGE and METEOR.\nWe corroborate these improvements through human evaluation.\n","authors":["Asish Ghoshal","Arash Einolghozati","Ankit Arun","Haoran Li","Lili Yu","Yashar Mehdad","Scott Wen-tau Yih","Asli Celikyilmaz"],"pdf_url":"https://arxiv.org/pdf/2212.09726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09724v1","updated":"2022-12-19T18:50:54Z","published":"2022-12-19T18:50:54Z","title":"A Retrieve-and-Read Framework for Knowledge Graph Link Prediction","summary":"  Knowledge graph (KG) link prediction aims to infer new facts based on\nexisting facts in the KG. Recent studies have shown that using the graph\nneighborhood of a node via graph neural networks (GNNs) provides more useful\ninformation compared to just using the query information. Conventional GNNs for\nKG link prediction follow the standard message-passing paradigm on the entire\nKG, which leads to over-smoothing of representations and also limits their\nscalability. On a large scale, it becomes computationally expensive to\naggregate useful information from the entire KG for inference. To address the\nlimitations of existing KG link prediction frameworks, we propose a novel\nretrieve-and-read framework, which first retrieves a relevant subgraph context\nfor the query and then jointly reasons over the context and the query with a\nhigh-capacity reader. As part of our exemplar instantiation for the new\nframework, we propose a novel Transformer-based GNN as the reader, which\nincorporates graph-based attention structure and cross-attention between query\nand context for deep fusion. This design enables the model to focus on salient\ncontext information relevant to the query. Empirical results on two standard KG\nlink prediction datasets demonstrate the competitive performance of the\nproposed method.\n","authors":["Vardaan Pahuja","Boshi Wang","Hugo Latapie","Jayanth Srinivasa","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2212.09724v1.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.09723v1","updated":"2022-12-19T18:49:50Z","published":"2022-12-19T18:49:50Z","title":"MANER: Mask Augmented Named Entity Recognition for Extreme Low-Resource\n  Languages","summary":"  This paper investigates the problem of Named Entity Recognition (NER) for\nextreme low-resource languages with only a few hundred tagged data samples. NER\nis a fundamental task in Natural Language Processing (NLP). A critical driver\naccelerating NER systems' progress is the existence of large-scale language\ncorpora that enable NER systems to achieve outstanding performance in languages\nsuch as English and French with abundant training data. However, NER for\nlow-resource languages remains relatively unexplored. In this paper, we\nintroduce Mask Augmented Named Entity Recognition (MANER), a new methodology\nthat leverages the distributional hypothesis of pre-trained masked language\nmodels (MLMs) for NER. The <mask> token in pre-trained MLMs encodes valuable\nsemantic contextual information. MANER re-purposes the <mask> token for NER\nprediction. Specifically, we prepend the <mask> token to every word in a\nsentence for which we would like to predict the named entity tag. During\ntraining, we jointly fine-tune the MLM and a new NER prediction head attached\nto each <mask> token. We demonstrate that MANER is well-suited for NER in\nlow-resource languages; our experiments show that for 100 languages with as few\nas 100 training examples, it improves on state-of-the-art methods by up to 48%\nand by 12% on average on F1 score. We also perform detailed analyses and\nablation studies to understand the scenarios that are best-suited to MANER.\n","authors":["Shashank Sonkar","Zichao Wang","Richard G. Baraniuk"],"pdf_url":"https://arxiv.org/pdf/2212.09723v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09721v1","updated":"2022-12-19T18:49:09Z","published":"2022-12-19T18:49:09Z","title":"KNIFE: Knowledge Distillation with Free-Text Rationales","summary":"  Free-text rationales (FTRs) follow how humans communicate by explaining\nreasoning processes via natural language. A number of recent works have studied\nhow to improve language model (LM) generalization by using FTRs to teach LMs\nthe correct reasoning processes behind correct task outputs. These prior works\naim to learn from FTRs by appending them to the LM input or target output, but\nthis may introduce an input distribution shift or conflict with the task\nobjective, respectively. We propose KNIFE, which distills FTR knowledge from an\nFTR-augmented teacher LM (takes both task input and FTR) to a student LM (takes\nonly task input), which is used for inference. Crucially, the teacher LM's\nforward computation has a bottleneck stage in which all of its FTR states are\nmasked out, which pushes knowledge from the FTR states into the task\ninput/output states. Then, FTR knowledge is distilled to the student LM by\ntraining its task input/output states to align with the teacher LM's. On two\nquestion answering datasets, we show that KNIFE significantly outperforms\nexisting FTR learning methods, in both fully-supervised and low-resource\nsettings.\n","authors":["Aaron Chan","Zhiyuan Zeng","Wyatt Lake","Brihi Joshi","Hanjie Chen","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.09721v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.09710v1","updated":"2022-12-19T18:39:43Z","published":"2022-12-19T18:39:43Z","title":"Continual Learning for Instruction Following from Realtime Feedback","summary":"  We study the problem of continually training an instruction-following agent\nthrough feedback provided by users during collaborative interactions. During\ninteraction, human users instruct an agent using natural language, and provide\nrealtime binary feedback as they observe the agent's instruction execution. We\ncast learning as a contextual bandit problem, converting the user feedback to\nimmediate reward. We evaluate through multiple rounds of human-agent\ninteractions, demonstrating 15.4% absolute improvement in instruction execution\nover time. We also show our approach is robust to several design variations,\nand that the feedback signal is roughly equivalent to the learning signal of\nsupervised demonstration data.\n","authors":["Alane Suhr","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2212.09710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09702v1","updated":"2022-12-19T18:30:36Z","published":"2022-12-19T18:30:36Z","title":"On Event Individuation for Document-Level Information Extraction","summary":"  As information extraction (IE) systems have grown more capable at\nwhole-document extraction, the classic task of \\emph{template filling} has seen\nrenewed interest as a benchmark for evaluating them. In this position paper, we\ncall into question the suitability of template filling for this purpose. We\nargue that the task demands definitive answers to thorny questions of\n\\emph{event individuation} -- the problem of distinguishing distinct events --\nabout which even human experts disagree. We show through annotation studies and\nerror analysis that this raises concerns about the usefulness of template\nfilling evaluation metrics, the quality of datasets for the task, and the\nability of models to learn it. Finally, we consider possible solutions.\n","authors":["William Gantt","Reno Kriz","Yunmo Chen","Siddharth Vashishtha","Aaron Steven White"],"pdf_url":"https://arxiv.org/pdf/2212.09702v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09701v1","updated":"2022-12-19T18:30:26Z","published":"2022-12-19T18:30:26Z","title":"Graph-based Semantical Extractive Text Analysis","summary":"  In the past few decades, there has been an explosion in the amount of\navailable data produced from various sources with different topics. The\navailability of this enormous data necessitates us to adopt effective\ncomputational tools to explore the data. This leads to an intense growing\ninterest in the research community to develop computational methods focused on\nprocessing this text data. A line of study focused on condensing the text so\nthat we are able to get a higher level of understanding in a shorter time. The\ntwo important tasks to do this are keyword extraction and text summarization.\nIn keyword extraction, we are interested in finding the key important words\nfrom a text. This makes us familiar with the general topic of a text. In text\nsummarization, we are interested in producing a short-length text which\nincludes important information about the document. The TextRank algorithm, an\nunsupervised learning method that is an extension of the PageRank (algorithm\nwhich is the base algorithm of Google search engine for searching pages and\nranking them) has shown its efficacy in large-scale text mining, especially for\ntext summarization and keyword extraction. this algorithm can automatically\nextract the important parts of a text (keywords or sentences) and declare them\nas the result. However, this algorithm neglects the semantic similarity between\nthe different parts. In this work, we improved the results of the TextRank\nalgorithm by incorporating the semantic similarity between parts of the text.\nAside from keyword extraction and text summarization, we develop a topic\nclustering algorithm based on our framework which can be used individually or\nas a part of generating the summary to overcome coverage problems.\n","authors":["Mina Samizadeh"],"pdf_url":"https://arxiv.org/pdf/2212.09701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09700v1","updated":"2022-12-19T18:30:09Z","published":"2022-12-19T18:30:09Z","title":"Resoling Open-textured Rules with Templated Interpretive Arguments","summary":"  Open-textured terms in written rules are typically settled through\ninterpretive argumentation. Ongoing work has attempted to catalogue the schemes\nused in such interpretive argumentation. But how can the use of these schemes\naffect the way in which people actually use and reason over the proper\ninterpretations of open-textured terms? Using the interpretive\nargument-eliciting game Aporia as our framework, we carried out an empirical\nstudy to answer this question. Differing from previous work, we did not allow\nparticipants to argue for interpretations arbitrarily, but to only use\narguments that fit with a given set of interpretive argument templates.\nFinally, we analyze the results captured by this new dataset, specifically\nfocusing on practical implications for the development of\ninterpretation-capable artificial reasoners.\n","authors":["John Licato","Logan Fields","Zaid Marji"],"pdf_url":"https://arxiv.org/pdf/2212.09700v1.pdf","comment":"Presented at the 2022 European Conference on Argumentation (ECA)"},{"id":"http://arxiv.org/abs/2212.09699v1","updated":"2022-12-19T18:29:31Z","published":"2022-12-19T18:29:31Z","title":"SegAugment: Maximizing the Utility of Speech Translation Data with\n  Segmentation-based Augmentations","summary":"  Data scarcity is one of the main issues with the end-to-end approach for\nSpeech Translation, as compared to the cascaded one. Although most data\nresources for Speech Translation are originally document-level, they offer a\nsentence-level view, which can be directly used during training. But this\nsentence-level view is single and static, potentially limiting the utility of\nthe data. Our proposed data augmentation method SegAugment challenges this idea\nand aims to increase data availability by providing multiple alternative\nsentence-level views of a dataset. Our method heavily relies on an Audio\nSegmentation system to re-segment the speech of each document, after which we\nobtain the target text with alignment methods. The Audio Segmentation system\ncan be parameterized with different length constraints, thus giving us access\nto multiple and diverse sentence-level views for each document. Experiments in\nMuST-C show consistent gains across 8 language pairs, with an average increase\nof 2.2 BLEU points, and up to 4.7 BLEU for lower-resource scenarios in mTEDx.\nAdditionally, we find that SegAugment is also applicable to purely\nsentence-level data, as in CoVoST, and that it enables Speech Translation\nmodels to completely close the gap between the gold and automatic segmentation\nat inference time.\n","authors":["Ioannis Tsiamas","José A. R. Fonollosa","Marta R. Costa-jussà"],"pdf_url":"https://arxiv.org/pdf/2212.09699v1.pdf","comment":"Work in progress, 10 pages + appendix"},{"id":"http://arxiv.org/abs/2211.09102v2","updated":"2022-12-19T18:25:43Z","published":"2022-11-16T18:42:37Z","title":"Prompting PaLM for Translation: Assessing Strategies and Performance","summary":"  Large language models (LLMs) that have been trained on multilingual but not\nparallel text exhibit a remarkable ability to translate between languages. We\nprobe this ability in an in-depth study of the pathways language model (PaLM),\nwhich has demonstrated the strongest machine translation (MT) performance among\nsimilarly-trained LLMs to date. We investigate various strategies for choosing\ntranslation examples for few-shot prompting, concluding that example quality is\nthe most important factor. Using optimized prompts, we revisit previous\nassessments of PaLM's MT capabilities with more recent test sets, modern MT\nmetrics, and human evaluation, and find that its performance, while impressive,\nstill lags that of state-of-the-art supervised systems. We conclude by\nproviding an analysis of PaLM's MT output which reveals some interesting\nproperties and prospects for future work.\n","authors":["David Vilar","Markus Freitag","Colin Cherry","Jiaming Luo","Viresh Ratnakar","George Foster"],"pdf_url":"https://arxiv.org/pdf/2211.09102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09689v1","updated":"2022-12-19T18:21:00Z","published":"2022-12-19T18:21:00Z","title":"Unnatural Instructions: Tuning Language Models with (Almost) No Human\n  Labor","summary":"  Instruction tuning enables pretrained language models to perform new tasks\nfrom inference-time natural language descriptions. These approaches rely on\nvast amounts of human supervision in the form of crowdsourced datasets or user\ninteractions. In this work, we introduce Unnatural Instructions: a large\ndataset of creative and diverse instructions, collected with virtually no human\nlabor. We collect 64,000 examples by prompting a language model with three seed\nexamples of instructions and eliciting a fourth. This set is then expanded by\nprompting the model to rephrase each instruction, creating a total of\napproximately 240,000 examples of instructions, inputs, and outputs.\nExperiments show that despite containing a fair amount of noise, training on\nUnnatural Instructions rivals the effectiveness of training on open-source\nmanually-curated datasets, surpassing the performance of models such as T0++\nand Tk-Instruct across various benchmarks. These results demonstrate the\npotential of model-generated data as a cost-effective alternative to\ncrowdsourcing for dataset expansion and diversification.\n","authors":["Or Honovich","Thomas Scialom","Omer Levy","Timo Schick"],"pdf_url":"https://arxiv.org/pdf/2212.09689v1.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.09686v1","updated":"2022-12-19T18:14:36Z","published":"2022-12-19T18:14:36Z","title":"A Natural Bias for Language Generation Models","summary":"  After just a few hundred training updates, a standard probabilistic model for\nlanguage generation has likely not yet learnt many semantic or syntactic rules\nof natural language, which inherently makes it difficult to estimate the right\nprobability distribution over next tokens. Yet around this point, these models\nhave identified a simple, loss-minimising behaviour: to output the unigram\ndistribution of the target training corpus. The use of such a crude heuristic\nraises the question: Rather than wasting precious compute resources and model\ncapacity for learning this strategy at early training stages, can we initialise\nour models with this behaviour? Here, we show that we can effectively endow our\nmodel with a separate module that reflects unigram frequency statistics as\nprior knowledge. Standard neural language generation architectures offer a\nnatural opportunity for implementing this idea: by initialising the bias term\nin a model's final linear layer with the log-unigram distribution. Experiments\nin neural machine translation demonstrate that this simple technique: (i)\nimproves learning efficiency; (ii) achieves better overall performance; and\n(iii) appears to disentangle strong frequency effects, encouraging the model to\nspecialise in non-frequency-related aspects of language.\n","authors":["Clara Meister","Wojciech Stokowiec","Tiago Pimentel","Lei Yu","Laura Rimell","Adhiguna Kuncoro"],"pdf_url":"https://arxiv.org/pdf/2212.09686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09683v1","updated":"2022-12-19T18:11:10Z","published":"2022-12-19T18:11:10Z","title":"Human-in-the-loop Evaluation for Early Misinformation Detection: A Case\n  Study of COVID-19 Treatments","summary":"  We present a human-in-the-loop evaluation framework for fact-checking novel\nmisinformation claims and identifying social media messages that violate\nrelevant policies. Our approach extracts structured representations of\ncheck-worthy claims, which are aggregated and ranked for review. Stance\nclassifiers are then used to identify tweets supporting novel misinformation\nclaims, which are further reviewed to determine whether they violate relevant\npolicies. To demonstrate the feasibility of our approach, we develop a baseline\nsystem based on modern NLP methods for human-in-the-loop fact-checking in the\ndomain of COVID-19 treatments. Using our baseline system, we show that human\nfact-checkers can identify 124 tweets per hour that violate Twitter's policies\non COVID-19 misinformation. We will make our code, data, and detailed\nannotation guidelines available to support the evaluation of human-in-the-loop\nsystems that identify novel misinformation directly from raw user-generated\ncontent.\n","authors":["Ethan Mendes","Yang Chen","Alan Ritter","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09682v1","updated":"2022-12-19T18:10:23Z","published":"2022-12-19T18:10:23Z","title":"Multilingual Sequence-to-Sequence Models for Hebrew NLP","summary":"  Recent work attributes progress in NLP to large language models (LMs) with\nincreased model size and large quantities of pretraining data. Despite this,\ncurrent state-of-the-art LMs for Hebrew are both under-parameterized and\nunder-trained compared to LMs in other languages. Additionally, previous work\non pretrained Hebrew LMs focused on encoder-only models. While the encoder-only\narchitecture is beneficial for classification tasks, it does not cater well for\nsub-word prediction tasks, such as Named Entity Recognition, when considering\nthe morphologically rich nature of Hebrew. In this paper we argue that\nsequence-to-sequence generative architectures are more suitable for LLMs in the\ncase of morphologically rich languages (MRLs) such as Hebrew. We demonstrate\nthat by casting tasks in the Hebrew NLP pipeline as text-to-text tasks, we can\nleverage powerful multilingual, pretrained sequence-to-sequence models as mT5,\neliminating the need for a specialized, morpheme-based, separately fine-tuned\ndecoder. Using this approach, our experiments show substantial improvements\nover previously published results on existing Hebrew NLP benchmarks. These\nresults suggest that multilingual sequence-to-sequence models present a\npromising building block for NLP for MRLs.\n","authors":["Matan Eyal","Hila Noga","Roee Aharoni","Idan Szpektor","Reut Tsarfaty"],"pdf_url":"https://arxiv.org/pdf/2212.09682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09676v1","updated":"2022-12-19T18:01:06Z","published":"2022-12-19T18:01:06Z","title":"Words as Gatekeepers: Measuring Discipline-specific Terms and Meanings\n  in Scholarly Publications","summary":"  Scholarly text is often laden with jargon, or specialized language that\ndivides disciplines. We extend past work that characterizes science at the\nlevel of word types, by using BERT-based word sense induction to find\nadditional words that are widespread but overloaded with different uses across\nfields. We define scholarly jargon as discipline-specific word types and\nsenses, and estimate its prevalence across hundreds of fields using\ninterpretable, information-theoretic metrics. We demonstrate the utility of our\napproach for science of science and computational sociolinguistics by\nhighlighting two key social implications. First, we measure audience design,\nand find that most fields reduce jargon when publishing in general-purpose\njournals, but some do so more than others. Second, though jargon has varying\ncorrelation with articles' citation rates within fields, it nearly always\nimpedes interdisciplinary impact. Broadly, our measurements can inform ways in\nwhich language could be revised to serve as a bridge rather than a barrier in\nscience.\n","authors":["Li Lucy","Jesse Dodge","David Bamman","Katherine A. Keith"],"pdf_url":"https://arxiv.org/pdf/2212.09676v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.09674v1","updated":"2022-12-19T18:00:09Z","published":"2022-12-19T18:00:09Z","title":"LR-Sum: Summarization for Less-Resourced Languages","summary":"  This preprint describes work in progress on LR-Sum, a new\npermissively-licensed dataset created with the goal of enabling further\nresearch in automatic summarization for less-resourced languages. LR-Sum\ncontains human-written summaries for 40 languages, many of which are\nless-resourced. We describe our process for extracting and filtering the\ndataset from the Multilingual Open Text corpus (Palen-Michel et al., 2022). The\nsource data is public domain newswire collected from from Voice of America\nwebsites, and LR-Sum is released under a Creative Commons license (CC BY 4.0),\nmaking it one of the most openly-licensed multilingual summarization datasets.\nWe describe how we plan to use the data for modeling experiments and discuss\nlimitations of the dataset.\n","authors":["Chester Palen-Michel","Constantine Lignos"],"pdf_url":"https://arxiv.org/pdf/2212.09674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09670v1","updated":"2022-12-19T17:59:18Z","published":"2022-12-19T17:59:18Z","title":"StyleFlow: Disentangle Latent Representations via Normalizing Flow for\n  Unsupervised Text Style Transfer","summary":"  Text style transfer aims to alter the style of a sentence while preserving\nits content. Due to the lack of parallel corpora, most recent work focuses on\nunsupervised methods and often uses cycle construction to train models. Since\ncycle construction helps to improve the style transfer ability of the model by\nrebuilding transferred sentences back to original-style sentences, it brings\nabout a content loss in unsupervised text style transfer tasks. In this paper,\nwe propose a novel disentanglement-based style transfer model StyleFlow to\nenhance content preservation. Instead of the typical encoder-decoder scheme,\nStyleFlow can not only conduct the forward process to obtain the output, but\nalso infer to the input through the output. We design an attention-aware\ncoupling layers to disentangle the content representations and the style\nrepresentations of a sentence. Besides, we propose a data augmentation method\nbased on Normalizing Flow to improve the robustness of the model. Experiment\nresults demonstrate that our model preserves content effectively and achieves\nthe state-of-the-art performance on the most metrics.\n","authors":["Kangchen Zhu","Zhiliang Tian","Ruifeng Luo","Xiaoguang Mao"],"pdf_url":"https://arxiv.org/pdf/2212.09670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09667v1","updated":"2022-12-19T17:51:47Z","published":"2022-12-19T17:51:47Z","title":"Foveate, Attribute, and Rationalize: Towards Safe and Trustworthy AI","summary":"  Users' physical safety is an increasing concern as the market for intelligent\nsystems continues to grow, where unconstrained systems may recommend users\ndangerous actions that can lead to serious injury. Covertly unsafe text,\nlanguage that contains actionable physical harm, but requires further reasoning\nto identify such harm, is an area of particular interest, as such texts may\narise from everyday scenarios and are challenging to detect as harmful.\nQualifying the knowledge required to reason about the safety of various texts\nand providing human-interpretable rationales can shed light on the risk of\nsystems to specific user groups, helping both stakeholders manage the risks of\ntheir systems and policymakers to provide concrete safeguards for consumer\nsafety. We propose FARM, a novel framework that leverages external knowledge\nfor trustworthy rationale generation in the context of safety. In particular,\nFARM foveates on missing knowledge in specific scenarios, retrieves this\nknowledge with attribution to trustworthy sources, and uses this to both\nclassify the safety of the original text and generate human-interpretable\nrationales, combining critically important qualities for sensitive domains such\nas user safety. Furthermore, FARM obtains state-of-the-art results on the\nSafeText dataset, improving safety classification accuracy by 5.29 points.\n","authors":["Alex Mei","Sharon Levy","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09667v1.pdf","comment":"9 pages, 3 figures, 5 tables"},{"id":"http://arxiv.org/abs/2212.09666v1","updated":"2022-12-19T17:50:05Z","published":"2022-12-19T17:50:05Z","title":"MultiCoder: Multi-Programming-Lingual Pre-Training for Low-Resource Code\n  Completion","summary":"  Code completion is a valuable topic in both academia and industry. Recently,\nlarge-scale mono-programming-lingual (MonoPL) pre-training models have been\nproposed to boost the performance of code completion. However, the code\ncompletion on low-resource programming languages (PL) is difficult for the\ndata-driven paradigm, while there are plenty of developers using low-resource\nPLs. On the other hand, there are few studies exploring the effects of\nmulti-programming-lingual (MultiPL) pre-training for the code completion,\nespecially the impact on low-resource programming languages. To this end, we\npropose the MultiCoder to enhance the low-resource code completion via MultiPL\npre-training and MultiPL Mixture-of-Experts (MoE) layers. We further propose a\nnovel PL-level MoE routing strategy (PL-MoE) for improving the code completion\non all PLs. Experimental results on CodeXGLUE and MultiCC demonstrate that 1)\nthe proposed MultiCoder significantly outperforms the MonoPL baselines on\nlow-resource programming languages, and 2) the PL-MoE module further boosts the\nperformance on six programming languages. In addition, we analyze the effects\nof the proposed method in details and explore the effectiveness of our method\nin a variety of scenarios.\n","authors":["Zi Gong","Yinpeng Guo","Pingyi Zhou","Cuiyun Gao","Yasheng Wang","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09663v1","updated":"2022-12-19T17:45:07Z","published":"2022-12-19T17:45:07Z","title":"Norm of word embedding encodes information gain","summary":"  Distributed representations of words encode lexical semantic information, but\nhow is that information encoded in word embeddings? Focusing on the skip-gram\nwith negative-sampling method, we show theoretically and experimentally that\nthe squared norm of word embedding encodes the information gain defined by the\nKullback-Leibler divergence of the co-occurrence distribution of a word to the\nunigram distribution of the corpus. Furthermore, through experiments on tasks\nof keyword extraction, hypernym prediction, and part-of-speech discrimination,\nwe confirmed that the KL divergence and the squared norm of embedding work as a\nmeasure of the informativeness of a word provided that the bias caused by word\nfrequency is adequately corrected.\n","authors":["Momose Oyama","Sho Yokoi","Hidetoshi Shimodaira"],"pdf_url":"https://arxiv.org/pdf/2212.09663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09662v1","updated":"2022-12-19T17:44:54Z","published":"2022-12-19T17:44:54Z","title":"MatCha: Enhancing Visual Language Pretraining with Math Reasoning and\n  Chart Derendering","summary":"  Visual language data such as plots, charts, and infographics are ubiquitous\nin the human world. However, state-of-the-art vision-language models do not\nperform well on these data. We propose MatCha (Math reasoning and Chart\nderendering pretraining) to enhance visual language models' capabilities in\njointly modeling charts/plots and language data. Specifically, we propose\nseveral pretraining tasks that cover plot deconstruction and numerical\nreasoning which are the key capabilities in visual language modeling.\n  We perform the MatCha pretraining starting from Pix2Struct, a recently\nproposed image-to-text visual language model. On standard benchmarks such as\nPlotQA and ChartQA, the MatCha model outperforms state-of-the-art methods by as\nmuch as nearly 20%. We also examine how well MatCha pretraining transfers to\ndomains such as screenshots, textbook diagrams, and document figures and\nobserve overall improvement, verifying the usefulness of MatCha pretraining on\nbroader visual language tasks.\n","authors":["Fangyu Liu","Francesco Piccinno","Syrine Krichene","Chenxi Pang","Kenton Lee","Mandar Joshi","Yasemin Altun","Nigel Collier","Julian Martin Eisenschlos"],"pdf_url":"https://arxiv.org/pdf/2212.09662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09660v1","updated":"2022-12-19T17:42:07Z","published":"2022-12-19T17:42:07Z","title":"The Decades Progress on Code-Switching Research in NLP: A Systematic\n  Survey on Trends and Challenges","summary":"  Code-Switching, a common phenomenon in written text and conversation, has\nbeen studied over decades by the natural language processing (NLP) research\ncommunity. Initially, code-switching is intensively explored by leveraging\nlinguistic theories and, currently, more machine-learning oriented approaches\nto develop models. We introduce a comprehensive systematic survey on\ncode-switching research in natural language processing to understand the\nprogress of the past decades and conceptualize the challenges and tasks on the\ncode-switching topic. Finally, we summarize the trends and findings and\nconclude with a discussion for future direction and open questions for further\ninvestigation.\n","authors":["Genta Indra Winata","Alham Fikri Aji","Zheng-Xin Yong","Thamar Solorio"],"pdf_url":"https://arxiv.org/pdf/2212.09660v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.09656v1","updated":"2022-12-19T17:39:07Z","published":"2022-12-19T17:39:07Z","title":"Visconde: Multi-document QA with GPT-3 and Neural Reranking","summary":"  This paper proposes a question-answering system that can answer questions\nwhose supporting evidence is spread over multiple (potentially long) documents.\nThe system, called Visconde, uses a three-step pipeline to perform the task:\ndecompose, retrieve, and aggregate. The first step decomposes the question into\nsimpler questions using a few-shot large language model (LLM). Then, a\nstate-of-the-art search engine is used to retrieve candidate passages from a\nlarge collection for each decomposed question. In the final step, we use the\nLLM in a few-shot setting to aggregate the contents of the passages into the\nfinal answer. The system is evaluated on three datasets: IIRC, Qasper, and\nStrategyQA. Results suggest that current retrievers are the main bottleneck and\nthat readers are already performing at the human level as long as relevant\npassages are provided. The system is also shown to be more effective when the\nmodel is induced to give explanations before answering a question. Code is\navailable at \\url{https://github.com/neuralmind-ai/visconde}.\n","authors":["Jayr Pereira","Robson Fidalgo","Roberto Lotufo","Rodrigo Nogueira"],"pdf_url":"https://arxiv.org/pdf/2212.09656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09651v1","updated":"2022-12-19T17:29:37Z","published":"2022-12-19T17:29:37Z","title":"Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages","summary":"  Multilingual Pretrained Language Models (MPLMs) have shown their strong\nmultilinguality in recent empirical cross-lingual transfer studies. In this\npaper, we propose the Prompts Augmented by Retrieval Crosslingually (PARC)\npipeline to improve the zero-shot performance on low-resource languages (LRLs)\nby augmenting the context with semantically similar sentences retrieved from a\nhigh-resource language (HRL) as prompts. PARC improves the zero-shot\nperformance on three downstream tasks (binary sentiment classification, topic\ncategorization and natural language inference) with multilingual parallel test\nsets across 10 LRLs covering 6 language families in both unlabeled settings\n(+5.1%) and labeled settings (+16.3%). PARC-labeled also outperforms the\nfinetuning baseline by 3.7%. We find a significant positive correlation between\ncross-lingual transfer performance on one side, and the similarity between the\nhigh- and low-resource languages as well as the amount of low-resource\npretraining data on the other side. A robustness analysis suggests that PARC\nhas the potential to achieve even stronger performance with more powerful\nMPLMs.\n","authors":["Ercong Nie","Sheng Liang","Helmut Schmid","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2212.09651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09648v1","updated":"2022-12-19T17:28:22Z","published":"2022-12-19T17:28:22Z","title":"NusaCrowd: Open Source Initiative for Indonesian NLP Resources","summary":"  We present NusaCrowd, a collaborative initiative to collect and unite\nexisting resources for Indonesian languages, including opening access to\npreviously non-public resources. Through this initiative, we have has brought\ntogether 137 datasets and 117 standardized data loaders. The quality of the\ndatasets has been assessed manually and automatically, and their effectiveness\nhas been demonstrated in multiple experiments. NusaCrowd's data collection\nenables the creation of the first zero-shot benchmarks for natural language\nunderstanding and generation in Indonesian and its local languages.\nFurthermore, NusaCrowd brings the creation of the first multilingual automatic\nspeech recognition benchmark in Indonesian and its local languages. Our work is\nintended to help advance natural language processing research in\nunder-represented languages.\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Alham Fikri Aji","Genta Indra Winata","Bryan Wilie","Rahmad Mahendra","Christian Wibisono","Ade Romadhony","Karissa Vincentio","Fajri Koto","Jennifer Santoso","David Moeljadi","Cahya Wirawan","Frederikus Hudi","Ivan Halim Parmonangan","Ika Alfina","Muhammad Satrio Wicaksono","Ilham Firdausi Putra","Samsul Rahmadani","Yulianti Oenang","Ali Akbar Septiandri","James Jaya","Kaustubh D. Dhole","Arie Ardiyanti Suryani","Rifki Afina Putri","Dan Su","Keith Stevens","Made Nindyatama Nityasya","Muhammad Farid Adilazuarda","Ryan Ignatius","Ryandito Diandaru","Tiezheng Yu","Vito Ghifari","Wenliang Dai","Yan Xu","Dyah Damapuspita","Cuk Tho","Ichwanul Muslim Karo Karo","Tirana Noor Fatyanosa","Ziwei Ji","Pascale Fung","Graham Neubig","Timothy Baldwin","Sebastian Ruder","Herry Sujaini","Sakriani Sakti","Ayu Purwarianti"],"pdf_url":"https://arxiv.org/pdf/2212.09648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09631v1","updated":"2022-12-19T17:06:58Z","published":"2022-12-19T17:06:58Z","title":"Optimal Transport for Unsupervised Hallucination Detection in Neural\n  Machine Translation","summary":"  Neural machine translation (NMT) has become the de-facto standard in\nreal-world machine translation applications. However, NMT models can\nunpredictably produce severely pathological translations, known as\nhallucinations, that seriously undermine user trust. It becomes thus crucial to\nimplement effective preventive strategies to guarantee their proper\nfunctioning. In this paper, we address the problem of hallucination detection\nin NMT by following a simple intuition: as hallucinations are detached from the\nsource content, they exhibit encoder-decoder attention patterns that are\nstatistically different from those of good quality translations. We frame this\nproblem with an optimal transport formulation and propose a fully unsupervised,\nplug-in detector that can be used with any attention-based NMT model.\nExperimental results show that our detector not only outperforms all previous\nmodel-based detectors, but is also competitive with detectors that employ large\nmodels trained on millions of samples.\n","authors":["Nuno M. Guerreiro","Pierre Colombo","Pablo Piantanida","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2212.09631v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09621v1","updated":"2022-12-19T17:00:54Z","published":"2022-12-19T17:00:54Z","title":"Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document\n  Understanding","summary":"  Unsupervised pre-training on millions of digital-born or scanned documents\nhas shown promising advances in visual document understanding~(VDU). While\nvarious vision-language pre-training objectives are studied in existing\nsolutions, the document textline, as an intrinsic granularity in VDU, has\nseldom been explored so far. A document textline usually contains words that\nare spatially and semantically correlated, which can be easily obtained from\nOCR engines. In this paper, we propose Wukong-Reader, trained with new\npre-training objectives to leverage the structural knowledge nested in document\ntextlines. We introduce textline-region contrastive learning to achieve\nfine-grained alignment between the visual regions and texts of document\ntextlines. Furthermore, masked region modeling and textline-grid matching are\nalso designed to enhance the visual and layout representations of textlines.\nExperiments show that our Wukong-Reader has superior performance on various VDU\ntasks such as information extraction. The fine-grained alignment over textlines\nalso empowers Wukong-Reader with promising localization ability.\n","authors":["Haoli Bai","Zhiguang Liu","Xiaojun Meng","Wentao Li","Shuang Liu","Nian Xie","Rongfu Zheng","Liangwei Wang","Lu Hou","Jiansheng Wei","Xin Jiang","Qun Liu"],"pdf_url":"https://arxiv.org/pdf/2212.09621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09611v1","updated":"2022-12-19T16:50:41Z","published":"2022-12-19T16:50:41Z","title":"Optimizing Prompts for Text-to-Image Generation","summary":"  Well-designed prompts can guide text-to-image models to generate amazing\nimages. However, the performant prompts are often model-specific and misaligned\nwith user input. Instead of laborious human engineering, we propose prompt\nadaptation, a general framework that automatically adapts original user input\nto model-preferred prompts. Specifically, we first perform supervised\nfine-tuning with a pretrained language model on a small collection of manually\nengineered prompts. Then we use reinforcement learning to explore better\nprompts. We define a reward function that encourages the policy to generate\nmore aesthetically pleasing images while preserving the original user\nintentions. Experimental results on Stable Diffusion show that our method\noutperforms manual prompt engineering in terms of both automatic metrics and\nhuman preference ratings. Moreover, reinforcement learning further boosts\nperformance, especially on out-of-domain prompts. The pretrained checkpoints\nare available at https://aka.ms/promptist. The demo can be found at\nhttps://aka.ms/promptist-demo.\n","authors":["Yaru Hao","Zewen Chi","Li Dong","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.09611v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2212.09603v1","updated":"2022-12-19T16:41:19Z","published":"2022-12-19T16:41:19Z","title":"Explanation Regeneration via Information Bottleneck","summary":"  Explaining the black-box predictions of NLP models naturally and accurately\nis an important open problem in natural language generation. These free-text\nexplanations are expected to contain sufficient and carefully-selected evidence\nto form supportive arguments for predictions. Due to the superior generative\ncapacity of large pretrained language models, recent work built on prompt\nengineering enables explanation generation without specific training. However,\nexplanation generated through single-pass prompting often lacks sufficiency and\nconciseness. To address this problem, we develop an information bottleneck\nmethod EIB to produce refined explanations that are sufficient and concise. Our\napproach regenerates the free-text explanation by polishing the single-pass\noutput from the pretrained language model but retaining the information that\nsupports the contents being explained. Experiments on two out-of-domain tasks\nverify the effectiveness of EIB through automatic evaluation and\nthoroughly-conducted human evaluation.\n","authors":["Qintong Li","Zhiyong Wu","Lingpeng Kong","Wei Bi"],"pdf_url":"https://arxiv.org/pdf/2212.09603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08410v2","updated":"2022-12-19T16:33:30Z","published":"2022-12-16T11:24:42Z","title":"Teaching Small Language Models to Reason","summary":"  Chain of thought prompting successfully improves the reasoning capabilities\nof large language models, achieving state of the art results on a range of\ndatasets. However, these reasoning capabilities only appear to emerge in models\nwith a size of over 100 billion parameters. In this paper, we explore the\ntransfer of such reasoning capabilities to models with less than 100 billion\nparameters via knowledge distillation. Specifically, we finetune a student\nmodel on the chain of thought outputs generated by a larger teacher model. Our\nexperiments show that the proposed method improves task performance across\narithmetic, commonsense and symbolic reasoning datasets. For example, the\naccuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on\nPaLM-540B generated chains of thought.\n","authors":["Lucie Charlotte Magister","Jonathan Mallinson","Jakub Adamek","Eric Malmi","Aliaksei Severyn"],"pdf_url":"https://arxiv.org/pdf/2212.08410v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09597v1","updated":"2022-12-19T16:32:42Z","published":"2022-12-19T16:32:42Z","title":"Reasoning with Language Model Prompting: A Survey","summary":"  Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions.\n","authors":["Shuofei Qiao","Yixin Ou","Ningyu Zhang","Xiang Chen","Yunzhi Yao","Shumin Deng","Chuanqi Tan","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2212.09597v1.pdf","comment":"Work in progress and resources are available at\n  https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically)"},{"id":"http://arxiv.org/abs/2212.09593v1","updated":"2022-12-19T16:29:26Z","published":"2022-12-19T16:29:26Z","title":"Unsupervised Summarization Re-ranking","summary":"  With the rise of task-specific pre-training objectives, abstractive\nsummarization models like PEGASUS offer appealing zero-shot performance on\ndownstream summarization tasks. However, the performance of such unsupervised\nmodels still lags significantly behind their supervised counterparts. Similarly\nto the supervised setup, we notice a very high variance in quality among\nsummary candidates from these models whereas only one candidate is kept as the\nsummary output. In this paper, we propose to re-rank summary candidates in an\nunsupervised manner, aiming to close the performance gap between unsupervised\nand supervised models. Our approach improves the pre-trained unsupervised\nPEGASUS by 4.37% to 7.27% relative mean ROUGE across four widely-adopted\nsummarization benchmarks, and achieves relative gains of 7.51% (up to 23.73%)\naveraged over 30 transfer setups.\n","authors":["Mathieu Ravaut","Shafiq Joty","Nancy Chen"],"pdf_url":"https://arxiv.org/pdf/2212.09593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09588v1","updated":"2022-12-19T16:21:05Z","published":"2022-12-19T16:21:05Z","title":"Query Enhanced Knowledge-Intensive Conversation via Unsupervised Joint\n  Modeling","summary":"  The quality of knowledge retrieval is crucial in knowledge-intensive\nconversations. Two common strategies to improve the retrieval quality are\nfinetuning the retriever or generating a self-contained query, while they\nencounter heavy burdens on expensive computation and elaborate annotations. In\nthis paper, we propose an unsupervised query enhanced approach for\nknowledge-intensive conversations, namely QKConv. There are three modules in\nQKConv: a query generator, an off-the-shelf knowledge selector, and a response\ngenerator. Without extra supervision, the end-to-end joint training of QKConv\nexplores multiple candidate queries and utilizes corresponding selected\nknowledge to yield the target response. To evaluate the effectiveness of the\nproposed method, we conducted comprehensive experiments on conversational\nquestion-answering, task-oriented dialogue, and knowledge-grounded\nconversation. Experimental results demonstrate that QKConv achieves\nstate-of-the-art performance compared to unsupervised methods and competitive\nperformance compared to supervised methods.\n","authors":["Mingzhu Cai","Siqi Bao","Xin Tian","Huang He","Fan Wang","Hua Wu"],"pdf_url":"https://arxiv.org/pdf/2212.09588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09580v1","updated":"2022-12-19T16:13:52Z","published":"2022-12-19T16:13:52Z","title":"Independent Components of Word Embeddings Represent Semantic Features","summary":"  Independent Component Analysis (ICA) is an algorithm originally developed for\nfinding separate sources in a mixed signal, such as a recording of multiple\npeople in the same room speaking at the same time. It has also been used to\nfind linguistic features in distributional representations. In this paper, we\nused ICA to analyze words embeddings. We have found that ICA can be used to\nfind semantic features of the words and these features can easily be combined\nto search for words that satisfy the combination. We show that only some of the\nindependent components represent such features, but those that do are stable\nwith regard to random initialization of the algorithm.\n","authors":["Tomáš Musil","David Mareček"],"pdf_url":"https://arxiv.org/pdf/2212.09580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09577v1","updated":"2022-12-19T16:10:56Z","published":"2022-12-19T16:10:56Z","title":"CiteBench: A benchmark for Scientific Citation Text Generation","summary":"  The publication rates are skyrocketing across many fields of science, and it\nis difficult to stay up to date with the latest research. This makes\nautomatically summarizing the latest findings and helping scholars to\nsynthesize related work in a given area an attractive research objective. In\nthis paper we study the problem of citation text generation, where given a set\nof cited papers and citing context the model should generate a citation text.\nWhile citation text generation has been tackled in prior work, existing studies\nuse different datasets and task definitions, which makes it hard to study\ncitation text generation systematically. To address this, we propose CiteBench:\na benchmark for citation text generation that unifies the previous datasets and\nenables standardized evaluation of citation text generation models across task\nsettings and domains. Using the new benchmark, we investigate the performance\nof multiple strong baselines, test their transferability between the datasets,\nand deliver new insights into task definition and evaluation to guide the\nfuture research in citation text generation. We make CiteBench publicly\navailable at https://github.com/UKPLab/citebench.\n","authors":["Martin Funkquist","Ilia Kuznetsov","Yufang Hou","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2212.09577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09573v1","updated":"2022-12-19T16:06:45Z","published":"2022-12-19T16:06:45Z","title":"Privacy Adhering Machine Un-learning in NLP","summary":"  Regulations introduced by General Data Protection Regulation (GDPR) in the EU\nor California Consumer Privacy Act (CCPA) in the US have included provisions on\nthe \\textit{right to be forgotten} that mandates industry applications to\nremove data related to an individual from their systems. In several real world\nindustry applications that use Machine Learning to build models on user data,\nsuch mandates require significant effort both in terms of data cleansing as\nwell as model retraining while ensuring the models do not deteriorate in\nprediction quality due to removal of data. As a result, continuous removal of\ndata and model retraining steps do not scale if these applications receive such\nrequests at a very high frequency. Recently, a few researchers proposed the\nidea of \\textit{Machine Unlearning} to tackle this challenge. Despite the\nsignificant importance of this task, the area of Machine Unlearning is\nunder-explored in Natural Language Processing (NLP) tasks. In this paper, we\nexplore the Unlearning framework on various GLUE tasks \\cite{Wang:18}, such as,\nQQP, SST and MNLI. We propose computationally efficient approaches (SISA-FC and\nSISA-A) to perform \\textit{guaranteed} Unlearning that provides significant\nreduction in terms of both memory (90-95\\%), time (100x) and space consumption\n(99\\%) in comparison to the baselines while keeping model performance constant.\n","authors":["Vinayshekhar Bannihatti Kumar","Rashmi Gangadharaiah","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2212.09573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09563v1","updated":"2022-12-19T15:53:12Z","published":"2022-12-19T15:53:12Z","title":"Source-Free Domain Adaptation for Question Answering with Masked\n  Self-training","summary":"  Most previous unsupervised domain adaptation (UDA) methods for question\nanswering(QA) require access to source domain data while fine-tuning the model\nfor the target domain. Source domain data may, however, contain sensitive\ninformation and may be restricted. In this study, we investigate a more\nchallenging setting, source-free UDA, in which we have only the pretrained\nsource model and target domain data, without access to source domain data. We\npropose a novel self-training approach to QA models that integrates a unique\nmask module for domain adaptation. The mask is auto-adjusted to extract key\ndomain knowledge while trained on the source domain. To maintain previously\nlearned domain knowledge, certain mask weights are frozen during adaptation,\nwhile other weights are adjusted to mitigate domain shifts with pseudo-labeled\nsamples generated in the target domain. %As part of the self-training process,\nwe generate pseudo-labeled samples in the target domain based on models trained\nin the source domain. Our empirical results on four benchmark datasets suggest\nthat our approach significantly enhances the performance of pretrained QA\nmodels on the target domain, and even outperforms models that have access to\nthe source data during adaptation.\n","authors":["M. Yin","B. Wang","Y. Dong","C. Ling"],"pdf_url":"https://arxiv.org/pdf/2212.09563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09561v1","updated":"2022-12-19T15:51:52Z","published":"2022-12-19T15:51:52Z","title":"Large Language Models are reasoners with Self-Verification","summary":"  When a large language model (LLM) performs complex reasoning by chain of\nthought (CoT), it can be highly sensitive to individual mistakes. We have had\nto train verifiers to address this issue. As we all know, after human inferring\na conclusion, they often check it by re-verifying it, which can avoid some\nmistakes. We propose a new method called self-verification that uses the\nconclusion of the CoT as a condition to build a new sample and asks the LLM to\nre-predict the original conditions which be masked. We calculate an explainable\nverification score based on the accuracy. This method can improve the accuracy\nof multiple arithmetics and logical reasoning datasets when using few-shot\nlearning. we have demonstrated that LLMs can conduct explainable\nself-verification of their own conclusions and achieve competitive reasoning\nperformance. Extensive experimentals have demonstrated that our method can help\nmultiple large language models with self-verification can avoid interference\nfrom incorrect CoT. Code is available at\n\\url{https://github.com/WENGSYX/Self-Verification}\n","authors":["Yixuan Weng","Minjun Zhu","Shizhu He","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2212.09561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01837v2","updated":"2022-12-19T15:46:25Z","published":"2022-11-03T14:18:48Z","title":"Latent Prompt Tuning for Text Summarization","summary":"  Prompts with different control signals (e.g., length, keywords, etc.) can be\nused to control text summarization. When control signals are available, they\ncan control the properties of generated summaries and potentially improve\nsummarization quality (since more information are given). Unfortunately,\ncontrol signals are not already available during inference time. In this paper,\nwe propose Lotus (shorthand for Latent Prompt Tuning for Summarization), which\nis a single model that can be applied in both controlled and uncontrolled\n(without control signals) modes. During training, Lotus learns latent prompt\nrepresentations from prompts with gold control signals using a contrastive\nlearning objective. Experiments show Lotus in uncontrolled mode consistently\nimproves upon strong (uncontrollable) summarization models across four\ndifferent summarization datasets. We also demonstrate generated summaries can\nbe controlled using prompts with user specified control tokens.\n","authors":["Yubo Zhang","Xingxing Zhang","Xun Wang","Si-qing Chen","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2211.01837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09553v1","updated":"2022-12-19T15:45:36Z","published":"2022-12-19T15:45:36Z","title":"Mu$^{2}$SLAM: Multitask, Multilingual Speech and Language Models","summary":"  We present Mu$^{2}$SLAM, a multilingual sequence-to-sequence model\npre-trained jointly on unlabeled speech, unlabeled text and supervised data\nspanning Automatic Speech Recognition (ASR), Automatic Speech Translation (AST)\nand Machine Translation (MT), in over 100 languages. By leveraging a quantized\nrepresentation of speech as a target, Mu$^{2}$SLAM trains the speech-text\nmodels with a sequence-to-sequence masked denoising objective similar to T5 on\nthe decoder and a masked language modeling (MLM) objective on the encoder, for\nboth unlabeled speech and text, while utilizing the supervised tasks to improve\ncross-lingual and cross-modal representation alignment within the model. On\nCoVoST AST, Mu$^{2}$SLAM establishes a new state-of-the-art for models trained\non public datasets, improving on xx-en translation over the previous best by\n1.9 BLEU points and on en-xx translation by 1.1 BLEU points. On Voxpopuli ASR,\nour model matches the performance of an mSLAM model fine-tuned with an RNN-T\ndecoder, despite using a relatively weaker sequence-to-sequence architecture.\nOn text understanding tasks, our model improves by more than 6\\% over mSLAM on\nXNLI, getting closer to the performance of mT5 models of comparable capacity on\nXNLI and TydiQA, paving the way towards a single model for all speech and text\nunderstanding tasks.\n","authors":["Yong Cheng","Yu Zhang","Melvin Johnson","Wolfgang Macherey","Ankur Bapna"],"pdf_url":"https://arxiv.org/pdf/2212.09553v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09535v1","updated":"2022-12-19T15:24:45Z","published":"2022-12-19T15:24:45Z","title":"BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting","summary":"  The BLOOM model is a large open-source multilingual language model capable of\nzero-shot learning, but its pretraining was limited to 46 languages. To improve\nits zero-shot performance on unseen languages, it is desirable to adapt BLOOM,\nbut previous works have only explored adapting small language models. In this\nwork, we apply existing language adaptation strategies to BLOOM and benchmark\nits zero-shot prompting performance on eight new languages. We find language\nadaptation to be effective at improving zero-shot performance in new languages.\nSurprisingly, adapter-based finetuning is more effective than continued\npretraining for large models. In addition, we discover that prompting\nperformance is not significantly affected by language specifics, such as the\nwriting system. It is primarily determined by the size of the language\nadaptation data. We also add new languages to BLOOMZ, which is a multitask\nfinetuned version of BLOOM capable of following task instructions zero-shot. We\nfind including a new language in the multitask fine-tuning mixture to be the\nmost effective method to teach BLOOMZ a new language. We conclude that with\nsufficient training data language adaptation can generalize well to diverse\nlanguages. Our code is available at\n\\url{https://github.com/bigscience-workshop/multilingual-modeling/}.\n","authors":["Zheng-Xin Yong","Hailey Schoelkopf","Niklas Muennighoff","Alham Fikri Aji","David Ifeoluwa Adelani","Khalid Almubarak","M Saiful Bari","Lintang Sutawika","Jungo Kasai","Ahmed Baruwa","Genta Indra Winata","Stella Biderman","Dragomir Radev","Vassilina Nikoulina"],"pdf_url":"https://arxiv.org/pdf/2212.09535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09512v1","updated":"2022-12-19T14:48:08Z","published":"2022-12-19T14:48:08Z","title":"Rethinking Label Smoothing on Multi-hop Question Answering","summary":"  Label smoothing is a regularization technique widely used in supervised\nlearning to improve the generalization of models on various tasks, such as\nimage classification and machine translation. However, the effectiveness of\nlabel smoothing in multi-hop question answering (MHQA) has yet to be well\nstudied. In this paper, we systematically analyze the role of label smoothing\non various modules of MHQA and propose F1 smoothing, a novel label smoothing\ntechnique specifically designed for machine reading comprehension (MRC) tasks.\nWe evaluate our method on the HotpotQA dataset and demonstrate its superiority\nover several strong baselines, including models that utilize complex attention\nmechanisms. Our results suggest that label smoothing can be effective in MHQA,\nbut the choice of smoothing strategy can significantly affect performance.\n","authors":["Zhangyue Yin","Yuxin Wang","Yiguang Wu","Hang Yan","Xiannian Hu","Xinyu Zhang","Zhao Cao","Xuanjing Huang","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2212.09512v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2211.16944v2","updated":"2022-12-19T14:31:47Z","published":"2022-11-30T12:35:00Z","title":"AIONER: All-in-one scheme-based biomedical named entity recognition\n  using deep learning","summary":"  Biomedical named entity recognition (BioNER) seeks to automatically recognize\nbiomedical entities in natural language text, serving as a necessary foundation\nfor downstream text mining tasks and applications such as information\nextraction and question answering. Manually labeling training data for the\nBioNER task is costly, however, due to the significant domain expertise\nrequired for accurate annotation. The resulting data scarcity causes current\nBioNER approaches to be prone to overfitting, to suffer from limited\ngeneralizability, and to address a single entity type at a time (e.g., gene or\ndisease). We therefore propose a novel all-in-one (AIO) scheme that uses\nexternal data from existing annotated resources to improve generalization. We\nfurther present AIONER, a general-purpose BioNER tool based on cutting-edge\ndeep learning and our AIO schema. We evaluate AIONER on 14 BioNER benchmark\ntasks and show that AIONER is effective, robust, and compares favorably to\nother state-of-the-art approaches such as multi-task learning. We further\ndemonstrate the practical utility of AIONER in three independent tasks to\nrecognize entity types not previously seen in training data, as well as the\nadvantages of AIONER over existing methods for processing biomedical text at a\nlarge scale (e.g., the entire PubMed data).\n","authors":["Ling Luo","Chih-Hsuan Wei","Po-Ting Lai","Robert Leaman","Qingyu Chen","Zhiyong Lu"],"pdf_url":"https://arxiv.org/pdf/2211.16944v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09465v1","updated":"2022-12-19T13:58:48Z","published":"2022-12-19T13:58:48Z","title":"Improving the Generalizability of Text-Based Emotion Detection by\n  Leveraging Transformers with Psycholinguistic Features","summary":"  In recent years, there has been increased interest in building predictive\nmodels that harness natural language processing and machine learning techniques\nto detect emotions from various text sources, including social media posts,\nmicro-blogs or news articles. Yet, deployment of such models in real-world\nsentiment and emotion applications faces challenges, in particular poor\nout-of-domain generalizability. This is likely due to domain-specific\ndifferences (e.g., topics, communicative goals, and annotation schemes) that\nmake transfer between different models of emotion recognition difficult. In\nthis work we propose approaches for text-based emotion detection that leverage\ntransformer models (BERT and RoBERTa) in combination with Bidirectional Long\nShort-Term Memory (BiLSTM) networks trained on a comprehensive set of\npsycholinguistic features. First, we evaluate the performance of our models\nwithin-domain on two benchmark datasets: GoEmotion and ISEAR. Second, we\nconduct transfer learning experiments on six datasets from the Unified Emotion\nDataset to evaluate their out-of-domain robustness. We find that the proposed\nhybrid models improve the ability to generalize to out-of-distribution data\ncompared to a standard transformer-based approach. Moreover, we observe that\nthese models perform competitively on in-domain data.\n","authors":["Sourabh Zanwar","Daniel Wiechmann","Yu Qiao","Elma Kerz"],"pdf_url":"https://arxiv.org/pdf/2212.09465v1.pdf","comment":"accepted at EMNLP2022"},{"id":"http://arxiv.org/abs/2212.09462v1","updated":"2022-12-19T13:57:06Z","published":"2022-12-19T13:57:06Z","title":"Latent Diffusion for Language Generation","summary":"  Diffusion models have achieved great success in modeling continuous data\nmodalities such as images, audio, and video, but have seen limited use in\ndiscrete domains such as language. Recent attempts to adapt diffusion to\nlanguage have presented diffusion as an alternative to autoregressive language\ngeneration. We instead view diffusion as a complementary method that can\naugment the generative capabilities of existing pre-trained language models. We\ndemonstrate that continuous diffusion models can be learned in the latent space\nof a pre-trained encoder-decoder model, enabling us to sample continuous latent\nrepresentations that can be decoded into natural language with the pre-trained\ndecoder. We show that our latent diffusion models are more effective at\nsampling novel text from data distributions than a strong autoregressive\nbaseline and also enable controllable generation.\n","authors":["Justin Lovelace","Varsha Kishore","Chao Wan","Eliot Shekhtman","Kilian Weinberger"],"pdf_url":"https://arxiv.org/pdf/2212.09462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.08585v2","updated":"2022-12-19T13:22:59Z","published":"2021-05-18T15:13:04Z","title":"Revisiting Additive Compositionality: AND, OR and NOT Operations with\n  Word Embeddings","summary":"  It is well-known that typical word embedding methods such as Word2Vec and\nGloVe have the property that the meaning can be composed by adding up the\nembeddings (additive compositionality). Several theories have been proposed to\nexplain additive compositionality, but the following questions remain\nunanswered: (Q1) The assumptions of those theories do not hold for the\npractical word embedding. (Q2) Ordinary additive compositionality can be seen\nas an AND operation of word meanings, but it is not well understood how other\noperations, such as OR and NOT, can be computed by the embeddings. We address\nthese issues by the idea of frequency-weighted centering at its core. This\npaper proposes a post-processing method for bridging the gap between practical\nword embedding and the assumption of theory about additive compositionality as\nan answer to (Q1). It also gives a method for taking OR or NOT of the meaning\nby linear operation of word embedding as an answer to (Q2). Moreover, we\nconfirm experimentally that the accuracy of AND operation, i.e., the ordinary\nadditive compositionality, can be improved by our post-processing method (3.5x\nimprovement in top-100 accuracy) and that OR and NOT operations can be\nperformed correctly.\n","authors":["Masahiro Naito","Sho Yokoi","Geewook Kim","Hidetoshi Shimodaira"],"pdf_url":"https://arxiv.org/pdf/2105.08585v2.pdf","comment":"13pages; v1: accepted at ACL-IJCNLP 2021 Student Research Workshop;\n  v2: minor revision"},{"id":"http://arxiv.org/abs/2212.09422v1","updated":"2022-12-19T12:57:11Z","published":"2022-12-19T12:57:11Z","title":"Human in the loop: How to effectively create coherent topics by manually\n  labeling only a few documents per class","summary":"  Few-shot methods for accurate modeling under sparse label-settings have\nimproved significantly. However, the applications of few-shot modeling in\nnatural language processing remain solely in the field of document\nclassification. With recent performance improvements, supervised few-shot\nmethods, combined with a simple topic extraction method pose a significant\nchallenge to unsupervised topic modeling methods. Our research shows that\nsupervised few-shot learning, combined with a simple topic extraction method,\ncan outperform unsupervised topic modeling techniques in terms of generating\ncoherent topics, even when only a few labeled documents per class are used.\n","authors":["Anton Thielmann","Christoph Weisser","Benjamin Säfken"],"pdf_url":"https://arxiv.org/pdf/2212.09422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09420v1","updated":"2022-12-19T12:55:32Z","published":"2022-12-19T12:55:32Z","title":"When Neural Model Meets NL2Code: A Survey","summary":"  Given a natural language that describes the user's demands, the NL2Code task\naims to generate code that addresses the demands. This is a critical but\nchallenging task that mirrors the capabilities of AI-powered programming. The\nNL2Code task is inherently versatile, diverse and complex. For example, a\ndemand can be described in different languages, in different formats, and at\ndifferent levels of granularity. This inspired us to do this survey for\nNL2Code. In this survey, we focus on how does neural network (NN) solves\nNL2Code. We first propose a comprehensive framework, which is able to cover all\nstudies in this field. Then, we in-depth parse the existing studies into this\nframework. We create an online website to record the parsing results, which\ntracks existing and recent NL2Code progress. In addition, we summarize the\ncurrent challenges of NL2Code as well as its future directions. We hope that\nthis survey can foster the evolution of this field.\n","authors":["Daoguang Zan","Bei Chen","Fengji Zhang","Dianjie Lu","Bingchao Wu","Bei Guan","Yongji Wang","Jian-Guang Lou"],"pdf_url":"https://arxiv.org/pdf/2212.09420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09412v1","updated":"2022-12-19T12:44:25Z","published":"2022-12-19T12:44:25Z","title":"Difformer: Empowering Diffusion Model on Embedding Space for Text\n  Generation","summary":"  Diffusion models have achieved state-of-the-art synthesis quality on visual\nand audio tasks, and recent works adapt them to textual data by diffusing on\nthe embedding space. But the difference between the continuous data space and\nthe embedding space raises challenges to the diffusion model, which have not\nbeen carefully explored. In this paper, we conduct systematic studies and\nanalyze the challenges threefold. Firstly, the data distribution is learnable\nfor embeddings, which may lead to the collapse of the loss function. Secondly,\nas the norm of embedding varies between popular and rare words, adding the same\nnoise scale will lead to sub-optimal results. In addition, we find that noises\nsampled from a standard Gaussian distribution may distract the diffusion\nprocess. To solve the above challenges, we propose Difformer, a denoising\ndiffusion probabilistic model based on Transformer, which consists of three\ntechniques including utilizing an anchor loss function, a layer normalization\nmodule for embeddings, and a norm factor to the Gaussian noise. All techniques\nare complementary to each other and critical to boosting the model performance\ntogether. Experiments are conducted on benchmark datasets over two seminal text\ngeneration tasks including machine translation and text summarization. The\nresults show that Difformer significantly outperforms the embedding diffusion\nbaselines, while achieving competitive results with strong autoregressive\nbaselines.\n","authors":["Zhujin Gao","Junliang Guo","Xu Tan","Yongxin Zhu","Fang Zhang","Jiang Bian","Linli Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09412v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.09409v1","updated":"2022-12-19T12:40:18Z","published":"2022-12-19T12:40:18Z","title":"Multi-View Knowledge Distillation from Crowd Annotations for\n  Out-of-Domain Generalization","summary":"  Selecting an effective training signal for tasks in natural language\nprocessing is difficult: collecting expert annotations is expensive, and\ncrowd-sourced annotations may not be reliable. At the same time, recent work in\nmachine learning has demonstrated that learning from soft-labels acquired from\ncrowd annotations can be effective, especially when there is distribution shift\nin the test set. However, the best method for acquiring these soft labels is\ninconsistent across tasks. This paper proposes new methods for acquiring\nsoft-labels from crowd-annotations by aggregating the distributions produced by\nexisting methods. In particular, we propose to find a distribution over classes\nby learning from multiple-views of crowd annotations via temperature scaling\nand finding the Jensen-Shannon centroid of their distributions. We demonstrate\nthat using these aggregation methods leads to best or near-best performance\nacross four NLP tasks on out-of-domain test sets, mitigating fluctuations in\nperformance when using the constituent methods on their own. Additionally,\nthese methods result in best or near-best uncertainty estimation across tasks.\nWe argue that aggregating different views of crowd-annotations as soft-labels\nis an effective way to ensure performance which is as good or better than the\nbest individual view, which is useful given the inconsistency in performance of\nthe individual methods.\n","authors":["Dustin Wright","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2212.09409v1.pdf","comment":"14 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2212.09410v1","updated":"2022-12-19T12:40:18Z","published":"2022-12-19T12:40:18Z","title":"Less is More: Parameter-Free Text Classification with Gzip","summary":"  Deep neural networks (DNNs) are often used for text classification tasks as\nthey usually achieve high levels of accuracy. However, DNNs can be\ncomputationally intensive with billions of parameters and large amounts of\nlabeled data, which can make them expensive to use, to optimize and to transfer\nto out-of-distribution (OOD) cases in practice. In this paper, we propose a\nnon-parametric alternative to DNNs that's easy, light-weight and universal in\ntext classification: a combination of a simple compressor like gzip with a\n$k$-nearest-neighbor classifier. Without any training, pre-training or\nfine-tuning, our method achieves results that are competitive with\nnon-pretrained deep learning methods on six in-distributed datasets. It even\noutperforms BERT on all five OOD datasets, including four low-resource\nlanguages. Our method also performs particularly well in few-shot settings\nwhere labeled data are too scarce for DNNs to achieve a satisfying accuracy.\n","authors":["Zhiying Jiang","Matthew Y. R. Yang","Mikhail Tsirlin","Raphael Tang","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2212.09410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09400v1","updated":"2022-12-19T12:24:32Z","published":"2022-12-19T12:24:32Z","title":"An Efficient Drug-Drug Interactions Prediction Technology for\n  Molecularly Intelligent Manufacturing","summary":"  Drug-Drug Interactions (DDIs) prediction is an essential issue in the\nmolecular field. Traditional methods of observing DDIs in medical experiments\nrequire plenty of resources and labor. In this paper, we present a\ncomputational model dubbed MedKGQA based on Graph Neural Networks to\nautomatically predict the DDIs after reading multiple medical documents in the\nform of multi-hop machine reading comprehension. We introduced a knowledge\nfusion system to obtain the complete nature of drugs and proteins and exploited\na graph reasoning system to infer the drugs and proteins contained in the\ndocuments. Our model significantly improves the performance compared to\nprevious state-of-the-art models on the QANGAROO MedHop dataset, which obtained\na 4.5% improvement in terms of DDIs prediction accuracy.\n","authors":["Peng Gao","Feng Gao","Jian-Cheng Ni","Hamido Fujita"],"pdf_url":"https://arxiv.org/pdf/2212.09400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.00841v2","updated":"2022-12-19T12:22:34Z","published":"2021-07-02T05:29:39Z","title":"A Heterogeneous Graph Attention Network for Multi-hop Machine Reading\n  Comprehension","summary":"  Multi-hop machine reading comprehension is a challenging task in natural\nlanguage processing, which requires more reasoning ability across multiple\ndocuments. Spectral models based on graph convolutional networks grant\ninferring abilities and lead to competitive results. However, part of them\nstill faces the challenge of analyzing the reasoning in a human-understandable\nway. Inspired by the concept of the Grandmother Cells in cognitive\nneuroscience, a spatial graph attention framework named ClueReader was proposed\nin this paper, imitating the procedure. This model is designed to assemble the\nsemantic features in multi-level representations and automatically concentrate\nor alleviate information for reasoning via the attention mechanism. The name\nClueReader is a metaphor for the pattern of the model: regard the subjects of\nqueries as the start points of clues, take the reasoning entities as bridge\npoints, consider the latent candidate entities as the grandmother cells, and\nthe clues end up in candidate entities. The proposed model allows us to\nvisualize the reasoning graph, then analyze the importance of edges connecting\ntwo entities and the selectivity in the mention and candidate nodes, which can\nbe easier to be comprehended empirically. The official evaluations in the\nopen-domain multi-hop reading dataset WikiHop and the Drug-drug Interactions\ndataset MedHop prove the validity of our approach and show the probability of\nthe application of the model in the molecular biology domain.\n","authors":["Peng Gao","Feng Gao","Jian-Cheng Ni","Hamido Fujita"],"pdf_url":"https://arxiv.org/pdf/2107.00841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09387v1","updated":"2022-12-19T11:53:59Z","published":"2022-12-19T11:53:59Z","title":"Prompt Gating: A Parameter Efficient Tuning Method for Zero-Shot\n  Multi-Source Translation","summary":"  Multi-source translation (MST), which typically receives multiple source\nsentences of the same meaning in different languages, has been shown superior\nto single-source translation. As the quantity of multi-source parallel data is\nlimited, taking full advantage of single-source data and limited multi-source\ndata to make models perform well when receiving as many as possible sources\nremains a challenge. Unlike previous work mostly devoted to supervised\nscenarios, we focus on zero-shot MST: expecting models to be able to process\nunseen combinations of multiple sources, e.g., unseen language combinations,\nduring inference. We propose a simple yet effective parameter efficient method,\nnamed Prompt Gating, which appends prompts to the model inputs and attaches\ngates on the extended hidden states for each encoder layer. It shows strong\nzero-shot transferability (+9.0 BLEU points maximally) and remarkable\ncompositionality (+15.6 BLEU points maximally) on MST, and also shows its\nsuperiorities over baselines on lexically constrained translation.\n","authors":["Xuancheng Huang","Zijun Liu","Peng Li","Maosong Sun","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2212.09387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01504v2","updated":"2022-12-19T11:52:40Z","published":"2022-10-04T10:18:11Z","title":"Knowledge Unlearning for Mitigating Privacy Risks in Language Models","summary":"  Pretrained Language Models (LMs) memorize a vast amount of knowledge during\ninitial pretraining, including information that may violate the privacy of\npersonal lives and identities. Previous work addressing privacy issues for\nlanguage models has mostly focused on data preprocessing and differential\nprivacy methods, both requiring re-training the underlying LM. We propose\nknowledge unlearning as an alternative method to reduce privacy risks for LMs\npost hoc. We show that simply performing gradient ascent on target token\nsequences is effective at forgetting them with little to no degradation of\ngeneral language modeling performances for larger LMs; it sometimes even\nsubstantially improves the underlying LM with just a few iterations. We also\nfind that sequential unlearning is better than trying to unlearn all the data\nat once and that unlearning is highly dependent on which kind of data (domain)\nis forgotten. By showing comparisons with a previous data preprocessing method\nand a decoding method known to mitigate privacy risks for LMs, we show that\nunlearning can give a stronger empirical privacy guarantee in scenarios where\nthe data vulnerable to extraction attacks are known a priori while being much\nmore efficient and robust. We release the code and dataset needed to replicate\nour results at https://github.com/joeljang/knowledge-unlearning.\n","authors":["Joel Jang","Dongkeun Yoon","Sohee Yang","Sungmin Cha","Moontae Lee","Lajanugen Logeswaran","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2210.01504v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.12131v2","updated":"2022-12-19T11:44:38Z","published":"2022-06-24T07:49:47Z","title":"MVP: Multi-task Supervised Pre-training for Natural Language Generation","summary":"  Pre-trained language models (PLMs) have achieved remarkable success in\nnatural language generation (NLG) tasks. Up to now, most NLG-oriented PLMs are\npre-trained in an unsupervised manner using the large-scale general corpus. In\nthe meanwhile, an increasing number of models pre-trained with labeled data\n(i.e., ``supervised pre-training'') showcase superior performance compared to\nunsupervised pre-trained models. Motivated by the success of supervised\npre-training, we propose Multi-task superVised Pre-training~(MVP) for natural\nlanguage generation. We collect a large-scale natural language generation\ncorpus, MVPCorpus, from $77$ datasets over $11$ diverse NLG tasks. Then we\nunify these examples into a general text-to-text format to pre-train the text\ngeneration model MVP in a supervised manner. For each task, we further\npre-train specific soft prompts to stimulate the model's capacity to perform a\nspecific task. Extensive experiments have demonstrated the effectiveness and\ngenerality of our MVP model in a number of NLG tasks, which achieves\nstate-of-the-art performance on $13$ out of $17$ datasets.\n","authors":["Tianyi Tang","Junyi Li","Wayne Xin Zhao","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2206.12131v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09376v1","updated":"2022-12-19T11:26:23Z","published":"2022-12-19T11:26:23Z","title":"Enriching Relation Extraction with OpenIE","summary":"  Relation extraction (RE) is a sub-discipline of information extraction (IE)\nwhich focuses on the prediction of a relational predicate from a\nnatural-language input unit (such as a sentence, a clause, or even a short\nparagraph consisting of multiple sentences and/or clauses). Together with\nnamed-entity recognition (NER) and disambiguation (NED), RE forms the basis for\nmany advanced IE tasks such as knowledge-base (KB) population and verification.\nIn this work, we explore how recent approaches for open information extraction\n(OpenIE) may help to improve the task of RE by encoding structured information\nabout the sentences' principal units, such as subjects, objects, verbal\nphrases, and adverbials, into various forms of vectorized (and hence\nunstructured) representations of the sentences. Our main conjecture is that the\ndecomposition of long and possibly convoluted sentences into multiple smaller\nclauses via OpenIE even helps to fine-tune context-sensitive language models\nsuch as BERT (and its plethora of variants) for RE. Our experiments over two\nannotated corpora, KnowledgeNet and FewRel, demonstrate the improved accuracy\nof our enriched models compared to existing RE approaches. Our best results\nreach 92% and 71% of F1 score for KnowledgeNet and FewRel, respectively,\nproving the effectiveness of our approach on competitive benchmarks.\n","authors":["Alessandro Temperoni","Maria Biryukov","Martin Theobald"],"pdf_url":"https://arxiv.org/pdf/2212.09376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02069v2","updated":"2022-12-19T10:53:46Z","published":"2022-11-03T18:01:12Z","title":"LMentry: A Language Model Benchmark of Elementary Language Tasks","summary":"  As the performance of large language models rapidly improves, benchmarks are\ngetting larger and more complex as well. We present LMentry, a benchmark that\navoids this \"arms race\" by focusing on a compact set of tasks that are trivial\nto humans, e.g. writing a sentence containing a specific word, identifying\nwhich words in a list belong to a specific category, or choosing which of two\nwords is longer. LMentry is specifically designed to provide quick and\ninterpretable insights into the capabilities and robustness of large language\nmodels. Our experiments reveal a wide variety of failure cases that, while\nimmediately obvious to humans, pose a considerable challenge for large language\nmodels, including OpenAI's latest 175B-parameter instruction-tuned model,\nTextDavinci002. LMentry complements contemporary evaluation approaches of large\nlanguage models, providing a quick, automatic, and easy-to-run \"unit test\",\nwithout resorting to large benchmark suites of complex tasks.\n","authors":["Avia Efrat","Or Honovich","Omer Levy"],"pdf_url":"https://arxiv.org/pdf/2211.02069v2.pdf","comment":"minor results updates"},{"id":"http://arxiv.org/abs/2212.09359v1","updated":"2022-12-19T10:49:35Z","published":"2022-12-19T10:49:35Z","title":"WACO: Word-Aligned Contrastive Learning for Speech Translation","summary":"  End-to-end Speech Translation (E2E ST) aims to translate source speech into\ntarget translation without generating the intermediate transcript. However,\nexisting approaches for E2E ST degrade considerably when only limited ST data\nare available. We observe that an ST model's performance strongly correlates\nwith its embedding similarity from speech and transcript. In this paper, we\npropose Word-Aligned COntrastive learning (WACO), a novel method for few-shot\nspeech-to-text translation. Our key idea is bridging word-level representations\nfor both modalities via contrastive learning. We evaluate WACO and other\nmethods on the MuST-C dataset, a widely used ST benchmark. Our experiments\ndemonstrate that WACO outperforms the best baseline methods by 0.7-8.5 BLEU\npoints with only 1-hour parallel data. Code is available at\nhttps://anonymous.4open.science/r/WACO .\n","authors":["Siqi Ouyang","Rong Ye","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2212.09359v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09353v1","updated":"2022-12-19T10:38:30Z","published":"2022-12-19T10:38:30Z","title":"Bridging The Gap: Entailment Fused-T5 for Open-retrieval Conversational\n  Machine Reading Comprehension","summary":"  Open-retrieval conversational machine reading comprehension (OCMRC) simulates\nreal-life conversational interaction scenes. Machines are required to make a\ndecision of \"Yes/No/Inquire\" or generate a follow-up question when the decision\nis \"Inquire\" based on retrieved rule texts, user scenario, user question, and\ndialogue history. Recent studies explored the methods to reduce the information\ngap between decision-making and question generation and thus improve the\nperformance of generation. However, the information gap still exists because\nthese pipeline structures are still limited in decision-making, span\nextraction, and question rephrasing three stages. Decision-making and\ngeneration are reasoning separately, and the entailment reasoning utilized in\ndecision-making is hard to share through all stages. To tackle the above\nproblem, we proposed a novel one-stage end-to-end framework, called Entailment\nFused-T5 (EFT), to bridge the information gap between decision-making and\ngeneration in a global understanding manner. The extensive experimental results\ndemonstrate that our proposed framework achieves new state-of-the-art\nperformance on the OR-ShARC benchmark.\n","authors":["Xiao Zhang","Heyan Huang","Zewen Chi","Xian-Ling Mao"],"pdf_url":"https://arxiv.org/pdf/2212.09353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.09023v2","updated":"2022-12-19T10:16:23Z","published":"2021-01-22T09:43:33Z","title":"Enhanced word embeddings using multi-semantic representation through\n  lexical chains","summary":"  The relationship between words in a sentence often tells us more about the\nunderlying semantic content of a document than its actual words, individually.\nIn this work, we propose two novel algorithms, called Flexible Lexical Chain II\nand Fixed Lexical Chain II. These algorithms combine the semantic relations\nderived from lexical chains, prior knowledge from lexical databases, and the\nrobustness of the distributional hypothesis in word embeddings as building\nblocks forming a single system. In short, our approach has three main\ncontributions: (i) a set of techniques that fully integrate word embeddings and\nlexical chains; (ii) a more robust semantic representation that considers the\nlatent relation between words in a document; and (iii) lightweight word\nembeddings models that can be extended to any natural language task. We intend\nto assess the knowledge of pre-trained models to evaluate their robustness in\nthe document classification task. The proposed techniques are tested against\nseven word embeddings algorithms using five different machine learning\nclassifiers over six scenarios in the document classification task. Our results\nshow the integration between lexical chains and word embeddings representations\nsustain state-of-the-art results, even against more complex systems.\n","authors":["Terry Ruas","Charles Henrique Porto Ferreira","William Grosky","Fabrício Olivetti de França","Débora Maria Rossi Medeiros"],"pdf_url":"https://arxiv.org/pdf/2101.09023v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.08700v2","updated":"2022-12-19T10:03:47Z","published":"2021-01-21T16:22:34Z","title":"Multi-sense embeddings through a word sense disambiguation process","summary":"  Natural Language Understanding has seen an increasing number of publications\nin the last few years, especially after robust word embeddings models became\nprominent, when they proved themselves able to capture and represent semantic\nrelationships from massive amounts of data. Nevertheless, traditional models\noften fall short in intrinsic issues of linguistics, such as polysemy and\nhomonymy. Any expert system that makes use of natural language in its core, can\nbe affected by a weak semantic representation of text, resulting in inaccurate\noutcomes based on poor decisions. To mitigate such issues, we propose a novel\napproach called Most Suitable Sense Annotation (MSSA), that disambiguates and\nannotates each word by its specific sense, considering the semantic effects of\nits context. Our approach brings three main contributions to the semantic\nrepresentation scenario: (i) an unsupervised technique that disambiguates and\nannotates words by their senses, (ii) a multi-sense embeddings model that can\nbe extended to any traditional word embeddings algorithm, and (iii) a recurrent\nmethodology that allows our models to be re-used and their representations\nrefined. We test our approach on six different benchmarks for the word\nsimilarity task, showing that our approach can produce state-of-the-art results\nand outperforms several more complex state-of-the-art systems.\n","authors":["Terry Ruas","William Grosky","Akiko Aizawa"],"pdf_url":"https://arxiv.org/pdf/2101.08700v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06767v2","updated":"2022-12-19T09:38:57Z","published":"2022-09-14T16:45:13Z","title":"Parameter-Efficient Finetuning for Robust Continual Multilingual\n  Learning","summary":"  We study the underexplored problem of Continual Multilingual Learning, where\na multilingual model, already trained on task-specific data from all supported\nlanguages, is continually updated using batches of new multilingual training\ndata for the same task. We show that naively updating the multilingual model\ncan lead to losses in performance over a subset of languages although the\naggregated performance metric shows an improvement. We establish this\nphenomenon over four tasks belonging to three task families (token-level,\nsentence-level and seq2seq). We then build upon recent advances in\nparameter-efficient finetuning to develop novel finetuning strategies that\nallow us to jointly minimize language-specific forgetting while encouraging\npositive cross-lingual transfer observed in this setup. Our proposed pipeline,\nLAFT-URIEL, improves the spread of gains over the supported languages while\nreducing the magnitude of language-specific losses incurred.\n","authors":["Kartikeya Badola","Shachi Dave","Partha Talukdar"],"pdf_url":"https://arxiv.org/pdf/2209.06767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09306v1","updated":"2022-12-19T09:03:32Z","published":"2022-12-19T09:03:32Z","title":"E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text","summary":"  Identifying named entities such as a person, location or organization, in\ndocuments can highlight key information to readers. Training Named Entity\nRecognition (NER) models requires an annotated data set, which can be a\ntime-consuming labour-intensive task. Nevertheless, there are publicly\navailable NER data sets for general English. Recently there has been interest\nin developing NER for legal text. However, prior work and experimental results\nreported here indicate that there is a significant degradation in performance\nwhen NER methods trained on a general English data set are applied to legal\ntext. We describe a publicly available legal NER data set, called E-NER, based\non legal company filings available from the US Securities and Exchange\nCommission's EDGAR data set. Training a number of different NER algorithms on\nthe general English CoNLL-2003 corpus but testing on our test collection\nconfirmed significant degradations in accuracy, as measured by the F1-score, of\nbetween 29.4\\% and 60.4\\%, compared to training and testing on the E-NER\ncollection.\n","authors":["Ting Wai Terence Au","Ingemar J. Cox","Vasileios Lampos"],"pdf_url":"https://arxiv.org/pdf/2212.09306v1.pdf","comment":"5 pages, 3 figures, submitted to NLLP workshop in EMNLP 2022"},{"id":"http://arxiv.org/abs/2212.09305v1","updated":"2022-12-19T09:02:16Z","published":"2022-12-19T09:02:16Z","title":"SEScore2: Retrieval Augmented Pretraining for Text Generation Evaluation","summary":"  Is it possible to leverage large scale raw and raw parallel corpora to build\na general learned metric? Existing learned metrics have gaps to human\njudgements, are model-dependent or are limited to the domains or tasks where\nhuman ratings are available. In this paper, we propose SEScore2, a model-based\nmetric pretrained over million-scale synthetic dataset constructed by our novel\nretrieval augmented data synthesis pipeline. SEScore2 achieves high correlation\nto human judgements without any human rating supervisions. Importantly, our\nunsupervised SEScore2 can outperform supervised metrics, which are trained on\nthe News human ratings, at the TED domain. We evaluate SEScore2 over four text\ngeneration tasks across three languages. SEScore2 outperforms all prior\nunsupervised evaluation metrics in machine translation, speech translation,\ndata-to-text and dialogue generation, with average Kendall improvements 0.158.\nSEScore2 even outperforms SOTA supervised BLEURT at data-to-text, dialogue\ngeneration and overall correlation.\n","authors":["Wenda Xu","Xian Qian","Mingxuan Wang","Lei Li","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09292v1","updated":"2022-12-19T08:15:16Z","published":"2022-12-19T08:15:16Z","title":"ChatGPT: The End of Online Exam Integrity?","summary":"  This study evaluated the ability of ChatGPT, a recently developed artificial\nintelligence (AI) agent, to perform high-level cognitive tasks and produce text\nthat is indistinguishable from human-generated text. This capacity raises\nconcerns about the potential use of ChatGPT as a tool for academic misconduct\nin online exams. The study found that ChatGPT is capable of exhibiting critical\nthinking skills and generating highly realistic text with minimal input, making\nit a potential threat to the integrity of online exams, particularly in\ntertiary education settings where such exams are becoming more prevalent.\nReturning to invigilated and oral exams could form part of the solution, while\nusing advanced proctoring techniques and AI-text output detectors may be\neffective in addressing this issue, they are not likely to be foolproof\nsolutions. Further research is needed to fully understand the implications of\nlarge language models like ChatGPT and to devise strategies for combating the\nrisk of cheating using these tools. It is crucial for educators and\ninstitutions to be aware of the possibility of ChatGPT being used for cheating\nand to investigate measures to address it in order to maintain the fairness and\nvalidity of online exams for all students.\n","authors":["Teo Susnjak"],"pdf_url":"https://arxiv.org/pdf/2212.09292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09284v1","updated":"2022-12-19T07:41:39Z","published":"2022-12-19T07:41:39Z","title":"An Investigation of Indian Native Language Phonemic Influences on L2\n  English Pronunciations","summary":"  Speech systems are sensitive to accent variations. This is especially\nchallenging in the Indian context, with an abundance of languages but a dearth\nof linguistic studies characterising pronunciation variations. The growing\nnumber of L2 English speakers in India reinforces the need to study accents and\nL1-L2 interactions. We investigate the accents of Indian English (IE) speakers\nand report in detail our observations, both specific and common to all regions.\nIn particular, we observe the phonemic variations and phonotactics occurring in\nthe speakers' native languages and apply this to their English pronunciations.\nWe demonstrate the influence of 18 Indian languages on IE by comparing the\nnative language pronunciations with IE pronunciations obtained jointly from\nexisting literature studies and phonetically annotated speech of 80 speakers.\nConsequently, we are able to validate the intuitions of Indian language\ninfluences on IE pronunciations by justifying pronunciation rules from the\nperspective of Indian language phonology. We obtain a comprehensive description\nin terms of universal and region-specific characteristics of IE, which\nfacilitates accent conversion and adaptation of existing ASR and TTS systems to\ndifferent Indian accents.\n","authors":["Shelly Jain","Priyanshi Pal","Anil Vuppala","Prasanta Ghosh","Chiranjeevi Yarra"],"pdf_url":"https://arxiv.org/pdf/2212.09284v1.pdf","comment":"9 pages, 1 figure"},{"id":"http://arxiv.org/abs/2212.09282v1","updated":"2022-12-19T07:40:02Z","published":"2022-12-19T07:40:02Z","title":"APOLLO: A Simple Approach for Adaptive Pretraining of Language Models\n  for Logical Reasoning","summary":"  Logical reasoning of text is an important ability that requires understanding\nthe information present in the text, their interconnections, and then reasoning\nthrough them to infer new conclusions. Prior works on improving the logical\nreasoning ability of language models require complex processing of training\ndata (e.g., aligning symbolic knowledge to text), yielding task-specific data\naugmentation solutions that restrict the learning of general logical reasoning\nskills. In this work, we propose APOLLO, an adaptively pretrained language\nmodel that has improved logical reasoning abilities. We select a subset of\nWikipedia, based on a set of logical inference keywords, for continued\npretraining of a language model. We use two self-supervised loss functions: a\nmodified masked language modeling loss where only specific parts-of-speech\nwords, that would likely require more reasoning than basic language\nunderstanding, are masked, and a sentence-level classification loss that\nteaches the model to distinguish between entailment and contradiction types of\nsentences. The proposed training paradigm is both simple and independent of\ntask formats. We demonstrate the effectiveness of APOLLO by comparing it with\nprior baselines on two logical reasoning datasets. APOLLO performs comparably\non ReClor and outperforms baselines on LogiQA.\n","authors":["Soumya Sanyal","Yichong Xu","Shuohang Wang","Ziyi Yang","Reid Pryzant","Wenhao Yu","Chenguang Zhu","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.09282v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.09278v1","updated":"2022-12-19T07:14:32Z","published":"2022-12-19T07:14:32Z","title":"MIGA: A Unified Multi-task Generation Framework for Conversational\n  Text-to-SQL","summary":"  Conversational text-to-SQL is designed to translate multi-turn natural\nlanguage questions into their corresponding SQL queries. Most state-of-the-art\nconversational text- to-SQL methods are incompatible with generative\npre-trained language models (PLMs), such as T5. In this paper, we present a\ntwo-stage unified MultI-task Generation frAmework (MIGA) that leverages PLMs'\nability to tackle conversational text-to-SQL. In the pre-training stage, MIGA\nfirst decomposes the main task into several related sub-tasks and then unifies\nthem into the same sequence-to-sequence (Seq2Seq) paradigm with task-specific\nnatural language prompts to boost the main task from multi-task training. Later\nin the fine-tuning stage, we propose four SQL perturbations to alleviate the\nerror propagation problem. MIGA tends to achieve state-of-the-art performance\non two benchmarks (SparC and CoSQL). We also provide extensive analyses and\ndiscussions to shed light on some new perspectives for conversational\ntext-to-SQL.\n","authors":["Yingwen Fu","Wenjie Ou","Zhou Yu","Yue Lin"],"pdf_url":"https://arxiv.org/pdf/2212.09278v1.pdf","comment":"Accepted by AAAI23"},{"id":"http://arxiv.org/abs/2212.09272v1","updated":"2022-12-19T06:55:42Z","published":"2022-12-19T06:55:42Z","title":"Statistical Dataset Evaluation: Reliability, Difficulty, and Validity","summary":"  Datasets serve as crucial training resources and model performance trackers.\nHowever, existing datasets have exposed a plethora of problems, inducing biased\nmodels and unreliable evaluation results. In this paper, we propose a\nmodel-agnostic dataset evaluation framework for automatic dataset quality\nevaluation. We seek the statistical properties of the datasets and address\nthree fundamental dimensions: reliability, difficulty, and validity, following\na classical testing theory. Taking the Named Entity Recognition (NER) datasets\nas a case study, we introduce $9$ statistical metrics for a statistical dataset\nevaluation framework. Experimental results and human evaluation validate that\nour evaluation framework effectively assesses various aspects of the dataset\nquality. Furthermore, we study how the dataset scores on our statistical\nmetrics affect the model performance, and appeal for dataset quality evaluation\nor targeted dataset improvement before training or testing models.\n","authors":["Chengwen Wang","Qingxiu Dong","Xiaochen Wang","Haitao Wang","Zhifang Sui"],"pdf_url":"https://arxiv.org/pdf/2212.09272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09257v1","updated":"2022-12-19T06:04:54Z","published":"2022-12-19T06:04:54Z","title":"PromptBoosting: Black-Box Text Classification with Ten Forward Passes","summary":"  We describe PromptBoosting, a query-efficient procedure for building a text\nclassifier from a neural language model (LM) without access to the LM's\nparameters, gradients, or hidden representations. This form of \"black-box\"\nclassifier training has become increasingly important as the cost of training\nand inference in large-scale LMs grows. But existing black-box LM classifier\nlearning approaches are themselves computationally inefficient, typically\nspecializing LMs to the target task by searching in a large space of (discrete\nor continuous) prompts using zeroth-order optimization methods. Instead of\ndirectly optimizing in prompt space, PromptBoosting obtains a small pool of\nprompts via a gradient-free approach and then constructs a large pool of weak\nlearners by pairing these prompts with different elements of the LM's output\ndistribution. These weak learners are then ensembled using the AdaBoost\nalgorithm. The entire learning process requires only a small number of forward\npasses and no backward pass. Experiments show that PromptBoosting achieves\nstate-of-the-art performance in multiple black-box few-shot classification\ntasks, and matches or outperforms full fine-tuning in both few-shot and\nstandard learning paradigms, while training 10x faster than existing black-box\nmethods.\n","authors":["Bairu Hou","Joe O'Connor","Jacob Andreas","Shiyu Chang","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.09257v1.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.09255v1","updated":"2022-12-19T06:03:04Z","published":"2022-12-19T06:03:04Z","title":"Multi hash embeddings in spaCy","summary":"  The distributed representation of symbols is one of the key technologies in\nmachine learning systems today, playing a pivotal role in modern natural\nlanguage processing. Traditional word embeddings associate a separate vector\nwith each word. While this approach is simple and leads to good performance, it\nrequires a lot of memory for representing a large vocabulary. To reduce the\nmemory footprint, the default embedding layer in spaCy is a hash embeddings\nlayer. It is a stochastic approximation of traditional embeddings that provides\nunique vectors for a large number of words without explicitly storing a\nseparate vector for each of them. To be able to compute meaningful\nrepresentations for both known and unknown words, hash embeddings represent\neach word as a summary of the normalized word form, subword information and\nword shape. Together, these features produce a multi-embedding of a word. In\nthis technical report we lay out a bit of history and introduce the embedding\nmethods in spaCy in detail. Second, we critically evaluate the hash embedding\narchitecture with multi-embeddings on Named Entity Recognition datasets from a\nvariety of domains and languages. The experiments validate most key design\nchoices behind spaCy's embedders, but we also uncover a few surprising results.\n","authors":["Lester James Miranda","Ákos Kádár","Adriane Boyd","Sofie Van Landeghem","Anders Søgaard","Matthew Honnibal"],"pdf_url":"https://arxiv.org/pdf/2212.09255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09254v1","updated":"2022-12-19T05:55:58Z","published":"2022-12-19T05:55:58Z","title":"TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven\n  Optimization","summary":"  Robustness evaluation against adversarial examples has become increasingly\nimportant to unveil the trustworthiness of the prevailing deep models in\nnatural language processing (NLP). However, in contrast to the computer vision\ndomain where the first-order projected gradient descent (PGD) is used as the\nbenchmark approach to generate adversarial examples for robustness evaluation,\nthere lacks a principled first-order gradient-based robustness evaluation\nframework in NLP. The emerging optimization challenges lie in 1) the discrete\nnature of textual inputs together with the strong coupling between the\nperturbation location and the actual content, and 2) the additional constraint\nthat the perturbed text should be fluent and achieve a low perplexity under a\nlanguage model. These challenges make the development of PGD-like NLP attacks\ndifficult. To bridge the gap, we propose TextGrad, a new attack generator using\ngradient-driven optimization, supporting high-accuracy and high-quality\nassessment of adversarial robustness in NLP. Specifically, we address the\naforementioned challenges in a unified optimization framework. And we develop\nan effective convex relaxation method to co-optimize the continuously-relaxed\nsite selection and perturbation variables and leverage an effective sampling\nmethod to establish an accurate mapping from the continuous optimization\nvariables to the discrete textual perturbations. Moreover, as a first-order\nattack generation method, TextGrad can be baked into adversarial training to\nfurther improve the robustness of NLP models. Extensive experiments are\nprovided to demonstrate the effectiveness of TextGrad not only in attack\ngeneration for robustness evaluation but also in adversarial defense.\n","authors":["Bairu Hou","Jinghan Jia","Yihua Zhang","Guanhua Zhang","Yang Zhang","Sijia Liu","Shiyu Chang"],"pdf_url":"https://arxiv.org/pdf/2212.09254v1.pdf","comment":"18 pages, 2 figures"},{"id":"http://arxiv.org/abs/2110.07150v3","updated":"2022-12-19T05:53:11Z","published":"2021-10-14T04:36:29Z","title":"Cross-Lingual Open-Domain Question Answering with Answer Sentence\n  Generation","summary":"  Open-Domain Generative Question Answering has achieved impressive performance\nin English by combining document-level retrieval with answer generation. These\napproaches, which we refer to as GenQA, can generate complete sentences,\neffectively answering both factoid and non-factoid questions. In this paper, we\nextend GenQA to the multilingual and cross-lingual settings. For this purpose,\nwe first introduce GenTyDiQA, an extension of the TyDiQA dataset with\nwell-formed and complete answers for Arabic, Bengali, English, Japanese, and\nRussian. Based on GenTyDiQA, we design a cross-lingual generative model that\nproduces full-sentence answers by exploiting passages written in multiple\nlanguages, including languages different from the question. Our cross-lingual\ngenerative system outperforms answer sentence selection baselines for all 5\nlanguages and monolingual generative pipelines for three out of five languages\nstudied.\n","authors":["Benjamin Muller","Luca Soldaini","Rik Koncel-Kedziorski","Eric Lind","Alessandro Moschitti"],"pdf_url":"https://arxiv.org/pdf/2110.07150v3.pdf","comment":"AACL 2022 Long Paper"},{"id":"http://arxiv.org/abs/2212.09252v1","updated":"2022-12-19T05:17:33Z","published":"2022-12-19T05:17:33Z","title":"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems","summary":"  Many dialogue systems (DSs) lack characteristics humans have, such as emotion\nperception, factuality, and informativeness. Enhancing DSs with knowledge\nalleviates this problem, but, as many ways of doing so exist, keeping track of\nall proposed methods is difficult. Here, we present the first survey of\nknowledge-enhanced DSs. We define three categories of systems - internal,\nexternal, and hybrid - based on the knowledge they use. We survey the\nmotivation for enhancing DSs with knowledge, used datasets, and methods for\nknowledge search, knowledge encoding, and knowledge incorporation. Finally, we\npropose how to improve existing systems based on theories from linguistics and\ncognitive science.\n","authors":["Sagi Shaier","Lawrence Hunter","Katharina Kann"],"pdf_url":"https://arxiv.org/pdf/2212.09252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09783v5","updated":"2022-12-19T05:15:58Z","published":"2022-11-17T18:54:47Z","title":"UniSumm: Unified Few-shot Summarization with Multi-Task Pre-Training and\n  Prefix-Tuning","summary":"  The diverse demands of different summarization tasks and their high\nannotation costs are driving a need for few-shot summarization. However,\ndespite the emergence of many summarization tasks and datasets, the current\ntraining paradigm for few-shot summarization systems ignores potentially\nshareable knowledge in heterogeneous datasets. To this end, we propose\n\\textsc{UniSumm}, a unified few-shot summarization model pre-trained with\nmultiple summarization tasks and can be prefix-tuned to excel at any few-shot\nsummarization datasets. Meanwhile, to better evaluate few-shot summarization\nsystems, under the principles of diversity and robustness, we assemble and\npublicize a new benchmark \\textsc{SummZoo}. It consists of $8$ diverse\nsummarization tasks with multiple sets of few-shot samples for each task,\ncovering both monologue and dialogue domains. Experimental results and ablation\nstudies show that \\textsc{UniSumm} outperforms strong baseline systems by a\nlarge margin across all tasks in \\textsc{SummZoo} under both automatic and\nhuman evaluations. We release our code and benchmark at\n\\url{https://github.com/microsoft/UniSumm}.\n","authors":["Yulong Chen","Yang Liu","Ruochen Xu","Ziyi Yang","Chenguang Zhu","Michael Zeng","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.09783v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09251v1","updated":"2022-12-19T05:13:52Z","published":"2022-12-19T05:13:52Z","title":"Discovering Language Model Behaviors with Model-Written Evaluations","summary":"  As language models (LMs) scale, they develop many novel behaviors, good and\nbad, exacerbating the need to evaluate how they behave. Prior work creates\nevaluations with crowdwork (which is time-consuming and expensive) or existing\ndata sources (which are not always available). Here, we automatically generate\nevaluations with LMs. We explore approaches with varying amounts of human\neffort, from instructing LMs to write yes/no questions to making complex\nWinogender schemas with multiple stages of LM-based generation and filtering.\nCrowdworkers rate the examples as highly relevant and agree with 90-100% of\nlabels, sometimes more so than corresponding human-written datasets. We\ngenerate 154 datasets and discover new cases of inverse scaling where LMs get\nworse with size. Larger LMs repeat back a dialog user's preferred answer\n(\"sycophancy\") and express greater desire to pursue concerning goals like\nresource acquisition and goal preservation. We also find some of the first\nexamples of inverse scaling in RL from Human Feedback (RLHF), where more RLHF\nmakes LMs worse. For example, RLHF makes LMs express stronger political views\n(on gun rights and immigration) and a greater desire to avoid shut down.\nOverall, LM-written evaluations are high-quality and let us quickly discover\nmany novel LM behaviors.\n","authors":["Ethan Perez","Sam Ringer","Kamilė Lukošiūtė","Karina Nguyen","Edwin Chen","Scott Heiner","Craig Pettit","Catherine Olsson","Sandipan Kundu","Saurav Kadavath","Andy Jones","Anna Chen","Ben Mann","Brian Israel","Bryan Seethor","Cameron McKinnon","Christopher Olah","Da Yan","Daniela Amodei","Dario Amodei","Dawn Drain","Dustin Li","Eli Tran-Johnson","Guro Khundadze","Jackson Kernion","James Landis","Jamie Kerr","Jared Mueller","Jeeyoon Hyun","Joshua Landau","Kamal Ndousse","Landon Goldberg","Liane Lovitt","Martin Lucas","Michael Sellitto","Miranda Zhang","Neerav Kingsland","Nelson Elhage","Nicholas Joseph","Noemí Mercado","Nova DasSarma","Oliver Rausch","Robin Larson","Sam McCandlish","Scott Johnston","Shauna Kravec","Sheer El Showk","Tamera Lanham","Timothy Telleen-Lawton","Tom Brown","Tom Henighan","Tristan Hume","Yuntao Bai","Zac Hatfield-Dodds","Jack Clark","Samuel R. Bowman","Amanda Askell","Roger Grosse","Danny Hernandez","Deep Ganguli","Evan Hubinger","Nicholas Schiefer","Jared Kaplan"],"pdf_url":"https://arxiv.org/pdf/2212.09251v1.pdf","comment":"for associated data visualizations, see\n  https://www.evals.anthropic.com/model-written/ for full datasets, see\n  https://github.com/anthropics/evals"},{"id":"http://arxiv.org/abs/2212.09248v1","updated":"2022-12-19T05:06:00Z","published":"2022-12-19T05:06:00Z","title":"Natural Language to Code Generation in Interactive Data Science\n  Notebooks","summary":"  Computational notebooks, such as Jupyter notebooks, are interactive computing\nenvironments that are ubiquitous among data scientists to perform data\nwrangling and analytic tasks. To measure the performance of AI pair programmers\nthat automatically synthesize programs for those tasks given natural language\n(NL) intents from users, we build ARCADE, a benchmark of 1082 code generation\nproblems using the pandas data analysis framework in data science notebooks.\nARCADE features multiple rounds of NL-to-code problems from the same notebook.\nIt requires a model to understand rich multi-modal contexts, such as existing\nnotebook cells and their execution states as well as previous turns of\ninteraction. To establish a strong baseline on this challenging task, we\ndevelop PaChiNCo, a 62B code language model (LM) for Python computational\nnotebooks, which significantly outperforms public code LMs. Finally, we explore\nfew-shot prompting strategies to elicit better code with step-by-step\ndecomposition and NL explanation, showing the potential to improve the\ndiversity and explainability of model predictions.\n","authors":["Pengcheng Yin","Wen-Ding Li","Kefan Xiao","Abhishek Rao","Yeming Wen","Kensen Shi","Joshua Howland","Paige Bailey","Michele Catasta","Henryk Michalewski","Alex Polozov","Charles Sutton"],"pdf_url":"https://arxiv.org/pdf/2212.09248v1.pdf","comment":"46 pages. 32 figures"},{"id":"http://arxiv.org/abs/2212.09246v1","updated":"2022-12-19T04:47:49Z","published":"2022-12-19T04:47:49Z","title":"I2D2: Inductive Knowledge Distillation with NeuroLogic and\n  Self-Imitation","summary":"  Pre-trained language models, despite their rapid advancements powered by\nscale, still fall short of robust commonsense capabilities. And yet, scale\nappears to be the winning recipe; after all, the largest models seem to have\nacquired the largest amount of commonsense capabilities. Or is it?\n  In this paper, we investigate the possibility of a seemingly impossible\nmatch: can smaller language models with dismal commonsense capabilities (i.e.,\nGPT-2), ever win over models that are orders of magnitude larger and better\n(i.e., GPT-3), if the smaller models are powered with novel commonsense\ndistillation algorithms? The key intellectual question we ask here is whether\nit is possible, if at all, to design a learning algorithm that does not benefit\nfrom scale, yet leads to a competitive level of commonsense acquisition. In\nthis work, we study the generative models of commonsense knowledge, focusing on\nthe task of generating generics, statements of commonsense facts about everyday\nconcepts, e.g., birds can fly.\n  We introduce a novel commonsense distillation framework, I2D2, that loosely\nfollows the Symbolic Knowledge Distillation of West et al. but breaks the\ndependence on the extreme-scale models as the teacher model by two innovations:\n(1) the novel adaptation of NeuroLogic Decoding to enhance the generation\nquality of the weak, off-the-shelf language models, and (2) self-imitation\nlearning to iteratively learn from the model's own enhanced commonsense\nacquisition capabilities. Empirical results suggest that scale is not the only\nway, as novel algorithms can be a promising alternative. Moreover, our study\nleads to a new corpus of generics, Gen-A-Tomic, that is of the largest and\nhighest quality available to date.\n","authors":["Chandra Bhagavatula","Jena D. Hwang","Doug Downey","Ronan Le Bras","Ximing Lu","Keisuke Sakaguchi","Swabha Swayamdipta","Peter West","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2212.09246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09235v1","updated":"2022-12-19T04:12:54Z","published":"2022-12-19T04:12:54Z","title":"PAL: Persona-Augmented Emotional Support Conversation Generation","summary":"  Due to the lack of human resources for mental health support, there is an\nincreasing demand for employing conversational agents for support. Recent work\nhas demonstrated the effectiveness of dialogue models in providing emotional\nsupport. As previous studies have demonstrated that seekers' persona is an\nimportant factor for effective support, we investigate whether there are\nbenefits to modeling such information in dialogue models for support. In this\npaper, our empirical analysis verifies that persona has an important impact on\nemotional support. Therefore, we propose a framework for dynamically inferring\nand modeling seekers' persona. We first train a model for inferring the\nseeker's persona from the conversation history. Accordingly, we propose PAL, a\nmodel that leverages persona information and, in conjunction with our\nstrategy-based controllable generation method, provides personalized emotional\nsupport. Automatic and manual evaluations demonstrate that our proposed model,\nPAL, achieves state-of-the-art results, outperforming the baselines on the\nstudied benchmark. Our code and data are publicly available at\nhttps://github.com/chengjl19/PAL.\n","authors":["Jiale Cheng","Sahand Sabour","Hao Sun","Zhuang Chen","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2212.09235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09233v1","updated":"2022-12-19T04:04:17Z","published":"2022-12-19T04:04:17Z","title":"OASum: Large-Scale Open Domain Aspect-based Summarization","summary":"  Aspect or query-based summarization has recently caught more attention, as it\ncan generate differentiated summaries based on users' interests. However, the\ncurrent dataset for aspect or query-based summarization either focuses on\nspecific domains, contains relatively small-scale instances, or includes only a\nfew aspect types. Such limitations hinder further explorations in this\ndirection. In this work, we take advantage of crowd-sourcing knowledge on\nWikipedia.org and automatically create a high-quality, large-scale open-domain\naspect-based summarization dataset named OASum, which contains more than 3.7\nmillion instances with around 1 million different aspects on 2 million\nWikipedia pages. We provide benchmark results on OAsum and demonstrate its\nability for diverse aspect-based summarization generation. To overcome the data\nscarcity problem on specific domains, we also perform zero-shot, few-shot, and\nfine-tuning on seven downstream datasets. Specifically, zero/few-shot and\nfine-tuning results show that the model pre-trained on our corpus demonstrates\na strong aspect or query-focused generation ability compared with the backbone\nmodel. Our dataset and pre-trained checkpoints are publicly available.\n","authors":["Xianjun Yang","Kaiqiang Song","Sangwoo Cho","Xiaoyang Wang","Xiaoman Pan","Linda Petzold","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2212.09233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08216v2","updated":"2022-12-19T04:01:57Z","published":"2022-12-16T01:10:41Z","title":"Azimuth: Systematic Error Analysis for Text Classification","summary":"  We present Azimuth, an open-source and easy-to-use tool to perform error\nanalysis for text classification. Compared to other stages of the ML\ndevelopment cycle, such as model training and hyper-parameter tuning, the\nprocess and tooling for the error analysis stage are less mature. However, this\nstage is critical for the development of reliable and trustworthy AI systems.\nTo make error analysis more systematic, we propose an approach comprising\ndataset analysis and model quality assessment, which Azimuth facilitates. We\naim to help AI practitioners discover and address areas where the model does\nnot generalize by leveraging and integrating a range of ML techniques, such as\nsaliency maps, similarity, uncertainty, and behavioral analyses, all in one\ntool. Our code and documentation are available at\ngithub.com/servicenow/azimuth.\n","authors":["Gabrielle Gauthier-Melançon","Orlando Marquez Ayala","Lindsay Brin","Chris Tyler","Frédéric Branchaud-Charron","Joseph Marinier","Karine Grande","Di Le"],"pdf_url":"https://arxiv.org/pdf/2212.08216v2.pdf","comment":"To be published in Proceedings of the 2022 Conference on Empirical\n  Methods in Natural Language Processing: System Demonstrations. 13 pages and\n  14 figures"},{"id":"http://arxiv.org/abs/2211.06869v3","updated":"2022-12-19T03:18:36Z","published":"2022-11-13T10:16:39Z","title":"What would Harry say? Building Dialogue Agents for Characters in a Story","summary":"  We have a Christmas gift for Harry Potter fans all over the world. In this\npaper, we present Harry Potter Dialogue (HPD), a dataset that helps train Harry\nPotter-like dialogue agents. Such a task is typically viewed as a variant of\npersonalized dialogue agents, but they differ significantly in three respects:\n1) Harry lived in a virtual world of wizards, thus, real-world commonsense may\nnot apply to Harry's conversations; 2) Harry's behavior is strongly linked to\nbackground information in conversations: the scene, its attributes and its\nrelationship to other speakers; and 3) Such backgrounds are dynamically altered\nas the storyline goes on. The HPD dataset, as the first dataset to facilitate\nthe study of dialogue agent construction for characters within a story,\nprovides rich contextual information about each dialogue session such as\nscenes, character attributes, and relations. More importantly, all the\nbackground information will change over the course of the story. In addition,\nHPD could support both dialogue generation and retrieval tasks. We evaluate\nbaselines such as Dialog-GPT and BOB to determine the extent to which they can\ngenerate Harry Potter-like responses. The experimental results disappoint us in\nthat although the generated responses are fluent, they still seem out of\ncharacter for Harry. Besides, we validate the current most robust dialogue\nagent, ChatGPT, which also can't generate plausible Harry-Potter-like responses\nin some cases, either. Our results suggest that there is much scope for future\nresearch.\n","authors":["Nuo Chen","Yan Wang","Haiyun Jiang","Deng Cai","Ziyang Chen","Longyue Wang","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2211.06869v3.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2212.09196v1","updated":"2022-12-19T00:04:56Z","published":"2022-12-19T00:04:56Z","title":"Emergent Analogical Reasoning in Large Language Models","summary":"  The recent advent of large language models - large neural networks trained on\na simple predictive objective over a massive corpus of natural language - has\nreinvigorated debate over whether human cognitive capacities might emerge in\nsuch generic models given sufficient training data. Of particular interest is\nthe ability of these models to reason about novel problems zero-shot, without\nany direct training on those problems. In human cognition, this capacity is\nclosely tied to an ability to reason by analogy. Here, we performed a direct\ncomparison between human reasoners and a large language model (GPT-3) on a\nrange of analogical tasks, including a novel text-based matrix reasoning task\nclosely modeled on Raven's Progressive Matrices. We found that GPT-3 displayed\na surprisingly strong capacity for abstract pattern induction, matching or even\nsurpassing human capabilities in most settings. Our results indicate that large\nlanguage models such as GPT-3 have acquired an emergent ability to find\nzero-shot solutions to a broad range of analogy problems.\n","authors":["Taylor Webb","Keith J. Holyoak","Hongjing Lu"],"pdf_url":"https://arxiv.org/pdf/2212.09196v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09917v1","updated":"2022-12-19T23:45:05Z","published":"2022-12-19T23:45:05Z","title":"Inverse Reinforcement Learning for Text Summarization","summary":"  Current state-of-the-art summarization models are trained with either maximum\nlikelihood estimation (MLE) or reinforcement learning (RL). In this study, we\ninvestigate the third training paradigm and argue that inverse reinforcement\nlearning (IRL) may be more suitable for text summarization. IRL focuses on\nestimating the reward function of an agent, given a set of observations of that\nagent's behavior. Generally, IRL provides advantages in situations where the\nreward function is not explicitly known or where it is difficult to define or\ninteract with the environment directly. These situations are exactly what we\nobserve in summarization. Thus, we introduce inverse reinforcement learning\ninto text summarization and define a suite of sub-rewards that are important\nfor summarization optimization. By simultaneously estimating the reward\nfunction and optimizing the summarization agent with expert demonstrations, we\nshow that the model trained with IRL produces summaries that closely follow\nhuman behavior, in terms of better ROUGE, coverage, novelty, compression ratio\nand factuality when compared to the baselines trained with MLE and RL.\n","authors":["Yu Fu","Deyi Xiong","Yue Dong"],"pdf_url":"https://arxiv.org/pdf/2212.09917v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2211.01994v2","updated":"2022-12-19T23:41:21Z","published":"2022-11-03T17:08:26Z","title":"lilGym: Natural Language Visual Reasoning with Reinforcement Learning","summary":"  We present lilGym, a new benchmark for language-conditioned reinforcement\nlearning in visual environments. lilGym is based on 2,661 highly-compositional\nhuman-written natural language statements grounded in an interactive visual\nenvironment. We introduce a new approach for exact reward computation in every\npossible world state by annotating all statements with executable Python\nprograms. Each statement is paired with multiple start states and reward\nfunctions to form thousands of distinct Markov Decision Processes of varying\ndifficulty. We experiment with lilGym with different models and learning\nregimes. Our results and analysis show that while existing methods are able to\nachieve non-trivial performance, lilGym forms a challenging open problem.\nlilGym is available at https://lil.nlp.cornell.edu/lilgym/.\n","authors":["Anne Wu","Kianté Brantley","Noriyuki Kojima","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2211.01994v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09912v1","updated":"2022-12-19T23:33:21Z","published":"2022-12-19T23:33:21Z","title":"Tokenization Consistency Matters for Generative Models on Extractive NLP\n  Tasks","summary":"  Generative models have been widely applied to solve extractive tasks, where\nparts of the input is extracted to form the desired output, and achieved\nsignificant success. For example, in extractive question answering (QA),\ngenerative models have constantly yielded state-of-the-art results. In this\nwork, we identify the issue of tokenization inconsistency that is commonly\nneglected in training these models. This issue damages the extractive nature of\nthese tasks after the input and output are tokenized inconsistently by the\ntokenizer, and thus leads to performance drop as well as hallucination. We\npropose a simple yet effective fix to this issue and conduct a case study on\nextractive QA. We show that, with consistent tokenization, the model performs\nbetter in both in-domain and out-of-domain datasets, with a notable average of\n+1.7 F2 gain when a BART model is trained on SQuAD and evaluated on 8 QA\ndatasets. Further, the model converges faster, and becomes less likely to\ngenerate out-of-context answers. With these findings, we would like to call for\nmore attention on how tokenization should be done when solving extractive tasks\nand recommend applying consistent tokenization during training.\n","authors":["Kaiser Sun","Peng Qi","Yuhao Zhang","Lan Liu","William Yang Wang","Zhiheng Huang"],"pdf_url":"https://arxiv.org/pdf/2212.09912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09897v1","updated":"2022-12-19T22:37:46Z","published":"2022-12-19T22:37:46Z","title":"Inducing Character-level Structure in Subword-based Language Models with\n  Type-level Interchange Intervention Training","summary":"  Language tasks involving character-level manipulations (e.g., spelling\ncorrection, many word games) are challenging for models based in subword\ntokenization. To address this, we adapt the interchange intervention training\nmethod of Geiger et al. (2021) to operate on type-level variables over\ncharacters. This allows us to encode robust, position-independent\ncharacter-level information in the internal representations of subword-based\nmodels. We additionally introduce a suite of character-level tasks that\nsystematically vary in their dependence on meaning and sequence-level context.\nWhile simple character-level tokenization approaches still perform best on\npurely form-based tasks like string reversal, our method is superior for more\ncomplex tasks that blend form, meaning, and context, such as spelling\ncorrection in context and word search games. Our approach also leads to\nsubword-based models with human-intepretable internal representations of\ncharacters.\n","authors":["Jing Huang","Zhengxuan Wu","Kyle Mahowald","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2212.09897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09895v1","updated":"2022-12-19T22:36:53Z","published":"2022-12-19T22:36:53Z","title":"Improved Long-Form Spoken Language Translation with Large Language\n  Models","summary":"  A challenge in spoken language translation is that plenty of spoken content\nis long-form, but short units are necessary for obtaining high-quality\ntranslations. To address this mismatch, we fine-tune a general-purpose, large\nlanguage model to split long ASR transcripts into segments that can be\nindependently translated so as to maximize the overall translation quality. We\ncompare to several segmentation strategies and find that our approach improves\nBLEU score on three languages by an average of 2.7 BLEU overall compared to an\nautomatic punctuation baseline. Further, we demonstrate the effectiveness of\ntwo constrained decoding strategies to improve well-formedness of the model\noutput from above 99% to 100%.\n","authors":["Arya D. McCarthy","Hao Zhang","Shankar Kumar","Felix Stahlberg","Axel H. Ng"],"pdf_url":"https://arxiv.org/pdf/2212.09895v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09885v1","updated":"2022-12-19T22:08:36Z","published":"2022-12-19T22:08:36Z","title":"Asking Clarification Questions for Code Generation in General-Purpose\n  Programming Language","summary":"  Code generation from text requires understanding the user's intent from a\nnatural language description (NLD) and generating an executable program code\nsnippet that satisfies this intent. While recent pretrained language models\n(PLMs) demonstrate remarkable performance for this task, these models fail when\nthe given NLD is ambiguous due to the lack of enough specifications for\ngenerating a high-quality code snippet. In this work, we introduce a novel and\nmore realistic setup for this task. We hypothesize that ambiguities in the\nspecifications of an NLD are resolved by asking clarification questions (CQs).\nTherefore, we collect and introduce a new dataset named CodeClarQA containing\nNLD-Code pairs with created CQAs. We evaluate the performance of PLMs for code\ngeneration on our dataset. The empirical results support our hypothesis that\nclarifications result in more precise generated code, as shown by an\nimprovement of 17.52 in BLEU, 12.72 in CodeBLEU, and 7.7\\% in the exact match.\nAlongside this, our task and dataset introduce new challenges to the community,\nincluding when and what CQs should be asked.\n","authors":["Haau-Sing Li","Mohsen Mesgar","André F. T. Martins","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2212.09885v1.pdf","comment":"8 pages (excluding Limitations and Ethics Concerns), 4 figures, 7\n  tables"},{"id":"http://arxiv.org/abs/2212.09879v1","updated":"2022-12-19T21:59:22Z","published":"2022-12-19T21:59:22Z","title":"Unsigned Play by Milan Kundera? An Authorship Attribution Study","summary":"  In addition to being a widely recognised novelist, Milan Kundera has also\nauthored three pieces for theatre: The Owners of the Keys (Majitel\\'e\nkl\\'i\\v{c}\\r{u}, 1961), The Blunder (Pt\\'akovina, 1967), and Jacques and his\nMaster (Jakub a jeho p\\'an, 1971). In recent years, however, the hypothesis has\nbeen raised that Kundera is the true author of a fourth play: Juro\nJ\\'ano\\v{s}\\'ik, first performed in a 1974 production under the name of Karel\nSteigerwald, who was Kundera's student at the time. In this study, we make use\nof supervised machine learning to settle the question of authorship attribution\nin the case of Juro J\\'ano\\v{s}\\'ik, with results strongly supporting the\nhypothesis of Kundera's authorship.\n","authors":["Lenka Jungmannová","Petr Plecháč"],"pdf_url":"https://arxiv.org/pdf/2212.09879v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2212.09748v1","updated":"2022-12-19T18:59:58Z","published":"2022-12-19T18:59:58Z","title":"Scalable Diffusion Models with Transformers","summary":"  We explore a new class of diffusion models based on the transformer\narchitecture. We train latent diffusion models of images, replacing the\ncommonly-used U-Net backbone with a transformer that operates on latent\npatches. We analyze the scalability of our Diffusion Transformers (DiTs)\nthrough the lens of forward pass complexity as measured by Gflops. We find that\nDiTs with higher Gflops -- through increased transformer depth/width or\nincreased number of input tokens -- consistently have lower FID. In addition to\npossessing good scalability properties, our largest DiT-XL/2 models outperform\nall prior diffusion models on the class-conditional ImageNet 512x512 and\n256x256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.\n","authors":["William Peebles","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2212.09748v1.pdf","comment":"Code, project page and videos available at\n  https://www.wpeebles.com/DiT"},{"id":"http://arxiv.org/abs/2212.08663v1","updated":"2022-12-19T18:59:57Z","published":"2022-12-19T18:59:57Z","title":"Randomized Quantization for Data Agnostic Representation Learning","summary":"  Self-supervised representation learning follows a paradigm of withholding\nsome part of the data and tasking the network to predict it from the remaining\npart. Towards this end, masking has emerged as a generic and powerful tool\nwhere content is withheld along the sequential dimension, e.g., spatial in\nimages, temporal in audio, and syntactic in language. In this paper, we explore\nthe orthogonal channel dimension for generic data augmentation. The data for\neach channel is quantized through a non-uniform quantizer, with the quantized\nvalue sampled randomly within randomly sampled quantization bins. From another\nperspective, quantization is analogous to channel-wise masking, as it removes\nthe information within each bin, but preserves the information across bins. We\napply the randomized quantization in conjunction with sequential augmentations\non self-supervised contrastive models. This generic approach achieves results\non par with modality-specific augmentation on vision tasks, and\nstate-of-the-art results on 3D point clouds as well as on audio. We also\ndemonstrate this method to be applicable for augmenting intermediate embeddings\nin a deep neural network on the comprehensive DABS benchmark which is comprised\nof various data modalities. Code is availabel at\nhttp://www.github.com/microsoft/random_quantize.\n","authors":["Huimin Wu","Chenyang Lei","Xiao Sun","Peng-Shuai Wang","Qifeng Chen","Kwang-Ting Cheng","Stephen Lin","Zhirong Wu"],"pdf_url":"https://arxiv.org/pdf/2212.08663v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2212.09737v1","updated":"2022-12-19T18:55:43Z","published":"2022-12-19T18:55:43Z","title":"Position-guided Text Prompt for Vision-Language Pre-training","summary":"  Vision-Language Pre-Training (VLP) has shown promising capabilities to align\nimage and text pairs, facilitating a broad variety of cross-modal learning\ntasks. However, we observe that VLP models often lack the visual\ngrounding/localization capability which is critical for many downstream tasks\nsuch as visual reasoning. In this work, we propose a novel Position-guided Text\nPrompt (PTP) paradigm to enhance the visual grounding ability of cross-modal\nmodels trained with VLP. Specifically, in the VLP phase, PTP divides the image\ninto $N\\times N$ blocks, and identifies the objects in each block through the\nwidely used object detector in VLP. It then reformulates the visual grounding\ntask into a fill-in-the-blank problem given a PTP by encouraging the model to\npredict the objects in the given blocks or regress the blocks of a given\nobject, e.g. filling `P\" or ``O\" in aPTP ``The block P has a O\". This mechanism\nimproves the visual grounding capability of VLP models and thus helps them\nbetter handle various downstream tasks. By introducing PTP into several\nstate-of-the-art VLP frameworks, we observe consistently significant\nimprovements across representative cross-modal learning model architectures and\nseveral benchmarks, e.g. zero-shot Flickr30K Retrieval (+4.8 in average\nrecall@1) for ViLT \\cite{vilt} baseline, and COCO Captioning (+5.3 in CIDEr)\nfor SOTA BLIP \\cite{blip} baseline. Moreover, PTP achieves comparable results\nwith object-detector based methods, and much faster inference speed since PTP\ndiscards its object detector for inference while the later cannot. Our code and\npre-trained weight will be released at \\url{https://github.com/sail-sg/ptp}.\n","authors":["Alex Jinpeng Wang","Pan Zhou","Mike Zheng Shou","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2212.09737v1.pdf","comment":"Work in progress, code is in https://github.com/sail-sg/ptp"},{"id":"http://arxiv.org/abs/2212.09735v1","updated":"2022-12-19T18:54:59Z","published":"2022-12-19T18:54:59Z","title":"Correspondence Distillation from NeRF-based GAN","summary":"  The neural radiance field (NeRF) has shown promising results in preserving\nthe fine details of objects and scenes. However, unlike mesh-based\nrepresentations, it remains an open problem to build dense correspondences\nacross different NeRFs of the same category, which is essential in many\ndownstream tasks. The main difficulties of this problem lie in the implicit\nnature of NeRF and the lack of ground-truth correspondence annotations. In this\npaper, we show it is possible to bypass these challenges by leveraging the rich\nsemantics and structural priors encapsulated in a pre-trained NeRF-based GAN.\nSpecifically, we exploit such priors from three aspects, namely 1) a dual\ndeformation field that takes latent codes as global structural indicators, 2) a\nlearning objective that regards generator features as geometric-aware local\ndescriptors, and 3) a source of infinite object-specific NeRF samples. Our\nexperiments demonstrate that such priors lead to 3D dense correspondence that\nis accurate, smooth, and robust. We also show that established dense\ncorrespondence across NeRFs can effectively enable many NeRF-based downstream\napplications such as texture transfer.\n","authors":["Yushi Lan","Chen Change Loy","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2212.09735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09713v1","updated":"2022-12-19T18:42:19Z","published":"2022-12-19T18:42:19Z","title":"A Probabilistic Framework for Lifelong Test-Time Adaptation","summary":"  Test-time adaptation is the problem of adapting a source pre-trained model\nusing test inputs from a target domain without access to source domain data.\nMost of the existing approaches address the setting in which the target domain\nis stationary. Moreover, these approaches are prone to making erroneous\npredictions with unreliable uncertainty estimates when distribution shifts\noccur. Hence, test-time adaptation in the face of non-stationary target domain\nshift becomes a problem of significant interest. To address these issues, we\npropose a principled approach, PETAL (Probabilistic lifElong Test-time\nAdaptation with seLf-training prior), which looks into this problem from a\nprobabilistic perspective using a partly data-dependent prior. A\nstudent-teacher framework, where the teacher model is an exponential moving\naverage of the student model naturally emerges from this probabilistic\nperspective. In addition, the knowledge from the posterior distribution\nobtained for the source task acts as a regularizer. To handle catastrophic\nforgetting in the long term, we also propose a data-driven model parameter\nresetting mechanism based on the Fisher information matrix (FIM). Moreover,\nimprovements in experimental results suggest that FIM based data-driven\nparameter restoration contributes to reducing the error accumulation and\nmaintaining the knowledge of recent domain by restoring only the irrelevant\nparameters. In terms of predictive error rate as well as uncertainty based\nmetrics such as Brier score and negative log-likelihood, our method achieves\nbetter results than the current state-of-the-art for online lifelong test time\nadaptation across various benchmarks, such as CIFAR-10C, CIFAR-100C, ImageNetC,\nand ImageNet3DCC datasets.\n","authors":["Dhanajit Brahma","Piyush Rai"],"pdf_url":"https://arxiv.org/pdf/2212.09713v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2212.09681v1","updated":"2022-12-19T18:09:34Z","published":"2022-12-19T18:09:34Z","title":"Annual field-scale maps of tall and short crops at the global scale\n  using GEDI and Sentinel-2","summary":"  Crop type maps are critical for tracking agricultural land use and estimating\ncrop production. Remote sensing has proven an efficient and reliable tool for\ncreating these maps in regions with abundant ground labels for model training,\nyet these labels remain difficult to obtain in many regions and years. NASA's\nGlobal Ecosystem Dynamics Investigation (GEDI) spaceborne lidar instrument,\noriginally designed for forest monitoring, has shown promise for distinguishing\ntall and short crops. In the current study, we leverage GEDI to develop\nwall-to-wall maps of short vs tall crops on a global scale at 10 m resolution\nfor 2019-2021. Specifically, we show that (1) GEDI returns can reliably be\nclassified into tall and short crops after removing shots with extreme view\nangles or topographic slope, (2) the frequency of tall crops over time can be\nused to identify months when tall crops are at their peak height, and (3) GEDI\nshots in these months can then be used to train random forest models that use\nSentinel-2 time series to accurately predict short vs. tall crops. Independent\nreference data from around the world are then used to evaluate these GEDI-S2\nmaps. We find that GEDI-S2 performed nearly as well as models trained on\nthousands of local reference training points, with accuracies of at least 87%\nand often above 90% throughout the Americas, Europe, and East Asia. Systematic\nunderestimation of tall crop area was observed in regions where crops\nfrequently exhibit low biomass, namely Africa and South Asia, and further work\nis needed in these systems. Although the GEDI-S2 approach only differentiates\ntall from short crops, in many landscapes this distinction goes a long way\ntoward mapping the main individual crop types. The combination of GEDI and\nSentinel-2 thus presents a very promising path towards global crop mapping with\nminimal reliance on ground data.\n","authors":["Stefania Di Tommaso","Sherrie Wang","Vivek Vajipey","Noel Gorelick","Rob Strey","David B. Lobell"],"pdf_url":"https://arxiv.org/pdf/2212.09681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.04866v2","updated":"2022-12-19T17:54:22Z","published":"2022-10-10T17:34:49Z","title":"PoGaIN: Poisson-Gaussian Image Noise Modeling from Paired Samples","summary":"  Image noise can often be accurately fitted to a Poisson-Gaussian\ndistribution. However, estimating the distribution parameters from a noisy\nimage only is a challenging task. Here, we study the case when paired noisy and\nnoise-free samples are accessible. No method is currently available to exploit\nthe noise-free information, which may help to achieve more accurate\nestimations. To fill this gap, we derive a novel, cumulant-based, approach for\nPoisson-Gaussian noise modeling from paired image samples. We show its improved\nperformance over different baselines, with special emphasis on MSE, effect of\noutliers, image dependence, and bias. We additionally derive the log-likelihood\nfunction for further insights and discuss real-world applicability.\n","authors":["Nicolas Bähler","Majed El Helou","Étienne Objois","Kaan Okumuş","Sabine Süsstrunk"],"pdf_url":"https://arxiv.org/pdf/2210.04866v2.pdf","comment":"5 pages, 4 figures, and 3 tables. Code is available at\n  https://github.com/IVRL/PoGaIN"},{"id":"http://arxiv.org/abs/2212.09662v1","updated":"2022-12-19T17:44:54Z","published":"2022-12-19T17:44:54Z","title":"MatCha: Enhancing Visual Language Pretraining with Math Reasoning and\n  Chart Derendering","summary":"  Visual language data such as plots, charts, and infographics are ubiquitous\nin the human world. However, state-of-the-art vision-language models do not\nperform well on these data. We propose MatCha (Math reasoning and Chart\nderendering pretraining) to enhance visual language models' capabilities in\njointly modeling charts/plots and language data. Specifically, we propose\nseveral pretraining tasks that cover plot deconstruction and numerical\nreasoning which are the key capabilities in visual language modeling.\n  We perform the MatCha pretraining starting from Pix2Struct, a recently\nproposed image-to-text visual language model. On standard benchmarks such as\nPlotQA and ChartQA, the MatCha model outperforms state-of-the-art methods by as\nmuch as nearly 20%. We also examine how well MatCha pretraining transfers to\ndomains such as screenshots, textbook diagrams, and document figures and\nobserve overall improvement, verifying the usefulness of MatCha pretraining on\nbroader visual language tasks.\n","authors":["Fangyu Liu","Francesco Piccinno","Syrine Krichene","Chenxi Pang","Kenton Lee","Mandar Joshi","Yasemin Altun","Nigel Collier","Julian Martin Eisenschlos"],"pdf_url":"https://arxiv.org/pdf/2212.09662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.10409v2","updated":"2022-12-19T17:22:49Z","published":"2022-07-21T11:00:44Z","title":"Sequence Models for Drone vs Bird Classification","summary":"  Drone detection has become an essential task in object detection as drone\ncosts have decreased and drone technology has improved. It is, however,\ndifficult to detect distant drones when there is weak contrast, long range, and\nlow visibility. In this work, we propose several sequence classification\narchitectures to reduce the detected false-positive ratio of drone tracks.\nMoreover, we propose a new drone vs. bird sequence classification dataset to\ntrain and evaluate the proposed architectures. 3D CNN, LSTM, and Transformer\nbased sequence classification architectures have been trained on the proposed\ndataset to show the effectiveness of the proposed idea. As experiments show,\nusing sequence information, bird classification and overall F1 scores can be\nincreased by up to 73% and 35%, respectively. Among all sequence classification\nmodels, R(2+1)D-based fully convolutional model yields the best transfer\nlearning and fine-tuning results.\n","authors":["Fatih Cagatay Akyon","Erdem Akagunduz","Sinan Onur Altinuc","Alptekin Temizel"],"pdf_url":"https://arxiv.org/pdf/2207.10409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09621v1","updated":"2022-12-19T17:00:54Z","published":"2022-12-19T17:00:54Z","title":"Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document\n  Understanding","summary":"  Unsupervised pre-training on millions of digital-born or scanned documents\nhas shown promising advances in visual document understanding~(VDU). While\nvarious vision-language pre-training objectives are studied in existing\nsolutions, the document textline, as an intrinsic granularity in VDU, has\nseldom been explored so far. A document textline usually contains words that\nare spatially and semantically correlated, which can be easily obtained from\nOCR engines. In this paper, we propose Wukong-Reader, trained with new\npre-training objectives to leverage the structural knowledge nested in document\ntextlines. We introduce textline-region contrastive learning to achieve\nfine-grained alignment between the visual regions and texts of document\ntextlines. Furthermore, masked region modeling and textline-grid matching are\nalso designed to enhance the visual and layout representations of textlines.\nExperiments show that our Wukong-Reader has superior performance on various VDU\ntasks such as information extraction. The fine-grained alignment over textlines\nalso empowers Wukong-Reader with promising localization ability.\n","authors":["Haoli Bai","Zhiguang Liu","Xiaojun Meng","Wentao Li","Shuang Liu","Nian Xie","Rongfu Zheng","Liangwei Wang","Lu Hou","Jiansheng Wei","Xin Jiang","Qun Liu"],"pdf_url":"https://arxiv.org/pdf/2212.09621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09611v1","updated":"2022-12-19T16:50:41Z","published":"2022-12-19T16:50:41Z","title":"Optimizing Prompts for Text-to-Image Generation","summary":"  Well-designed prompts can guide text-to-image models to generate amazing\nimages. However, the performant prompts are often model-specific and misaligned\nwith user input. Instead of laborious human engineering, we propose prompt\nadaptation, a general framework that automatically adapts original user input\nto model-preferred prompts. Specifically, we first perform supervised\nfine-tuning with a pretrained language model on a small collection of manually\nengineered prompts. Then we use reinforcement learning to explore better\nprompts. We define a reward function that encourages the policy to generate\nmore aesthetically pleasing images while preserving the original user\nintentions. Experimental results on Stable Diffusion show that our method\noutperforms manual prompt engineering in terms of both automatic metrics and\nhuman preference ratings. Moreover, reinforcement learning further boosts\nperformance, especially on out-of-domain prompts. The pretrained checkpoints\nare available at https://aka.ms/promptist. The demo can be found at\nhttps://aka.ms/promptist-demo.\n","authors":["Yaru Hao","Zewen Chi","Li Dong","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.09611v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2212.09597v1","updated":"2022-12-19T16:32:42Z","published":"2022-12-19T16:32:42Z","title":"Reasoning with Language Model Prompting: A Survey","summary":"  Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions.\n","authors":["Shuofei Qiao","Yixin Ou","Ningyu Zhang","Xiang Chen","Yunzhi Yao","Shumin Deng","Chuanqi Tan","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2212.09597v1.pdf","comment":"Work in progress and resources are available at\n  https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically)"},{"id":"http://arxiv.org/abs/2212.09581v1","updated":"2022-12-19T16:15:02Z","published":"2022-12-19T16:15:02Z","title":"Reference-based Image and Video Super-Resolution via C2-Matching","summary":"  Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising\nparadigm to enhance a low-resolution (LR) input image or video by introducing\nan additional high-resolution (HR) reference image. Existing Ref-SR methods\nmostly rely on implicit correspondence matching to borrow HR textures from\nreference images to compensate for the information loss in input images.\nHowever, performing local transfer is difficult because of two gaps between\ninput and reference images: the transformation gap (e.g., scale and rotation)\nand the resolution gap (e.g., HR and LR). To tackle these challenges, we\npropose C2-Matching in this work, which performs explicit robust matching\ncrossing transformation and resolution. 1) To bridge the transformation gap, we\npropose a contrastive correspondence network, which learns\ntransformation-robust correspondences using augmented views of the input image.\n2) To address the resolution gap, we adopt teacher-student correlation\ndistillation, which distills knowledge from the easier HR-HR matching to guide\nthe more ambiguous LR-HR matching. 3) Finally, we design a dynamic aggregation\nmodule to address the potential misalignment issue between input images and\nreference images. In addition, to faithfully evaluate the performance of\nReference-based Image Super-Resolution under a realistic setting, we contribute\nthe Webly-Referenced SR (WR-SR) dataset, mimicking the practical usage\nscenario. We also extend C2-Matching to Reference-based Video Super-Resolution\ntask, where an image taken in a similar scene serves as the HR reference image.\nExtensive experiments demonstrate that our proposed C2-Matching significantly\noutperforms state of the arts on the standard CUFED5 benchmark and also boosts\nthe performance of video SR by incorporating the C2-Matching component into\nVideo SR pipelines.\n","authors":["Yuming Jiang","Kelvin C. K. Chan","Xintao Wang","Chen Change Loy","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2212.09581v1.pdf","comment":"To appear in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI). arXiv admin note: substantial text overlap with\n  arXiv:2106.01863"},{"id":"http://arxiv.org/abs/2212.09555v1","updated":"2022-12-19T15:45:47Z","published":"2022-12-19T15:45:47Z","title":"Interactive Cartoonization with Controllable Perceptual Factors","summary":"  Cartoonization is a task that renders natural photos into cartoon styles.\nPrevious deep cartoonization methods only have focused on end-to-end\ntranslation, which may hinder editability. Instead, we propose a novel solution\nwith editing features of texture and color based on the cartoon creation\nprocess. To do that, we design a model architecture to have separate decoders,\ntexture and color, to decouple these attributes. In the texture decoder, we\npropose a texture controller, which enables a user to control stroke style and\nabstraction to generate diverse cartoon textures. We also introduce an HSV\ncolor augmentation to induce the networks to generate diverse and controllable\ncolor translation. To the best of our knowledge, our work is the first deep\napproach to control the cartoonization at inference while showing profound\nquality improvement over to baselines.\n","authors":["Namhyuk Ahn","Patrick Kwon","Jihye Back","Kibeom Hong","Seungkwon Kim"],"pdf_url":"https://arxiv.org/pdf/2212.09555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.02351v2","updated":"2022-12-19T15:45:33Z","published":"2022-03-04T14:40:44Z","title":"Uncertainty Estimation for Heatmap-based Landmark Localization","summary":"  Automatic anatomical landmark localization has made great strides by\nleveraging deep learning methods in recent years. The ability to quantify the\nuncertainty of these predictions is a vital component needed for these methods\nto be adopted in clinical settings, where it is imperative that erroneous\npredictions are caught and corrected. We propose Quantile Binning, a\ndata-driven method to categorize predictions by uncertainty with estimated\nerror bounds. Our framework can be applied to any continuous uncertainty\nmeasure, allowing straightforward identification of the best subset of\npredictions with accompanying estimated error bounds. We facilitate easy\ncomparison between uncertainty measures by constructing two evaluation metrics\nderived from Quantile Binning. We compare and contrast three epistemic\nuncertainty measures (two baselines, and a proposed method combining aspects of\nthe two), derived from two heatmap-based landmark localization model paradigms\n(U-Net and patch-based). We show results across three datasets, including a\npublicly available Cephalometric dataset. We illustrate how filtering out gross\nmispredictions caught in our Quantile Bins significantly improves the\nproportion of predictions under an acceptable error threshold. Finally, we\ndemonstrate that Quantile Binning remains effective on landmarks with high\naleatoric uncertainty caused by inherent landmark ambiguity, and offer\nrecommendations on which uncertainty measure to use and how to use it. The code\nand data are available at https://github.com/schobs/qbin.\n","authors":["Lawrence Schobs","Andrew J. Swift","Haiping Lu"],"pdf_url":"https://arxiv.org/pdf/2203.02351v2.pdf","comment":"14 pages, in IEEE Transactions on Medical Imaging, 2022"},{"id":"http://arxiv.org/abs/2212.09530v1","updated":"2022-12-19T15:21:55Z","published":"2022-12-19T15:21:55Z","title":"HARP: Personalized Hand Reconstruction from a Monocular RGB Video","summary":"  We present HARP (HAnd Reconstruction and Personalization), a personalized\nhand avatar creation approach that takes a short monocular RGB video of a human\nhand as input and reconstructs a faithful hand avatar exhibiting a\nhigh-fidelity appearance and geometry. In contrast to the major trend of neural\nimplicit representations, HARP models a hand with a mesh-based parametric hand\nmodel, a vertex displacement map, a normal map, and an albedo without any\nneural components. As validated by our experiments, the explicit nature of our\nrepresentation enables a truly scalable, robust, and efficient approach to hand\navatar creation. HARP is optimized via gradient descent from a short sequence\ncaptured by a hand-held mobile phone and can be directly used in AR/VR\napplications with real-time rendering capability. To enable this, we carefully\ndesign and implement a shadow-aware differentiable rendering scheme that is\nrobust to high degree articulations and self-shadowing regularly present in\nhand motion sequences, as well as challenging lighting conditions. It also\ngeneralizes to unseen poses and novel viewpoints, producing photo-realistic\nrenderings of hand animations performing highly-articulated motions.\nFurthermore, the learned HARP representation can be used for improving 3D hand\npose estimation quality in challenging viewpoints. The key advantages of HARP\nare validated by the in-depth analyses on appearance reconstruction, novel-view\nand novel pose synthesis, and 3D hand pose refinement. It is an AR/VR-ready\npersonalized hand representation that shows superior fidelity and scalability.\n","authors":["Korrawe Karunratanakul","Sergey Prokudin","Otmar Hilliges","Siyu Tang"],"pdf_url":"https://arxiv.org/pdf/2212.09530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.03277v2","updated":"2022-12-19T15:19:37Z","published":"2021-12-06T16:30:43Z","title":"Automatic quality control framework for more reliable integration of\n  machine learning-based image segmentation into medical workflows","summary":"  Machine learning algorithms underpin modern diagnostic-aiding software, which\nhas proved valuable in clinical practice, particularly in radiology. However,\ninaccuracies, mainly due to the limited availability of clinical samples for\ntraining these algorithms, hamper their wider applicability, acceptance, and\nrecognition amongst clinicians. We present an analysis of state-of-the-art\nautomatic quality control (QC) approaches that can be implemented within these\nalgorithms to estimate the certainty of their outputs. We validated the most\npromising approaches on a brain image segmentation task identifying white\nmatter hyperintensities (WMH) in magnetic resonance imaging data. WMH are a\ncorrelate of small vessel disease common in mid-to-late adulthood and are\nparticularly challenging to segment due to their varied size, and\ndistributional patterns. Our results show that the aggregation of uncertainty\nand Dice prediction were most effective in failure detection for this task.\nBoth methods independently improved mean Dice from 0.82 to 0.84. Our work\nreveals how QC methods can help to detect failed segmentation cases and\ntherefore make automatic segmentation more reliable and suitable for clinical\npractice.\n","authors":["Elena Williams","Sebastian Niehaus","Janis Reinelt","Alberto Merola","Paul Glad Mihai","Kersten Villringer","Konstantin Thierbach","Evelyn Medawar","Daniel Lichterfeld","Ingo Roeder","Nico Scherf","Maria del C. Valdés Hernández"],"pdf_url":"https://arxiv.org/pdf/2112.03277v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2104.06728v2","updated":"2022-12-19T15:16:43Z","published":"2021-04-14T09:32:01Z","title":"Adversarial Sticker: A Stealthy Attack Method in the Physical World","summary":"  To assess the vulnerability of deep learning in the physical world, recent\nworks introduce adversarial patches and apply them on different tasks. In this\npaper, we propose another kind of adversarial patch: the Meaningful Adversarial\nSticker, a physically feasible and stealthy attack method by using real\nstickers existing in our life. Unlike the previous adversarial patches by\ndesigning perturbations, our method manipulates the sticker's pasting position\nand rotation angle on the objects to perform physical attacks. Because the\nposition and rotation angle are less affected by the printing loss and color\ndistortion, adversarial stickers can keep good attacking performance in the\nphysical world. Besides, to make adversarial stickers more practical in real\nscenes, we conduct attacks in the black-box setting with the limited\ninformation rather than the white-box setting with all the details of threat\nmodels. To effectively solve for the sticker's parameters, we design the Region\nbased Heuristic Differential Evolution Algorithm, which utilizes the new-found\nregional aggregation of effective solutions and the adaptive adjustment\nstrategy of the evaluation criteria. Our method is comprehensively verified in\nthe face recognition and then extended to the image retrieval and traffic sign\nrecognition. Extensive experiments show the proposed method is effective and\nefficient in complex physical conditions and has a good generalization for\ndifferent tasks.\n","authors":["Xingxing Wei","Ying Guo","Jie Yu"],"pdf_url":"https://arxiv.org/pdf/2104.06728v2.pdf","comment":"accepted by TPAMI 2022"},{"id":"http://arxiv.org/abs/2212.09525v1","updated":"2022-12-19T15:14:20Z","published":"2022-12-19T15:14:20Z","title":"FreeEnricher: Enriching Face Landmarks without Additional Cost","summary":"  Recent years have witnessed significant growth of face alignment. Though\ndense facial landmark is highly demanded in various scenarios, e.g., cosmetic\nmedicine and facial beautification, most works only consider sparse face\nalignment. To address this problem, we present a framework that can enrich\nlandmark density by existing sparse landmark datasets, e.g., 300W with 68\npoints and WFLW with 98 points. Firstly, we observe that the local patches\nalong each semantic contour are highly similar in appearance. Then, we propose\na weakly-supervised idea of learning the refinement ability on original sparse\nlandmarks and adapting this ability to enriched dense landmarks. Meanwhile,\nseveral operators are devised and organized together to implement the idea.\nFinally, the trained model is applied as a plug-and-play module to the existing\nface alignment networks. To evaluate our method, we manually label the dense\nlandmarks on 300W testset. Our method yields state-of-the-art accuracy not only\nin newly-constructed dense 300W testset but also in the original sparse 300W\nand WFLW testsets without additional cost.\n","authors":["Yangyu Huang","Xi Chen","Jongyoo Kim","Hao Yang","Chong Li","Jiaolong Yang","Dong Chen"],"pdf_url":"https://arxiv.org/pdf/2212.09525v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2109.05721v2","updated":"2022-12-19T15:12:48Z","published":"2021-09-13T06:05:28Z","title":"ADNet: Leveraging Error-Bias Towards Normal Direction in Face Alignment","summary":"  The recent progress of CNN has dramatically improved face alignment\nperformance. However, few works have paid attention to the error-bias with\nrespect to error distribution of facial landmarks. In this paper, we\ninvestigate the error-bias issue in face alignment, where the distributions of\nlandmark errors tend to spread along the tangent line to landmark curves. This\nerror-bias is not trivial since it is closely connected to the ambiguous\nlandmark labeling task. Inspired by this observation, we seek a way to leverage\nthe error-bias property for better convergence of CNN model. To this end, we\npropose anisotropic direction loss (ADL) and anisotropic attention module (AAM)\nfor coordinate and heatmap regression, respectively. ADL imposes strong binding\nforce in normal direction for each landmark point on facial boundaries. On the\nother hand, AAM is an attention module which can get anisotropic attention mask\nfocusing on the region of point and its local edge connected by adjacent\npoints, it has a stronger response in tangent than in normal, which means\nrelaxed constraints in the tangent. These two methods work in a complementary\nmanner to learn both facial structures and texture details. Finally, we\nintegrate them into an optimized end-to-end training pipeline named ADNet. Our\nADNet achieves state-of-the-art results on 300W, WFLW and COFW datasets, which\ndemonstrates the effectiveness and robustness.\n","authors":["Yangyu Huang","Hao Yang","Chong Li","Jongyoo Kim","Fangyun Wei"],"pdf_url":"https://arxiv.org/pdf/2109.05721v2.pdf","comment":"Proceedings of the IEEE/CVF International Conference on Computer\n  Vision. 2021 (ICCV 2021)"},{"id":"http://arxiv.org/abs/2212.09522v1","updated":"2022-12-19T15:05:40Z","published":"2022-12-19T15:05:40Z","title":"MIST: Multi-modal Iterative Spatial-Temporal Transformer for Long-form\n  Video Question Answering","summary":"  To build Video Question Answering (VideoQA) systems capable of assisting\nhumans in daily activities, seeking answers from long-form videos with diverse\nand complex events is a must. Existing multi-modal VQA models achieve promising\nperformance on images or short video clips, especially with the recent success\nof large-scale multi-modal pre-training. However, when extending these methods\nto long-form videos, new challenges arise. On the one hand, using a dense video\nsampling strategy is computationally prohibitive. On the other hand, methods\nrelying on sparse sampling struggle in scenarios where multi-event and\nmulti-granularity visual reasoning are required. In this work, we introduce a\nnew model named Multi-modal Iterative Spatial-temporal Transformer (MIST) to\nbetter adapt pre-trained models for long-form VideoQA. Specifically, MIST\ndecomposes traditional dense spatial-temporal self-attention into cascaded\nsegment and region selection modules that adaptively select frames and image\nregions that are closely relevant to the question itself. Visual concepts at\ndifferent granularities are then processed efficiently through an attention\nmodule. In addition, MIST iteratively conducts selection and attention over\nmultiple layers to support reasoning over multiple events. The experimental\nresults on four VideoQA datasets, including AGQA, NExT-QA, STAR, and Env-QA,\nshow that MIST achieves state-of-the-art performance and is superior at\ncomputation efficiency and interpretability.\n","authors":["Difei Gao","Luowei Zhou","Lei Ji","Linchao Zhu","Yi Yang","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2212.09522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09517v1","updated":"2022-12-19T14:57:13Z","published":"2022-12-19T14:57:13Z","title":"Fake it, Mix it, Segment it: Bridging the Domain Gap Between Lidar\n  Sensors","summary":"  Segmentation of lidar data is a task that provides rich, point-wise\ninformation about the environment of robots or autonomous vehicles. Currently\nbest performing neural networks for lidar segmentation are fine-tuned to\nspecific datasets. Switching the lidar sensor without retraining on a big set\nof annotated data from the new sensor creates a domain shift, which causes the\nnetwork performance to drop drastically. In this work we propose a new method\nfor lidar domain adaption, in which we use annotated panoptic lidar datasets\nand recreate the recorded scenes in the structure of a different lidar sensor.\nWe narrow the domain gap to the target data by recreating panoptic data from\none domain in another and mixing the generated data with parts of (pseudo)\nlabeled target domain data. Our method improves the nuScenes to SemanticKITTI\nunsupervised domain adaptation performance by 15.2 mean Intersection over Union\npoints (mIoU) and by 48.3 mIoU in our semi-supervised approach. We demonstrate\na similar improvement for the SemanticKITTI to nuScenes domain adaptation by\n21.8 mIoU and 51.5 mIoU, respectively. We compare our method with two state of\nthe art approaches for semantic lidar segmentation domain adaptation with a\nsignificant improvement for unsupervised and semi-supervised domain adaptation.\nFurthermore we successfully apply our proposed method to two entirely unlabeled\ndatasets of two state of the art lidar sensors Velodyne Alpha Prime and\nInnovizTwo, and train well performing semantic segmentation networks for both.\n","authors":["Frederik Hasecke","Pascal Colling","Anton Kummert"],"pdf_url":"https://arxiv.org/pdf/2212.09517v1.pdf","comment":"10 pages, 7 figures, to be published in proceedings of \"International\n  Conference on Pattern Recognition Applications and Methods 2023\""},{"id":"http://arxiv.org/abs/2209.03648v2","updated":"2022-12-19T14:18:49Z","published":"2022-09-08T08:47:57Z","title":"FETA: Towards Specializing Foundation Models for Expert Task\n  Applications","summary":"  Foundation Models (FMs) have demonstrated unprecedented capabilities\nincluding zero-shot learning, high fidelity data synthesis, and out of domain\ngeneralization. However, as we show in this paper, FMs still have poor\nout-of-the-box performance on expert tasks (e.g. retrieval of car manuals\ntechnical illustrations from language queries), data for which is either unseen\nor belonging to a long-tail part of the data distribution of the huge datasets\nused for FM pre-training. This underlines the necessity to explicitly evaluate\nand finetune FMs on such expert tasks, arguably ones that appear the most in\npractical real-world applications. In this paper, we propose a first of its\nkind FETA benchmark built around the task of teaching FMs to understand\ntechnical documentation, via learning to match their graphical illustrations to\ncorresponding language descriptions. Our FETA benchmark focuses on\ntext-to-image and image-to-text retrieval in public car manuals and sales\ncatalogue brochures. FETA is equipped with a procedure for completely automatic\nannotation extraction (code would be released upon acceptance), allowing easy\nextension of FETA to more documentation types and application domains in the\nfuture. Our automatic annotation leads to an automated performance metric shown\nto be consistent with metrics computed on human-curated annotations (also\nreleased). We provide multiple baselines and analysis of popular FMs on FETA\nleading to several interesting findings that we believe would be very valuable\nto the FM community, paving the way towards real-world application of FMs for\npractical expert tasks currently 'overlooked' by standard benchmarks focusing\non common objects.\n","authors":["Amit Alfassy","Assaf Arbelle","Oshri Halimi","Sivan Harary","Roei Herzig","Eli Schwartz","Rameswar Panda","Michele Dolfi","Christoph Auer","Kate Saenko","PeterW. J. Staar","Rogerio Feris","Leonid Karlinsky"],"pdf_url":"https://arxiv.org/pdf/2209.03648v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09478v1","updated":"2022-12-19T14:11:52Z","published":"2022-12-19T14:11:52Z","title":"MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and\n  Video Generation","summary":"  We propose the first joint audio-video generation framework that brings\nengaging watching and listening experiences simultaneously, towards\nhigh-quality realistic videos. To generate joint audio-video pairs, we propose\na novel Multi-Modal Diffusion model (i.e., MM-Diffusion), with two-coupled\ndenoising autoencoders. In contrast to existing single-modal diffusion models,\nMM-Diffusion consists of a sequential multi-modal U-Net for a joint denoising\nprocess by design. Two subnets for audio and video learn to gradually generate\naligned audio-video pairs from Gaussian noises. To ensure semantic consistency\nacross modalities, we propose a novel random-shift based attention block\nbridging over the two subnets, which enables efficient cross-modal alignment,\nand thus reinforces the audio-video fidelity for each other. Extensive\nexperiments show superior results in unconditional audio-video generation, and\nzero-shot conditional tasks (e.g., video-to-audio). In particular, we achieve\nthe best FVD and FAD on Landscape and AIST++ dancing datasets. Turing tests of\n10k votes further demonstrate dominant preferences for our model. The code and\npre-trained models can be downloaded at\nhttps://github.com/researchmm/MM-Diffusion.\n","authors":["Ludan Ruan","Yiyang Ma","Huan Yang","Huiguo He","Bei Liu","Jianlong Fu","Nicholas Jing Yuan","Qin Jin","Baining Guo"],"pdf_url":"https://arxiv.org/pdf/2212.09478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07560v2","updated":"2022-12-19T14:11:41Z","published":"2022-12-15T00:25:05Z","title":"Multi-level and multi-modal feature fusion for accurate 3D object\n  detection in Connected and Automated Vehicles","summary":"  Aiming at highly accurate object detection for connected and automated\nvehicles (CAVs), this paper presents a Deep Neural Network based 3D object\ndetection model that leverages a three-stage feature extractor by developing a\nnovel LIDAR-Camera fusion scheme. The proposed feature extractor extracts\nhigh-level features from two input sensory modalities and recovers the\nimportant features discarded during the convolutional process. The novel fusion\nscheme effectively fuses features across sensory modalities and convolutional\nlayers to find the best representative global features. The fused features are\nshared by a two-stage network: the region proposal network (RPN) and the\ndetection head (DH). The RPN generates high-recall proposals, and the DH\nproduces final detection results. The experimental results show the proposed\nmodel outperforms more recent research on the KITTI 2D and 3D detection\nbenchmark, particularly for distant and highly occluded instances.\n","authors":["Yiming Hou","Mahdi Rezaei","Richard Romano"],"pdf_url":"https://arxiv.org/pdf/2212.07560v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09460v1","updated":"2022-12-19T13:53:04Z","published":"2022-12-19T13:53:04Z","title":"Hardware Acceleration of Lane Detection Algorithm: A GPU Versus FPGA\n  Comparison","summary":"  A Complete Computer vision system can be divided into two main categories:\ndetection and classification. The Lane detection algorithm is a part of the\ncomputer vision detection category and has been applied in autonomous driving\nand smart vehicle systems. The lane detection system is responsible for lane\nmarking in a complex road environment. At the same time, lane detection plays a\ncrucial role in the warning system for a car when departs the lane. The\nimplemented lane detection algorithm is mainly divided into two steps: edge\ndetection and line detection. In this paper, we will compare the\nstate-of-the-art implementation performance obtained with both FPGA and GPU to\nevaluate the trade-off for latency, power consumption, and utilization. Our\ncomparison emphasises the advantages and disadvantages of the two systems.\n","authors":["Mohamed Alshemi","Sherif Saif","Mohamed Taher"],"pdf_url":"https://arxiv.org/pdf/2212.09460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.00179v2","updated":"2022-12-19T13:51:52Z","published":"2022-04-30T06:58:56Z","title":"Towards Feature Distribution Alignment and Diversity Enhancement for\n  Data-Free Quantization","summary":"  To obtain lower inference latency and less memory footprint of deep neural\nnetworks, model quantization has been widely employed in deep model deployment,\nby converting the floating points to low-precision integers. However, previous\nmethods (such as quantization aware training and post training quantization)\nrequire original data for the fine-tuning or calibration of quantized model,\nwhich makes them inapplicable to the cases that original data are not accessed\ndue to privacy or security. This gives birth to the data-free quantization\nmethod with synthetic data generation. While current data-free quantization\nmethods still suffer from severe performance degradation when quantizing a\nmodel into lower bit, caused by the low inter-class separability of semantic\nfeatures. To this end, we propose a new and effective data-free quantization\nmethod termed ClusterQ, which utilizes the feature distribution alignment for\nsynthetic data generation. To obtain high inter-class separability of semantic\nfeatures, we cluster and align the feature distribution statistics to imitate\nthe distribution of real data, so that the performance degradation is\nalleviated. Moreover, we incorporate the diversity enhancement to solve\nclass-wise mode collapse. We also employ the exponential moving average to\nupdate the centroid of each cluster for further feature distribution\nimprovement. Extensive experiments based on different deep models (e.g.,\nResNet-18 and MobileNet-V2) over the ImageNet dataset demonstrate that our\nproposed ClusterQ model obtains state-of-the-art performance.\n","authors":["Yangcheng Gao","Zhao Zhang","Richang Hong","Haijun Zhang","Jicong Fan","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2205.00179v2.pdf","comment":"Please cite this work as: Yangcheng Gao, Zhao Zhang, Richang Hong,\n  Haijun Zhang, Jicong Fan and Shuicheng Yan, \"Towards Feature Distribution\n  Alignment and Diversity Enhancement for Data-Free Quantization,\" In:\n  Proceedings of the 22nd IEEE International Conference on Data Mining (ICDM),\n  Orlando, FL, USA, pp.1-10, Aug 2022"},{"id":"http://arxiv.org/abs/2211.11753v2","updated":"2022-12-19T13:30:28Z","published":"2022-11-20T08:55:58Z","title":"SplitNet: Learnable Clean-Noisy Label Splitting for Learning with Noisy\n  Labels","summary":"  Annotating the dataset with high-quality labels is crucial for performance of\ndeep network, but in real world scenarios, the labels are often contaminated by\nnoise. To address this, some methods were proposed to automatically split clean\nand noisy labels, and learn a semi-supervised learner in a Learning with Noisy\nLabels (LNL) framework. However, they leverage a handcrafted module for\nclean-noisy label splitting, which induces a confirmation bias in the\nsemi-supervised learning phase and limits the performance. In this paper, we\nfor the first time present a learnable module for clean-noisy label splitting,\ndubbed SplitNet, and a novel LNL framework which complementarily trains the\nSplitNet and main network for the LNL task. We propose to use a dynamic\nthreshold based on a split confidence by SplitNet to better optimize\nsemi-supervised learner. To enhance SplitNet training, we also present a risk\nhedging method. Our proposed method performs at a state-of-the-art level\nespecially in high noise ratio settings on various LNL benchmarks.\n","authors":["Daehwan Kim","Kwangrok Ryoo","Hansang Cho","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2211.11753v2.pdf","comment":"project page link: https://ku-cvlab.github.io/SplitNet/"},{"id":"http://arxiv.org/abs/2212.09438v1","updated":"2022-12-19T13:25:09Z","published":"2022-12-19T13:25:09Z","title":"Leveraging Road Area Semantic Segmentation with Auxiliary Steering Task","summary":"  Robustness of different pattern recognition methods is one of the key\nchallenges in autonomous driving, especially when driving in the high variety\nof road environments and weather conditions, such as gravel roads and snowfall.\nAlthough one can collect data from these adverse conditions using cars equipped\nwith sensors, it is quite tedious to annotate the data for training. In this\nwork, we address this limitation and propose a CNN-based method that can\nleverage the steering wheel angle information to improve the road area semantic\nsegmentation. As the steering wheel angle data can be easily acquired with the\nassociated images, one could improve the accuracy of road area semantic\nsegmentation by collecting data in new road environments without manual data\nannotation. We demonstrate the effectiveness of the proposed approach on two\nchallenging data sets for autonomous driving and show that when the steering\ntask is used in our segmentation model training, it leads to a 0.1-2.9% gain in\nthe road area mIoU (mean Intersection over Union) compared to the corresponding\nreference transfer learning model.\n","authors":["Jyri Maanpää","Iaroslav Melekhov","Josef Taher","Petri Manninen","Juha Hyyppä"],"pdf_url":"https://arxiv.org/pdf/2212.09438v1.pdf","comment":"11 pages, 4 figures (Supplementary material 6 pages, 3 figures).\n  Author's accepted version of the contribution included in proceedings of the\n  21st International Conference on Image Analysis and Processing (ICIAP), 2022"},{"id":"http://arxiv.org/abs/2212.07671v2","updated":"2022-12-19T13:19:21Z","published":"2022-12-15T09:04:45Z","title":"Multi-task Fusion for Efficient Panoptic-Part Segmentation","summary":"  In this paper, we introduce a novel network that generates semantic,\ninstance, and part segmentation using a shared encoder and effectively fuses\nthem to achieve panoptic-part segmentation. Unifying these three segmentation\nproblems allows for mutually improved and consistent representation learning.\nTo fuse the predictions of all three heads efficiently, we introduce a\nparameter-free joint fusion module that dynamically balances the logits and\nfuses them to create panoptic-part segmentation. Our method is evaluated on the\nCityscapes Panoptic Parts (CPP) and Pascal Panoptic Parts (PPP) datasets. For\nCPP, the PartPQ of our proposed model with joint fusion surpasses the previous\nstate-of-the-art by 1.6 and 4.7 percentage points for all areas and segments\nwith parts, respectively. On PPP, our joint fusion outperforms a model using\nthe previous top-down merging strategy by 3.3 percentage points in PartPQ and\n10.5 percentage points in PartPQ for partitionable classes.\n","authors":["Sravan Kumar Jagadeesh","René Schuster","Didier Stricker"],"pdf_url":"https://arxiv.org/pdf/2212.07671v2.pdf","comment":"Accepted in ICPRAM 2023"},{"id":"http://arxiv.org/abs/2208.05232v3","updated":"2022-12-19T13:07:15Z","published":"2022-08-10T09:21:28Z","title":"Trustworthy Visual Analytics in Clinical Gait Analysis: A Case Study for\n  Patients with Cerebral Palsy","summary":"  Three-dimensional clinical gait analysis is essential for selecting optimal\ntreatment interventions for patients with cerebral palsy (CP), but generates a\nlarge amount of time series data. For the automated analysis of these data,\nmachine learning approaches yield promising results. However, due to their\nblack-box nature, such approaches are often mistrusted by clinicians. We\npropose gaitXplorer, a visual analytics approach for the classification of\nCP-related gait patterns that integrates Grad-CAM, a well-established\nexplainable artificial intelligence algorithm, for explanations of machine\nlearning classifications. Regions of high relevance for classification are\nhighlighted in the interactive visual interface. The approach is evaluated in a\ncase study with two clinical gait experts. They inspected the explanations for\na sample of eight patients using the visual interface and expressed which\nrelevance scores they found trustworthy and which they found suspicious.\nOverall, the clinicians gave positive feedback on the approach as it allowed\nthem a better understanding of which regions in the data were relevant for the\nclassification.\n","authors":["Alexander Rind","Djordje Slijepčević","Matthias Zeppelzauer","Fabian Unglaube","Andreas Kranzl","Brian Horsak"],"pdf_url":"https://arxiv.org/pdf/2208.05232v3.pdf","comment":"7 pages, 4 figures; supplemental material 9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.09415v1","updated":"2022-12-19T12:49:03Z","published":"2022-12-19T12:49:03Z","title":"Training Lightweight Graph Convolutional Networks with Phase-field\n  Models","summary":"  In this paper, we design lightweight graph convolutional networks (GCNs)\nusing a particular class of regularizers, dubbed as phase-field models (PFMs).\nPFMs exhibit a bi-phase behavior using a particular ultra-local term that\nallows training both the topology and the weight parameters of GCNs as a part\nof a single \"end-to-end\" optimization problem. Our proposed solution also\nrelies on a reparametrization that pushes the mask of the topology towards\nbinary values leading to effective topology selection and high generalization\nwhile implementing any targeted pruning rate. Both masks and weights share the\nsame set of latent variables and this further enhances the generalization power\nof the resulting lightweight GCNs. Extensive experiments conducted on the\nchallenging task of skeleton-based recognition show the outperformance of PFMs\nagainst other staple regularizers as well as related lightweight design\nmethods.\n","authors":["Hichem Sahbi"],"pdf_url":"https://arxiv.org/pdf/2212.09415v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2203.13616"},{"id":"http://arxiv.org/abs/2212.09408v1","updated":"2022-12-19T12:40:13Z","published":"2022-12-19T12:40:13Z","title":"Million-scale Object Detection with Large Vision Model","summary":"  Over the past few years, developing a broad, universal, and general-purpose\ncomputer vision system has become a hot topic. A powerful universal system\nwould be capable of solving diverse vision tasks simultaneously without being\nrestricted to a specific problem or a specific data domain, which is of great\nimportance in practical real-world computer vision applications. This study\npushes the direction forward by concentrating on the million-scale multi-domain\nuniversal object detection problem. The problem is not trivial due to its\ncomplicated nature in terms of cross-dataset category label duplication, label\nconflicts, and the hierarchical taxonomy handling. Moreover, what is the\nresource-efficient way to utilize emerging large pre-trained vision models for\nmillion-scale cross-dataset object detection remains an open challenge. This\npaper tries to address these challenges by introducing our practices in label\nhandling, hierarchy-aware loss design and resource-efficient model training\nwith a pre-trained large model. Our method is ranked second in the object\ndetection track of Robust Vision Challenge 2022 (RVC 2022). We hope our\ndetailed study would serve as an alternative practice paradigm for similar\nproblems in the community. The code is available at\nhttps://github.com/linfeng93/Large-UniDet.\n","authors":["Feng Lin","Wenze Hu","Yaowei Wang","Yonghong Tian","Guangming Lu","Fanglin Chen","Yong Xu","Xiaoyu Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15772v2","updated":"2022-12-19T12:22:57Z","published":"2022-05-31T13:22:02Z","title":"The hybrid approach -- Convolutional Neural Networks and Expectation\n  Maximization Algorithm -- for Tomographic Reconstruction of Hyperspectral\n  Images","summary":"  We present a simple but novel hybrid approach to hyperspectral data cube\nreconstruction from computed tomography imaging spectrometry (CTIS) images that\nsequentially combines neural networks and the iterative Expectation\nMaximization (EM) algorithm. We train and test the ability of the method to\nreconstruct data cubes of $100\\times100\\times25$ and $100\\times100\\times100$\nvoxels, corresponding to 25 and 100 spectral channels, from simulated CTIS\nimages generated by our CTIS simulator. The hybrid approach utilizes the\ninherent strength of the Convolutional Neural Network (CNN) with regard to\nnoise and its ability to yield consistent reconstructions and make use of the\nEM algorithm's ability to generalize to spectral images of any object without\ntraining. The hybrid approach achieves better performance than both the CNNs\nand EM alone for seen (included in CNN training) and unseen (excluded from CNN\ntraining) cubes for both the 25- and 100-channel cases. For the 25 spectral\nchannels, the improvements from CNN to the hybrid model (CNN + EM) in terms of\nthe mean-squared errors are between 14-26%. For 100 spectral channels, the\nimprovements between 19-40% are attained with the largest improvement of 40%\nfor the unseen data, to which the CNNs are not exposed during the training.\n","authors":["Mads J. Ahlebæk","Mads S. Peters","Wei-Chih Huang","Mads T. Frandsen","René L. Eriksen","Bjarke Jørgensen"],"pdf_url":"https://arxiv.org/pdf/2205.15772v2.pdf","comment":"36 pages, 13 figures and 2 tables. Supplemental material: 21 pages\n  and 14 figures. v2: Clarifications added, analyses and argumentation updated"},{"id":"http://arxiv.org/abs/2212.09381v1","updated":"2022-12-19T11:43:02Z","published":"2022-12-19T11:43:02Z","title":"Cognitive Accident Prediction in Driving Scenes: A Multimodality\n  Benchmark","summary":"  Traffic accident prediction in driving videos aims to provide an early\nwarning of the accident occurrence, and supports the decision making of safe\ndriving systems. Previous works usually concentrate on the spatial-temporal\ncorrelation of object-level context, while they do not fit the inherent\nlong-tailed data distribution well and are vulnerable to severe environmental\nchange. In this work, we propose a Cognitive Accident Prediction (CAP) method\nthat explicitly leverages human-inspired cognition of text description on the\nvisual observation and the driver attention to facilitate model training. In\nparticular, the text description provides a dense semantic description guidance\nfor the primary context of the traffic scene, while the driver attention\nprovides a traction to focus on the critical region closely correlating with\nsafe driving. CAP is formulated by an attentive text-to-vision shift fusion\nmodule, an attentive scene context transfer module, and the driver attention\nguided accident prediction module. We leverage the attention mechanism in these\nmodules to explore the core semantic cues for accident prediction. In order to\ntrain CAP, we extend an existing self-collected DADA-2000 dataset (with\nannotated driver attention for each frame) with further factual text\ndescriptions for the visual observations before the accidents. Besides, we\nconstruct a new large-scale benchmark consisting of 11,727 in-the-wild accident\nvideos with over 2.19 million frames (named as CAP-DATA) together with labeled\nfact-effect-reason-introspection description and temporal accident frame label.\nBased on extensive experiments, the superiority of CAP is validated compared\nwith state-of-the-art approaches. The code, CAP-DATA, and all results will be\nreleased in \\url{https://github.com/JWFanggit/LOTVS-CAP}.\n","authors":["Jianwu Fang","Lei-Lei Li","Kuan Yang","Zhedong Zheng","Jianru Xue","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2212.09381v1.pdf","comment":"Submitted to IEEE Transactions journal for possible publication"},{"id":"http://arxiv.org/abs/2110.03479v4","updated":"2022-12-19T11:36:47Z","published":"2021-10-07T14:03:10Z","title":"Camera Calibration through Camera Projection Loss","summary":"  Camera calibration is a necessity in various tasks including 3D\nreconstruction, hand-eye coordination for a robotic interaction, autonomous\ndriving, etc. In this work we propose a novel method to predict extrinsic\n(baseline, pitch, and translation), intrinsic (focal length and principal point\noffset) parameters using an image pair. Unlike existing methods, instead of\ndesigning an end-to-end solution, we proposed a new representation that\nincorporates camera model equations as a neural network in multi-task learning\nframework. We estimate the desired parameters via novel camera projection loss\n(CPL) that uses the camera model neural network to reconstruct the 3D points\nand uses the reconstruction loss to estimate the camera parameters. To the best\nof our knowledge, ours is the first method to jointly estimate both the\nintrinsic and extrinsic parameters via a multi-task learning methodology that\ncombines analytical equations in learning framework for the estimation of\ncamera parameters. We also proposed a novel dataset using CARLA Simulator.\nEmpirically, we demonstrate that our proposed approach achieves better\nperformance with respect to both deep learning-based and traditional methods on\n8 out of 10 parameters evaluated using both synthetic and real data. Our code\nand generated dataset are available at\nhttps://github.com/thanif/Camera-Calibration-through-Camera-Projection-Loss.\n","authors":["Talha Hanif Butt","Murtaza Taj"],"pdf_url":"https://arxiv.org/pdf/2110.03479v4.pdf","comment":"5 pages, ICASSP 2022"},{"id":"http://arxiv.org/abs/2212.09368v1","updated":"2022-12-19T11:10:50Z","published":"2022-12-19T11:10:50Z","title":"TAS-NIR: A VIS+NIR Dataset for Fine-grained Semantic Segmentation in\n  Unstructured Outdoor Environments","summary":"  Vegetation Indices based on paired images of the visible color spectrum (VIS)\nand near infrared spectrum (NIR) have been widely used in remote sensing\napplications. These vegetation indices are extended for their application in\nautonomous driving in unstructured outdoor environments. In this domain we can\ncombine traditional vegetation indices like the Normalized Difference\nVegetation Index (NDVI) and Enhanced Vegetation Index (EVI) with Convolutional\nNeural Networks (CNNs) pre-trained on available VIS datasets. By laying a focus\non learning calibrated CNN outputs, we can provide an approach to fuse known\nhand-crafted image features with CNN predictions for different domains as well.\nThe method is evaluated on a VIS+NIR dataset of semantically annotated images\nin unstructured outdoor environments. The dataset is available at\nmucar3.de/iros2022-ppniv-tas-nir.\n","authors":["Peter Mortimer","Hans-Joachim Wuensche"],"pdf_url":"https://arxiv.org/pdf/2212.09368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09360v1","updated":"2022-12-19T10:54:51Z","published":"2022-12-19T10:54:51Z","title":"AI Security for Geoscience and Remote Sensing: Challenges and Future\n  Trends","summary":"  Recent advances in artificial intelligence (AI) have significantly\nintensified research in the geoscience and remote sensing (RS) field. AI\nalgorithms, especially deep learning-based ones, have been developed and\napplied widely to RS data analysis. The successful application of AI covers\nalmost all aspects of Earth observation (EO) missions, from low-level vision\ntasks like super-resolution, denoising, and inpainting, to high-level vision\ntasks like scene classification, object detection, and semantic segmentation.\nWhile AI techniques enable researchers to observe and understand the Earth more\naccurately, the vulnerability and uncertainty of AI models deserve further\nattention, considering that many geoscience and RS tasks are highly\nsafety-critical. This paper reviews the current development of AI security in\nthe geoscience and RS field, covering the following five important aspects:\nadversarial attack, backdoor attack, federated learning, uncertainty, and\nexplainability. Moreover, the potential opportunities and trends are discussed\nto provide insights for future research. To the best of the authors' knowledge,\nthis paper is the first attempt to provide a systematic review of AI\nsecurity-related research in the geoscience and RS community. Available code\nand datasets are also listed in the paper to move this vibrant field of\nresearch forward.\n","authors":["Yonghao Xu","Tao Bai","Weikang Yu","Shizhen Chang","Peter M. Atkinson","Pedram Ghamisi"],"pdf_url":"https://arxiv.org/pdf/2212.09360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.14513v3","updated":"2022-12-19T10:40:01Z","published":"2021-12-29T11:39:56Z","title":"Spatial Distribution Patterns of Clownfish in Recirculating Aquaculture\n  Systems","summary":"  Successful aquaculture systems can reduce the pressure and help secure the\nmost diverse and productive Red Sea coral reef ecosystem to maintain a healthy\nand functional ecosystem within a sustainable blue economy. Interestingly,\nrecirculating aquaculture systems are currently emerging in fish farm\nproduction practices. On the other hand, monitoring and detecting fish\nbehaviors provide essential information on fish welfare and contribute to an\nintelligent production in global aquaculture. This work proposes an efficient\napproach to analyze the spatial distribution status and motion patterns of\njuvenile clownfish \\textit{(Amphiprion bicinctus)} maintained in aquaria at\nthree stocking densities (1, 5, and 10 individuals/aquarium). The estimated\ndisplacement is crucial in assessing the dispersion and velocity to express the\nclownfish's spatial distribution and movement behavior in a recirculating\naquaculture system. Indeed, we aim to compute the velocity, magnitude, and\nturning angle using an optical flow method to assist aquaculturists in\nefficiently monitoring and identifying fish behavior. We test the system design\non a database containing two days of video streams of juvenile clownfish\nmaintained in aquaria. The proposed displacement estimation reveals good\nperformance in measuring clownfish's motion and dispersion characteristics\nleading to assessing the potential signs of stress behaviors. We demonstrate\nthe effectiveness of the proposed technique for quantifying variation in\nclownfish activity levels between recordings taken in the morning and afternoon\nat different stocking densities. It provides practical baseline support for\nonline predicting and monitoring feeding behavior in ornamental fish\naquaculture.\n","authors":["Fahad Aljehani","Ibrahima N'Doye","Micaela S. Justo","John E. Majoris","Michael L. Berumen","Taous-Meriem Laleg-Kirati"],"pdf_url":"https://arxiv.org/pdf/2112.14513v3.pdf","comment":"14 pages, 15 figures"},{"id":"http://arxiv.org/abs/2212.09352v1","updated":"2022-12-19T10:37:30Z","published":"2022-12-19T10:37:30Z","title":"Robust Anomaly Map Assisted Multiple Defect Detection with Supervised\n  Classification Techniques","summary":"  Industry 4.0 aims to optimize the manufacturing environment by leveraging new\ntechnological advances, such as new sensing capabilities and artificial\nintelligence. The DRAEM technique has shown state-of-the-art performance for\nunsupervised classification. The ability to create anomaly maps highlighting\nareas where defects probably lie can be leveraged to provide cues to supervised\nclassification models and enhance their performance. Our research shows that\nthe best performance is achieved when training a defect detection model by\nproviding an image and the corresponding anomaly map as input. Furthermore,\nsuch a setting provides consistent performance when framing the defect\ndetection as a binary or multiclass classification problem and is not affected\nby class balancing policies. We performed the experiments on three datasets\nwith real-world data provided by Philips Consumer Lifestyle BV.\n","authors":["Jože M. Rožanec","Patrik Zajec","Spyros Theodoropoulos","Erik Koehorst","Blaž Fortuna","Dunja Mladenić"],"pdf_url":"https://arxiv.org/pdf/2212.09352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09335v1","updated":"2022-12-19T10:02:50Z","published":"2022-12-19T10:02:50Z","title":"Distilling Vision-Language Pre-training to Collaborate with\n  Weakly-Supervised Temporal Action Localization","summary":"  Weakly-supervised temporal action localization (WTAL) learns to detect and\nclassify action instances with only category labels. Most methods widely adopt\nthe off-the-shelf Classification-Based Pre-training (CBP) to generate video\nfeatures for action localization. However, the different optimization\nobjectives between classification and localization, make temporally localized\nresults suffer from the serious incomplete issue. To tackle this issue without\nadditional annotations, this paper considers to distill free action knowledge\nfrom Vision-Language Pre-training (VLP), since we surprisingly observe that the\nlocalization results of vanilla VLP have an over-complete issue, which is just\ncomplementary to the CBP results. To fuse such complementarity, we propose a\nnovel distillation-collaboration framework with two branches acting as CBP and\nVLP respectively. The framework is optimized through a dual-branch alternate\ntraining strategy. Specifically, during the B step, we distill the confident\nbackground pseudo-labels from the CBP branch; while during the F step, the\nconfident foreground pseudo-labels are distilled from the VLP branch. And as a\nresult, the dual-branch complementarity is effectively fused to promote a\nstrong alliance. Extensive experiments and ablation studies on THUMOS14 and\nActivityNet1.2 reveal that our method significantly outperforms\nstate-of-the-art methods.\n","authors":["Chen Ju","Kunhao Zheng","Jinxiang Liu","Peisen Zhao","Ya Zhang","Jianlong Chang","Yanfeng Wang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2212.09335v1.pdf","comment":"The first two authors share the same contribution"},{"id":"http://arxiv.org/abs/2209.02965v2","updated":"2022-12-19T10:02:16Z","published":"2022-09-07T07:16:30Z","title":"Risk of Bias in Chest X-ray Foundation Models","summary":"  Foundation models are considered a breakthrough in all applications of AI,\npromising robust and reusable mechanisms for feature extraction, alleviating\nthe need for large amounts of high quality annotated training data for\ntask-specific prediction models. However, foundation models may potentially\nencode and even reinforce existing biases present in historic datasets. Given\nthe limited ability to scrutinize foundation models, it remains unclear whether\nthe opportunities outweigh the risks in safety critical applications such as\nclinical decision making. In our statistical bias analysis of a recently\npublished, and publicly accessible chest X-ray foundation model, we found\nreasons for concern as the model seems to encode protected characteristics\nincluding biological sex and racial identity. When used for the downstream\napplication of disease detection, we observed substantial degradation of\nperformance of the foundation model compared to a standard model with specific\ndisparities in protected subgroups. While research into foundation models for\nhealthcare applications is in an early stage, we hope to raise awareness of the\nrisks by highlighting the importance of conducting thorough bias and subgroup\nperformance analyses.\n","authors":["Ben Glocker","Charles Jones","Melanie Bernhardt","Stefan Winzeck"],"pdf_url":"https://arxiv.org/pdf/2209.02965v2.pdf","comment":"Code available under https://github.com/biomedia-mira/chexploration"},{"id":"http://arxiv.org/abs/2212.09330v1","updated":"2022-12-19T09:50:05Z","published":"2022-12-19T09:50:05Z","title":"StyleTRF: Stylizing Tensorial Radiance Fields","summary":"  Stylized view generation of scenes captured casually using a camera has\nreceived much attention recently. The geometry and appearance of the scene are\ntypically captured as neural point sets or neural radiance fields in the\nprevious work. An image stylization method is used to stylize the captured\nappearance by training its network jointly or iteratively with the structure\ncapture network. The state-of-the-art SNeRF method trains the NeRF and\nstylization network in an alternating manner. These methods have high training\ntime and require joint optimization. In this work, we present StyleTRF, a\ncompact, quick-to-optimize strategy for stylized view generation using TensoRF.\nThe appearance part is fine-tuned using sparse stylized priors of a few views\nrendered using the TensoRF representation for a few iterations. Our method thus\neffectively decouples style-adaption from view capture and is much faster than\nthe previous methods. We show state-of-the-art results on several scenes used\nfor this purpose.\n","authors":["Rahul Goel","Sirikonda Dhawal","Saurabh Saini","P. J. Narayanan"],"pdf_url":"https://arxiv.org/pdf/2212.09330v1.pdf","comment":"Accepted at ICVGIP-2022"},{"id":"http://arxiv.org/abs/2212.09329v1","updated":"2022-12-19T09:47:27Z","published":"2022-12-19T09:47:27Z","title":"SrTR: Self-reasoning Transformer with Visual-linguistic Knowledge for\n  Scene Graph Generation","summary":"  Objects in a scene are not always related. The execution efficiency of the\none-stage scene graph generation approaches are quite high, which infer the\neffective relation between entity pairs using sparse proposal sets and a few\nqueries. However, they only focus on the relation between subject and object in\ntriplet set subject entity, predicate entity, object entity, ignoring the\nrelation between subject and predicate or predicate and object, and the model\nlacks self-reasoning ability. In addition, linguistic modality has been\nneglected in the one-stage method. It is necessary to mine linguistic modality\nknowledge to improve model reasoning ability. To address the above-mentioned\nshortcomings, a Self-reasoning Transformer with Visual-linguistic Knowledge\n(SrTR) is proposed to add flexible self-reasoning ability to the model. An\nencoder-decoder architecture is adopted in SrTR, and a self-reasoning decoder\nis developed to complete three inferences of the triplet set, s+o-p, s+p-o and\np+o-s. Inspired by the large-scale pre-training image-text foundation models,\nvisual-linguistic prior knowledge is introduced and a visual-linguistic\nalignment strategy is designed to project visual representations into semantic\nspaces with prior knowledge to aid relational reasoning. Experiments on the\nVisual Genome dataset demonstrate the superiority and fast inference ability of\nthe proposed method.\n","authors":["Yuxiang Zhang","Zhenbo Liu","Shuai Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09321v1","updated":"2022-12-19T09:39:30Z","published":"2022-12-19T09:39:30Z","title":"Learning from Training Dynamics: Identifying Mislabeled Data Beyond\n  Manually Designed Features","summary":"  While mislabeled or ambiguously-labeled samples in the training set could\nnegatively affect the performance of deep models, diagnosing the dataset and\nidentifying mislabeled samples helps to improve the generalization power.\nTraining dynamics, i.e., the traces left by iterations of optimization\nalgorithms, have recently been proved to be effective to localize mislabeled\nsamples with hand-crafted features. In this paper, beyond manually designed\nfeatures, we introduce a novel learning-based solution, leveraging a noise\ndetector, instanced by an LSTM network, which learns to predict whether a\nsample was mislabeled using the raw training dynamics as input. Specifically,\nthe proposed method trains the noise detector in a supervised manner using the\ndataset with synthesized label noises and can adapt to various datasets (either\nnaturally or synthesized label-noised) without retraining. We conduct extensive\nexperiments to evaluate the proposed method. We train the noise detector based\non the synthesized label-noised CIFAR dataset and test such noise detector on\nTiny ImageNet, CUB-200, Caltech-256, WebVision and Clothing1M. Results show\nthat the proposed method precisely detects mislabeled samples on various\ndatasets without further adaptation, and outperforms state-of-the-art methods.\nBesides, more experiments demonstrate that the mislabel identification can\nguide a label correction, namely data debugging, providing orthogonal\nimprovements of algorithm-centric state-of-the-art techniques from the data\naspect.\n","authors":["Qingrui Jia","Xuhong Li","Lei Yu","Jiang Bian","Penghao Zhao","Shupeng Li","Haoyi Xiong","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2212.09321v1.pdf","comment":"AAAI23 accepted Conference Paper"},{"id":"http://arxiv.org/abs/2212.09317v1","updated":"2022-12-19T09:31:15Z","published":"2022-12-19T09:31:15Z","title":"Synthetic Data Augmentation Using GAN For Improved Automated Visual\n  Inspection","summary":"  Quality control is a crucial activity performed by manufacturing companies to\nensure their products conform to the requirements and specifications. The\nintroduction of artificial intelligence models enables to automate the visual\nquality inspection, speeding up the inspection process and ensuring all\nproducts are evaluated under the same criteria. In this research, we compare\nsupervised and unsupervised defect detection techniques and explore data\naugmentation techniques to mitigate the data imbalance in the context of\nautomated visual inspection. Furthermore, we use Generative Adversarial\nNetworks for data augmentation to enhance the classifiers' discriminative\nperformance. Our results show that state-of-the-art unsupervised defect\ndetection does not match the performance of supervised models but can be used\nto reduce the labeling workload by more than 50%. Furthermore, the best\nclassification performance was achieved considering GAN-based data generation\nwith AUC ROC scores equal to or higher than 0,9898, even when increasing the\ndataset imbalance by leaving only 25\\% of the images denoting defective\nproducts. We performed the research with real-world data provided by Philips\nConsumer Lifestyle BV.\n","authors":["Jože M. Rožanec","Patrik Zajec","Spyros Theodoropoulos","Erik Koehorst","Blaž Fortuna","Dunja Mladenić"],"pdf_url":"https://arxiv.org/pdf/2212.09317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09310v1","updated":"2022-12-19T09:14:23Z","published":"2022-12-19T09:14:23Z","title":"Multimodal CNN Networks for Brain Tumor Segmentation in MRI: A BraTS\n  2022 Challenge Solution","summary":"  Automatic segmentation is essential for the brain tumor diagnosis, disease\nprognosis, and follow-up therapy of patients with gliomas. Still, accurate\ndetection of gliomas and their sub-regions in multimodal MRI is very\nchallenging due to the variety of scanners and imaging protocols. Over the last\nyears, the BraTS Challenge has provided a large number of multi-institutional\nMRI scans as a benchmark for glioma segmentation algorithms. This paper\ndescribes our contribution to the BraTS 2022 Continuous Evaluation challenge.\nWe propose a new ensemble of multiple deep learning frameworks namely, DeepSeg,\nnnU-Net, and DeepSCAN for automatic glioma boundaries detection in\npre-operative MRI. It is worth noting that our ensemble models took first place\nin the final evaluation on the BraTS testing dataset with Dice scores of\n0.9294, 0.8788, and 0.8803, and Hausdorf distance of 5.23, 13.54, and 12.05,\nfor the whole tumor, tumor core, and enhancing tumor, respectively.\nFurthermore, the proposed ensemble method ranked first in the final ranking on\nanother unseen test dataset, namely Sub-Saharan Africa dataset, achieving mean\nDice scores of 0.9737, 0.9593, and 0.9022, and HD95 of 2.66, 1.72, 3.32 for the\nwhole tumor, tumor core, and enhancing tumor, respectively. The docker image\nfor the winning submission is publicly available at\n(https://hub.docker.com/r/razeineldin/camed22).\n","authors":["Ramy A. Zeineldin","Mohamed E. Karar","Oliver Burgert","Franziska Mathis-Ullrich"],"pdf_url":"https://arxiv.org/pdf/2212.09310v1.pdf","comment":"Accepted in BraTS 2022 (as part of the BrainLes workshop proceedings\n  distributed by Springer LNCS). arXiv admin note: text overlap with\n  arXiv:2112.06554"},{"id":"http://arxiv.org/abs/2212.09308v1","updated":"2022-12-19T09:10:23Z","published":"2022-12-19T09:10:23Z","title":"Diffusing Surrogate Dreams of Video Scenes to Predict Video Memorability","summary":"  As part of the MediaEval 2022 Predicting Video Memorability task we explore\nthe relationship between visual memorability, the visual representation that\ncharacterises it, and the underlying concept portrayed by that visual\nrepresentation. We achieve state-of-the-art memorability prediction performance\nwith a model trained and tested exclusively on surrogate dream images,\nelevating concepts to the status of a cornerstone memorability feature, and\nfinding strong evidence to suggest that the intrinsic memorability of visual\ncontent can be distilled to its underlying concept or meaning irrespective of\nits specific visual representational.\n","authors":["Lorin Sweeney","Graham Healy","Alan F. Smeaton"],"pdf_url":"https://arxiv.org/pdf/2212.09308v1.pdf","comment":"5 pages, 3 figures, 1 table, MediaEval-22: Multimedia Evaluation\n  Workshop, 13-15 January 2023, Bergen, Norway and Online"},{"id":"http://arxiv.org/abs/2212.09298v1","updated":"2022-12-19T08:31:08Z","published":"2022-12-19T08:31:08Z","title":"From a Bird's Eye View to See: Joint Camera and Subject Registration\n  without the Camera Calibration","summary":"  We tackle a new problem of multi-view camera and subject registration in the\nbird's eye view (BEV) without pre-given camera calibration. This is a very\nchallenging problem since its only input is several RGB images from different\nfirst-person views (FPVs) for a multi-person scene, without the BEV image and\nthe calibration of the FPVs, while the output is a unified plane with the\nlocalization and orientation of both the subjects and cameras in a BEV. We\npropose an end-to-end framework solving this problem, whose main idea can be\ndivided into following parts: i) creating a view-transform subject detection\nmodule to transform the FPV to a virtual BEV including localization and\norientation of each pedestrian, ii) deriving a geometric transformation based\nmethod to estimate camera localization and view direction, i.e., the camera\nregistration in a unified BEV, iii) making use of spatial and appearance\ninformation to aggregate the subjects into the unified BEV. We collect a new\nlarge-scale synthetic dataset with rich annotations for evaluation. The\nexperimental results show the remarkable effectiveness of our proposed method.\n","authors":["Zekun Qian","Ruize Han","Wei Feng","Feifan Wang","Song Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09297v1","updated":"2022-12-19T08:30:42Z","published":"2022-12-19T08:30:42Z","title":"Transferring General Multimodal Pretrained Models to Text Recognition","summary":"  This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained\nmodels to text recognition. Specifically, we recast text recognition as image\ncaptioning and directly transfer a unified vision-language pretrained model to\nthe end task. Without pretraining on large-scale annotated or synthetic text\nrecognition data, OFA-OCR outperforms the baselines and achieves\nstate-of-the-art performance in the Chinese text recognition benchmark.\nAdditionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate\nthat it can achieve competitive performance with the product-level API. The\ncode (https://github.com/OFA-Sys/OFA) and demo\n(https://modelscope.cn/studios/damo/ofa_ocr_pipeline/summary) are publicly\navailable.\n","authors":["Junyang Lin","Xuancheng Ren","Yichang Zhang","Gao Liu","Peng Wang","An Yang","Chang Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.09297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09281v1","updated":"2022-12-19T07:39:26Z","published":"2022-12-19T07:39:26Z","title":"Boosting Automatic COVID-19 Detection Performance with Self-Supervised\n  Learning and Batch Knowledge Ensembling","summary":"  Background and objective: COVID-19 and its variants have caused significant\ndisruptions in over 200 countries and regions worldwide, affecting the health\nand lives of billions of people. Detecting COVID-19 from chest X-Ray (CXR)\nimages has become one of the fastest and easiest methods for detecting COVID-19\nsince the common occurrence of radiological pneumonia findings in COVID-19\npatients. We present a novel high-accuracy COVID-19 detection method that uses\nCXR images. Methods: Our method consists of two phases. One is self-supervised\nlearning-based pertaining; the other is batch knowledge ensembling-based\nfine-tuning. Self-supervised learning-based pretraining can learn distinguished\nrepresentations from CXR images without manually annotated labels. On the other\nhand, batch knowledge ensembling-based fine-tuning can utilize category\nknowledge of images in a batch according to their visual feature similarities\nto improve detection performance. Unlike our previous implementation, we\nintroduce batch knowledge ensembling into the fine-tuning phase, reducing the\nmemory used in self-supervised learning and improving COVID-19 detection\naccuracy. Results: On two public COVID-19 CXR datasets, namely, a large dataset\nand an unbalanced dataset, our method exhibited promising COVID-19 detection\nperformance. Our method maintains high detection accuracy even when annotated\nCXR training images are reduced significantly (e.g., using only 10% of the\noriginal dataset). In addition, our method is insensitive to changes in\nhyperparameters. Conclusions: The proposed method outperforms other\nstate-of-the-art COVID-19 detection methods in different settings. Our method\ncan reduce the workloads of healthcare providers and radiologists.\n","authors":["Guang Li","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2212.09281v1.pdf","comment":"Submitted as a journal paper at Elsevier CBM"},{"id":"http://arxiv.org/abs/2212.09277v1","updated":"2022-12-19T07:12:49Z","published":"2022-12-19T07:12:49Z","title":"Building Height Prediction with Instance Segmentation","summary":"  Extracting building heights from satellite images is an active research area\nused in many fields such as telecommunications, city planning, etc. Many\nstudies utilize DSM (Digital Surface Models) generated with lidars or stereo\nimages for this purpose. Predicting the height of the buildings using only RGB\nimages is challenging due to the insufficient amount of data, low data quality,\nvariations of building types, different angles of light and shadow, etc. In\nthis study, we present an instance segmentation-based building height\nextraction method to predict building masks with their respective heights from\na single RGB satellite image. We used satellite images with building height\nannotations of certain cities along with an open-source satellite dataset with\nthe transfer learning approach. We reached, the bounding box mAP 59, the mask\nmAP 52.6, and the average accuracy value of 70% for buildings belonging to each\nheight class in our test set.\n","authors":["Furkan Burak Bagci","Ahmet Alp Kindriroglu","Metehan Yalcin","Ufuk Uyan","Mahiye Uluyagmur Ozturk"],"pdf_url":"https://arxiv.org/pdf/2212.09277v1.pdf","comment":"Instance Segmentation, Satellite Images, Building Height Prediction"},{"id":"http://arxiv.org/abs/2212.09276v1","updated":"2022-12-19T07:10:51Z","published":"2022-12-19T07:10:51Z","title":"COVID-19 Detection Based on Self-Supervised Transfer Learning Using\n  Chest X-Ray Images","summary":"  Purpose: Considering several patients screened due to COVID-19 pandemic,\ncomputer-aided detection has strong potential in assisting clinical workflow\nefficiency and reducing the incidence of infections among radiologists and\nhealthcare providers. Since many confirmed COVID-19 cases present radiological\nfindings of pneumonia, radiologic examinations can be useful for fast\ndetection. Therefore, chest radiography can be used to fast screen COVID-19\nduring the patient triage, thereby determining the priority of patient's care\nto help saturated medical facilities in a pandemic situation. Methods: In this\npaper, we propose a new learning scheme called self-supervised transfer\nlearning for detecting COVID-19 from chest X-ray (CXR) images. We compared six\nself-supervised learning (SSL) methods (Cross, BYOL, SimSiam, SimCLR,\nPIRL-jigsaw, and PIRL-rotation) with the proposed method. Additionally, we\ncompared six pretrained DCNNs (ResNet18, ResNet50, ResNet101, CheXNet,\nDenseNet201, and InceptionV3) with the proposed method. We provide quantitative\nevaluation on the largest open COVID-19 CXR dataset and qualitative results for\nvisual inspection. Results: Our method achieved a harmonic mean (HM) score of\n0.985, AUC of 0.999, and four-class accuracy of 0.953. We also used the\nvisualization technique Grad-CAM++ to generate visual explanations of different\nclasses of CXR images with the proposed method to increase the\ninterpretability. Conclusions: Our method shows that the knowledge learned from\nnatural images using transfer learning is beneficial for SSL of the CXR images\nand boosts the performance of representation learning for COVID-19 detection.\nOur method promises to reduce the incidence of infections among radiologists\nand healthcare providers.\n","authors":["Guang Li","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2212.09276v1.pdf","comment":"Published as a journal paper at Springer IJCARS"},{"id":"http://arxiv.org/abs/2212.09273v1","updated":"2022-12-19T06:56:14Z","published":"2022-12-19T06:56:14Z","title":"Learning Object-level Point Augmentor for Semi-supervised 3D Object\n  Detection","summary":"  Semi-supervised object detection is important for 3D scene understanding\nbecause obtaining large-scale 3D bounding box annotations on point clouds is\ntime-consuming and labor-intensive. Existing semi-supervised methods usually\nemploy teacher-student knowledge distillation together with an augmentation\nstrategy to leverage unlabeled point clouds. However, these methods adopt\nglobal augmentation with scene-level transformations and hence are sub-optimal\nfor instance-level object detection. In this work, we propose an object-level\npoint augmentor (OPA) that performs local transformations for semi-supervised\n3D object detection. In this way, the resultant augmentor is derived to\nemphasize object instances rather than irrelevant backgrounds, making the\naugmented data more useful for object detector training. Extensive experiments\non the ScanNet and SUN RGB-D datasets show that the proposed OPA performs\nfavorably against the state-of-the-art methods under various experimental\nsettings. The source code will be available at https://github.com/nomiaro/OPA.\n","authors":["Cheng-Ju Ho","Chen-Hsuan Tai","Yi-Hsuan Tsai","Yen-Yu Lin","Ming-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2212.09273v1.pdf","comment":"BMVC2022"},{"id":"http://arxiv.org/abs/2105.03939v2","updated":"2022-12-19T06:48:43Z","published":"2021-05-09T13:30:16Z","title":"Differentiable Neural Architecture Search for Extremely Lightweight\n  Image Super-Resolution","summary":"  Single Image Super-Resolution (SISR) tasks have achieved significant\nperformance with deep neural networks. However, the large number of parameters\nin CNN-based met-hods for SISR tasks require heavy computations. Although\nseveral efficient SISR models have been recently proposed, most are handcrafted\nand thus lack flexibility. In this work, we propose a novel differentiable\nNeural Architecture Search (NAS) approach on both the cell-level and\nnetwork-level to search for lightweight SISR models. Specifically, the\ncell-level search space is designed based on an information distillation\nmechanism, focusing on the combinations of lightweight operations and aiming to\nbuild a more lightweight and accurate SR structure. The network-level search\nspace is designed to consider the feature connections among the cells and aims\nto find which information flow benefits the cell most to boost the performance.\nUnlike the existing Reinforcement Learning (RL) or Evolutionary Algorithm (EA)\nbased NAS methods for SISR tasks, our search pipeline is fully differentiable,\nand the lightweight SISR models can be efficiently searched on both the\ncell-level and network-level jointly on a single GPU. Experiments show that our\nmethods can achieve state-of-the-art performance on the benchmark datasets in\nterms of PSNR, SSIM, and model complexity with merely 68G Multi-Adds for\n$\\times 2$ and 18G Multi-Adds for $\\times 4$ SR tasks.\n","authors":["Han Huang","Li Shen","Chaoyang He","Weisheng Dong","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2105.03939v2.pdf","comment":"Accepted to IEEE Transactions on Circuits and Systems for Video\n  Technology"},{"id":"http://arxiv.org/abs/2212.09263v1","updated":"2022-12-19T06:17:22Z","published":"2022-12-19T06:17:22Z","title":"Focal-UNet: UNet-like Focal Modulation for Medical Image Segmentation","summary":"  Recently, many attempts have been made to construct a transformer base\nU-shaped architecture, and new methods have been proposed that outperformed\nCNN-based rivals. However, serious problems such as blockiness and cropped\nedges in predicted masks remain because of transformers' patch partitioning\noperations. In this work, we propose a new U-shaped architecture for medical\nimage segmentation with the help of the newly introduced focal modulation\nmechanism. The proposed architecture has asymmetric depths for the encoder and\ndecoder. Due to the ability of the focal module to aggregate local and global\nfeatures, our model could simultaneously benefit the wide receptive field of\ntransformers and local viewing of CNNs. This helps the proposed method balance\nthe local and global feature usage to outperform one of the most powerful\ntransformer-based U-shaped models called Swin-UNet. We achieved a 1.68% higher\nDICE score and a 0.89 better HD metric on the Synapse dataset. Also, with\nextremely limited data, we had a 4.25% higher DICE score on the NeoPolyp\ndataset. Our implementations are available at:\nhttps://github.com/givkashi/Focal-UNet\n","authors":["MohammadReza Naderi","MohammadHossein Givkashi","Fatemeh Piri","Nader Karimi","Shadrokh Samavi"],"pdf_url":"https://arxiv.org/pdf/2212.09263v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.09262v1","updated":"2022-12-19T06:16:58Z","published":"2022-12-19T06:16:58Z","title":"Photo-Realistic Out-of-domain GAN inversion via Invertibility\n  Decomposition","summary":"  The fidelity of Generative Adversarial Networks (GAN) inversion is impeded by\nOut-Of-Domain (OOD) areas (e.g., background, accessories) in the image.\nDetecting the OOD areas beyond the generation ability of the pretrained model\nand blending these regions with the input image can enhance fidelity. The\n``invertibility mask\" figures out these OOD areas, and existing methods predict\nthe mask with the reconstruction error. However, the estimated mask is usually\ninaccurate due to the influence of the reconstruction error in the In-Domain\n(ID) area. In this paper, we propose a novel framework that enhances the\nfidelity of human face inversion by designing a new module to decompose the\ninput images to ID and OOD partitions with invertibility masks. Unlike previous\nworks, our invertibility detector is simultaneously learned with a spatial\nalignment module. We iteratively align the generated features to the input\ngeometry and reduce the reconstruction error in the ID regions. Thus, the OOD\nareas are more distinguishable and can be precisely predicted. Then, we improve\nthe fidelity of our results by blending the OOD areas from the input image with\nthe ID GAN inversion results. Our method produces photo-realistic results for\nreal-world human face image inversion and manipulation. Extensive experiments\ndemonstrate our method's superiority over existing methods in the quality of\nGAN inversion and attribute manipulation.\n","authors":["Xin Yang","Xiaogang Xu","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2212.09262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09258v1","updated":"2022-12-19T06:05:34Z","published":"2022-12-19T06:05:34Z","title":"CHAD: Charlotte Anomaly Dataset","summary":"  In recent years, we have seen a significant interest in data-driven deep\nlearning approaches for video anomaly detection, where an algorithm must\ndetermine if specific frames of a video contain abnormal behaviors. However,\nvideo anomaly detection is particularly context-specific, and the availability\nof representative datasets heavily limits real-world accuracy. Additionally,\nthe metrics currently reported by most state-of-the-art methods often do not\nreflect how well the model will perform in real-world scenarios. In this\narticle, we present the Charlotte Anomaly Dataset (CHAD). CHAD is a\nhigh-resolution, multi-camera anomaly dataset in a commercial parking lot\nsetting. In addition to frame-level anomaly labels, CHAD is the first anomaly\ndataset to include bounding box, identity, and pose annotations for each actor.\nThis is especially beneficial for skeleton-based anomaly detection, which is\nuseful for its lower computational demand in real-world settings. CHAD is also\nthe first anomaly dataset to contain multiple views of the same scene. With\nfour camera views and over 1.15 million frames, CHAD is the largest fully\nannotated anomaly detection dataset including person annotations, collected\nfrom continuous video streams from stationary cameras for smart video\nsurveillance applications. To demonstrate the efficacy of CHAD for training and\nevaluation, we benchmark two state-of-the-art skeleton-based anomaly detection\nalgorithms on CHAD and provide comprehensive analysis, including both\nquantitative results and qualitative examination.\n","authors":["Armin Danesh Pazho","Ghazal Alinezhad Noghre","Babak Rahimi Ardabili","Christopher Neff","Hamed Tabkhi"],"pdf_url":"https://arxiv.org/pdf/2212.09258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02340v2","updated":"2022-12-19T06:03:42Z","published":"2022-12-05T15:15:27Z","title":"CBNet: A Plug-and-Play Network for Segmentation-based Scene Text\n  Detection","summary":"  Recently, segmentation-based methods are quite popular in scene text\ndetection, which mainly contain two steps: text kernel segmentation and\nexpansion. However, the segmentation process only considers each pixel\nindependently, and the expansion process is difficult to achieve a favorable\naccuracy-speed trade-off. In this paper, we propose a Context-aware and\nBoundary-guided Network (CBN) to tackle these problems. In CBN, a basic text\ndetector is firstly used to predict initial segmentation results. Then, we\npropose a context-aware module to enhance text kernel feature representations,\nwhich considers both global and local contexts. Finally, we introduce a\nboundary-guided module to expand enhanced text kernels adaptively with only the\npixels on the contours, which not only obtains accurate text boundaries but\nalso keeps high speed, especially on high-resolution output maps. In\nparticular, with a lightweight backbone, the basic detector equipped with our\nproposed CBN achieves state-of-the-art results on several popular benchmarks,\nand our proposed CBN can be plugged into several segmentation-based methods.\nCode will be available on https://github.com/XiiZhao/cbn.pytorch.\n","authors":["Xi Zhao","Wei Feng","Zheng Zhang","Jingjing Lv","Xin Zhu","Zhangang Lin","Jinghe Hu","Jingping Shao"],"pdf_url":"https://arxiv.org/pdf/2212.02340v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00911v2","updated":"2022-12-19T05:16:20Z","published":"2022-10-03T13:14:00Z","title":"Learning Equivariant Segmentation with Instance-Unique Querying","summary":"  Prevalent state-of-the-art instance segmentation methods fall into a\nquery-based scheme, in which instance masks are derived by querying the image\nfeature using a set of instance-aware embeddings. In this work, we devise a new\ntraining framework that boosts query-based models through discriminative query\nembedding learning. It explores two essential properties, namely dataset-level\nuniqueness and transformation equivariance, of the relation between queries and\ninstances. First, our algorithm uses the queries to retrieve the corresponding\ninstances from the whole training dataset, instead of only searching within\nindividual scenes. As querying instances across scenes is more challenging, the\nsegmenters are forced to learn more discriminative queries for effective\ninstance separation. Second, our algorithm encourages both image (instance)\nrepresentations and queries to be equivariant against geometric\ntransformations, leading to more robust, instance-query matching. On top of\nfour famous, query-based models ($i.e.,$ CondInst, SOLOv2, SOTR, and\nMask2Former), our training algorithm provides significant performance gains\n($e.g.,$ +1.6 - 3.2 AP) on COCO dataset. In addition, our algorithm promotes\nthe performance of SOLOv2 by 2.7 AP, on LVISv1 dataset.\n","authors":["Wenguan Wang","James Liang","Dongfang Liu"],"pdf_url":"https://arxiv.org/pdf/2210.00911v2.pdf","comment":"Accepted to NeurIPS 2022; Code:\n  https://github.com/JamesLiang819/Instance_Unique_Querying"},{"id":"http://arxiv.org/abs/2212.09247v1","updated":"2022-12-19T04:49:26Z","published":"2022-12-19T04:49:26Z","title":"ColoristaNet for Photorealistic Video Style Transfer","summary":"  Photorealistic style transfer aims to transfer the artistic style of an image\nonto an input image or video while keeping photorealism. In this paper, we\nthink it's the summary statistics matching scheme in existing algorithms that\nleads to unrealistic stylization. To avoid employing the popular Gram loss, we\npropose a self-supervised style transfer framework, which contains a style\nremoval part and a style restoration part. The style removal network removes\nthe original image styles, and the style restoration network recovers image\nstyles in a supervised manner. Meanwhile, to address the problems in current\nfeature transformation methods, we propose decoupled instance normalization to\ndecompose feature transformation into style whitening and restylization. It\nworks quite well in ColoristaNet and can transfer image styles efficiently\nwhile keeping photorealism. To ensure temporal coherency, we also incorporate\noptical flow methods and ConvLSTM to embed contextual information. Experiments\ndemonstrates that ColoristaNet can achieve better stylization effects when\ncompared with state-of-the-art algorithms.\n","authors":["Xiaowen Qiu","Ruize Xu","Boan He","Yingtao Zhang","Wenqiang Zhang","Weifeng Ge"],"pdf_url":"https://arxiv.org/pdf/2212.09247v1.pdf","comment":"30 pages, 29 figures"},{"id":"http://arxiv.org/abs/2212.08327v2","updated":"2022-12-19T03:48:37Z","published":"2022-12-16T08:00:54Z","title":"WavEnhancer: Unifying Wavelet and Transformer for Image Enhancement","summary":"  Image enhancement is a technique that frequently utilized in digital image\nprocessing. In recent years, the popularity of learning-based techniques for\nenhancing the aesthetic performance of photographs has increased. However, the\nmajority of current works do not optimize an image from different frequency\ndomains and typically focus on either pixel-level or global-level enhancements.\nIn this paper, we propose a transformer-based model in the wavelet domain to\nrefine different frequency bands of an image. Our method focuses both on local\ndetails and high-level features for enhancement, which can generate superior\nresults. On the basis of comprehensive benchmark evaluations, our method\noutperforms the state-of-the-art methods.\n","authors":["Zinuo Li","Xuhang Chen","Chi-Man Pun","Shuqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.08327v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09225v1","updated":"2022-12-19T03:29:47Z","published":"2022-12-19T03:29:47Z","title":"An Extension of Fisher's Criterion: Theoretical Results with a Neural\n  Network Realization","summary":"  Fisher's criterion is a widely used tool in machine learning for feature\nselection. For large search spaces, Fisher's criterion can provide a scalable\nsolution to select features. A challenging limitation of Fisher's criterion,\nhowever, is that it performs poorly when mean values of class-conditional\ndistributions are close to each other. Motivated by this challenge, we propose\nan extension of Fisher's criterion to overcome this limitation. The proposed\nextension utilizes the available heteroscedasticity of class-conditional\ndistributions to distinguish one class from another. Additionally, we describe\nhow our theoretical results can be casted into a neural network framework, and\nconduct a proof-of-concept experiment to demonstrate the viability of our\napproach to solve classification problems.\n","authors":["Ibrahim Alsolami","Tomoki Fukai"],"pdf_url":"https://arxiv.org/pdf/2212.09225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.03677v4","updated":"2022-12-19T03:06:16Z","published":"2022-07-08T03:44:34Z","title":"SuperTickets: Drawing Task-Agnostic Lottery Tickets from Supernets via\n  Jointly Architecture Searching and Parameter Pruning","summary":"  Neural architecture search (NAS) has demonstrated amazing success in\nsearching for efficient deep neural networks (DNNs) from a given supernet. In\nparallel, the lottery ticket hypothesis has shown that DNNs contain small\nsubnetworks that can be trained from scratch to achieve a comparable or higher\naccuracy than original DNNs. As such, it is currently a common practice to\ndevelop efficient DNNs via a pipeline of first search and then prune.\nNevertheless, doing so often requires a search-train-prune-retrain process and\nthus prohibitive computational cost. In this paper, we discover for the first\ntime that both efficient DNNs and their lottery subnetworks (i.e., lottery\ntickets) can be directly identified from a supernet, which we term as\nSuperTickets, via a two-in-one training scheme with jointly architecture\nsearching and parameter pruning. Moreover, we develop a progressive and unified\nSuperTickets identification strategy that allows the connectivity of\nsubnetworks to change during supernet training, achieving better accuracy and\nefficiency trade-offs than conventional sparse training. Finally, we evaluate\nwhether such identified SuperTickets drawn from one task can transfer well to\nother tasks, validating their potential of handling multiple tasks\nsimultaneously. Extensive experiments and ablation studies on three tasks and\nfour benchmark datasets validate that our proposed SuperTickets achieve boosted\naccuracy and efficiency trade-offs than both typical NAS and pruning pipelines,\nregardless of having retraining or not. Codes and pretrained models are\navailable at https://github.com/RICE-EIC/SuperTickets.\n","authors":["Haoran You","Baopu Li","Zhanyi Sun","Xu Ouyang","Yingyan Lin"],"pdf_url":"https://arxiv.org/pdf/2207.03677v4.pdf","comment":"Accepted by ECCV 2022"},{"id":"http://arxiv.org/abs/2209.07042v3","updated":"2022-12-19T02:15:03Z","published":"2022-09-15T04:51:17Z","title":"Efficient Perception, Planning, and Control Algorithms for Vision-Based\n  Automated Vehicles","summary":"  Owing to resource limitations, efficient computation systems have long been a\ncritical demand for those designing autonomous vehicles. In addition, sensor\ncost and size have restricted the development of self-driving cars. To overcome\nthese restrictions, this study proposed an efficient framework for the\noperation of vision-based automatic vehicles; a front-facing camera and a few\ninexpensive radars are the required sensors for driving environment perception.\nThe proposed algorithm comprises a multi-task UNet (MTUNet) network for\nextracting image features and constrained iterative linear quadratic regulator\n(CILQR) modules for rapid lateral and longitudinal motion planning. The MTUNet\nis designed to simultaneously solve lane line segmentation, ego vehicle heading\nangle regression, road type classification, and traffic object detection tasks\nat an approximate speed of 40 FPS (frames per second) when an RGB image of size\n228 x 228 is fed into it. The linear CILQR controllers then apply processed\nMTUNet outputs and radar data as inputs to produce driving commands for lateral\nand longitudinal guidance related to autonomous vehicle operation; optimal\ncontrol problems can be solved within 1 ms. The linear CILQR approaches are\nmore efficient than the standard sequential quadratic programming (SQP) methods\nand can be combined with MTUNet for autonomous vehicle operation in simulated\nenvironments for lane-keeping and car-following maneuvers without the use of\nhigh-definition (HD) maps. Our experiments demonstrate that the proposed\nautonomous driving system is applicable to current automobile technology.\n","authors":["Der-Hau Lee"],"pdf_url":"https://arxiv.org/pdf/2209.07042v3.pdf","comment":"7 figures, 12 pages"},{"id":"http://arxiv.org/abs/2105.08383v3","updated":"2022-12-19T02:13:43Z","published":"2021-05-18T09:20:58Z","title":"I2C2W: Image-to-Character-to-Word Transformers for Accurate Scene Text\n  Recognition","summary":"  Leveraging the advances of natural language processing, most recent scene\ntext recognizers adopt an encoder-decoder architecture where text images are\nfirst converted to representative features and then a sequence of characters\nvia `sequential decoding'. However, scene text images suffer from rich noises\nof different sources such as complex background and geometric distortions which\noften confuse the decoder and lead to incorrect alignment of visual features at\nnoisy decoding time steps. This paper presents I2C2W, a novel scene text\nrecognition technique that is tolerant to geometric and photometric degradation\nby decomposing scene text recognition into two inter-connected tasks. The first\ntask focuses on image-to-character (I2C) mapping which detects a set of\ncharacter candidates from images based on different alignments of visual\nfeatures in an non-sequential way. The second task tackles character-to-word\n(C2W) mapping which recognizes scene text by decoding words from the detected\ncharacter candidates. The direct learning from character semantics (instead of\nnoisy image features) corrects falsely detected character candidates\neffectively which improves the final text recognition accuracy greatly.\nExtensive experiments over nine public datasets show that the proposed I2C2W\noutperforms the state-of-the-art by large margins for challenging scene text\ndatasets with various curvature and perspective distortions. It also achieves\nvery competitive recognition performance over multiple normal scene text\ndatasets.\n","authors":["Chuhui Xue","Jiaxing Huang","Wenqing Zhang","Shijian Lu","Changhu Wang","Song Bai"],"pdf_url":"https://arxiv.org/pdf/2105.08383v3.pdf","comment":"Accepted by special issue Transformer Models in Vision of the\n  Transactions on Pattern Analysis and Machine Intelligence"},{"id":"http://arxiv.org/abs/2212.08624v2","updated":"2022-12-19T01:56:43Z","published":"2022-12-16T17:59:40Z","title":"Development of A Real-time POCUS Image Quality Assessment and\n  Acquisition Guidance System","summary":"  Point-of-care ultrasound (POCUS) is one of the most commonly applied tools\nfor cardiac function imaging in the clinical routine of the emergency\ndepartment and pediatric intensive care unit. The prior studies demonstrate\nthat AI-assisted software can guide nurses or novices without prior sonography\nexperience to acquire POCUS by recognizing the interest region, assessing image\nquality, and providing instructions. However, these AI algorithms cannot simply\nreplace the role of skilled sonographers in acquiring diagnostic-quality POCUS.\nUnlike chest X-ray, CT, and MRI, which have standardized imaging protocols,\nPOCUS can be acquired with high inter-observer variability. Though being with\nvariability, they are usually all clinically acceptable and interpretable. In\nchallenging clinical environments, sonographers employ novel heuristics to\nacquire POCUS in complex scenarios. To help novice learners to expedite the\ntraining process while reducing the dependency on experienced sonographers in\nthe curriculum implementation, We will develop a framework to perform real-time\nAI-assisted quality assessment and probe position guidance to provide training\nprocess for novice learners with less manual intervention.\n","authors":["Zhenge Jia","Yiyu Shi","Jingtong Hu","Lei Yang","Benjamin Nti"],"pdf_url":"https://arxiv.org/pdf/2212.08624v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09206v1","updated":"2022-12-19T01:27:50Z","published":"2022-12-19T01:27:50Z","title":"Segmentation Ability Map: Interpret deep features for medical image\n  segmentation","summary":"  Deep convolutional neural networks (CNNs) have been widely used for medical\nimage segmentation. In most studies, only the output layer is exploited to\ncompute the final segmentation results and the hidden representations of the\ndeep learned features have not been well understood. In this paper, we propose\na prototype segmentation (ProtoSeg) method to compute a binary segmentation map\nbased on deep features. We measure the segmentation abilities of the features\nby computing the Dice between the feature segmentation map and ground-truth,\nnamed as the segmentation ability score (SA score for short). The corresponding\nSA score can quantify the segmentation abilities of deep features in different\nlayers and units to understand the deep neural networks for segmentation. In\naddition, our method can provide a mean SA score which can give a performance\nestimation of the output on the test images without ground-truth. Finally, we\nuse the proposed ProtoSeg method to compute the segmentation map directly on\ninput images to further understand the segmentation ability of each input\nimage. Results are presented on segmenting tumors in brain MRI, lesions in skin\nimages, COVID-related abnormality in CT images, prostate segmentation in\nabdominal MRI, and pancreatic mass segmentation in CT images. Our method can\nprovide new insights for interpreting and explainable AI systems for medical\nimage segmentation.\n  Our code is available on: \\url{https://github.com/shengfly/ProtoSeg}.\n","authors":["Sheng He","Yanfang Feng","P. Ellen Grant","Yangming Ou"],"pdf_url":"https://arxiv.org/pdf/2212.09206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.00116v4","updated":"2022-12-19T00:47:51Z","published":"2021-05-31T21:55:56Z","title":"Effect of Pre-Training Scale on Intra- and Inter-Domain Full and\n  Few-Shot Transfer Learning for Natural and Medical X-Ray Chest Images","summary":"  Increasing model, data and compute budget scale in the pre-training has been\nshown to strongly improve model generalization and transfer learning in vast\nline of work done in language modeling and natural image recognition. However,\nmost studies on the positive effect of larger scale were done in scope of\nin-domain setting, with source and target data being in close proximity. To\nstudy effect of larger scale for both in-domain and out-of-domain setting when\nperforming full and few-shot transfer, we combine here for the first time\nlarge, openly available medical X-Ray chest imaging datasets to reach a scale\nfor medical imaging domain comparable to ImageNet-1k, routinely used for\npre-training in natural image domain. We then conduct supervised pre-training,\nwhile varying network size and source data scale and domain, being either large\nnatural (ImageNet-1k/21k) or large medical chest X-Ray datasets, and transfer\npre-trained models to different natural or medical targets. We observe strong\nimprovement due to larger pre-training scale for intra-domain natural-natural\nand medical-medical transfer. For inter-domain natural-medical transfer, we\nfind improvements due to larger pre-training scale on larger X-Ray targets in\nfull shot regime, while for smaller targets and for few-shot regime the\nimprovement is not visible. Remarkably, large networks pre-trained on very\nlarge natural ImageNet-21k are as good or better than networks pre-trained on\nlargest available medical X-Ray data when performing transfer to large X-Ray\ntargets. We conclude that substantially increasing model and generic, medical\ndomain-agnostic natural image source data scale in the pre-training can enable\nhigh quality out-of-domain transfer to medical domain specific targets,\nremoving dependency on large medical domain-specific source data often not\navailable in the practice.\n","authors":["Mehdi Cherti","Jenia Jitsev"],"pdf_url":"https://arxiv.org/pdf/2106.00116v4.pdf","comment":"Short version published in MedNeurIPS 2021. Long version published in\n  IJCNN 2022. Code: https://github.com/SLAMPAI/large-scale-pretraining-transfer"},{"id":"http://arxiv.org/abs/2212.09902v1","updated":"2022-12-19T22:50:40Z","published":"2022-12-19T22:50:40Z","title":"Dexterous Manipulation from Images: Autonomous Real-World RL via Substep\n  Guidance","summary":"  Complex and contact-rich robotic manipulation tasks, particularly those that\ninvolve multi-fingered hands and underactuated object manipulation, present a\nsignificant challenge to any control method. Methods based on reinforcement\nlearning offer an appealing choice for such settings, as they can enable robots\nto learn to delicately balance contact forces and dexterously reposition\nobjects without strong modeling assumptions. However, running reinforcement\nlearning on real-world dexterous manipulation systems often requires\nsignificant manual engineering. This negates the benefits of autonomous data\ncollection and ease of use that reinforcement learning should in principle\nprovide. In this paper, we describe a system for vision-based dexterous\nmanipulation that provides a \"programming-free\" approach for users to define\nnew tasks and enable robots with complex multi-fingered hands to learn to\nperform them through interaction. The core principle underlying our system is\nthat, in a vision-based setting, users should be able to provide high-level\nintermediate supervision that circumvents challenges in teleoperation or\nkinesthetic teaching which allow a robot to not only learn a task efficiently\nbut also to autonomously practice. Our system includes a framework for users to\ndefine a final task and intermediate sub-tasks with image examples, a\nreinforcement learning procedure that learns the task autonomously without\ninterventions, and experimental results with a four-finger robotic hand\nlearning multi-stage object manipulation tasks directly in the real world,\nwithout simulation, manual modeling, or reward engineering.\n","authors":["Kelvin Xu","Zheyuan Hu","Ria Doshi","Aaron Rovinsky","Vikash Kumar","Abhishek Gupta","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2212.09902v1.pdf","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2212.09898v1","updated":"2022-12-19T22:41:46Z","published":"2022-12-19T22:41:46Z","title":"MetaCLUE: Towards Comprehensive Visual Metaphors Research","summary":"  Creativity is an indispensable part of human cognition and also an inherent\npart of how we make sense of the world. Metaphorical abstraction is fundamental\nin communicating creative ideas through nuanced relationships between abstract\nconcepts such as feelings. While computer vision benchmarks and approaches\npredominantly focus on understanding and generating literal interpretations of\nimages, metaphorical comprehension of images remains relatively unexplored.\nTowards this goal, we introduce MetaCLUE, a set of vision tasks on visual\nmetaphor. We also collect high-quality and rich metaphor annotations (abstract\nobjects, concepts, relationships along with their corresponding object boxes)\nas there do not exist any datasets that facilitate the evaluation of these\ntasks. We perform a comprehensive analysis of state-of-the-art models in vision\nand language based on our annotations, highlighting strengths and weaknesses of\ncurrent approaches in visual metaphor Classification, Localization,\nUnderstanding (retrieval, question answering, captioning) and gEneration\n(text-to-image synthesis) tasks. We hope this work provides a concrete step\ntowards developing AI systems with human-like creative capabilities.\n","authors":["Arjun R. Akula","Brendan Driscoll","Pradyumna Narayana","Soravit Changpinyo","Zhiwei Jia","Suyash Damle","Garima Pruthi","Sugato Basu","Leonidas Guibas","William T. Freeman","Yuanzhen Li","Varun Jampani"],"pdf_url":"https://arxiv.org/pdf/2212.09898v1.pdf","comment":"Project page: https://metaclue.github.io/ , Video summary:\n  https://www.youtube.com/watch?v=Ez6jY4qMXY8"},{"id":"http://arxiv.org/abs/2202.09006v2","updated":"2022-12-19T22:29:03Z","published":"2022-02-18T03:32:08Z","title":"KINet: Keypoint Interaction Networks for Unsupervised Forward Modeling","summary":"  Object-centric representation is an essential abstraction for forward\nprediction. Most existing forward models learn this representation through\nextensive supervision (e.g., object class and bounding box) although such\nground-truth information is not readily accessible in reality. To address this,\nwe introduce KINet (Keypoint Interaction Network) -- an end-to-end unsupervised\nframework to reason about object interactions based on a keypoint\nrepresentation. Using visual observations, our model learns to associate\nobjects with keypoint coordinates and discovers a graph representation of the\nsystem as a set of keypoint embeddings and their relations. It then learns an\naction-conditioned forward model using contrastive estimation to predict future\nkeypoint states. By learning to perform physical reasoning in the keypoint\nspace, our model automatically generalizes to scenarios with a different number\nof objects, novel backgrounds, and unseen object geometries. Experiments\ndemonstrate the effectiveness of our model in accurately performing forward\nprediction and learning plannable object-centric representations which can also\nbe used in downstream robotic manipulation tasks.\n","authors":["Alireza Rezazadeh","Changhyun Choi"],"pdf_url":"https://arxiv.org/pdf/2202.09006v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.14228v3","updated":"2022-12-19T22:15:58Z","published":"2021-07-29T17:59:05Z","title":"Open-World Entity Segmentation","summary":"  We introduce a new image segmentation task, called Entity Segmentation (ES),\nwhich aims to segment all visual entities (objects and stuffs) in an image\nwithout predicting their semantic labels. By removing the need of class label\nprediction, the models trained for such task can focus more on improving\nsegmentation quality. It has many practical applications such as image\nmanipulation and editing where the quality of segmentation masks is crucial but\nclass labels are less important. We conduct the first-ever study to investigate\nthe feasibility of convolutional center-based representation to segment things\nand stuffs in a unified manner, and show that such representation fits\nexceptionally well in the context of ES. More specifically, we propose a\nCondInst-like fully-convolutional architecture with two novel modules\nspecifically designed to exploit the class-agnostic and non-overlapping\nrequirements of ES. Experiments show that the models designed and trained for\nES significantly outperforms popular class-specific panoptic segmentation\nmodels in terms of segmentation quality. Moreover, an ES model can be easily\ntrained on a combination of multiple datasets without the need to resolve label\nconflicts in dataset merging, and the model trained for ES on one or more\ndatasets can generalize very well to other test datasets of unseen domains. The\ncode has been released at https://github.com/dvlab-research/Entity/.\n","authors":["Lu Qi","Jason Kuen","Yi Wang","Jiuxiang Gu","Hengshuang Zhao","Zhe Lin","Philip Torr","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2107.14228v3.pdf","comment":"Project page: http://luqi.info/Entity_Web"},{"id":"http://arxiv.org/abs/2212.09877v1","updated":"2022-12-19T21:57:35Z","published":"2022-12-19T21:57:35Z","title":"LayoutDETR: Detection Transformer Is a Good Multimodal Layout Designer","summary":"  Graphic layout designs play an essential role in visual communication. Yet\nhandcrafting layout designs are skill-demanding, time-consuming, and\nnon-scalable to batch production. Although generative models emerge to make\ndesign automation no longer utopian, it remains non-trivial to customize\ndesigns that comply with designers' multimodal desires, i.e., constrained by\nbackground images and driven by foreground contents. In this study, we propose\n\\textit{LayoutDETR} that inherits the high quality and realism from generative\nmodeling, in the meanwhile reformulating content-aware requirements as a\ndetection problem: we learn to detect in a background image the reasonable\nlocations, scales, and spatial relations for multimodal elements in a layout.\nExperiments validate that our solution yields new state-of-the-art performance\nfor layout generation on public benchmarks and on our newly-curated ads banner\ndataset. For practical usage, we build our solution into a graphical system\nthat facilitates user studies. We demonstrate that our designs attract more\nsubjective preference than baselines by significant margins. Our code, models,\ndataset, graphical system, and demos are available at\nhttps://github.com/salesforce/LayoutDETR.\n","authors":["Ning Yu","Chia-Chih Chen","Zeyuan Chen","Rui Meng","Gang Wu","Paul Josel","Juan Carlos Niebles","Caiming Xiong","Ran Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09860v1","updated":"2022-12-19T21:18:27Z","published":"2022-12-19T21:18:27Z","title":"Predicting Ejection Fraction from Chest X-rays Using Computer Vision for\n  Diagnosing Heart Failure","summary":"  Heart failure remains a major public health challenge with growing costs.\nEjection fraction (EF) is a key metric for the diagnosis and management of\nheart failure however estimation of EF using echocardiography remains expensive\nfor the healthcare system and subject to intra/inter operator variability.\nWhile chest x-rays (CXR) are quick, inexpensive, and require less expertise,\nthey do not provide sufficient information to the human eye to estimate EF.\nThis work explores the efficacy of computer vision techniques to predict\nreduced EF solely from CXRs. We studied a dataset of 3488 CXRs from the MIMIC\nCXR-jpg (MCR) dataset. Our work establishes benchmarks using multiple\nstate-of-the-art convolutional neural network architectures. The subsequent\nanalysis shows increasing model sizes from 8M to 23M parameters improved\nclassification performance without overfitting the dataset. We further show how\ndata augmentation techniques such as CXR rotation and random cropping further\nimproves model performance another ~5%. Finally, we conduct an error analysis\nusing saliency maps and Grad-CAMs to better understand the failure modes of\nconvolutional models on this task.\n","authors":["Walt Williams","Rohan Doshi","Yanran Li","Kexuan Liang"],"pdf_url":"https://arxiv.org/pdf/2212.09860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.06049v3","updated":"2022-12-19T19:21:47Z","published":"2022-08-11T21:58:36Z","title":"MILAN: Masked Image Pretraining on Language Assisted Representation","summary":"  Self-attention based transformer models have been dominating many computer\nvision tasks in the past few years. Their superb model qualities heavily depend\non the excessively large labeled image datasets. In order to reduce the\nreliance on large labeled datasets, reconstruction based masked autoencoders\nare gaining popularity, which learn high quality transferable representations\nfrom unlabeled images. For the same purpose, recent weakly supervised image\npretraining methods explore language supervision from text captions\naccompanying the images. In this work, we propose masked image pretraining on\nlanguage assisted representation, dubbed as MILAN. Instead of predicting raw\npixels or low level features, our pretraining objective is to reconstruct the\nimage features with substantial semantic signals that are obtained using\ncaption supervision. Moreover, to accommodate our reconstruction target, we\npropose a more effective prompting decoder architecture and a semantic aware\nmask sampling mechanism, which further advance the transfer performance of the\npretrained model. Experimental results demonstrate that MILAN delivers higher\naccuracy than the previous works. When the masked autoencoder is pretrained and\nfinetuned on ImageNet-1K dataset with an input resolution of 224x224, MILAN\nachieves a top-1 accuracy of 85.4% on ViT-Base, surpassing previous\nstate-of-the-arts by 1%. In the downstream semantic segmentation task, MILAN\nachieves 52.7 mIoU using ViT-Base on ADE20K dataset, outperforming previous\nmasked pretraining results by 4 points.\n","authors":["Zejiang Hou","Fei Sun","Yen-Kuang Chen","Yuan Xie","Sun-Yuan Kung"],"pdf_url":"https://arxiv.org/pdf/2208.06049v3.pdf","comment":"add new experiments and improved results. provide repo link"},{"id":"http://arxiv.org/abs/2212.09802v1","updated":"2022-12-19T19:15:36Z","published":"2022-12-19T19:15:36Z","title":"Panoptic Lifting for 3D Scene Understanding with Neural Fields","summary":"  We propose Panoptic Lifting, a novel approach for learning panoptic 3D\nvolumetric representations from images of in-the-wild scenes. Once trained, our\nmodel can render color images together with 3D-consistent panoptic segmentation\nfrom novel viewpoints.\n  Unlike existing approaches which use 3D input directly or indirectly, our\nmethod requires only machine-generated 2D panoptic segmentation masks inferred\nfrom a pre-trained network. Our core contribution is a panoptic lifting scheme\nbased on a neural field representation that generates a unified and multi-view\nconsistent, 3D panoptic representation of the scene. To account for\ninconsistencies of 2D instance identifiers across views, we solve a linear\nassignment with a cost based on the model's current predictions and the\nmachine-generated segmentation masks, thus enabling us to lift 2D instances to\n3D in a consistent way. We further propose and ablate contributions that make\nour method more robust to noisy, machine-generated labels, including test-time\naugmentations for confidence estimates, segment consistency loss, bounded\nsegmentation fields, and gradient stopping.\n  Experimental results validate our approach on the challenging Hypersim,\nReplica, and ScanNet datasets, improving by 8.4, 13.8, and 10.6% in scene-level\nPQ over state of the art.\n","authors":["Yawar Siddiqui","Lorenzo Porzi","Samuel Rota Buló","Norman Müller","Matthias Nießner","Angela Dai","Peter Kontschieder"],"pdf_url":"https://arxiv.org/pdf/2212.09802v1.pdf","comment":"Project Page: https://nihalsid.github.io/panoptic-lifting/, Video:\n  https://youtu.be/QtsiL-6rSuM"},{"id":"http://arxiv.org/abs/2212.10275v1","updated":"2022-12-19T16:29:20Z","published":"2022-12-19T16:29:20Z","title":"ARO-Net: Learning Neural Fields from Anchored Radial Observations","summary":"  We introduce anchored radial observations (ARO), a novel shape encoding for\nlearning neural field representation of shapes that is category-agnostic and\ngeneralizable amid significant shape variations. The main idea behind our work\nis to reason about shapes through partial observations from a set of\nviewpoints, called anchors. We develop a general and unified shape\nrepresentation by employing a fixed set of anchors, via Fibonacci sampling, and\ndesigning a coordinate-based deep neural network to predict the occupancy value\nof a query point in space. Differently from prior neural implicit models, that\nuse global shape feature, our shape encoder operates on contextual,\nquery-specific features. To predict point occupancy, locally observed shape\ninformation from the perspective of the anchors surrounding the input query\npoint are encoded and aggregated through an attention module, before implicit\ndecoding is performed. We demonstrate the quality and generality of our\nnetwork, coined ARO-Net, on surface reconstruction from sparse point clouds,\nwith tests on novel and unseen object categories, \"one-shape\" training, and\ncomparisons to state-of-the-art neural and classical methods for reconstruction\nand tessellation.\n","authors":["Yizhi Wang","Zeyu Huang","Ariel Shamir","Hui Huang","Hao Zhang","Ruizhen Hu"],"pdf_url":"https://arxiv.org/pdf/2212.10275v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.09744v1","updated":"2022-12-19T18:59:34Z","published":"2022-12-19T18:59:34Z","title":"DSI++: Updating Transformer Memory with New Documents","summary":"  Differentiable Search Indices (DSIs) encode a corpus of documents in the\nparameters of a model and use the same model to map queries directly to\nrelevant document identifiers. Despite the strong performance of DSI models,\ndeploying them in situations where the corpus changes over time is\ncomputationally expensive because reindexing the corpus requires re-training\nthe model. In this work, we introduce DSI++, a continual learning challenge for\nDSI to incrementally index new documents while being able to answer queries\nrelated to both previously and newly indexed documents. Across different model\nscales and document identifier representations, we show that continual indexing\nof new documents leads to considerable forgetting of previously indexed\ndocuments. We also hypothesize and verify that the model experiences forgetting\nevents during training, leading to unstable learning. To mitigate these issues,\nwe investigate two approaches. The first focuses on modifying the training\ndynamics. Flatter minima implicitly alleviate forgetting, so we optimize for\nflatter loss basins and show that the model stably memorizes more documents\n(+12\\%). Next, we introduce a generative memory to sample pseudo-queries for\ndocuments and supplement them during continual indexing to prevent forgetting\nfor the retrieval task. Extensive experiments on novel continual indexing\nbenchmarks based on Natural Questions (NQ) and MS MARCO demonstrate that our\nproposed solution mitigates forgetting by a significant margin. Concretely, it\nimproves the average Hits@10 by $+21.1\\%$ over competitive baselines for NQ and\nrequires $6$ times fewer model updates compared to re-training the DSI model\nfor incrementally indexing five corpora in a sequence.\n","authors":["Sanket Vaibhav Mehta","Jai Gupta","Yi Tay","Mostafa Dehghani","Vinh Q. Tran","Jinfeng Rao","Marc Najork","Emma Strubell","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2212.09744v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2101.12430v2","updated":"2022-12-19T17:56:42Z","published":"2021-01-29T06:50:27Z","title":"Subgraph nomination: Query by Example Subgraph Retrieval in Networks","summary":"  This paper introduces the subgraph nomination inference task, in which\nexample subgraphs of interest are used to query a network for similarly\ninteresting subgraphs. This type of problem appears time and again in real\nworld problems connected to, for example, user recommendation systems and\nstructural retrieval tasks in social and biological/connectomic networks. We\nformally define the subgraph nomination framework with an emphasis on the\nnotion of a user-in-the-loop in the subgraph nomination pipeline. In this\nsetting, a user can provide additional post-nomination light supervision that\ncan be incorporated into the retrieval task. After introducing and formalizing\nthe retrieval task, we examine the nuanced effect that user-supervision can\nhave on performance, both analytically and across real and simulated data\nexamples.\n","authors":["Al-Fahad M. Al-Qadhi","Carey E. Priebe","Hayden S. Helm","Vince Lyzinski"],"pdf_url":"https://arxiv.org/pdf/2101.12430v2.pdf","comment":"37 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.09656v1","updated":"2022-12-19T17:39:07Z","published":"2022-12-19T17:39:07Z","title":"Visconde: Multi-document QA with GPT-3 and Neural Reranking","summary":"  This paper proposes a question-answering system that can answer questions\nwhose supporting evidence is spread over multiple (potentially long) documents.\nThe system, called Visconde, uses a three-step pipeline to perform the task:\ndecompose, retrieve, and aggregate. The first step decomposes the question into\nsimpler questions using a few-shot large language model (LLM). Then, a\nstate-of-the-art search engine is used to retrieve candidate passages from a\nlarge collection for each decomposed question. In the final step, we use the\nLLM in a few-shot setting to aggregate the contents of the passages into the\nfinal answer. The system is evaluated on three datasets: IIRC, Qasper, and\nStrategyQA. Results suggest that current retrievers are the main bottleneck and\nthat readers are already performing at the human level as long as relevant\npassages are provided. The system is also shown to be more effective when the\nmodel is induced to give explanations before answering a question. Code is\navailable at \\url{https://github.com/neuralmind-ai/visconde}.\n","authors":["Jayr Pereira","Robson Fidalgo","Roberto Lotufo","Rodrigo Nogueira"],"pdf_url":"https://arxiv.org/pdf/2212.09656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09598v1","updated":"2022-12-19T16:34:19Z","published":"2022-12-19T16:34:19Z","title":"Query-as-context Pre-training for Dense Passage Retrieval","summary":"  This paper presents a pre-training technique called query-as-context that\nuses query prediction to improve dense retrieval. Previous research has applied\nquery prediction to document expansion in order to alleviate the problem of\nlexical mismatch in sparse retrieval. However, query prediction has not yet\nbeen studied in the context of dense retrieval. Query-as-context pre-training\nassumes that the predicted query is a special context for the document and uses\ncontrastive learning or contextual masked auto-encoding learning to compress\nthe document and query into dense vectors. The technique is evaluated on\nlarge-scale passage retrieval benchmarks and shows considerable improvements\ncompared to existing strong baselines such as coCondenser and CoT-MAE,\ndemonstrating its effectiveness. Our code will be available at\nhttps://github.com/caskcsg/ir/tree/main/cotmae-qc .\n","authors":["Xing Wu","Guangyuan Ma","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2212.09598v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.09597v1","updated":"2022-12-19T16:32:42Z","published":"2022-12-19T16:32:42Z","title":"Reasoning with Language Model Prompting: A Survey","summary":"  Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions.\n","authors":["Shuofei Qiao","Yixin Ou","Ningyu Zhang","Xiang Chen","Yunzhi Yao","Shumin Deng","Chuanqi Tan","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2212.09597v1.pdf","comment":"Work in progress and resources are available at\n  https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically)"},{"id":"http://arxiv.org/abs/2212.09376v1","updated":"2022-12-19T11:26:23Z","published":"2022-12-19T11:26:23Z","title":"Enriching Relation Extraction with OpenIE","summary":"  Relation extraction (RE) is a sub-discipline of information extraction (IE)\nwhich focuses on the prediction of a relational predicate from a\nnatural-language input unit (such as a sentence, a clause, or even a short\nparagraph consisting of multiple sentences and/or clauses). Together with\nnamed-entity recognition (NER) and disambiguation (NED), RE forms the basis for\nmany advanced IE tasks such as knowledge-base (KB) population and verification.\nIn this work, we explore how recent approaches for open information extraction\n(OpenIE) may help to improve the task of RE by encoding structured information\nabout the sentences' principal units, such as subjects, objects, verbal\nphrases, and adverbials, into various forms of vectorized (and hence\nunstructured) representations of the sentences. Our main conjecture is that the\ndecomposition of long and possibly convoluted sentences into multiple smaller\nclauses via OpenIE even helps to fine-tune context-sensitive language models\nsuch as BERT (and its plethora of variants) for RE. Our experiments over two\nannotated corpora, KnowledgeNet and FewRel, demonstrate the improved accuracy\nof our enriched models compared to existing RE approaches. Our best results\nreach 92% and 71% of F1 score for KnowledgeNet and FewRel, respectively,\nproving the effectiveness of our approach on competitive benchmarks.\n","authors":["Alessandro Temperoni","Maria Biryukov","Martin Theobald"],"pdf_url":"https://arxiv.org/pdf/2212.09376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.10796v4","updated":"2022-12-19T09:41:36Z","published":"2022-07-09T13:15:56Z","title":"Multiple Robust Learning for Recommendation","summary":"  In recommender systems, a common problem is the presence of various biases in\nthe collected data, which deteriorates the generalization ability of the\nrecommendation models and leads to inaccurate predictions. Doubly robust (DR)\nlearning has been studied in many tasks in RS, with the advantage that unbiased\nlearning can be achieved when either a single imputation or a single propensity\nmodel is accurate. In this paper, we propose a multiple robust (MR) estimator\nthat can take the advantage of multiple candidate imputation and propensity\nmodels to achieve unbiasedness. Specifically, the MR estimator is unbiased when\nany of the imputation or propensity models, or a linear combination of these\nmodels is accurate. Theoretical analysis shows that the proposed MR is an\nenhanced version of DR when only having a single imputation and propensity\nmodel, and has a smaller bias. Inspired by the generalization error bound of\nMR, we further propose a novel multiple robust learning approach with\nstabilization. We conduct extensive experiments on real-world and\nsemi-synthetic datasets, which demonstrates the superiority of the proposed\napproach over state-of-the-art methods.\n","authors":["Haoxuan Li","Quanyu Dai","Yuru Li","Yan Lyu","Zhenhua Dong","Xiao-Hua Zhou","Peng Wu"],"pdf_url":"https://arxiv.org/pdf/2207.10796v4.pdf","comment":"Accepted by AAAI'23"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2212.09748v1","updated":"2022-12-19T18:59:58Z","published":"2022-12-19T18:59:58Z","title":"Scalable Diffusion Models with Transformers","summary":"  We explore a new class of diffusion models based on the transformer\narchitecture. We train latent diffusion models of images, replacing the\ncommonly-used U-Net backbone with a transformer that operates on latent\npatches. We analyze the scalability of our Diffusion Transformers (DiTs)\nthrough the lens of forward pass complexity as measured by Gflops. We find that\nDiTs with higher Gflops -- through increased transformer depth/width or\nincreased number of input tokens -- consistently have lower FID. In addition to\npossessing good scalability properties, our largest DiT-XL/2 models outperform\nall prior diffusion models on the class-conditional ImageNet 512x512 and\n256x256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.\n","authors":["William Peebles","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2212.09748v1.pdf","comment":"Code, project page and videos available at\n  https://www.wpeebles.com/DiT"},{"id":"http://arxiv.org/abs/2212.09744v1","updated":"2022-12-19T18:59:34Z","published":"2022-12-19T18:59:34Z","title":"DSI++: Updating Transformer Memory with New Documents","summary":"  Differentiable Search Indices (DSIs) encode a corpus of documents in the\nparameters of a model and use the same model to map queries directly to\nrelevant document identifiers. Despite the strong performance of DSI models,\ndeploying them in situations where the corpus changes over time is\ncomputationally expensive because reindexing the corpus requires re-training\nthe model. In this work, we introduce DSI++, a continual learning challenge for\nDSI to incrementally index new documents while being able to answer queries\nrelated to both previously and newly indexed documents. Across different model\nscales and document identifier representations, we show that continual indexing\nof new documents leads to considerable forgetting of previously indexed\ndocuments. We also hypothesize and verify that the model experiences forgetting\nevents during training, leading to unstable learning. To mitigate these issues,\nwe investigate two approaches. The first focuses on modifying the training\ndynamics. Flatter minima implicitly alleviate forgetting, so we optimize for\nflatter loss basins and show that the model stably memorizes more documents\n(+12\\%). Next, we introduce a generative memory to sample pseudo-queries for\ndocuments and supplement them during continual indexing to prevent forgetting\nfor the retrieval task. Extensive experiments on novel continual indexing\nbenchmarks based on Natural Questions (NQ) and MS MARCO demonstrate that our\nproposed solution mitigates forgetting by a significant margin. Concretely, it\nimproves the average Hits@10 by $+21.1\\%$ over competitive baselines for NQ and\nrequires $6$ times fewer model updates compared to re-training the DSI model\nfor incrementally indexing five corpora in a sequence.\n","authors":["Sanket Vaibhav Mehta","Jai Gupta","Yi Tay","Mostafa Dehghani","Vinh Q. Tran","Jinfeng Rao","Marc Najork","Emma Strubell","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2212.09744v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2212.09730v1","updated":"2022-12-19T18:53:04Z","published":"2022-12-19T18:53:04Z","title":"Speaking Style Conversion With Discrete Self-Supervised Units","summary":"  Voice Conversion (VC) is the task of making a spoken utterance by one speaker\nsound as if uttered by a different speaker, while keeping other aspects like\ncontent unchanged. Current VC methods, focus primarily on spectral features\nlike timbre, while ignoring the unique speaking style of people which often\nimpacts prosody. In this study, we introduce a method for converting not only\nthe timbre, but also prosodic information (i.e., rhythm and pitch changes) to\nthose of the target speaker. The proposed approach is based on a pretrained,\nself-supervised, model for encoding speech to discrete units, which make it\nsimple, effective, and easy to optimise. We consider the many-to-many setting\nwith no paired data. We introduce a suite of quantitative and qualitative\nevaluation metrics for this setup, and empirically demonstrate the proposed\napproach is significantly superior to the evaluated baselines. Code and samples\ncan be found under https://pages.cs.huji.ac.il/adiyoss-lab/dissc/ .\n","authors":["Gallil Maimon","Yossi Adi"],"pdf_url":"https://arxiv.org/pdf/2212.09730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09726v1","updated":"2022-12-19T18:51:06Z","published":"2022-12-19T18:51:06Z","title":"Improving Faithfulness of Abstractive Summarization by Controlling\n  Confounding Effect of Irrelevant Sentences","summary":"  Lack of factual correctness is an issue that still plagues state-of-the-art\nsummarization systems despite their impressive progress on generating seemingly\nfluent summaries. In this paper, we show that factual inconsistency can be\ncaused by irrelevant parts of the input text, which act as confounders. To that\nend, we leverage information-theoretic measures of causal effects to quantify\nthe amount of confounding and precisely quantify how they affect the\nsummarization performance. Based on insights derived from our theoretical\nresults, we design a simple multi-task model to control such confounding by\nleveraging human-annotated relevant sentences when available. Crucially, we\ngive a principled characterization of data distributions where such confounding\ncan be large thereby necessitating the use of human annotated relevant\nsentences to generate factual summaries. Our approach improves faithfulness\nscores by 20\\% over strong baselines on AnswerSumm\n\\citep{fabbri2021answersumm}, a conversation summarization dataset where lack\nof faithfulness is a significant issue due to the subjective nature of the\ntask. Our best method achieves the highest faithfulness score while also\nachieving state-of-the-art results on standard metrics like ROUGE and METEOR.\nWe corroborate these improvements through human evaluation.\n","authors":["Asish Ghoshal","Arash Einolghozati","Ankit Arun","Haoran Li","Lili Yu","Yashar Mehdad","Scott Wen-tau Yih","Asli Celikyilmaz"],"pdf_url":"https://arxiv.org/pdf/2212.09726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09721v1","updated":"2022-12-19T18:49:09Z","published":"2022-12-19T18:49:09Z","title":"KNIFE: Knowledge Distillation with Free-Text Rationales","summary":"  Free-text rationales (FTRs) follow how humans communicate by explaining\nreasoning processes via natural language. A number of recent works have studied\nhow to improve language model (LM) generalization by using FTRs to teach LMs\nthe correct reasoning processes behind correct task outputs. These prior works\naim to learn from FTRs by appending them to the LM input or target output, but\nthis may introduce an input distribution shift or conflict with the task\nobjective, respectively. We propose KNIFE, which distills FTR knowledge from an\nFTR-augmented teacher LM (takes both task input and FTR) to a student LM (takes\nonly task input), which is used for inference. Crucially, the teacher LM's\nforward computation has a bottleneck stage in which all of its FTR states are\nmasked out, which pushes knowledge from the FTR states into the task\ninput/output states. Then, FTR knowledge is distilled to the student LM by\ntraining its task input/output states to align with the teacher LM's. On two\nquestion answering datasets, we show that KNIFE significantly outperforms\nexisting FTR learning methods, in both fully-supervised and low-resource\nsettings.\n","authors":["Aaron Chan","Zhiyuan Zeng","Wyatt Lake","Brihi Joshi","Hanjie Chen","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.09721v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.09720v1","updated":"2022-12-19T18:48:33Z","published":"2022-12-19T18:48:33Z","title":"The case for 4-bit precision: k-bit Inference Scaling Laws","summary":"  Quantization methods reduce the number of bits required to represent each\nparameter in a model, trading accuracy for smaller memory footprints and\ninference latencies. However, the final model size depends on both the number\nof parameters of the original model and the rate of compression. For example, a\n30B 8-bit model and a 60B 4-bit model have the same number of bits but may have\nvery different zero-shot accuracies. In this work, we study this trade-off by\ndeveloping inference scaling laws of zero-shot performance in Large Language\nModels (LLMs) to determine the bit-precision and model size that maximizes\nzero-shot performance. We run more than 35,000 zero-shot experiments with\n16-bit inputs and k-bit parameters to examine which quantization methods\nimprove scaling for 3 to 8-bit precision at scales of 19M to 66B parameters\nacross the LLM families BLOOM, OPT, NeoX/Pythia, and GPT-2. We find that it is\nchallenging to improve the bit-level scaling trade-off, with the only\nimprovements being the use of a small block size -- splitting the parameters\ninto small independently quantized blocks -- and the quantization data type\nbeing used (e.g., Int vs Float). Overall, our findings show that 4-bit\nprecision is almost universally optimal for total model bits and zero-shot\naccuracy.\n","authors":["Tim Dettmers","Luke Zettlemoyer"],"pdf_url":"https://arxiv.org/pdf/2212.09720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09713v1","updated":"2022-12-19T18:42:19Z","published":"2022-12-19T18:42:19Z","title":"A Probabilistic Framework for Lifelong Test-Time Adaptation","summary":"  Test-time adaptation is the problem of adapting a source pre-trained model\nusing test inputs from a target domain without access to source domain data.\nMost of the existing approaches address the setting in which the target domain\nis stationary. Moreover, these approaches are prone to making erroneous\npredictions with unreliable uncertainty estimates when distribution shifts\noccur. Hence, test-time adaptation in the face of non-stationary target domain\nshift becomes a problem of significant interest. To address these issues, we\npropose a principled approach, PETAL (Probabilistic lifElong Test-time\nAdaptation with seLf-training prior), which looks into this problem from a\nprobabilistic perspective using a partly data-dependent prior. A\nstudent-teacher framework, where the teacher model is an exponential moving\naverage of the student model naturally emerges from this probabilistic\nperspective. In addition, the knowledge from the posterior distribution\nobtained for the source task acts as a regularizer. To handle catastrophic\nforgetting in the long term, we also propose a data-driven model parameter\nresetting mechanism based on the Fisher information matrix (FIM). Moreover,\nimprovements in experimental results suggest that FIM based data-driven\nparameter restoration contributes to reducing the error accumulation and\nmaintaining the knowledge of recent domain by restoring only the irrelevant\nparameters. In terms of predictive error rate as well as uncertainty based\nmetrics such as Brier score and negative log-likelihood, our method achieves\nbetter results than the current state-of-the-art for online lifelong test time\nadaptation across various benchmarks, such as CIFAR-10C, CIFAR-100C, ImageNetC,\nand ImageNet3DCC datasets.\n","authors":["Dhanajit Brahma","Piyush Rai"],"pdf_url":"https://arxiv.org/pdf/2212.09713v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2212.09710v1","updated":"2022-12-19T18:39:43Z","published":"2022-12-19T18:39:43Z","title":"Continual Learning for Instruction Following from Realtime Feedback","summary":"  We study the problem of continually training an instruction-following agent\nthrough feedback provided by users during collaborative interactions. During\ninteraction, human users instruct an agent using natural language, and provide\nrealtime binary feedback as they observe the agent's instruction execution. We\ncast learning as a contextual bandit problem, converting the user feedback to\nimmediate reward. We evaluate through multiple rounds of human-agent\ninteractions, demonstrating 15.4% absolute improvement in instruction execution\nover time. We also show our approach is robust to several design variations,\nand that the feedback signal is roughly equivalent to the learning signal of\nsupervised demonstration data.\n","authors":["Alane Suhr","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2212.09710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09702v1","updated":"2022-12-19T18:30:36Z","published":"2022-12-19T18:30:36Z","title":"On Event Individuation for Document-Level Information Extraction","summary":"  As information extraction (IE) systems have grown more capable at\nwhole-document extraction, the classic task of \\emph{template filling} has seen\nrenewed interest as a benchmark for evaluating them. In this position paper, we\ncall into question the suitability of template filling for this purpose. We\nargue that the task demands definitive answers to thorny questions of\n\\emph{event individuation} -- the problem of distinguishing distinct events --\nabout which even human experts disagree. We show through annotation studies and\nerror analysis that this raises concerns about the usefulness of template\nfilling evaluation metrics, the quality of datasets for the task, and the\nability of models to learn it. Finally, we consider possible solutions.\n","authors":["William Gantt","Reno Kriz","Yunmo Chen","Siddharth Vashishtha","Aaron Steven White"],"pdf_url":"https://arxiv.org/pdf/2212.09702v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09701v1","updated":"2022-12-19T18:30:26Z","published":"2022-12-19T18:30:26Z","title":"Graph-based Semantical Extractive Text Analysis","summary":"  In the past few decades, there has been an explosion in the amount of\navailable data produced from various sources with different topics. The\navailability of this enormous data necessitates us to adopt effective\ncomputational tools to explore the data. This leads to an intense growing\ninterest in the research community to develop computational methods focused on\nprocessing this text data. A line of study focused on condensing the text so\nthat we are able to get a higher level of understanding in a shorter time. The\ntwo important tasks to do this are keyword extraction and text summarization.\nIn keyword extraction, we are interested in finding the key important words\nfrom a text. This makes us familiar with the general topic of a text. In text\nsummarization, we are interested in producing a short-length text which\nincludes important information about the document. The TextRank algorithm, an\nunsupervised learning method that is an extension of the PageRank (algorithm\nwhich is the base algorithm of Google search engine for searching pages and\nranking them) has shown its efficacy in large-scale text mining, especially for\ntext summarization and keyword extraction. this algorithm can automatically\nextract the important parts of a text (keywords or sentences) and declare them\nas the result. However, this algorithm neglects the semantic similarity between\nthe different parts. In this work, we improved the results of the TextRank\nalgorithm by incorporating the semantic similarity between parts of the text.\nAside from keyword extraction and text summarization, we develop a topic\nclustering algorithm based on our framework which can be used individually or\nas a part of generating the summary to overcome coverage problems.\n","authors":["Mina Samizadeh"],"pdf_url":"https://arxiv.org/pdf/2212.09701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09689v1","updated":"2022-12-19T18:21:00Z","published":"2022-12-19T18:21:00Z","title":"Unnatural Instructions: Tuning Language Models with (Almost) No Human\n  Labor","summary":"  Instruction tuning enables pretrained language models to perform new tasks\nfrom inference-time natural language descriptions. These approaches rely on\nvast amounts of human supervision in the form of crowdsourced datasets or user\ninteractions. In this work, we introduce Unnatural Instructions: a large\ndataset of creative and diverse instructions, collected with virtually no human\nlabor. We collect 64,000 examples by prompting a language model with three seed\nexamples of instructions and eliciting a fourth. This set is then expanded by\nprompting the model to rephrase each instruction, creating a total of\napproximately 240,000 examples of instructions, inputs, and outputs.\nExperiments show that despite containing a fair amount of noise, training on\nUnnatural Instructions rivals the effectiveness of training on open-source\nmanually-curated datasets, surpassing the performance of models such as T0++\nand Tk-Instruct across various benchmarks. These results demonstrate the\npotential of model-generated data as a cost-effective alternative to\ncrowdsourcing for dataset expansion and diversification.\n","authors":["Or Honovich","Thomas Scialom","Omer Levy","Timo Schick"],"pdf_url":"https://arxiv.org/pdf/2212.09689v1.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2206.07520v2","updated":"2022-12-19T18:16:20Z","published":"2022-06-09T18:16:28Z","title":"Principal Trade-off Analysis","summary":"  This paper develops Principal Trade-off Analysis (PTA), a decomposition\nmethod, analogous to Principal Component Analysis (PCA), which permits the\nrepresentation of any game as the weighted sum of disc games (continuous R-P-S\ngames). Applying PTA to empirically generated tournament graphs produces a\nsequence of embeddings into orthogonal 2D feature planes representing\nindependent strategic trade-offs. Each trade-off generates a mode of cyclic\ncompetition. Like PCA, PTA provides optimal low rank estimates of the\ntournament graphs that can be truncated for approximation. The complexity of\ncyclic competition can be quantified by computing the number of significant\ncyclic modes. We illustrate the PTA via application to a pair of games (Blotto,\nPokemon). The resulting 2D disc game representations are shown to be well\nsuited for visualization and are easily interpretable. In Blotto, PTA\nidentifies game symmetries, and specifies strategic trade-offs associated with\ndistinct win conditions. For Pokemon, PTA embeddings produce clusters in the\nembedding space that naturally correspond to Pokemon types, a design in the\ngame that produces cyclic trade offs.\n","authors":["Alexander Strang","David SeWell","Alexander Kim","Kevin Alcedo","David Rosenbluth"],"pdf_url":"https://arxiv.org/pdf/2206.07520v2.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.09681v1","updated":"2022-12-19T18:09:34Z","published":"2022-12-19T18:09:34Z","title":"Annual field-scale maps of tall and short crops at the global scale\n  using GEDI and Sentinel-2","summary":"  Crop type maps are critical for tracking agricultural land use and estimating\ncrop production. Remote sensing has proven an efficient and reliable tool for\ncreating these maps in regions with abundant ground labels for model training,\nyet these labels remain difficult to obtain in many regions and years. NASA's\nGlobal Ecosystem Dynamics Investigation (GEDI) spaceborne lidar instrument,\noriginally designed for forest monitoring, has shown promise for distinguishing\ntall and short crops. In the current study, we leverage GEDI to develop\nwall-to-wall maps of short vs tall crops on a global scale at 10 m resolution\nfor 2019-2021. Specifically, we show that (1) GEDI returns can reliably be\nclassified into tall and short crops after removing shots with extreme view\nangles or topographic slope, (2) the frequency of tall crops over time can be\nused to identify months when tall crops are at their peak height, and (3) GEDI\nshots in these months can then be used to train random forest models that use\nSentinel-2 time series to accurately predict short vs. tall crops. Independent\nreference data from around the world are then used to evaluate these GEDI-S2\nmaps. We find that GEDI-S2 performed nearly as well as models trained on\nthousands of local reference training points, with accuracies of at least 87%\nand often above 90% throughout the Americas, Europe, and East Asia. Systematic\nunderestimation of tall crop area was observed in regions where crops\nfrequently exhibit low biomass, namely Africa and South Asia, and further work\nis needed in these systems. Although the GEDI-S2 approach only differentiates\ntall from short crops, in many landscapes this distinction goes a long way\ntoward mapping the main individual crop types. The combination of GEDI and\nSentinel-2 thus presents a very promising path towards global crop mapping with\nminimal reliance on ground data.\n","authors":["Stefania Di Tommaso","Sherrie Wang","Vivek Vajipey","Noel Gorelick","Rob Strey","David B. Lobell"],"pdf_url":"https://arxiv.org/pdf/2212.09681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.12430v2","updated":"2022-12-19T17:56:42Z","published":"2021-01-29T06:50:27Z","title":"Subgraph nomination: Query by Example Subgraph Retrieval in Networks","summary":"  This paper introduces the subgraph nomination inference task, in which\nexample subgraphs of interest are used to query a network for similarly\ninteresting subgraphs. This type of problem appears time and again in real\nworld problems connected to, for example, user recommendation systems and\nstructural retrieval tasks in social and biological/connectomic networks. We\nformally define the subgraph nomination framework with an emphasis on the\nnotion of a user-in-the-loop in the subgraph nomination pipeline. In this\nsetting, a user can provide additional post-nomination light supervision that\ncan be incorporated into the retrieval task. After introducing and formalizing\nthe retrieval task, we examine the nuanced effect that user-supervision can\nhave on performance, both analytically and across real and simulated data\nexamples.\n","authors":["Al-Fahad M. Al-Qadhi","Carey E. Priebe","Hayden S. Helm","Vince Lyzinski"],"pdf_url":"https://arxiv.org/pdf/2101.12430v2.pdf","comment":"37 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.09668v1","updated":"2022-12-19T17:54:36Z","published":"2022-12-19T17:54:36Z","title":"Task-Oriented Communications for NextG: End-to-End Deep Learning and AI\n  Security Aspects","summary":"  Communications systems to date are primarily designed with the goal of\nreliable (error-free) transfer of digital sequences (bits). Next generation\n(NextG) communication systems are beginning to explore shifting this design\nparadigm of reliably decoding bits to reliably executing a given task.\nTask-oriented communications system design is likely to find impactful\napplications, for example, considering the relative importance of messages. In\nthis paper, a wireless signal classification is considered as the task to be\nperformed in the NextG Radio Access Network (RAN) for signal intelligence and\nspectrum awareness applications such as user equipment (UE) identification and\nauthentication, and incumbent signal detection for spectrum co-existence. For\nthat purpose, edge devices collect wireless signals and communicate with the\nNextG base station (gNodeB) that needs to know the signal class. Edge devices\nmay not have sufficient processing power and may not be trusted to perform the\nsignal classification task, whereas the transfer of the captured signals from\nthe edge devices to the gNodeB may not be efficient or even feasible subject to\nstringent delay, rate, and energy restrictions. We present a task-oriented\ncommunications approach, where all the transmitter, receiver and classifier\nfunctionalities are jointly trained as two deep neural networks (DNNs), one for\nthe edge device and another for the gNodeB. We show that this approach achieves\nbetter accuracy with smaller DNNs compared to the baselines that treat\ncommunications and signal classification as two separate tasks. Finally, we\ndiscuss how adversarial machine learning poses a major security threat for the\nuse of DNNs for task-oriented communications. We demonstrate the major\nperformance loss under backdoor (Trojan) attacks and adversarial (evasion)\nattacks that target the training and test processes of task-oriented\ncommunications.\n","authors":["Yalin E. Sagduyu","Sennur Ulukus","Aylin Yener"],"pdf_url":"https://arxiv.org/pdf/2212.09668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09667v1","updated":"2022-12-19T17:51:47Z","published":"2022-12-19T17:51:47Z","title":"Foveate, Attribute, and Rationalize: Towards Safe and Trustworthy AI","summary":"  Users' physical safety is an increasing concern as the market for intelligent\nsystems continues to grow, where unconstrained systems may recommend users\ndangerous actions that can lead to serious injury. Covertly unsafe text,\nlanguage that contains actionable physical harm, but requires further reasoning\nto identify such harm, is an area of particular interest, as such texts may\narise from everyday scenarios and are challenging to detect as harmful.\nQualifying the knowledge required to reason about the safety of various texts\nand providing human-interpretable rationales can shed light on the risk of\nsystems to specific user groups, helping both stakeholders manage the risks of\ntheir systems and policymakers to provide concrete safeguards for consumer\nsafety. We propose FARM, a novel framework that leverages external knowledge\nfor trustworthy rationale generation in the context of safety. In particular,\nFARM foveates on missing knowledge in specific scenarios, retrieves this\nknowledge with attribution to trustworthy sources, and uses this to both\nclassify the safety of the original text and generate human-interpretable\nrationales, combining critically important qualities for sensitive domains such\nas user safety. Furthermore, FARM obtains state-of-the-art results on the\nSafeText dataset, improving safety classification accuracy by 5.29 points.\n","authors":["Alex Mei","Sharon Levy","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09667v1.pdf","comment":"9 pages, 3 figures, 5 tables"},{"id":"http://arxiv.org/abs/2207.10409v2","updated":"2022-12-19T17:22:49Z","published":"2022-07-21T11:00:44Z","title":"Sequence Models for Drone vs Bird Classification","summary":"  Drone detection has become an essential task in object detection as drone\ncosts have decreased and drone technology has improved. It is, however,\ndifficult to detect distant drones when there is weak contrast, long range, and\nlow visibility. In this work, we propose several sequence classification\narchitectures to reduce the detected false-positive ratio of drone tracks.\nMoreover, we propose a new drone vs. bird sequence classification dataset to\ntrain and evaluate the proposed architectures. 3D CNN, LSTM, and Transformer\nbased sequence classification architectures have been trained on the proposed\ndataset to show the effectiveness of the proposed idea. As experiments show,\nusing sequence information, bird classification and overall F1 scores can be\nincreased by up to 73% and 35%, respectively. Among all sequence classification\nmodels, R(2+1)D-based fully convolutional model yields the best transfer\nlearning and fine-tuning results.\n","authors":["Fatih Cagatay Akyon","Erdem Akagunduz","Sinan Onur Altinuc","Alptekin Temizel"],"pdf_url":"https://arxiv.org/pdf/2207.10409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09641v1","updated":"2022-12-19T17:16:41Z","published":"2022-12-19T17:16:41Z","title":"Uncovering the Origins of Instability in Dynamical Systems: How\n  Attention Mechanism Can Help?","summary":"  The behavior of the network and its stability are governed by both dynamics\nof individual nodes as well as their topological interconnections. Attention\nmechanism as an integral part of neural network models was initially designed\nfor natural language processing (NLP), and so far, has shown excellent\nperformance in combining dynamics of individual nodes and the coupling\nstrengths between them within a network. Despite undoubted impact of attention\nmechanism, it is not yet clear why some nodes of a network get higher attention\nweights. To come up with more explainable solutions, we tried to look at the\nproblem from stability perspective. Based on stability theory, negative\nconnections in a network can create feedback loops or other complex structures\nby allowing information to flow in the opposite direction. These structures\nplay a critical role in the dynamics of a complex system and can contribute to\nabnormal synchronization, amplification, or suppression. We hypothesized that\nthose nodes that are involved in organizing such structures can push the entire\nnetwork into instability modes and therefore need higher attention during\nanalysis. To test this hypothesis, attention mechanism along with spectral and\ntopological stability analyses was performed on a real-world numerical problem,\ni.e., a linear Multi Input Multi Output state-space model of a piezoelectric\ntube actuator. The findings of our study suggest that the attention should be\ndirected toward the collective behaviour of imbalanced structures and\npolarity-driven structural instabilities within the network. The results\ndemonstrated that the nodes receiving more attention cause more instability in\nthe system. Our study provides a proof of concept to understand why perturbing\nsome nodes of a network may cause dramatic changes in the network dynamics.\n","authors":["Nooshin Bahador","Milad Lankarany"],"pdf_url":"https://arxiv.org/pdf/2212.09641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09637v1","updated":"2022-12-19T17:13:59Z","published":"2022-12-19T17:13:59Z","title":"A Sequential Concept Drift Detection Method for On-Device Learning on\n  Low-End Edge Devices","summary":"  A practical issue of edge AI systems is that data distributions of trained\ndataset and deployed environment may differ due to noise and environmental\nchanges over time. Such a phenomenon is known as a concept drift, and this gap\ndegrades the performance of edge AI systems and may introduce system failures.\nTo address this gap, a retraining of neural network models triggered by concept\ndrift detection is a practical approach. However, since available compute\nresources are strictly limited in edge devices, in this paper we propose a\nlightweight concept drift detection method in cooperation with a recently\nproposed on-device learning technique of neural networks. In this case, both\nthe neural network retraining and the proposed concept drift detection are done\nby sequential computation only to reduce computation cost and memory\nutilization. Evaluation results of the proposed approach shows that while the\naccuracy is decreased by 3.8%-4.3% compared to existing batch-based detection\nmethods, it decreases the memory size by 88.9%-96.4% and the execution time by\n1.3%-83.8%. As a result, the combination of the neural network retraining and\nthe proposed concept drift detection method is demonstrated on Raspberry Pi\nPico that has 264kB memory.\n","authors":["Takeya Yamada","Hiroki Matsutani"],"pdf_url":"https://arxiv.org/pdf/2212.09637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09633v1","updated":"2022-12-19T17:10:06Z","published":"2022-12-19T17:10:06Z","title":"Towards Assessing Data Bias in Clinical Trials","summary":"  Algorithms and technologies are essential tools that pervade all aspects of\nour daily lives. In the last decades, health care research benefited from new\ncomputer-based recruiting methods, the use of federated architectures for data\nstorage, the introduction of innovative analyses of datasets, and so on.\nNevertheless, health care datasets can still be affected by data bias. Due to\ndata bias, they provide a distorted view of reality, leading to wrong analysis\nresults and, consequently, decisions. For example, in a clinical trial that\nstudied the risk of cardiovascular diseases, predictions were wrong due to the\nlack of data on ethnic minorities. It is, therefore, of paramount importance\nfor researchers to acknowledge data bias that may be present in the datasets\nthey use, eventually adopt techniques to mitigate them and control if and how\nanalyses results are impacted. This paper proposes a method to address bias in\ndatasets that: (i) defines the types of data bias that may be present in the\ndataset, (ii) characterizes and quantifies data bias with adequate metrics,\n(iii) provides guidelines to identify, measure, and mitigate data bias for\ndifferent data sources. The method we propose is applicable both for\nprospective and retrospective clinical trials. We evaluate our proposal both\nthrough theoretical considerations and through interviews with researchers in\nthe health care environment.\n","authors":["Chiara Criscuolo","Tommaso Dolci","Mattia Salnitri"],"pdf_url":"https://arxiv.org/pdf/2212.09633v1.pdf","comment":"13 pages, 6 figures, accepted for publication at The Eighth\n  International Workshop on Data Management and Analytics for Medicine and\n  Healthcare (VLDB DMAH 2022)"},{"id":"http://arxiv.org/abs/2204.12676v2","updated":"2022-12-19T17:09:57Z","published":"2022-04-27T03:07:39Z","title":"The Multimarginal Optimal Transport Formulation of Adversarial\n  Multiclass Classification","summary":"  We study a family of adversarial multiclass classification problems and\nprovide equivalent reformulations in terms of: 1) a family of generalized\nbarycenter problems introduced in the paper and 2) a family of multimarginal\noptimal transport problems where the number of marginals is equal to the number\nof classes in the original classification problem. These new theoretical\nresults reveal a rich geometric structure of adversarial learning problems in\nmulticlass classification and extend recent results restricted to the binary\nclassification setting. A direct computational implication of our results is\nthat by solving either the barycenter problem and its dual, or the MOT problem\nand its dual, we can recover the optimal robust classification rule and the\noptimal adversarial strategy for the original adversarial problem. Examples\nwith synthetic and real data illustrate our results.\n","authors":["Nicolas Garcia Trillos","Matt Jacobs","Jakwang Kim"],"pdf_url":"https://arxiv.org/pdf/2204.12676v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09631v1","updated":"2022-12-19T17:06:58Z","published":"2022-12-19T17:06:58Z","title":"Optimal Transport for Unsupervised Hallucination Detection in Neural\n  Machine Translation","summary":"  Neural machine translation (NMT) has become the de-facto standard in\nreal-world machine translation applications. However, NMT models can\nunpredictably produce severely pathological translations, known as\nhallucinations, that seriously undermine user trust. It becomes thus crucial to\nimplement effective preventive strategies to guarantee their proper\nfunctioning. In this paper, we address the problem of hallucination detection\nin NMT by following a simple intuition: as hallucinations are detached from the\nsource content, they exhibit encoder-decoder attention patterns that are\nstatistically different from those of good quality translations. We frame this\nproblem with an optimal transport formulation and propose a fully unsupervised,\nplug-in detector that can be used with any attention-based NMT model.\nExperimental results show that our detector not only outperforms all previous\nmodel-based detectors, but is also competitive with detectors that employ large\nmodels trained on millions of samples.\n","authors":["Nuno M. Guerreiro","Pierre Colombo","Pablo Piantanida","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2212.09631v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.07338v4","updated":"2022-12-19T17:04:43Z","published":"2022-07-15T08:30:33Z","title":"Context-sensitive neocortical neurons transform the effectiveness and\n  efficiency of neural information processing","summary":"  Deep learning (DL) can arguably achieve superhuman performance in many\nreal-world domains but at the cost of unsustainably high energy levels. We\nhypothesise that the fundamental problem lies in its intrinsic dependence on\nsimplified 'point' neurons that inherently maximise the transmission of\ninformation irrespective of whether the information is relevant to other\nneurons or for the long-term benefit of the whole network. This leads to\nunnecessary neural firing and conflicting messages to higher perceptual layers,\nwhich makes DL energy inefficient and hard to train. We can circumvent this\nlimitation of DL by mimicking a context-sensitive two-point neocortical neuron\nthat at one point receives input from diverse neurons as context to amplify and\nsuppress the transmission of coherent and incoherent feedforward (FF)\ninformation received at the other point, respectively. We show that a deep\nnetwork composed of such local processors seeks to maximise agreement between\nthe active neurons, thus restricting the transmission of conflicting\ninformation to higher levels and reducing the amount of neural activity\nrequired to process large amounts of heterogeneous real-world data. As shown to\nbe far more effective and efficient than current forms of DL, this two-point\nneuron study offers a step-change in transforming the cellular foundations of\ndeep network architectures.\n","authors":["Ahsan Adeel","Mario Franco","Mohsin Raza","Khubaib Ahmed"],"pdf_url":"https://arxiv.org/pdf/2207.07338v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09612v1","updated":"2022-12-19T16:50:58Z","published":"2022-12-19T16:50:58Z","title":"Taming Lagrangian Chaos with Multi-Objective Reinforcement Learning","summary":"  We consider the problem of two active particles in 2D complex flows with the\nmulti-objective goals of minimizing both the dispersion rate and the energy\nconsumption of the pair. We approach the problem by means of Multi Objective\nReinforcement Learning (MORL), combining scalarization techniques together with\na Q-learning algorithm, for Lagrangian drifters that have variable swimming\nvelocity. We show that MORL is able to find a set of trade-off solutions\nforming an optimal Pareto frontier. As a benchmark, we show that a set of\nheuristic strategies are dominated by the MORL solutions. We consider the\nsituation in which the agents cannot update their control variables\ncontinuously, but only after a discrete (decision) time, $\\tau$. We show that\nthere is a range of decision times, in between the Lyapunov time and the\ncontinuous updating limit, where Reinforcement Learning finds strategies that\nsignificantly improve over heuristics. In particular, we discuss how large\ndecision times require enhanced knowledge of the flow, whereas for smaller\n$\\tau$ all a priori heuristic strategies become Pareto optimal.\n","authors":["Chiara Calascibetta","Luca Biferale","Francesco Borra","Antonio Celani","Massimo Cencini"],"pdf_url":"https://arxiv.org/pdf/2212.09612v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.09606v1","updated":"2022-12-19T16:43:44Z","published":"2022-12-19T16:43:44Z","title":"Discrimination, calibration, and point estimate accuracy of\n  GRU-D-Weibull architecture for real-time individualized endpoint prediction","summary":"  Real-time individual endpoint prediction has always been a challenging task\nbut of great clinic utility for both patients and healthcare providers. With\n6,879 chronic kidney disease stage 4 (CKD4) patients as a use case, we explored\nthe feasibility and performance of gated recurrent units with decay that models\nWeibull probability density function (GRU-D-Weibull) as a semi-parametric\nlongitudinal model for real-time individual endpoint prediction. GRU-D-Weibull\nhas a maximum C-index of 0.77 at 4.3 years of follow-up, compared to 0.68\nachieved by competing models. The L1-loss of GRU-D-Weibull is ~66% of XGB(AFT),\n~60% of MTLR, and ~30% of AFT model at CKD4 index date. The average absolute\nL1-loss of GRU-D-Weibull is around one year, with a minimum of 40% Parkes\nserious error after index date. GRU-D-Weibull is not calibrated and\nsignificantly underestimates true survival probability. Feature importance\ntests indicate blood pressure becomes increasingly important during follow-up,\nwhile eGFR and blood albumin are less important. Most continuous features have\nnon-linear/parabola impact on predicted survival time, and the results are\ngenerally consistent with existing knowledge. GRU-D-Weibull as a\nsemi-parametric temporal model shows advantages in built-in parameterization of\nmissing, native support for asynchronously arrived measurement, capability of\noutput both probability and point estimates at arbitrary time point for\narbitrary prediction horizon, improved discrimination and point estimate\naccuracy after incorporating newly arrived data. Further research on its\nperformance with more comprehensive input features, in-process or post-process\ncalibration are warranted to benefit CKD4 or alike terminally-ill patients.\n","authors":["Xiaoyang Ruan","Liwei Wang","Michelle Mai","Charat Thongprayoon","Wisit Cheungpasitporn","Hongfang Liu"],"pdf_url":"https://arxiv.org/pdf/2212.09606v1.pdf","comment":"30 pages, 3 tables, 1 supplementary table, 9 figures, 8 supplementary\n  figures, 52 references"},{"id":"http://arxiv.org/abs/2206.01152v2","updated":"2022-12-19T16:36:02Z","published":"2022-06-02T17:09:51Z","title":"Causal Structure Learning: a Combinatorial Perspective","summary":"  In this review, we discuss approaches for learning causal structure from\ndata, also called causal discovery. In particular, we focus on approaches for\nlearning directed acyclic graphs (DAGs) and various generalizations which allow\nfor some variables to be unobserved in the available data. We devote special\nattention to two fundamental combinatorial aspects of causal structure\nlearning. First, we discuss the structure of the search space over causal\ngraphs. Second, we discuss the structure of equivalence classes over causal\ngraphs, i.e., sets of graphs which represent what can be learned from\nobservational data alone, and how these equivalence classes can be refined by\nadding interventional data.\n","authors":["Chandler Squires","Caroline Uhler"],"pdf_url":"https://arxiv.org/pdf/2206.01152v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08410v2","updated":"2022-12-19T16:33:30Z","published":"2022-12-16T11:24:42Z","title":"Teaching Small Language Models to Reason","summary":"  Chain of thought prompting successfully improves the reasoning capabilities\nof large language models, achieving state of the art results on a range of\ndatasets. However, these reasoning capabilities only appear to emerge in models\nwith a size of over 100 billion parameters. In this paper, we explore the\ntransfer of such reasoning capabilities to models with less than 100 billion\nparameters via knowledge distillation. Specifically, we finetune a student\nmodel on the chain of thought outputs generated by a larger teacher model. Our\nexperiments show that the proposed method improves task performance across\narithmetic, commonsense and symbolic reasoning datasets. For example, the\naccuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on\nPaLM-540B generated chains of thought.\n","authors":["Lucie Charlotte Magister","Jonathan Mallinson","Jakub Adamek","Eric Malmi","Aliaksei Severyn"],"pdf_url":"https://arxiv.org/pdf/2212.08410v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09597v1","updated":"2022-12-19T16:32:42Z","published":"2022-12-19T16:32:42Z","title":"Reasoning with Language Model Prompting: A Survey","summary":"  Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions.\n","authors":["Shuofei Qiao","Yixin Ou","Ningyu Zhang","Xiang Chen","Yunzhi Yao","Shumin Deng","Chuanqi Tan","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2212.09597v1.pdf","comment":"Work in progress and resources are available at\n  https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically)"},{"id":"http://arxiv.org/abs/2212.09586v1","updated":"2022-12-19T16:19:24Z","published":"2022-12-19T16:19:24Z","title":"Learning Latent Representations to Co-Adapt to Humans","summary":"  When robots interact with humans in homes, roads, or factories the human's\nbehavior often changes in response to the robot. Non-stationary humans are\nchallenging for robot learners: actions the robot has learned to coordinate\nwith the original human may fail after the human adapts to the robot. In this\npaper we introduce an algorithmic formalism that enables robots (i.e., ego\nagents) to co-adapt alongside dynamic humans (i.e., other agents) using only\nthe robot's low-level states, actions, and rewards. A core challenge is that\nhumans not only react to the robot's behavior, but the way in which humans\nreact inevitably changes both over time and between users. To deal with this\nchallenge, our insight is that -- instead of building an exact model of the\nhuman -- robots can learn and reason over high-level representations of the\nhuman's policy and policy dynamics. Applying this insight we develop RILI:\nRobustly Influencing Latent Intent. RILI first embeds low-level robot\nobservations into predictions of the human's latent strategy and strategy\ndynamics. Next, RILI harnesses these predictions to select actions that\ninfluence the adaptive human towards advantageous, high reward behaviors over\nrepeated interactions. We demonstrate that -- given RILI's measured performance\nwith users sampled from an underlying distribution -- we can probabilistically\nbound RILI's expected performance across new humans sampled from the same\ndistribution. Our simulated experiments compare RILI to state-of-the-art\nrepresentation and reinforcement learning baselines, and show that RILI better\nlearns to coordinate with imperfect, noisy, and time-varying agents. Finally,\nwe conduct two user studies where RILI co-adapts alongside actual humans in a\ngame of tag and a tower-building task. See videos of our user studies here:\nhttps://youtu.be/WYGO5amDXbQ\n","authors":["Sagar Parekh","Dylan P. Losey"],"pdf_url":"https://arxiv.org/pdf/2212.09586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.04236v2","updated":"2022-12-19T16:14:47Z","published":"2022-03-08T17:52:57Z","title":"A Complete Characterization of Linear Estimators for Offline Policy\n  Evaluation","summary":"  Offline policy evaluation is a fundamental statistical problem in\nreinforcement learning that involves estimating the value function of some\ndecision-making policy given data collected by a potentially different policy.\nIn order to tackle problems with complex, high-dimensional observations, there\nhas been significant interest from theoreticians and practitioners alike in\nunderstanding the possibility of function approximation in reinforcement\nlearning. Despite significant study, a sharp characterization of when we might\nexpect offline policy evaluation to be tractable, even in the simplest setting\nof linear function approximation, has so far remained elusive, with a\nsurprising number of strong negative results recently appearing in the\nliterature.\n  In this work, we identify simple control-theoretic and linear-algebraic\nconditions that are necessary and sufficient for classical methods, in\nparticular Fitted Q-iteration (FQI) and least squares temporal difference\nlearning (LSTD), to succeed at offline policy evaluation. Using this\ncharacterization, we establish a precise hierarchy of regimes under which these\nestimators succeed. We prove that LSTD works under strictly weaker conditions\nthan FQI. Furthermore, we establish that if a problem is not solvable via LSTD,\nthen it cannot be solved by a broad class of linear estimators, even in the\nlimit of infinite data. Taken together, our results provide a complete picture\nof the behavior of linear estimators for offline policy evaluation, unify\npreviously disparate analyses of canonical algorithms, and provide\nsignificantly sharper notions of the underlying statistical complexity of\noffline policy evaluation.\n","authors":["Juan C. Perdomo","Akshay Krishnamurthy","Peter Bartlett","Sham Kakade"],"pdf_url":"https://arxiv.org/pdf/2203.04236v2.pdf","comment":"added extensions to misspecified case, comparisons to Bellman\n  residual minimization, 41 pages"},{"id":"http://arxiv.org/abs/2212.09567v1","updated":"2022-12-19T15:59:00Z","published":"2022-12-19T15:59:00Z","title":"Answering Complex Logical Queries on Knowledge Graphs via Query Tree\n  Optimization","summary":"  Answering complex logical queries on incomplete knowledge graphs is a\nchallenging task, and has been widely studied. Embedding-based methods require\ntraining on complex queries, and cannot generalize well to out-of-distribution\nquery structures. Recent work frames this task as an end-to-end optimization\nproblem, and it only requires a pretrained link predictor. However, due to the\nexponentially large combinatorial search space, the optimal solution can only\nbe approximated, limiting the final accuracy. In this work, we propose QTO\n(Query Tree Optimization) that can efficiently find the exact optimal solution.\nQTO finds the optimal solution by a forward-backward propagation on the\ntree-like computation graph, i.e., query tree. In particular, QTO utilizes the\nindependence encoded in the query tree to reduce the search space, where only\nlocal computations are involved during the optimization procedure. Experiments\non 3 datasets show that QTO obtains state-of-the-art performance on complex\nquery answering, outperforming previous best results by an average of 22%.\nMoreover, QTO can interpret the intermediate solutions for each of the one-hop\natoms in the query with over 90% accuracy.\n","authors":["Yushi Bai","Xin Lv","Juanzi Li","Lei Hou"],"pdf_url":"https://arxiv.org/pdf/2212.09567v1.pdf","comment":"Code is available at https://github.com/bys0318/QTO"},{"id":"http://arxiv.org/abs/2203.02351v2","updated":"2022-12-19T15:45:33Z","published":"2022-03-04T14:40:44Z","title":"Uncertainty Estimation for Heatmap-based Landmark Localization","summary":"  Automatic anatomical landmark localization has made great strides by\nleveraging deep learning methods in recent years. The ability to quantify the\nuncertainty of these predictions is a vital component needed for these methods\nto be adopted in clinical settings, where it is imperative that erroneous\npredictions are caught and corrected. We propose Quantile Binning, a\ndata-driven method to categorize predictions by uncertainty with estimated\nerror bounds. Our framework can be applied to any continuous uncertainty\nmeasure, allowing straightforward identification of the best subset of\npredictions with accompanying estimated error bounds. We facilitate easy\ncomparison between uncertainty measures by constructing two evaluation metrics\nderived from Quantile Binning. We compare and contrast three epistemic\nuncertainty measures (two baselines, and a proposed method combining aspects of\nthe two), derived from two heatmap-based landmark localization model paradigms\n(U-Net and patch-based). We show results across three datasets, including a\npublicly available Cephalometric dataset. We illustrate how filtering out gross\nmispredictions caught in our Quantile Bins significantly improves the\nproportion of predictions under an acceptable error threshold. Finally, we\ndemonstrate that Quantile Binning remains effective on landmarks with high\naleatoric uncertainty caused by inherent landmark ambiguity, and offer\nrecommendations on which uncertainty measure to use and how to use it. The code\nand data are available at https://github.com/schobs/qbin.\n","authors":["Lawrence Schobs","Andrew J. Swift","Haiping Lu"],"pdf_url":"https://arxiv.org/pdf/2203.02351v2.pdf","comment":"14 pages, in IEEE Transactions on Medical Imaging, 2022"},{"id":"http://arxiv.org/abs/2212.09541v1","updated":"2022-12-19T15:33:34Z","published":"2022-12-19T15:33:34Z","title":"Positive-incentive Noise","summary":"  Noise is conventionally viewed as a severe problem in diverse fields, e.g.,\nengineering, learning systems. However, this paper aims to investigate whether\nthe conventional proposition always holds. It begins with the definition of\ntask entropy, which extends from the information entropy and measures the\ncomplexity of the task. After introducing the task entropy, the noise can be\nclassified into two kinds, Positive-incentive noise (Pi-noise or $\\pi$-noise)\nand pure noise, according to whether the noise can reduce the complexity of the\ntask. Interestingly, as shown theoretically and empirically, even the simple\nrandom noise can be the $\\pi$-noise that simplifies the task. $\\pi$-noise\noffers new explanations for some models and provides a new principle for some\nfields, such as multi-task learning, adversarial training, etc. Moreover, it\nreminds us to rethink the investigation of noises.\n","authors":["Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2212.09541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09535v1","updated":"2022-12-19T15:24:45Z","published":"2022-12-19T15:24:45Z","title":"BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting","summary":"  The BLOOM model is a large open-source multilingual language model capable of\nzero-shot learning, but its pretraining was limited to 46 languages. To improve\nits zero-shot performance on unseen languages, it is desirable to adapt BLOOM,\nbut previous works have only explored adapting small language models. In this\nwork, we apply existing language adaptation strategies to BLOOM and benchmark\nits zero-shot prompting performance on eight new languages. We find language\nadaptation to be effective at improving zero-shot performance in new languages.\nSurprisingly, adapter-based finetuning is more effective than continued\npretraining for large models. In addition, we discover that prompting\nperformance is not significantly affected by language specifics, such as the\nwriting system. It is primarily determined by the size of the language\nadaptation data. We also add new languages to BLOOMZ, which is a multitask\nfinetuned version of BLOOM capable of following task instructions zero-shot. We\nfind including a new language in the multitask fine-tuning mixture to be the\nmost effective method to teach BLOOMZ a new language. We conclude that with\nsufficient training data language adaptation can generalize well to diverse\nlanguages. Our code is available at\n\\url{https://github.com/bigscience-workshop/multilingual-modeling/}.\n","authors":["Zheng-Xin Yong","Hailey Schoelkopf","Niklas Muennighoff","Alham Fikri Aji","David Ifeoluwa Adelani","Khalid Almubarak","M Saiful Bari","Lintang Sutawika","Jungo Kasai","Ahmed Baruwa","Genta Indra Winata","Stella Biderman","Dragomir Radev","Vassilina Nikoulina"],"pdf_url":"https://arxiv.org/pdf/2212.09535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09518v1","updated":"2022-12-19T14:57:52Z","published":"2022-12-19T14:57:52Z","title":"FedTADBench: Federated Time-Series Anomaly Detection Benchmark","summary":"  Time series anomaly detection strives to uncover potential abnormal behaviors\nand patterns from temporal data, and has fundamental significance in diverse\napplication scenarios. Constructing an effective detection model usually\nrequires adequate training data stored in a centralized manner, however, this\nrequirement sometimes could not be satisfied in realistic scenarios. As a\nprevailing approach to address the above problem, federated learning has\ndemonstrated its power to cooperate with the distributed data available while\nprotecting the privacy of data providers. However, it is still unclear that how\nexisting time series anomaly detection algorithms perform with decentralized\ndata storage and privacy protection through federated learning. To study this,\nwe conduct a federated time series anomaly detection benchmark, named\nFedTADBench, which involves five representative time series anomaly detection\nalgorithms and four popular federated learning methods. We would like to answer\nthe following questions: (1)How is the performance of time series anomaly\ndetection algorithms when meeting federated learning? (2) Which federated\nlearning method is the most appropriate one for time series anomaly detection?\n(3) How do federated time series anomaly detection approaches perform on\ndifferent partitions of data in clients? Numbers of results as well as\ncorresponding analysis are provided from extensive experiments with various\nsettings. The source code of our benchmark is publicly available at\nhttps://github.com/fanxingliu2020/FedTADBench.\n","authors":["Fanxing Liu","Cheng Zeng","Le Zhang","Yingjie Zhou","Qing Mu","Yanru Zhang","Ling Zhang","Ce Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.09518v1.pdf","comment":"8 pages, 6 figures, published by IEEE HPCC 2022"},{"id":"http://arxiv.org/abs/2212.09517v1","updated":"2022-12-19T14:57:13Z","published":"2022-12-19T14:57:13Z","title":"Fake it, Mix it, Segment it: Bridging the Domain Gap Between Lidar\n  Sensors","summary":"  Segmentation of lidar data is a task that provides rich, point-wise\ninformation about the environment of robots or autonomous vehicles. Currently\nbest performing neural networks for lidar segmentation are fine-tuned to\nspecific datasets. Switching the lidar sensor without retraining on a big set\nof annotated data from the new sensor creates a domain shift, which causes the\nnetwork performance to drop drastically. In this work we propose a new method\nfor lidar domain adaption, in which we use annotated panoptic lidar datasets\nand recreate the recorded scenes in the structure of a different lidar sensor.\nWe narrow the domain gap to the target data by recreating panoptic data from\none domain in another and mixing the generated data with parts of (pseudo)\nlabeled target domain data. Our method improves the nuScenes to SemanticKITTI\nunsupervised domain adaptation performance by 15.2 mean Intersection over Union\npoints (mIoU) and by 48.3 mIoU in our semi-supervised approach. We demonstrate\na similar improvement for the SemanticKITTI to nuScenes domain adaptation by\n21.8 mIoU and 51.5 mIoU, respectively. We compare our method with two state of\nthe art approaches for semantic lidar segmentation domain adaptation with a\nsignificant improvement for unsupervised and semi-supervised domain adaptation.\nFurthermore we successfully apply our proposed method to two entirely unlabeled\ndatasets of two state of the art lidar sensors Velodyne Alpha Prime and\nInnovizTwo, and train well performing semantic segmentation networks for both.\n","authors":["Frederik Hasecke","Pascal Colling","Anton Kummert"],"pdf_url":"https://arxiv.org/pdf/2212.09517v1.pdf","comment":"10 pages, 7 figures, to be published in proceedings of \"International\n  Conference on Pattern Recognition Applications and Methods 2023\""},{"id":"http://arxiv.org/abs/2212.09513v1","updated":"2022-12-19T14:48:54Z","published":"2022-12-19T14:48:54Z","title":"Stochastic Inexact Augmented Lagrangian Method for Nonconvex Expectation\n  Constrained Optimization","summary":"  Many real-world problems not only have complicated nonconvex functional\nconstraints but also use a large number of data points. This motivates the\ndesign of efficient stochastic methods on finite-sum or expectation constrained\nproblems. In this paper, we design and analyze stochastic inexact augmented\nLagrangian methods (Stoc-iALM) to solve problems involving a nonconvex\ncomposite (i.e. smooth+nonsmooth) objective and nonconvex smooth functional\nconstraints. We adopt the standard iALM framework and design a subroutine by\nusing the momentum-based variance-reduced proximal stochastic gradient method\n(PStorm) and a postprocessing step. Under certain regularity conditions\n(assumed also in existing works), to reach an $\\varepsilon$-KKT point in\nexpectation, we establish an oracle complexity result of $O(\\varepsilon^{-5})$,\nwhich is better than the best-known $O(\\varepsilon^{-6})$ result. Numerical\nexperiments on the fairness constrained problem and the Neyman-Pearson\nclassification problem with real data demonstrate that our proposed method\noutperforms an existing method with the previously best-known complexity\nresult.\n","authors":["Zichong Li","Pin-Yu Chen","Sijia Liu","Songtao Lu","Yangyang Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09510v1","updated":"2022-12-19T14:46:57Z","published":"2022-12-19T14:46:57Z","title":"Near-optimal Policy Identification in Active Reinforcement Learning","summary":"  Many real-world reinforcement learning tasks require control of complex\ndynamical systems that involve both costly data acquisition processes and large\nstate spaces. In cases where the transition dynamics can be readily evaluated\nat specified states (e.g., via a simulator), agents can operate in what is\noften referred to as planning with a \\emph{generative model}. We propose the\nAE-LSVI algorithm for best-policy identification, a novel variant of the\nkernelized least-squares value iteration (LSVI) algorithm that combines\noptimism with pessimism for active exploration (AE). AE-LSVI provably\nidentifies a near-optimal policy \\emph{uniformly} over an entire state space\nand achieves polynomial sample complexity guarantees that are independent of\nthe number of states. When specialized to the recently introduced offline\ncontextual Bayesian optimization setting, our algorithm achieves improved\nsample complexity bounds. Experimentally, we demonstrate that AE-LSVI\noutperforms other RL algorithms in a variety of environments when robustness to\nthe initial state is required.\n","authors":["Xiang Li","Viraj Mehta","Johannes Kirschner","Ian Char","Willie Neiswanger","Jeff Schneider","Andreas Krause","Ilija Bogunovic"],"pdf_url":"https://arxiv.org/pdf/2212.09510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09508v1","updated":"2022-12-19T14:44:37Z","published":"2022-12-19T14:44:37Z","title":"A note on the smallest eigenvalue of the empirical covariance of causal\n  Gaussian processes","summary":"  We present a simple proof for bounding the smallest eigenvalue of the\nempirical covariance in a causal Gaussian process. Along the way, we establish\na one-sided tail inequality for Gaussian quadratic forms using a causal\ndecomposition. Our proof only uses elementary facts about the Gaussian\ndistribution and the union bound.\n","authors":["Ingvar Ziemann"],"pdf_url":"https://arxiv.org/pdf/2212.09508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09507v1","updated":"2022-12-19T14:43:22Z","published":"2022-12-19T14:43:22Z","title":"VC dimensions of group convolutional neural networks","summary":"  We study the generalization capacity of group convolutional neural networks.\nWe identify precise estimates for the VC dimensions of simple sets of group\nconvolutional neural networks. In particular, we find that for infinite groups\nand appropriately chosen convolutional kernels, already two-parameter families\nof convolutional neural networks have an infinite VC dimension, despite being\ninvariant to the action of an infinite group.\n","authors":["Philipp Christian Petersen","Anna Sepliarskaia"],"pdf_url":"https://arxiv.org/pdf/2212.09507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16509v2","updated":"2022-12-19T14:26:02Z","published":"2022-11-29T12:08:06Z","title":"Multimodal Learning for Multi-Omics: A Survey","summary":"  With advanced imaging, sequencing, and profiling technologies, multiple omics\ndata become increasingly available and hold promises for many healthcare\napplications such as cancer diagnosis and treatment. Multimodal learning for\nintegrative multi-omics analysis can help researchers and practitioners gain\ndeep insights into human diseases and improve clinical decisions. However,\nseveral challenges are hindering the development in this area, including the\navailability of easily accessible open-source tools. This survey aims to\nprovide an up-to-date overview of the data challenges, fusion approaches,\ndatasets, and software tools from several new perspectives. We identify and\ninvestigate various omics data challenges that can help us understand the field\nbetter. We categorize fusion approaches comprehensively to cover existing\nmethods in this area. We collect existing open-source tools to facilitate their\nbroader utilization and development. We explore a broad range of omics data\nmodalities and a list of accessible datasets. Finally, we summarize future\ndirections that can potentially address existing gaps and answer the pressing\nneed to advance multimodal learning for multi-omics data analysis.\n","authors":["Sina Tabakhi","Mohammod Naimul Islam Suvon","Pegah Ahadian","Haiping Lu"],"pdf_url":"https://arxiv.org/pdf/2211.16509v2.pdf","comment":"52 pages, 3 figures; Revised matrix factorization fusion section"},{"id":"http://arxiv.org/abs/2211.15413v2","updated":"2022-12-19T14:23:25Z","published":"2022-11-23T22:43:48Z","title":"Towards Developing Safety Assurance Cases for Learning-Enabled Medical\n  Cyber-Physical Systems","summary":"  Machine Learning (ML) technologies have been increasingly adopted in Medical\nCyber-Physical Systems (MCPS) to enable smart healthcare. Assuring the safety\nand effectiveness of learning-enabled MCPS is challenging, as such systems must\naccount for diverse patient profiles and physiological dynamics and handle\noperational uncertainties. In this paper, we develop a safety assurance case\nfor ML controllers in learning-enabled MCPS, with an emphasis on establishing\nconfidence in the ML-based predictions. We present the safety assurance case in\ndetail for Artificial Pancreas Systems (APS) as a representative application of\nlearning-enabled MCPS, and provide a detailed analysis by implementing a deep\nneural network for the prediction in APS. We check the sufficiency of the ML\ndata and analyze the correctness of the ML-based prediction using formal\nverification. Finally, we outline open research problems based on our\nexperience in this paper.\n","authors":["Maryam Bagheri","Josephine Lamp","Xugui Zhou","Lu Feng","Homa Alemzadeh"],"pdf_url":"https://arxiv.org/pdf/2211.15413v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09483v1","updated":"2022-12-19T14:19:07Z","published":"2022-12-19T14:19:07Z","title":"Adaptive Control of Client Selection and Gradient Compression for\n  Efficient Federated Learning","summary":"  Federated learning (FL) allows multiple clients cooperatively train models\nwithout disclosing local data. However, the existing works fail to address all\nthese practical concerns in FL: limited communication resources, dynamic\nnetwork conditions and heterogeneous client properties, which slow down the\nconvergence of FL. To tackle the above challenges, we propose a\nheterogeneity-aware FL framework, called FedCG, with adaptive client selection\nand gradient compression. Specifically, the parameter server (PS) selects a\nrepresentative client subset considering statistical heterogeneity and sends\nthe global model to them. After local training, these selected clients upload\ncompressed model updates matching their capabilities to the PS for aggregation,\nwhich significantly alleviates the communication load and mitigates the\nstraggler effect. We theoretically analyze the impact of both client selection\nand gradient compression on convergence performance. Guided by the derived\nconvergence rate, we develop an iteration-based algorithm to jointly optimize\nclient selection and compression ratio decision using submodular maximization\nand linear programming. Extensive experiments on both real-world prototypes and\nsimulations show that FedCG can provide up to 5.3$\\times$ speedup compared to\nother methods.\n","authors":["Zhida Jiang","Yang Xu","Hongli Xu","Zhiyuan Wang","Chen Qian"],"pdf_url":"https://arxiv.org/pdf/2212.09483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.11072v2","updated":"2022-12-19T14:18:06Z","published":"2022-06-22T13:37:58Z","title":"AlphaMLDigger: A Novel Machine Learning Solution to Explore Excess\n  Return on Investment","summary":"  How to quickly and automatically mine effective information and serve\ninvestment decisions has attracted more and more attention from academia and\nindustry. And new challenges have arisen with the global pandemic. This paper\nproposes a two-phase AlphaMLDigger that effectively finds excessive returns in\na highly fluctuated market. In phase 1, a deep sequential natural language\nprocessing (NLP) model is proposed to transfer Sina Microblog blogs to market\nsentiment. In phase 2, the predicted market sentiment is combined with social\nnetwork indicator features and stock market history features to predict the\nstock movements with different Machine Learning models and optimizers. The\nresults show that the ensemble models achieve an accuracy of 0.984 and\nsignificantly outperform the baseline model. In addition, we find that COVID-19\nbrings data shift to China's stock market.\n","authors":["Jimei Shen","Zhehu Yuan","Yifan Jin"],"pdf_url":"https://arxiv.org/pdf/2206.11072v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.04744v3","updated":"2022-12-19T13:58:03Z","published":"2022-02-09T22:12:19Z","title":"Robust Bayesian Inference for Simulator-based Models via the MMD\n  Posterior Bootstrap","summary":"  Simulator-based models are models for which the likelihood is intractable but\nsimulation of synthetic data is possible. They are often used to describe\ncomplex real-world phenomena, and as such can often be misspecified in\npractice. Unfortunately, existing Bayesian approaches for simulators are known\nto perform poorly in those cases. In this paper, we propose a novel algorithm\nbased on the posterior bootstrap and maximum mean discrepancy estimators. This\nleads to a highly-parallelisable Bayesian inference algorithm with strong\nrobustness properties. This is demonstrated through an in-depth theoretical\nstudy which includes generalisation bounds and proofs of frequentist\nconsistency and robustness of our posterior. The approach is then assessed on a\nrange of examples including a g-and-k distribution and a toggle-switch model.\n","authors":["Charita Dellaporta","Jeremias Knoblauch","Theodoros Damoulas","François-Xavier Briol"],"pdf_url":"https://arxiv.org/pdf/2202.04744v3.pdf","comment":"Accepted for publication (with an oral presentation) at AISTATS 2022.\n  A preliminary version of this paper was accepted in the NeurIPS 2021 workshop\n  \"Your Model is Wrong: Robustness and misspecification in probabilistic\n  modeling\". v2: added some references. v3: corrected small error in theorem 3"},{"id":"http://arxiv.org/abs/2212.09462v1","updated":"2022-12-19T13:57:06Z","published":"2022-12-19T13:57:06Z","title":"Latent Diffusion for Language Generation","summary":"  Diffusion models have achieved great success in modeling continuous data\nmodalities such as images, audio, and video, but have seen limited use in\ndiscrete domains such as language. Recent attempts to adapt diffusion to\nlanguage have presented diffusion as an alternative to autoregressive language\ngeneration. We instead view diffusion as a complementary method that can\naugment the generative capabilities of existing pre-trained language models. We\ndemonstrate that continuous diffusion models can be learned in the latent space\nof a pre-trained encoder-decoder model, enabling us to sample continuous latent\nrepresentations that can be decoded into natural language with the pre-trained\ndecoder. We show that our latent diffusion models are more effective at\nsampling novel text from data distributions than a strong autoregressive\nbaseline and also enable controllable generation.\n","authors":["Justin Lovelace","Varsha Kishore","Chao Wan","Eliot Shekhtman","Kilian Weinberger"],"pdf_url":"https://arxiv.org/pdf/2212.09462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09458v1","updated":"2022-12-19T13:51:06Z","published":"2022-12-19T13:51:06Z","title":"Exploring Optimal Substructure for Out-of-distribution Generalization\n  via Feature-targeted Model Pruning","summary":"  Recent studies show that even highly biased dense networks contain an\nunbiased substructure that can achieve better out-of-distribution (OOD)\ngeneralization than the original model. Existing works usually search the\ninvariant subnetwork using modular risk minimization (MRM) with out-domain\ndata. Such a paradigm may bring about two potential weaknesses: 1) Unfairness,\ndue to the insufficient observation of out-domain data during training; and 2)\nSub-optimal OOD generalization, due to the feature-untargeted model pruning on\nthe whole data distribution. In this paper, we propose a novel Spurious\nFeature-targeted model Pruning framework, dubbed SFP, to automatically explore\ninvariant substructures without referring to the above weaknesses.\nSpecifically, SFP identifies in-distribution (ID) features during training\nusing our theoretically verified task loss, upon which, SFP can perform ID\ntargeted-model pruning that removes branches with strong dependencies on ID\nfeatures. Notably, by attenuating the projections of spurious features into\nmodel space, SFP can push the model learning toward invariant features and pull\nthat out of environmental features, devising optimal OOD generalization.\nMoreover, we also conduct detailed theoretical analysis to provide the\nrationality guarantee and a proof framework for OOD structures via model\nsparsity, and for the first time, reveal how a highly biased data distribution\naffects the model's OOD generalization. Extensive experiments on various OOD\ndatasets show that SFP can significantly outperform both structure-based and\nnon-structure OOD generalization SOTAs, with accuracy improvement up to 4.72%\nand 23.35%, respectively.\n","authors":["Yingchun Wang","Jingcai Guo","Song Guo","Weizhan Zhang","Jie Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.09458v1.pdf","comment":"9 pages;2 figures"},{"id":"http://arxiv.org/abs/2211.16059v2","updated":"2022-12-19T13:35:17Z","published":"2022-11-29T10:10:39Z","title":"On Large-Scale Multiple Testing Over Networks: An Asymptotic Approach","summary":"  This work concerns developing communication- and computation-efficient\nmethods for large-scale multiple testing over networks, which is of interest to\nmany practical applications. We take an asymptotic approach and propose two\nmethods, proportion-matching and greedy aggregation, tailored to distributed\nsettings. The proportion-matching method achieves the global BH performance yet\nonly requires a one-shot communication of the (estimated) proportion of true\nnull hypotheses as well as the number of p-values at each node. By focusing on\nthe asymptotic optimal power, we go beyond the BH procedure by providing an\nexplicit characterization of the asymptotic optimal solution. This leads to the\ngreedy aggregation method that effectively approximate the optimal rejection\nregions at each node, while computation-efficiency comes from the greedy-type\napproach naturally. Extensive numerical results over a variety of challenging\nsettings are provided to support our theoretical findings.\n","authors":["Mehrdad Pournaderi","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2211.16059v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11753v2","updated":"2022-12-19T13:30:28Z","published":"2022-11-20T08:55:58Z","title":"SplitNet: Learnable Clean-Noisy Label Splitting for Learning with Noisy\n  Labels","summary":"  Annotating the dataset with high-quality labels is crucial for performance of\ndeep network, but in real world scenarios, the labels are often contaminated by\nnoise. To address this, some methods were proposed to automatically split clean\nand noisy labels, and learn a semi-supervised learner in a Learning with Noisy\nLabels (LNL) framework. However, they leverage a handcrafted module for\nclean-noisy label splitting, which induces a confirmation bias in the\nsemi-supervised learning phase and limits the performance. In this paper, we\nfor the first time present a learnable module for clean-noisy label splitting,\ndubbed SplitNet, and a novel LNL framework which complementarily trains the\nSplitNet and main network for the LNL task. We propose to use a dynamic\nthreshold based on a split confidence by SplitNet to better optimize\nsemi-supervised learner. To enhance SplitNet training, we also present a risk\nhedging method. Our proposed method performs at a state-of-the-art level\nespecially in high noise ratio settings on various LNL benchmarks.\n","authors":["Daehwan Kim","Kwangrok Ryoo","Hansang Cho","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2211.11753v2.pdf","comment":"project page link: https://ku-cvlab.github.io/SplitNet/"},{"id":"http://arxiv.org/abs/2210.06543v2","updated":"2022-12-19T13:26:21Z","published":"2022-10-12T19:14:07Z","title":"A General Stochastic Optimization Framework for Convergence Bidding","summary":"  Convergence (virtual) bidding is an important part of two-settlement electric\npower markets as it can effectively reduce discrepancies between the day-ahead\nand real-time markets. Consequently, there is extensive research into the\nbidding strategies of virtual participants aiming to obtain optimal bids to\nsubmit to the day-ahead market. In this paper, we introduce a price-based\ngeneral stochastic optimization framework to obtain optimal convergence bid\ncurves. Within this framework, we develop a computationally tractable linear\nprogramming-based optimization model, which produces bid prices and volumes\nsimultaneously. We also show that different approximations and simplifications\nin the general model lead naturally to state-of-the-art convergence bidding\napproaches, such as self-scheduling and opportunistic approaches. Our general\nframework also provides a straightforward way to compare the performance of\nthese models, which is demonstrated by numerical experiments on the California\n(CAISO) market.\n","authors":["Letif Mones","Sean Lovett"],"pdf_url":"https://arxiv.org/pdf/2210.06543v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09429v1","updated":"2022-12-19T13:08:58Z","published":"2022-12-19T13:08:58Z","title":"On the Complexity of Representation Learning in Contextual Linear\n  Bandits","summary":"  In contextual linear bandits, the reward function is assumed to be a linear\ncombination of an unknown reward vector and a given embedding of context-arm\npairs. In practice, the embedding is often learned at the same time as the\nreward vector, thus leading to an online representation learning problem.\nExisting approaches to representation learning in contextual bandits are either\nvery generic (e.g., model-selection techniques or algorithms for learning with\narbitrary function classes) or specialized to particular structures (e.g.,\nnested features or representations with certain spectral properties). As a\nresult, the understanding of the cost of representation learning in contextual\nlinear bandit is still limited. In this paper, we take a systematic approach to\nthe problem and provide a comprehensive study through an instance-dependent\nperspective. We show that representation learning is fundamentally more complex\nthan linear bandits (i.e., learning with a given representation). In\nparticular, learning with a given set of representations is never simpler than\nlearning with the worst realizable representation in the set, while we show\ncases where it can be arbitrarily harder. We complement this result with an\nextensive discussion of how it relates to existing literature and we illustrate\npositive instances where representation learning is as complex as learning with\na fixed representation and where sub-logarithmic regret is achievable.\n","authors":["Andrea Tirinzoni","Matteo Pirotta","Alessandro Lazaric"],"pdf_url":"https://arxiv.org/pdf/2212.09429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.05232v3","updated":"2022-12-19T13:07:15Z","published":"2022-08-10T09:21:28Z","title":"Trustworthy Visual Analytics in Clinical Gait Analysis: A Case Study for\n  Patients with Cerebral Palsy","summary":"  Three-dimensional clinical gait analysis is essential for selecting optimal\ntreatment interventions for patients with cerebral palsy (CP), but generates a\nlarge amount of time series data. For the automated analysis of these data,\nmachine learning approaches yield promising results. However, due to their\nblack-box nature, such approaches are often mistrusted by clinicians. We\npropose gaitXplorer, a visual analytics approach for the classification of\nCP-related gait patterns that integrates Grad-CAM, a well-established\nexplainable artificial intelligence algorithm, for explanations of machine\nlearning classifications. Regions of high relevance for classification are\nhighlighted in the interactive visual interface. The approach is evaluated in a\ncase study with two clinical gait experts. They inspected the explanations for\na sample of eight patients using the visual interface and expressed which\nrelevance scores they found trustworthy and which they found suspicious.\nOverall, the clinicians gave positive feedback on the approach as it allowed\nthem a better understanding of which regions in the data were relevant for the\nclassification.\n","authors":["Alexander Rind","Djordje Slijepčević","Matthias Zeppelzauer","Fabian Unglaube","Andreas Kranzl","Brian Horsak"],"pdf_url":"https://arxiv.org/pdf/2208.05232v3.pdf","comment":"7 pages, 4 figures; supplemental material 9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.09426v1","updated":"2022-12-19T13:01:51Z","published":"2022-12-19T13:01:51Z","title":"Multistep Multiappliance Load Prediction","summary":"  A well-performing prediction model is vital for a recommendation system\nsuggesting actions for energy-efficient consumer behavior. However, reliable\nand accurate predictions depend on informative features and a suitable model\ndesign to perform well and robustly across different households and appliances.\nMoreover, customers' unjustifiably high expectations of accurate predictions\nmay discourage them from using the system in the long term. In this paper, we\ndesign a three-step forecasting framework to assess predictability, engineering\nfeatures, and deep learning architectures to forecast 24 hourly load values.\nFirst, our predictability analysis provides a tool for expectation management\nto cushion customers' anticipations. Second, we design several new weather-,\ntime- and appliance-related parameters for the modeling procedure and test\ntheir contribution to the model's prediction performance. Third, we examine six\ndeep learning techniques and compare them to tree- and support vector\nregression benchmarks. We develop a robust and accurate model for the\nappliance-level load prediction based on four datasets from four different\nregions (US, UK, Austria, and Canada) with an equal set of appliances. The\nempirical results show that cyclical encoding of time features and weather\nindicators alongside a long-short term memory (LSTM) model offer the optimal\nperformance.\n","authors":["Alona Zharova","Antonia Scherz"],"pdf_url":"https://arxiv.org/pdf/2212.09426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09412v1","updated":"2022-12-19T12:44:25Z","published":"2022-12-19T12:44:25Z","title":"Difformer: Empowering Diffusion Model on Embedding Space for Text\n  Generation","summary":"  Diffusion models have achieved state-of-the-art synthesis quality on visual\nand audio tasks, and recent works adapt them to textual data by diffusing on\nthe embedding space. But the difference between the continuous data space and\nthe embedding space raises challenges to the diffusion model, which have not\nbeen carefully explored. In this paper, we conduct systematic studies and\nanalyze the challenges threefold. Firstly, the data distribution is learnable\nfor embeddings, which may lead to the collapse of the loss function. Secondly,\nas the norm of embedding varies between popular and rare words, adding the same\nnoise scale will lead to sub-optimal results. In addition, we find that noises\nsampled from a standard Gaussian distribution may distract the diffusion\nprocess. To solve the above challenges, we propose Difformer, a denoising\ndiffusion probabilistic model based on Transformer, which consists of three\ntechniques including utilizing an anchor loss function, a layer normalization\nmodule for embeddings, and a norm factor to the Gaussian noise. All techniques\nare complementary to each other and critical to boosting the model performance\ntogether. Experiments are conducted on benchmark datasets over two seminal text\ngeneration tasks including machine translation and text summarization. The\nresults show that Difformer significantly outperforms the embedding diffusion\nbaselines, while achieving competitive results with strong autoregressive\nbaselines.\n","authors":["Zhujin Gao","Junliang Guo","Xu Tan","Yongxin Zhu","Fang Zhang","Jiang Bian","Linli Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09412v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2208.09478v2","updated":"2022-12-19T12:08:33Z","published":"2022-08-19T17:57:32Z","title":"Communication Size Reduction of Federated Learning based on Neural ODE\n  Model","summary":"  Federated learning is a machine learning method in which data is not\naggregated on a server, but is distributed to the edges, in consideration of\nsecurity and privacy. ResNet is a classic but representative neural network\nthat succeeds in deepening the neural network by learning a residual function\nthat adds the inputs and outputs together. In federated learning, communication\nis performed between the server and edge devices to exchange weight parameters,\nbut ResNet has deep layers and a large number of parameters, so communication\nsize becomes large. In this paper, we use Neural ODE as a lightweight model of\nResNet to reduce communication size in federated learning. In addition, we\nnewly introduce a flexible federated learning using Neural ODE models with\ndifferent number of iterations, which correspond to ResNet with different\ndepths. The CIFAR-10 dataset is used in the evaluation, and the use of Neural\nODE reduces communication size by approximately 90% compared to ResNet. We also\nshow that the proposed flexible federated learning can merge models with\ndifferent iteration counts.\n","authors":["Yuto Hoshino","Hiroki Kawakami","Hiroki Matsutani"],"pdf_url":"https://arxiv.org/pdf/2208.09478v2.pdf","comment":"PDF format error corrected"},{"id":"http://arxiv.org/abs/2212.09396v1","updated":"2022-12-19T12:05:37Z","published":"2022-12-19T12:05:37Z","title":"Rank-1 Matrix Completion with Gradient Descent and Small Random\n  Initialization","summary":"  The nonconvex formulation of matrix completion problem has received\nsignificant attention in recent years due to its affordable complexity compared\nto the convex formulation. Gradient descent (GD) is the simplest yet efficient\nbaseline algorithm for solving nonconvex optimization problems. The success of\nGD has been witnessed in many different problems in both theory and practice\nwhen it is combined with random initialization. However, previous works on\nmatrix completion require either careful initialization or regularizers to\nprove the convergence of GD. In this work, we study the rank-1 symmetric matrix\ncompletion and prove that GD converges to the ground truth when small random\ninitialization is used. We show that in logarithmic amount of iterations, the\ntrajectory enters the region where local convergence occurs. We provide an\nupper bound on the initialization size that is sufficient to guarantee the\nconvergence and show that a larger initialization can be used as more samples\nare available. We observe that implicit regularization effect of GD plays a\ncritical role in the analysis, and for the entire trajectory, it prevents each\nentry from becoming much larger than the others.\n","authors":["Daesung Kim","Hye Won Chung"],"pdf_url":"https://arxiv.org/pdf/2212.09396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09376v1","updated":"2022-12-19T11:26:23Z","published":"2022-12-19T11:26:23Z","title":"Enriching Relation Extraction with OpenIE","summary":"  Relation extraction (RE) is a sub-discipline of information extraction (IE)\nwhich focuses on the prediction of a relational predicate from a\nnatural-language input unit (such as a sentence, a clause, or even a short\nparagraph consisting of multiple sentences and/or clauses). Together with\nnamed-entity recognition (NER) and disambiguation (NED), RE forms the basis for\nmany advanced IE tasks such as knowledge-base (KB) population and verification.\nIn this work, we explore how recent approaches for open information extraction\n(OpenIE) may help to improve the task of RE by encoding structured information\nabout the sentences' principal units, such as subjects, objects, verbal\nphrases, and adverbials, into various forms of vectorized (and hence\nunstructured) representations of the sentences. Our main conjecture is that the\ndecomposition of long and possibly convoluted sentences into multiple smaller\nclauses via OpenIE even helps to fine-tune context-sensitive language models\nsuch as BERT (and its plethora of variants) for RE. Our experiments over two\nannotated corpora, KnowledgeNet and FewRel, demonstrate the improved accuracy\nof our enriched models compared to existing RE approaches. Our best results\nreach 92% and 71% of F1 score for KnowledgeNet and FewRel, respectively,\nproving the effectiveness of our approach on competitive benchmarks.\n","authors":["Alessandro Temperoni","Maria Biryukov","Martin Theobald"],"pdf_url":"https://arxiv.org/pdf/2212.09376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04902v2","updated":"2022-12-19T11:01:25Z","published":"2022-12-07T19:02:45Z","title":"Self-Supervised PPG Representation Learning Shows High Inter-Subject\n  Variability","summary":"  With the progress of sensor technology in wearables, the collection and\nanalysis of PPG signals are gaining more interest. Using Machine Learning, the\ncardiac rhythm corresponding to PPG signals can be used to predict different\ntasks such as activity recognition, sleep stage detection, or more general\nhealth status. However, supervised learning is often limited by the amount of\navailable labeled data, which is typically expensive to obtain. To address this\nproblem, we propose a Self-Supervised Learning (SSL) method with a pretext task\nof signal reconstruction to learn an informative generalized PPG\nrepresentation. The performance of the proposed SSL framework is compared with\ntwo fully supervised baselines. The results show that in a very limited label\ndata setting (10 samples per class or less), using SSL is beneficial, and a\nsimple classifier trained on SSL-learned representations outperforms fully\nsupervised deep neural networks. However, the results reveal that the\nSSL-learned representations are too focused on encoding the subjects.\nUnfortunately, there is high inter-subject variability in the SSL-learned\nrepresentations, which makes working with this data more challenging when\nlabeled data is scarce. The high inter-subject variability suggests that there\nis still room for improvements in learning representations. In general, the\nresults suggest that SSL may pave the way for the broader use of machine\nlearning models on PPG data in label-scarce regimes.\n","authors":["Ramin Ghorbani","Marcel J. T. Reinders","David M. J. Tax"],"pdf_url":"https://arxiv.org/pdf/2212.04902v2.pdf","comment":"The current version has been accepted to be presented at ICMLT 2023;\n  Typo corrected in the second author's name"},{"id":"http://arxiv.org/abs/2211.02069v2","updated":"2022-12-19T10:53:46Z","published":"2022-11-03T18:01:12Z","title":"LMentry: A Language Model Benchmark of Elementary Language Tasks","summary":"  As the performance of large language models rapidly improves, benchmarks are\ngetting larger and more complex as well. We present LMentry, a benchmark that\navoids this \"arms race\" by focusing on a compact set of tasks that are trivial\nto humans, e.g. writing a sentence containing a specific word, identifying\nwhich words in a list belong to a specific category, or choosing which of two\nwords is longer. LMentry is specifically designed to provide quick and\ninterpretable insights into the capabilities and robustness of large language\nmodels. Our experiments reveal a wide variety of failure cases that, while\nimmediately obvious to humans, pose a considerable challenge for large language\nmodels, including OpenAI's latest 175B-parameter instruction-tuned model,\nTextDavinci002. LMentry complements contemporary evaluation approaches of large\nlanguage models, providing a quick, automatic, and easy-to-run \"unit test\",\nwithout resorting to large benchmark suites of complex tasks.\n","authors":["Avia Efrat","Or Honovich","Omer Levy"],"pdf_url":"https://arxiv.org/pdf/2211.02069v2.pdf","comment":"minor results updates"},{"id":"http://arxiv.org/abs/2212.09352v1","updated":"2022-12-19T10:37:30Z","published":"2022-12-19T10:37:30Z","title":"Robust Anomaly Map Assisted Multiple Defect Detection with Supervised\n  Classification Techniques","summary":"  Industry 4.0 aims to optimize the manufacturing environment by leveraging new\ntechnological advances, such as new sensing capabilities and artificial\nintelligence. The DRAEM technique has shown state-of-the-art performance for\nunsupervised classification. The ability to create anomaly maps highlighting\nareas where defects probably lie can be leveraged to provide cues to supervised\nclassification models and enhance their performance. Our research shows that\nthe best performance is achieved when training a defect detection model by\nproviding an image and the corresponding anomaly map as input. Furthermore,\nsuch a setting provides consistent performance when framing the defect\ndetection as a binary or multiclass classification problem and is not affected\nby class balancing policies. We performed the experiments on three datasets\nwith real-world data provided by Philips Consumer Lifestyle BV.\n","authors":["Jože M. Rožanec","Patrik Zajec","Spyros Theodoropoulos","Erik Koehorst","Blaž Fortuna","Dunja Mladenić"],"pdf_url":"https://arxiv.org/pdf/2212.09352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08227v4","updated":"2022-12-19T10:30:12Z","published":"2022-08-17T11:16:52Z","title":"MultiPL-E: A Scalable and Extensible Approach to Benchmarking Neural\n  Code Generation","summary":"  Large language models have demonstrated the ability to generate both natural\nlanguage and programming language text. Such models open up the possibility of\nmulti-language code generation: could code generation models generalize\nknowledge from one language to another? Although contemporary code generation\nmodels can generate semantically correct Python code, little is known about\ntheir abilities with other languages. We propose MultiPL-E, a system for\ntranslating unit test-driven code generation benchmarks to new languages. We\ncreate the first massively multilingual code generation benchmark by using\nMultiPL-E to translate two popular Python code generation benchmarks to 18\nadditional programming languages.\n  We use MultiPL-E to extend the HumanEval benchmark and MBPP benchmark to 18\nlanguages that encompass a range of programming paradigms and popularity. Using\nthese new parallel benchmarks, we evaluate the multi-language performance of\nthree state-of-the-art code generation models: Codex, CodeGen, and InCoder. We\nfind that Codex matches or even exceeds its performance on Python for several\nother languages. The range of programming languages represented in MultiPL-E\nallow us to explore the impact of language frequency and language features on\nmodel performance. Finally, the MultiPL-E approach of compiling code generation\nbenchmarks to new programming languages is both scalable and extensible, making\nit straightforward to evaluate new models, benchmarks, and languages.\n","authors":["Federico Cassano","John Gouwar","Daniel Nguyen","Sydney Nguyen","Luna Phipps-Costin","Donald Pinckney","Ming-Ho Yee","Yangtian Zi","Carolyn Jane Anderson","Molly Q Feldman","Arjun Guha","Michael Greenberg","Abhinav Jangda"],"pdf_url":"https://arxiv.org/pdf/2208.08227v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.09023v2","updated":"2022-12-19T10:16:23Z","published":"2021-01-22T09:43:33Z","title":"Enhanced word embeddings using multi-semantic representation through\n  lexical chains","summary":"  The relationship between words in a sentence often tells us more about the\nunderlying semantic content of a document than its actual words, individually.\nIn this work, we propose two novel algorithms, called Flexible Lexical Chain II\nand Fixed Lexical Chain II. These algorithms combine the semantic relations\nderived from lexical chains, prior knowledge from lexical databases, and the\nrobustness of the distributional hypothesis in word embeddings as building\nblocks forming a single system. In short, our approach has three main\ncontributions: (i) a set of techniques that fully integrate word embeddings and\nlexical chains; (ii) a more robust semantic representation that considers the\nlatent relation between words in a document; and (iii) lightweight word\nembeddings models that can be extended to any natural language task. We intend\nto assess the knowledge of pre-trained models to evaluate their robustness in\nthe document classification task. The proposed techniques are tested against\nseven word embeddings algorithms using five different machine learning\nclassifiers over six scenarios in the document classification task. Our results\nshow the integration between lexical chains and word embeddings representations\nsustain state-of-the-art results, even against more complex systems.\n","authors":["Terry Ruas","Charles Henrique Porto Ferreira","William Grosky","Fabrício Olivetti de França","Débora Maria Rossi Medeiros"],"pdf_url":"https://arxiv.org/pdf/2101.09023v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02965v2","updated":"2022-12-19T10:02:16Z","published":"2022-09-07T07:16:30Z","title":"Risk of Bias in Chest X-ray Foundation Models","summary":"  Foundation models are considered a breakthrough in all applications of AI,\npromising robust and reusable mechanisms for feature extraction, alleviating\nthe need for large amounts of high quality annotated training data for\ntask-specific prediction models. However, foundation models may potentially\nencode and even reinforce existing biases present in historic datasets. Given\nthe limited ability to scrutinize foundation models, it remains unclear whether\nthe opportunities outweigh the risks in safety critical applications such as\nclinical decision making. In our statistical bias analysis of a recently\npublished, and publicly accessible chest X-ray foundation model, we found\nreasons for concern as the model seems to encode protected characteristics\nincluding biological sex and racial identity. When used for the downstream\napplication of disease detection, we observed substantial degradation of\nperformance of the foundation model compared to a standard model with specific\ndisparities in protected subgroups. While research into foundation models for\nhealthcare applications is in an early stage, we hope to raise awareness of the\nrisks by highlighting the importance of conducting thorough bias and subgroup\nperformance analyses.\n","authors":["Ben Glocker","Charles Jones","Melanie Bernhardt","Stefan Winzeck"],"pdf_url":"https://arxiv.org/pdf/2209.02965v2.pdf","comment":"Code available under https://github.com/biomedia-mira/chexploration"},{"id":"http://arxiv.org/abs/2212.09328v1","updated":"2022-12-19T09:45:58Z","published":"2022-12-19T09:45:58Z","title":"Quantum policy gradient algorithms","summary":"  Understanding the power and limitations of quantum access to data in machine\nlearning tasks is primordial to assess the potential of quantum computing in\nartificial intelligence. Previous works have already shown that speed-ups in\nlearning are possible when given quantum access to reinforcement learning\nenvironments. Yet, the applicability of quantum algorithms in this setting\nremains very limited, notably in environments with large state and action\nspaces. In this work, we design quantum algorithms to train state-of-the-art\nreinforcement learning policies by exploiting quantum interactions with an\nenvironment. However, these algorithms only offer full quadratic speed-ups in\nsample complexity over their classical analogs when the trained policies\nsatisfy some regularity conditions. Interestingly, we find that reinforcement\nlearning policies derived from parametrized quantum circuits are well-behaved\nwith respect to these conditions, which showcases the benefit of a\nfully-quantum reinforcement learning framework.\n","authors":["Sofiene Jerbi","Arjan Cornelissen","Māris Ozols","Vedran Dunjko"],"pdf_url":"https://arxiv.org/pdf/2212.09328v1.pdf","comment":"22 pages, 1 figure"},{"id":"http://arxiv.org/abs/2207.10796v4","updated":"2022-12-19T09:41:36Z","published":"2022-07-09T13:15:56Z","title":"Multiple Robust Learning for Recommendation","summary":"  In recommender systems, a common problem is the presence of various biases in\nthe collected data, which deteriorates the generalization ability of the\nrecommendation models and leads to inaccurate predictions. Doubly robust (DR)\nlearning has been studied in many tasks in RS, with the advantage that unbiased\nlearning can be achieved when either a single imputation or a single propensity\nmodel is accurate. In this paper, we propose a multiple robust (MR) estimator\nthat can take the advantage of multiple candidate imputation and propensity\nmodels to achieve unbiasedness. Specifically, the MR estimator is unbiased when\nany of the imputation or propensity models, or a linear combination of these\nmodels is accurate. Theoretical analysis shows that the proposed MR is an\nenhanced version of DR when only having a single imputation and propensity\nmodel, and has a smaller bias. Inspired by the generalization error bound of\nMR, we further propose a novel multiple robust learning approach with\nstabilization. We conduct extensive experiments on real-world and\nsemi-synthetic datasets, which demonstrates the superiority of the proposed\napproach over state-of-the-art methods.\n","authors":["Haoxuan Li","Quanyu Dai","Yuru Li","Yan Lyu","Zhenhua Dong","Xiao-Hua Zhou","Peng Wu"],"pdf_url":"https://arxiv.org/pdf/2207.10796v4.pdf","comment":"Accepted by AAAI'23"},{"id":"http://arxiv.org/abs/2212.09321v1","updated":"2022-12-19T09:39:30Z","published":"2022-12-19T09:39:30Z","title":"Learning from Training Dynamics: Identifying Mislabeled Data Beyond\n  Manually Designed Features","summary":"  While mislabeled or ambiguously-labeled samples in the training set could\nnegatively affect the performance of deep models, diagnosing the dataset and\nidentifying mislabeled samples helps to improve the generalization power.\nTraining dynamics, i.e., the traces left by iterations of optimization\nalgorithms, have recently been proved to be effective to localize mislabeled\nsamples with hand-crafted features. In this paper, beyond manually designed\nfeatures, we introduce a novel learning-based solution, leveraging a noise\ndetector, instanced by an LSTM network, which learns to predict whether a\nsample was mislabeled using the raw training dynamics as input. Specifically,\nthe proposed method trains the noise detector in a supervised manner using the\ndataset with synthesized label noises and can adapt to various datasets (either\nnaturally or synthesized label-noised) without retraining. We conduct extensive\nexperiments to evaluate the proposed method. We train the noise detector based\non the synthesized label-noised CIFAR dataset and test such noise detector on\nTiny ImageNet, CUB-200, Caltech-256, WebVision and Clothing1M. Results show\nthat the proposed method precisely detects mislabeled samples on various\ndatasets without further adaptation, and outperforms state-of-the-art methods.\nBesides, more experiments demonstrate that the mislabel identification can\nguide a label correction, namely data debugging, providing orthogonal\nimprovements of algorithm-centric state-of-the-art techniques from the data\naspect.\n","authors":["Qingrui Jia","Xuhong Li","Lei Yu","Jiang Bian","Penghao Zhao","Shupeng Li","Haoyi Xiong","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2212.09321v1.pdf","comment":"AAAI23 accepted Conference Paper"},{"id":"http://arxiv.org/abs/2208.11530v2","updated":"2022-12-19T09:23:56Z","published":"2022-08-24T13:23:26Z","title":"Collaborative Algorithms for Online Personalized Mean Estimation","summary":"  We consider an online estimation problem involving a set of agents. Each\nagent has access to a (personal) process that generates samples from a\nreal-valued distribution and seeks to estimate its mean. We study the case\nwhere some of the distributions have the same mean, and the agents are allowed\nto actively query information from other agents. The goal is to design an\nalgorithm that enables each agent to improve its mean estimate thanks to\ncommunication with other agents. The means as well as the number of\ndistributions with same mean are unknown, which makes the task nontrivial. We\nintroduce a novel collaborative strategy to solve this online personalized mean\nestimation problem. We analyze its time complexity and introduce variants that\nenjoy good performance in numerical experiments. We also extend our approach to\nthe setting where clusters of agents with similar means seek to estimate the\nmean of their cluster.\n","authors":["Mahsa Asadi","Aurélien Bellet","Odalric-Ambrym Maillard","Marc Tommasi"],"pdf_url":"https://arxiv.org/pdf/2208.11530v2.pdf","comment":"Accepted to Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2212.09310v1","updated":"2022-12-19T09:14:23Z","published":"2022-12-19T09:14:23Z","title":"Multimodal CNN Networks for Brain Tumor Segmentation in MRI: A BraTS\n  2022 Challenge Solution","summary":"  Automatic segmentation is essential for the brain tumor diagnosis, disease\nprognosis, and follow-up therapy of patients with gliomas. Still, accurate\ndetection of gliomas and their sub-regions in multimodal MRI is very\nchallenging due to the variety of scanners and imaging protocols. Over the last\nyears, the BraTS Challenge has provided a large number of multi-institutional\nMRI scans as a benchmark for glioma segmentation algorithms. This paper\ndescribes our contribution to the BraTS 2022 Continuous Evaluation challenge.\nWe propose a new ensemble of multiple deep learning frameworks namely, DeepSeg,\nnnU-Net, and DeepSCAN for automatic glioma boundaries detection in\npre-operative MRI. It is worth noting that our ensemble models took first place\nin the final evaluation on the BraTS testing dataset with Dice scores of\n0.9294, 0.8788, and 0.8803, and Hausdorf distance of 5.23, 13.54, and 12.05,\nfor the whole tumor, tumor core, and enhancing tumor, respectively.\nFurthermore, the proposed ensemble method ranked first in the final ranking on\nanother unseen test dataset, namely Sub-Saharan Africa dataset, achieving mean\nDice scores of 0.9737, 0.9593, and 0.9022, and HD95 of 2.66, 1.72, 3.32 for the\nwhole tumor, tumor core, and enhancing tumor, respectively. The docker image\nfor the winning submission is publicly available at\n(https://hub.docker.com/r/razeineldin/camed22).\n","authors":["Ramy A. Zeineldin","Mohamed E. Karar","Oliver Burgert","Franziska Mathis-Ullrich"],"pdf_url":"https://arxiv.org/pdf/2212.09310v1.pdf","comment":"Accepted in BraTS 2022 (as part of the BrainLes workshop proceedings\n  distributed by Springer LNCS). arXiv admin note: text overlap with\n  arXiv:2112.06554"},{"id":"http://arxiv.org/abs/2110.13632v3","updated":"2022-12-19T08:50:38Z","published":"2021-10-22T18:10:42Z","title":"Generative Networks for Precision Enthusiasts","summary":"  Generative networks are opening new avenues in fast event generation for the\nLHC. We show how generative flow networks can reach percent-level precision for\nkinematic distributions, how they can be trained jointly with a discriminator,\nand how this discriminator improves the generation. Our joint training relies\non a novel coupling of the two networks which does not require a Nash\nequilibrium. We then estimate the generation uncertainties through a Bayesian\nnetwork setup and through conditional data augmentation, while the\ndiscriminator ensures that there are no systematic inconsistencies compared to\nthe training data.\n","authors":["Anja Butter","Theo Heimel","Sander Hummerich","Tobias Krebs","Tilman Plehn","Armand Rousselot","Sophia Vent"],"pdf_url":"https://arxiv.org/pdf/2110.13632v3.pdf","comment":"28 pages, 14 figures"},{"id":"http://arxiv.org/abs/2212.09295v1","updated":"2022-12-19T08:29:38Z","published":"2022-12-19T08:29:38Z","title":"Unified, User and Task (UUT) Centered Artificial Intelligence for\n  Metaverse Edge Computing","summary":"  The Metaverse can be considered the extension of the present-day web, which\nintegrates the physical and virtual worlds, delivering hyper-realistic user\nexperiences. The inception of the Metaverse brings forth many ecosystem\nservices such as content creation, social entertainment, in-world value\ntransfer, intelligent traffic, healthcare. These services are compute-intensive\nand require computation offloading onto a Metaverse edge computing server\n(MECS). Existing Metaverse edge computing approaches do not efficiently and\neffectively handle resource allocation to ensure a fluid, seamless and\nhyper-realistic Metaverse experience required for Metaverse ecosystem services.\nTherefore, we introduce a new Metaverse-compatible, Unified, User and Task\n(UUT) centered artificial intelligence (AI)- based mobile edge computing (MEC)\nparadigm, which serves as a concept upon which future AI control algorithms\ncould be built to develop a more user and task-focused MEC.\n","authors":["Terence Jie Chua","Wenhan Yu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2212.09295v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2212.02977v4","updated":"2022-12-19T08:22:03Z","published":"2022-12-06T13:50:17Z","title":"Denoising diffusion probabilistic models for probabilistic energy\n  forecasting","summary":"  Scenario-based probabilistic forecasts have become a vital tool to equip\ndecision-makers to address the uncertain nature of renewable energies. To that\nend, this paper presents a recent promising deep learning generative approach\ncalled denoising diffusion probabilistic models. It is a class of latent\nvariable models which have recently demonstrated impressive results in the\ncomputer vision community. However, to the best of our knowledge, there has yet\nto be a demonstration that they can generate high-quality samples of load, PV,\nor wind power time series, crucial elements to face the new challenges in power\nsystems applications. Thus, we propose the first implementation of this model\nfor energy forecasting using the open data of the Global Energy Forecasting\nCompetition 2014. The results demonstrate this approach is competitive with\nother state-of-the-art deep learning generative models, including generative\nadversarial networks, variational autoencoders, and normalizing flows.\n","authors":["Esteban Hernandez Capel","Jonathan Dumas"],"pdf_url":"https://arxiv.org/pdf/2212.02977v4.pdf","comment":"Version submitted to Powertech 2023. arXiv admin note: text overlap\n  with arXiv:2106.09370, arXiv:2107.01034"},{"id":"http://arxiv.org/abs/2212.09290v1","updated":"2022-12-19T08:12:25Z","published":"2022-12-19T08:12:25Z","title":"XEngine: Optimal Tensor Rematerialization for Neural Networks in\n  Heterogeneous Environments","summary":"  Memory efficiency is crucial in training deep learning networks on\nresource-restricted devices. During backpropagation, forward tensors are used\nto calculate gradients. Despite the option of keeping those dependencies in\nmemory until they are reused in backpropagation, some forward tensors can be\ndiscarded and recomputed later from saved tensors, so-called checkpoints. This\nallows, in particular, for resource-constrained heterogeneous environments to\nmake use of all available compute devices. Unfortunately, the definition of\nthese checkpoints is a non-trivial problem and poses a challenge to the\nprogrammer - improper or excessive recomputations negate the benefit of\ncheckpointing.\n  In this article, we present XEngine, an approach that schedules network\noperators to heterogeneous devices in low memory environments by determining\ncheckpoints and recomputations of tensors. Our approach selects suitable\nresources per timestep and operator and optimizes the end-to-end time for\nneural networks taking the memory limitation of each device into account. For\nthis, we formulate a mixed-integer quadratic program (MIQP) to schedule\noperators of deep learning networks on heterogeneous systems. We compare our\nMIQP solver XEngine against Checkmate, a mixed-integer linear programming\n(MILP) approach that solves recomputation on a single device. Our solver finds\nsolutions that are up to 22.5 % faster than the fastest Checkmate schedule in\nwhich the network is computed exclusively on a single device. We also find\nvalid schedules for networks making use of both central processing units and\ngraphics processing units if memory limitations do not allow scheduling\nexclusively to the graphics processing unit.\n","authors":["Manuela Schuler","Richard Membarth","Philipp Slusallek"],"pdf_url":"https://arxiv.org/pdf/2212.09290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.04277v3","updated":"2022-12-19T08:06:25Z","published":"2022-10-09T14:49:27Z","title":"Boost Event-Driven Tactile Learning with Location Spiking Neurons","summary":"  Tactile sensing is essential for a variety of daily tasks. And recent\nadvances in event-driven tactile sensors and Spiking Neural Networks (SNNs)\nspur the research in related fields. However, SNN-enabled event-driven tactile\nlearning is still in its infancy due to the limited representation abilities of\nexisting spiking neurons and high spatio-temporal complexity in the\nevent-driven tactile data. In this paper, to improve the representation\ncapability of existing spiking neurons, we propose a novel neuron model called\n\"location spiking neuron\", which enables us to extract features of event-based\ndata in a novel way. Specifically, based on the classical Time Spike Response\nModel (TSRM), we develop the Location Spike Response Model (LSRM). In addition,\nbased on the most commonly-used Time Leaky Integrate-and-Fire (TLIF) model, we\ndevelop the Location Leaky Integrate-and-Fire (LLIF) model. Moreover, to\ndemonstrate the representation effectiveness of our proposed neurons and\ncapture the complex spatio-temporal dependencies in the event-driven tactile\ndata, we exploit the location spiking neurons to propose two hybrid models for\nevent-driven tactile learning. Specifically, the first hybrid model combines a\nfully-connected SNN with TSRM neurons and a fully-connected SNN with LSRM\nneurons. And the second hybrid model fuses the spatial spiking graph neural\nnetwork with TLIF neurons and the temporal spiking graph neural network with\nLLIF neurons. Extensive experiments demonstrate the significant improvements of\nour models over the state-of-the-art methods on event-driven tactile learning.\nMoreover, compared to the counterpart artificial neural networks (ANNs), our\nSNN models are 10x to 100x energy-efficient, which shows the superior energy\nefficiency of our models and may bring new opportunities to the spike-based\nlearning community and neuromorphic engineering.\n","authors":["Peng Kang","Srutarshi Banerjee","Henry Chopp","Aggelos Katsaggelos","Oliver Cossairt"],"pdf_url":"https://arxiv.org/pdf/2210.04277v3.pdf","comment":"Under review. Please note that this paper is a journal extension of\n  our previous conference paper: arXiv:2209.01080. Please check what we added\n  in the introduction part"},{"id":"http://arxiv.org/abs/2206.00050v4","updated":"2022-12-19T07:53:27Z","published":"2022-05-31T18:33:15Z","title":"FiLM-Ensemble: Probabilistic Deep Learning via Feature-wise Linear\n  Modulation","summary":"  The ability to estimate epistemic uncertainty is often crucial when deploying\nmachine learning in the real world, but modern methods often produce\noverconfident, uncalibrated uncertainty predictions. A common approach to\nquantify epistemic uncertainty, usable across a wide class of prediction\nmodels, is to train a model ensemble. In a naive implementation, the ensemble\napproach has high computational cost and high memory demand. This challenges in\nparticular modern deep learning, where even a single deep network is already\ndemanding in terms of compute and memory, and has given rise to a number of\nattempts to emulate the model ensemble without actually instantiating separate\nensemble members. We introduce FiLM-Ensemble, a deep, implicit ensemble method\nbased on the concept of Feature-wise Linear Modulation (FiLM). That technique\nwas originally developed for multi-task learning, with the aim of decoupling\ndifferent tasks. We show that the idea can be extended to uncertainty\nquantification: by modulating the network activations of a single deep network\nwith FiLM, one obtains a model ensemble with high diversity, and consequently\nwell-calibrated estimates of epistemic uncertainty, with low computational\noverhead in comparison. Empirically, FiLM-Ensemble outperforms other implicit\nensemble methods, and it and comes very close to the upper bound of an explicit\nensemble of networks (sometimes even beating it), at a fraction of the memory\ncost.\n","authors":["Mehmet Ozgur Turkoglu","Alexander Becker","Hüseyin Anil Gündüz","Mina Rezaei","Bernd Bischl","Rodrigo Caye Daudt","Stefano D'Aronco","Jan Dirk Wegner","Konrad Schindler"],"pdf_url":"https://arxiv.org/pdf/2206.00050v4.pdf","comment":"accepted at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.09282v1","updated":"2022-12-19T07:40:02Z","published":"2022-12-19T07:40:02Z","title":"APOLLO: A Simple Approach for Adaptive Pretraining of Language Models\n  for Logical Reasoning","summary":"  Logical reasoning of text is an important ability that requires understanding\nthe information present in the text, their interconnections, and then reasoning\nthrough them to infer new conclusions. Prior works on improving the logical\nreasoning ability of language models require complex processing of training\ndata (e.g., aligning symbolic knowledge to text), yielding task-specific data\naugmentation solutions that restrict the learning of general logical reasoning\nskills. In this work, we propose APOLLO, an adaptively pretrained language\nmodel that has improved logical reasoning abilities. We select a subset of\nWikipedia, based on a set of logical inference keywords, for continued\npretraining of a language model. We use two self-supervised loss functions: a\nmodified masked language modeling loss where only specific parts-of-speech\nwords, that would likely require more reasoning than basic language\nunderstanding, are masked, and a sentence-level classification loss that\nteaches the model to distinguish between entailment and contradiction types of\nsentences. The proposed training paradigm is both simple and independent of\ntask formats. We demonstrate the effectiveness of APOLLO by comparing it with\nprior baselines on two logical reasoning datasets. APOLLO performs comparably\non ReClor and outperforms baselines on LogiQA.\n","authors":["Soumya Sanyal","Yichong Xu","Shuohang Wang","Ziyi Yang","Reid Pryzant","Wenhao Yu","Chenguang Zhu","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.09282v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2211.11403v2","updated":"2022-12-19T07:20:51Z","published":"2022-11-21T12:25:58Z","title":"Time-reversal equivariant neural network potential and Hamiltonian for\n  magnetic materials","summary":"  This work presents Time-reversal Equivariant Neural Network (TENN) framework.\nWith TENN, the time-reversal symmetry is considered in the equivariant neural\nnetwork (ENN), which generalizes the ENN to consider physical quantities\nrelated to time-reversal symmetry such as spin and velocity of atoms. TENN-e3,\nas the time-reversal-extension of E(3) equivariant neural network, is developed\nto keep the Time-reversal E(3) equivariant with consideration of whether to\ninclude the spin-orbit effect for both collinear and non-collinear magnetic\nmoments situations for magnetic material. TENN-e3 can construct spin neural\nnetwork potential and the Hamiltonian of magnetic material from ab-initio\ncalculations. Time-reversal-E(3)-equivariant convolutions for interactions of\nspinor and geometric tensors are employed in TENN-e3. Compared to the popular\nENN, TENN-e3 can describe the complex spin-lattice coupling with high accuracy\nand keep time-reversal symmetry which is not preserved in the existing\nE(3)-equivariant model. Also, the Hamiltonian of magnetic material with\ntime-reversal symmetry can be built with TENN-e3. TENN paves a new way to\nspin-lattice dynamics simulations over long-time scales and electronic\nstructure calculations of large-scale magnetic materials.\n","authors":["Hongyu Yu","Yang Zhong","Junyi Ji","Xingao Gong","Hongjun Xiang"],"pdf_url":"https://arxiv.org/pdf/2211.11403v2.pdf","comment":"17 pages,2 figures and 2 tables"},{"id":"http://arxiv.org/abs/2212.09276v1","updated":"2022-12-19T07:10:51Z","published":"2022-12-19T07:10:51Z","title":"COVID-19 Detection Based on Self-Supervised Transfer Learning Using\n  Chest X-Ray Images","summary":"  Purpose: Considering several patients screened due to COVID-19 pandemic,\ncomputer-aided detection has strong potential in assisting clinical workflow\nefficiency and reducing the incidence of infections among radiologists and\nhealthcare providers. Since many confirmed COVID-19 cases present radiological\nfindings of pneumonia, radiologic examinations can be useful for fast\ndetection. Therefore, chest radiography can be used to fast screen COVID-19\nduring the patient triage, thereby determining the priority of patient's care\nto help saturated medical facilities in a pandemic situation. Methods: In this\npaper, we propose a new learning scheme called self-supervised transfer\nlearning for detecting COVID-19 from chest X-ray (CXR) images. We compared six\nself-supervised learning (SSL) methods (Cross, BYOL, SimSiam, SimCLR,\nPIRL-jigsaw, and PIRL-rotation) with the proposed method. Additionally, we\ncompared six pretrained DCNNs (ResNet18, ResNet50, ResNet101, CheXNet,\nDenseNet201, and InceptionV3) with the proposed method. We provide quantitative\nevaluation on the largest open COVID-19 CXR dataset and qualitative results for\nvisual inspection. Results: Our method achieved a harmonic mean (HM) score of\n0.985, AUC of 0.999, and four-class accuracy of 0.953. We also used the\nvisualization technique Grad-CAM++ to generate visual explanations of different\nclasses of CXR images with the proposed method to increase the\ninterpretability. Conclusions: Our method shows that the knowledge learned from\nnatural images using transfer learning is beneficial for SSL of the CXR images\nand boosts the performance of representation learning for COVID-19 detection.\nOur method promises to reduce the incidence of infections among radiologists\nand healthcare providers.\n","authors":["Guang Li","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2212.09276v1.pdf","comment":"Published as a journal paper at Springer IJCARS"},{"id":"http://arxiv.org/abs/2212.09271v1","updated":"2022-12-19T06:52:13Z","published":"2022-12-19T06:52:13Z","title":"Very Large Language Model as a Unified Methodology of Text Mining","summary":"  Text data mining is the process of deriving essential information from\nlanguage text. Typical text mining tasks include text categorization, text\nclustering, topic modeling, information extraction, and text summarization.\nVarious data sets are collected and various algorithms are designed for the\ndifferent types of tasks. In this paper, I present a blue sky idea that very\nlarge language model (VLLM) will become an effective unified methodology of\ntext mining. I discuss at least three advantages of this new methodology\nagainst conventional methods. Finally I discuss the challenges in the design\nand development of VLLM techniques for text mining.\n","authors":["Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2212.09271v1.pdf","comment":"4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.09270v1","updated":"2022-12-19T06:49:39Z","published":"2022-12-19T06:49:39Z","title":"The One-Inclusion Graph Algorithm is not Always Optimal","summary":"  The one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth\nachieves an optimal in-expectation risk bound in the standard PAC\nclassification setup. In one of the first COLT open problems, Warmuth\nconjectured that this prediction strategy always implies an optimal high\nprobability bound on the risk, and hence is also an optimal PAC algorithm. We\nrefute this conjecture in the strongest sense: for any practically interesting\nVapnik-Chervonenkis class, we provide an in-expectation optimal one-inclusion\ngraph algorithm whose high probability risk bound cannot go beyond that implied\nby Markov's inequality. Our construction of these poorly performing\none-inclusion graph algorithms uses Varshamov-Tenengolts error correcting\ncodes.\n  Our negative result has several implications. First, it shows that the same\npoor high-probability performance is inherited by several recent prediction\nstrategies based on generalizations of the one-inclusion graph algorithm.\nSecond, our analysis shows yet another statistical problem that enjoys an\nestimator that is provably optimal in expectation via a leave-one-out argument,\nbut fails in the high-probability regime. This discrepancy occurs despite the\nboundedness of the binary loss for which arguments based on concentration\ninequalities often provide sharp high probability risk bounds.\n","authors":["Ishaq Aden-Ali","Yeshwanth Cherapanamjeri","Abhishek Shetty","Nikita Zhivotovskiy"],"pdf_url":"https://arxiv.org/pdf/2212.09270v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2105.03939v2","updated":"2022-12-19T06:48:43Z","published":"2021-05-09T13:30:16Z","title":"Differentiable Neural Architecture Search for Extremely Lightweight\n  Image Super-Resolution","summary":"  Single Image Super-Resolution (SISR) tasks have achieved significant\nperformance with deep neural networks. However, the large number of parameters\nin CNN-based met-hods for SISR tasks require heavy computations. Although\nseveral efficient SISR models have been recently proposed, most are handcrafted\nand thus lack flexibility. In this work, we propose a novel differentiable\nNeural Architecture Search (NAS) approach on both the cell-level and\nnetwork-level to search for lightweight SISR models. Specifically, the\ncell-level search space is designed based on an information distillation\nmechanism, focusing on the combinations of lightweight operations and aiming to\nbuild a more lightweight and accurate SR structure. The network-level search\nspace is designed to consider the feature connections among the cells and aims\nto find which information flow benefits the cell most to boost the performance.\nUnlike the existing Reinforcement Learning (RL) or Evolutionary Algorithm (EA)\nbased NAS methods for SISR tasks, our search pipeline is fully differentiable,\nand the lightweight SISR models can be efficiently searched on both the\ncell-level and network-level jointly on a single GPU. Experiments show that our\nmethods can achieve state-of-the-art performance on the benchmark datasets in\nterms of PSNR, SSIM, and model complexity with merely 68G Multi-Adds for\n$\\times 2$ and 18G Multi-Adds for $\\times 4$ SR tasks.\n","authors":["Han Huang","Li Shen","Chaoyang He","Weisheng Dong","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2105.03939v2.pdf","comment":"Accepted to IEEE Transactions on Circuits and Systems for Video\n  Technology"},{"id":"http://arxiv.org/abs/2212.09252v1","updated":"2022-12-19T05:17:33Z","published":"2022-12-19T05:17:33Z","title":"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems","summary":"  Many dialogue systems (DSs) lack characteristics humans have, such as emotion\nperception, factuality, and informativeness. Enhancing DSs with knowledge\nalleviates this problem, but, as many ways of doing so exist, keeping track of\nall proposed methods is difficult. Here, we present the first survey of\nknowledge-enhanced DSs. We define three categories of systems - internal,\nexternal, and hybrid - based on the knowledge they use. We survey the\nmotivation for enhancing DSs with knowledge, used datasets, and methods for\nknowledge search, knowledge encoding, and knowledge incorporation. Finally, we\npropose how to improve existing systems based on theories from linguistics and\ncognitive science.\n","authors":["Sagi Shaier","Lawrence Hunter","Katharina Kann"],"pdf_url":"https://arxiv.org/pdf/2212.09252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09251v1","updated":"2022-12-19T05:13:52Z","published":"2022-12-19T05:13:52Z","title":"Discovering Language Model Behaviors with Model-Written Evaluations","summary":"  As language models (LMs) scale, they develop many novel behaviors, good and\nbad, exacerbating the need to evaluate how they behave. Prior work creates\nevaluations with crowdwork (which is time-consuming and expensive) or existing\ndata sources (which are not always available). Here, we automatically generate\nevaluations with LMs. We explore approaches with varying amounts of human\neffort, from instructing LMs to write yes/no questions to making complex\nWinogender schemas with multiple stages of LM-based generation and filtering.\nCrowdworkers rate the examples as highly relevant and agree with 90-100% of\nlabels, sometimes more so than corresponding human-written datasets. We\ngenerate 154 datasets and discover new cases of inverse scaling where LMs get\nworse with size. Larger LMs repeat back a dialog user's preferred answer\n(\"sycophancy\") and express greater desire to pursue concerning goals like\nresource acquisition and goal preservation. We also find some of the first\nexamples of inverse scaling in RL from Human Feedback (RLHF), where more RLHF\nmakes LMs worse. For example, RLHF makes LMs express stronger political views\n(on gun rights and immigration) and a greater desire to avoid shut down.\nOverall, LM-written evaluations are high-quality and let us quickly discover\nmany novel LM behaviors.\n","authors":["Ethan Perez","Sam Ringer","Kamilė Lukošiūtė","Karina Nguyen","Edwin Chen","Scott Heiner","Craig Pettit","Catherine Olsson","Sandipan Kundu","Saurav Kadavath","Andy Jones","Anna Chen","Ben Mann","Brian Israel","Bryan Seethor","Cameron McKinnon","Christopher Olah","Da Yan","Daniela Amodei","Dario Amodei","Dawn Drain","Dustin Li","Eli Tran-Johnson","Guro Khundadze","Jackson Kernion","James Landis","Jamie Kerr","Jared Mueller","Jeeyoon Hyun","Joshua Landau","Kamal Ndousse","Landon Goldberg","Liane Lovitt","Martin Lucas","Michael Sellitto","Miranda Zhang","Neerav Kingsland","Nelson Elhage","Nicholas Joseph","Noemí Mercado","Nova DasSarma","Oliver Rausch","Robin Larson","Sam McCandlish","Scott Johnston","Shauna Kravec","Sheer El Showk","Tamera Lanham","Timothy Telleen-Lawton","Tom Brown","Tom Henighan","Tristan Hume","Yuntao Bai","Zac Hatfield-Dodds","Jack Clark","Samuel R. Bowman","Amanda Askell","Roger Grosse","Danny Hernandez","Deep Ganguli","Evan Hubinger","Nicholas Schiefer","Jared Kaplan"],"pdf_url":"https://arxiv.org/pdf/2212.09251v1.pdf","comment":"for associated data visualizations, see\n  https://www.evals.anthropic.com/model-written/ for full datasets, see\n  https://github.com/anthropics/evals"},{"id":"http://arxiv.org/abs/2212.09247v1","updated":"2022-12-19T04:49:26Z","published":"2022-12-19T04:49:26Z","title":"ColoristaNet for Photorealistic Video Style Transfer","summary":"  Photorealistic style transfer aims to transfer the artistic style of an image\nonto an input image or video while keeping photorealism. In this paper, we\nthink it's the summary statistics matching scheme in existing algorithms that\nleads to unrealistic stylization. To avoid employing the popular Gram loss, we\npropose a self-supervised style transfer framework, which contains a style\nremoval part and a style restoration part. The style removal network removes\nthe original image styles, and the style restoration network recovers image\nstyles in a supervised manner. Meanwhile, to address the problems in current\nfeature transformation methods, we propose decoupled instance normalization to\ndecompose feature transformation into style whitening and restylization. It\nworks quite well in ColoristaNet and can transfer image styles efficiently\nwhile keeping photorealism. To ensure temporal coherency, we also incorporate\noptical flow methods and ConvLSTM to embed contextual information. Experiments\ndemonstrates that ColoristaNet can achieve better stylization effects when\ncompared with state-of-the-art algorithms.\n","authors":["Xiaowen Qiu","Ruize Xu","Boan He","Yingtao Zhang","Wenqiang Zhang","Weifeng Ge"],"pdf_url":"https://arxiv.org/pdf/2212.09247v1.pdf","comment":"30 pages, 29 figures"},{"id":"http://arxiv.org/abs/2210.13361v2","updated":"2022-12-19T04:33:42Z","published":"2022-10-24T16:03:42Z","title":"NASA: Neural Architecture Search and Acceleration for Hardware Inspired\n  Hybrid Networks","summary":"  Multiplication is arguably the most cost-dominant operation in modern deep\nneural networks (DNNs), limiting their achievable efficiency and thus more\nextensive deployment in resource-constrained applications. To tackle this\nlimitation, pioneering works have developed handcrafted multiplication-free\nDNNs, which require expert knowledge and time-consuming manual iteration,\ncalling for fast development tools. To this end, we propose a Neural\nArchitecture Search and Acceleration framework dubbed NASA, which enables\nautomated multiplication-reduced DNN development and integrates a dedicated\nmultiplication-reduced accelerator for boosting DNNs' achievable efficiency.\nSpecifically, NASA adopts neural architecture search (NAS) spaces that augment\nthe state-of-the-art one with hardware-inspired multiplication-free operators,\nsuch as shift and adder, armed with a novel progressive pretrain strategy (PGP)\ntogether with customized training recipes to automatically search for optimal\nmultiplication-reduced DNNs; On top of that, NASA further develops a dedicated\naccelerator, which advocates a chunk-based template and auto-mapper dedicated\nfor NASA-NAS resulting DNNs to better leverage their algorithmic properties for\nboosting hardware efficiency. Experimental results and ablation studies\nconsistently validate the advantages of NASA's algorithm-hardware co-design\nframework in terms of achievable accuracy and efficiency tradeoffs. Codes are\navailable at https://github.com/GATECH-EIC/NASA.\n","authors":["Huihong Shi","Haoran You","Yang Zhao","Zhongfeng Wang","Yingyan Lin"],"pdf_url":"https://arxiv.org/pdf/2210.13361v2.pdf","comment":"Accepted to ICCAD2022"},{"id":"http://arxiv.org/abs/2212.09240v1","updated":"2022-12-19T04:25:59Z","published":"2022-12-19T04:25:59Z","title":"Probabilistic machine learning based predictive and interpretable\n  digital twin for dynamical systems","summary":"  A framework for creating and updating digital twins for dynamical systems\nfrom a library of physics-based functions is proposed. The sparse Bayesian\nmachine learning is used to update and derive an interpretable expression for\nthe digital twin. Two approaches for updating the digital twin are proposed.\nThe first approach makes use of both the input and output information from a\ndynamical system, whereas the second approach utilizes output-only observations\nto update the digital twin. Both methods use a library of candidate functions\nrepresenting certain physics to infer new perturbation terms in the existing\ndigital twin model. In both cases, the resulting expressions of updated digital\ntwins are identical, and in addition, the epistemic uncertainties are\nquantified. In the first approach, the regression problem is derived from a\nstate-space model, whereas in the latter case, the output-only information is\ntreated as a stochastic process. The concepts of It\\^o calculus and\nKramers-Moyal expansion are being utilized to derive the regression equation.\nThe performance of the proposed approaches is demonstrated using highly\nnonlinear dynamical systems such as the crack-degradation problem. Numerical\nresults demonstrated in this paper almost exactly identify the correct\nperturbation terms along with their associated parameters in the dynamical\nsystem. The probabilistic nature of the proposed approach also helps in\nquantifying the uncertainties associated with updated models. The proposed\napproaches provide an exact and explainable description of the perturbations in\ndigital twin models, which can be directly used for better cyber-physical\nintegration, long-term future predictions, degradation monitoring, and\nmodel-agnostic control.\n","authors":["Tapas Tripura","Aarya Sheetal Desai","Sondipon Adhikari","Souvik Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2212.09240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00780v3","updated":"2022-12-19T04:23:27Z","published":"2022-09-02T01:52:10Z","title":"Index Tracking via Learning to Predict Market Sensitivities","summary":"  Index funds are substantially preferred by investors nowadays, and market\nsensitivities are instrumental in managing index funds. An index fund is a\nmutual fund aiming to track the returns of a predefined market index (e.g., the\nS&P 500). A basic strategy to manage an index fund is replicating the index's\nconstituents and weights identically, which is, however, cost-ineffective and\nimpractical. To address this issue, it is required to replicate the index\npartially with accurately predicted market sensitivities. Accordingly, we\npropose a novel partial-replication method via learning to predict market\nsensitivities. We first examine deep-learning models to predict market\nsensitivities in a supervised manner with our data-processing methods. Then, we\npropose a partial-index-tracking optimization model controlling the net\npredicted market sensitivities of the portfolios and index to be the same.\nThese processes' efficacy is corroborated by our experiments on the Korea Stock\nPrice Index 200. Our experiments show a significant reduction of the prediction\nerrors compared with historical estimations and competitive tracking errors of\nreplicating the index utilizing fewer than half of the entire constituents.\nTherefore, we show that applying deep learning to predict market sensitivities\nis promising and that our portfolio construction methods are practically\neffective. Additionally, to our knowledge, this is the first study addressing\nmarket sensitivities focused on deep learning.\n","authors":["Yoonsik Hong","Yanghoon Kim","Jeonghun Kim","Yongmin Choi"],"pdf_url":"https://arxiv.org/pdf/2209.00780v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08216v2","updated":"2022-12-19T04:01:57Z","published":"2022-12-16T01:10:41Z","title":"Azimuth: Systematic Error Analysis for Text Classification","summary":"  We present Azimuth, an open-source and easy-to-use tool to perform error\nanalysis for text classification. Compared to other stages of the ML\ndevelopment cycle, such as model training and hyper-parameter tuning, the\nprocess and tooling for the error analysis stage are less mature. However, this\nstage is critical for the development of reliable and trustworthy AI systems.\nTo make error analysis more systematic, we propose an approach comprising\ndataset analysis and model quality assessment, which Azimuth facilitates. We\naim to help AI practitioners discover and address areas where the model does\nnot generalize by leveraging and integrating a range of ML techniques, such as\nsaliency maps, similarity, uncertainty, and behavioral analyses, all in one\ntool. Our code and documentation are available at\ngithub.com/servicenow/azimuth.\n","authors":["Gabrielle Gauthier-Melançon","Orlando Marquez Ayala","Lindsay Brin","Chris Tyler","Frédéric Branchaud-Charron","Joseph Marinier","Karine Grande","Di Le"],"pdf_url":"https://arxiv.org/pdf/2212.08216v2.pdf","comment":"To be published in Proceedings of the 2022 Conference on Empirical\n  Methods in Natural Language Processing: System Demonstrations. 13 pages and\n  14 figures"},{"id":"http://arxiv.org/abs/2208.00349v3","updated":"2022-12-19T03:49:32Z","published":"2022-07-31T03:09:56Z","title":"What Do Deep Neural Networks Find in Disordered Structures of Glasses?","summary":"  Glass transitions are widely observed in various types of soft matter\nsystems. However, the physical mechanism of these transitions remains\n{elusive}, despite years of ambitious research. In particular, an important\nunanswered question is whether the glass transition is accompanied by a\ndivergence of the correlation lengths of the characteristic static structures.\nIn this study, we develop a deep-neural-network-based method that is used to\nextract the characteristic local meso-structures solely from instantaneous\n{particle} configurations without any {information} about the dynamics. We\nfirst train a neural network to classify configurations of liquids and glasses\ncorrectly. Then, we obtain the characteristic structures by quantifying the\ngrounds for the decisions made by the network using Gradient-weighted Class\nActivation Mapping (Grad-CAM). We considered two qualitatively different\nglass-forming binary systems, and through comparisons with several established\nstructural indicators, we demonstrate that our system can be used to identify\ncharacteristic structures that depend on the details of the systems. Moreover,\nthe extracted structures are remarkably correlated with the nonequilibrium\naging dynamics in thermal fluctuations.\n","authors":["Norihiro Oyama","Shihori Koyama","Takeshi Kawasaki"],"pdf_url":"https://arxiv.org/pdf/2208.00349v3.pdf","comment":"16+12 pages, 8+10 figures"},{"id":"http://arxiv.org/abs/2212.09225v1","updated":"2022-12-19T03:29:47Z","published":"2022-12-19T03:29:47Z","title":"An Extension of Fisher's Criterion: Theoretical Results with a Neural\n  Network Realization","summary":"  Fisher's criterion is a widely used tool in machine learning for feature\nselection. For large search spaces, Fisher's criterion can provide a scalable\nsolution to select features. A challenging limitation of Fisher's criterion,\nhowever, is that it performs poorly when mean values of class-conditional\ndistributions are close to each other. Motivated by this challenge, we propose\nan extension of Fisher's criterion to overcome this limitation. The proposed\nextension utilizes the available heteroscedasticity of class-conditional\ndistributions to distinguish one class from another. Additionally, we describe\nhow our theoretical results can be casted into a neural network framework, and\nconduct a proof-of-concept experiment to demonstrate the viability of our\napproach to solve classification problems.\n","authors":["Ibrahim Alsolami","Tomoki Fukai"],"pdf_url":"https://arxiv.org/pdf/2212.09225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.03677v4","updated":"2022-12-19T03:06:16Z","published":"2022-07-08T03:44:34Z","title":"SuperTickets: Drawing Task-Agnostic Lottery Tickets from Supernets via\n  Jointly Architecture Searching and Parameter Pruning","summary":"  Neural architecture search (NAS) has demonstrated amazing success in\nsearching for efficient deep neural networks (DNNs) from a given supernet. In\nparallel, the lottery ticket hypothesis has shown that DNNs contain small\nsubnetworks that can be trained from scratch to achieve a comparable or higher\naccuracy than original DNNs. As such, it is currently a common practice to\ndevelop efficient DNNs via a pipeline of first search and then prune.\nNevertheless, doing so often requires a search-train-prune-retrain process and\nthus prohibitive computational cost. In this paper, we discover for the first\ntime that both efficient DNNs and their lottery subnetworks (i.e., lottery\ntickets) can be directly identified from a supernet, which we term as\nSuperTickets, via a two-in-one training scheme with jointly architecture\nsearching and parameter pruning. Moreover, we develop a progressive and unified\nSuperTickets identification strategy that allows the connectivity of\nsubnetworks to change during supernet training, achieving better accuracy and\nefficiency trade-offs than conventional sparse training. Finally, we evaluate\nwhether such identified SuperTickets drawn from one task can transfer well to\nother tasks, validating their potential of handling multiple tasks\nsimultaneously. Extensive experiments and ablation studies on three tasks and\nfour benchmark datasets validate that our proposed SuperTickets achieve boosted\naccuracy and efficiency trade-offs than both typical NAS and pruning pipelines,\nregardless of having retraining or not. Codes and pretrained models are\navailable at https://github.com/RICE-EIC/SuperTickets.\n","authors":["Haoran You","Baopu Li","Zhanyi Sun","Xu Ouyang","Yingyan Lin"],"pdf_url":"https://arxiv.org/pdf/2207.03677v4.pdf","comment":"Accepted by ECCV 2022"},{"id":"http://arxiv.org/abs/2212.08109v2","updated":"2022-12-19T02:41:33Z","published":"2022-12-15T19:49:34Z","title":"An Empirical Study of Deep Learning Models for Vulnerability Detection","summary":"  Deep learning (DL) models of code have recently reported great progress for\nvulnerability detection. In some cases, DL-based models have outperformed\nstatic analysis tools. Although many great models have been proposed, we do not\nyet have a good understanding of these models. This limits the further\nadvancement of model robustness, debugging, and deployment for the\nvulnerability detection. In this paper, we surveyed and reproduced 9\nstate-of-the-art (SOTA) deep learning models on 2 widely used vulnerability\ndetection datasets: Devign and MSR. We investigated 6 research questions in\nthree areas, namely model capabilities, training data, and model\ninterpretation. We experimentally demonstrated the variability between\ndifferent runs of a model and the low agreement among different models'\noutputs. We investigated models trained for specific types of vulnerabilities\ncompared to a model that is trained on all the vulnerabilities at once. We\nexplored the types of programs DL may consider \"hard\" to handle. We\ninvestigated the relations of training data sizes and training data composition\nwith model performance. Finally, we studied model interpretations and analyzed\nimportant features that the models used to make predictions. We believe that\nour findings can help better understand model results, provide guidance on\npreparing training data, and improve the robustness of the models. All of our\ndatasets, code, and results are available at\nhttps://figshare.com/s/284abfba67dba448fdc2.\n","authors":["Benjamin Steenhoek","Md Mahbubur Rahman","Richard Jiles","Wei Le"],"pdf_url":"https://arxiv.org/pdf/2212.08109v2.pdf","comment":"11 pages, 14 figures. Accepted at ICSE 2023 (not camera-ready\n  version). Corrected typos in Listing 2"},{"id":"http://arxiv.org/abs/2212.08624v2","updated":"2022-12-19T01:56:43Z","published":"2022-12-16T17:59:40Z","title":"Development of A Real-time POCUS Image Quality Assessment and\n  Acquisition Guidance System","summary":"  Point-of-care ultrasound (POCUS) is one of the most commonly applied tools\nfor cardiac function imaging in the clinical routine of the emergency\ndepartment and pediatric intensive care unit. The prior studies demonstrate\nthat AI-assisted software can guide nurses or novices without prior sonography\nexperience to acquire POCUS by recognizing the interest region, assessing image\nquality, and providing instructions. However, these AI algorithms cannot simply\nreplace the role of skilled sonographers in acquiring diagnostic-quality POCUS.\nUnlike chest X-ray, CT, and MRI, which have standardized imaging protocols,\nPOCUS can be acquired with high inter-observer variability. Though being with\nvariability, they are usually all clinically acceptable and interpretable. In\nchallenging clinical environments, sonographers employ novel heuristics to\nacquire POCUS in complex scenarios. To help novice learners to expedite the\ntraining process while reducing the dependency on experienced sonographers in\nthe curriculum implementation, We will develop a framework to perform real-time\nAI-assisted quality assessment and probe position guidance to provide training\nprocess for novice learners with less manual intervention.\n","authors":["Zhenge Jia","Yiyu Shi","Jingtong Hu","Lei Yang","Benjamin Nti"],"pdf_url":"https://arxiv.org/pdf/2212.08624v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.04996v2","updated":"2022-12-19T01:45:19Z","published":"2021-10-11T04:35:33Z","title":"Learning criteria going beyond the usual risk","summary":"  Virtually all machine learning tasks are characterized using some form of\nloss function, and \"good performance\" is typically stated in terms of a\nsufficiently small average loss, taken over the random draw of test data. While\noptimizing for performance on average is intuitive, convenient to analyze in\ntheory, and easy to implement in practice, such a choice brings about\ntrade-offs. In this work, we survey and introduce a wide variety of\nnon-traditional criteria used to design and evaluate machine learning\nalgorithms, place the classical paradigm within the proper historical context,\nand propose a view of learning problems which emphasizes the question of \"what\nmakes for a desirable loss distribution?\" in place of tacit use of the expected\nloss.\n","authors":["Matthew J. Holland","Kazuki Tanabe"],"pdf_url":"https://arxiv.org/pdf/2110.04996v2.pdf","comment":"Substantial revision of initial draft"},{"id":"http://arxiv.org/abs/2106.00116v4","updated":"2022-12-19T00:47:51Z","published":"2021-05-31T21:55:56Z","title":"Effect of Pre-Training Scale on Intra- and Inter-Domain Full and\n  Few-Shot Transfer Learning for Natural and Medical X-Ray Chest Images","summary":"  Increasing model, data and compute budget scale in the pre-training has been\nshown to strongly improve model generalization and transfer learning in vast\nline of work done in language modeling and natural image recognition. However,\nmost studies on the positive effect of larger scale were done in scope of\nin-domain setting, with source and target data being in close proximity. To\nstudy effect of larger scale for both in-domain and out-of-domain setting when\nperforming full and few-shot transfer, we combine here for the first time\nlarge, openly available medical X-Ray chest imaging datasets to reach a scale\nfor medical imaging domain comparable to ImageNet-1k, routinely used for\npre-training in natural image domain. We then conduct supervised pre-training,\nwhile varying network size and source data scale and domain, being either large\nnatural (ImageNet-1k/21k) or large medical chest X-Ray datasets, and transfer\npre-trained models to different natural or medical targets. We observe strong\nimprovement due to larger pre-training scale for intra-domain natural-natural\nand medical-medical transfer. For inter-domain natural-medical transfer, we\nfind improvements due to larger pre-training scale on larger X-Ray targets in\nfull shot regime, while for smaller targets and for few-shot regime the\nimprovement is not visible. Remarkably, large networks pre-trained on very\nlarge natural ImageNet-21k are as good or better than networks pre-trained on\nlargest available medical X-Ray data when performing transfer to large X-Ray\ntargets. We conclude that substantially increasing model and generic, medical\ndomain-agnostic natural image source data scale in the pre-training can enable\nhigh quality out-of-domain transfer to medical domain specific targets,\nremoving dependency on large medical domain-specific source data often not\navailable in the practice.\n","authors":["Mehdi Cherti","Jenia Jitsev"],"pdf_url":"https://arxiv.org/pdf/2106.00116v4.pdf","comment":"Short version published in MedNeurIPS 2021. Long version published in\n  IJCNN 2022. Code: https://github.com/SLAMPAI/large-scale-pretraining-transfer"},{"id":"http://arxiv.org/abs/2212.09201v1","updated":"2022-12-19T00:42:21Z","published":"2022-12-19T00:42:21Z","title":"Spectral Regularized Kernel Two-Sample Tests","summary":"  Over the last decade, an approach that has gained a lot of popularity to\ntackle non-parametric testing problems on general (i.e., non-Euclidean) domains\nis based on the notion of reproducing kernel Hilbert space (RKHS) embedding of\nprobability distributions. The main goal of our work is to understand the\noptimality of two-sample tests constructed based on this approach. First, we\nshow that the popular MMD (maximum mean discrepancy) two-sample test is not\noptimal in terms of the separation boundary measured in Hellinger distance.\nSecond, we propose a modification to the MMD test based on spectral\nregularization by taking into account the covariance information (which is not\ncaptured by the MMD test) and prove the proposed test to be minimax optimal\nwith a smaller separation boundary than that achieved by the MMD test. Third,\nwe propose an adaptive version of the above test which involves a data-driven\nstrategy to choose the regularization parameter and show the adaptive test to\nbe almost minimax optimal up to a logarithmic factor. Moreover, our results\nhold for the permutation variant of the test where the test threshold is chosen\nelegantly through the permutation of the samples. Through numerical experiments\non synthetic and real-world data, we demonstrate the superior performance of\nthe proposed test in comparison to the MMD test.\n","authors":["Omar Hagrass","Bharath K. Sriperumbudur","Bing Li"],"pdf_url":"https://arxiv.org/pdf/2212.09201v1.pdf","comment":"63 pages"},{"id":"http://arxiv.org/abs/2211.01994v2","updated":"2022-12-19T23:41:21Z","published":"2022-11-03T17:08:26Z","title":"lilGym: Natural Language Visual Reasoning with Reinforcement Learning","summary":"  We present lilGym, a new benchmark for language-conditioned reinforcement\nlearning in visual environments. lilGym is based on 2,661 highly-compositional\nhuman-written natural language statements grounded in an interactive visual\nenvironment. We introduce a new approach for exact reward computation in every\npossible world state by annotating all statements with executable Python\nprograms. Each statement is paired with multiple start states and reward\nfunctions to form thousands of distinct Markov Decision Processes of varying\ndifficulty. We experiment with lilGym with different models and learning\nregimes. Our results and analysis show that while existing methods are able to\nachieve non-trivial performance, lilGym forms a challenging open problem.\nlilGym is available at https://lil.nlp.cornell.edu/lilgym/.\n","authors":["Anne Wu","Kianté Brantley","Noriyuki Kojima","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2211.01994v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09902v1","updated":"2022-12-19T22:50:40Z","published":"2022-12-19T22:50:40Z","title":"Dexterous Manipulation from Images: Autonomous Real-World RL via Substep\n  Guidance","summary":"  Complex and contact-rich robotic manipulation tasks, particularly those that\ninvolve multi-fingered hands and underactuated object manipulation, present a\nsignificant challenge to any control method. Methods based on reinforcement\nlearning offer an appealing choice for such settings, as they can enable robots\nto learn to delicately balance contact forces and dexterously reposition\nobjects without strong modeling assumptions. However, running reinforcement\nlearning on real-world dexterous manipulation systems often requires\nsignificant manual engineering. This negates the benefits of autonomous data\ncollection and ease of use that reinforcement learning should in principle\nprovide. In this paper, we describe a system for vision-based dexterous\nmanipulation that provides a \"programming-free\" approach for users to define\nnew tasks and enable robots with complex multi-fingered hands to learn to\nperform them through interaction. The core principle underlying our system is\nthat, in a vision-based setting, users should be able to provide high-level\nintermediate supervision that circumvents challenges in teleoperation or\nkinesthetic teaching which allow a robot to not only learn a task efficiently\nbut also to autonomously practice. Our system includes a framework for users to\ndefine a final task and intermediate sub-tasks with image examples, a\nreinforcement learning procedure that learns the task autonomously without\ninterventions, and experimental results with a four-finger robotic hand\nlearning multi-stage object manipulation tasks directly in the real world,\nwithout simulation, manual modeling, or reward engineering.\n","authors":["Kelvin Xu","Zheyuan Hu","Ria Doshi","Aaron Rovinsky","Vikash Kumar","Abhishek Gupta","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2212.09902v1.pdf","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2212.09900v1","updated":"2022-12-19T22:43:08Z","published":"2022-12-19T22:43:08Z","title":"Policy learning \"without'' overlap: Pessimism and generalized empirical\n  Bernstein's inequality","summary":"  This paper studies offline policy learning, which aims at utilizing\nobservations collected a priori (from either fixed or adaptively evolving\nbehavior policies) to learn an optimal individualized decision rule that\nachieves the best overall outcomes for a given population. Existing policy\nlearning methods rely on a uniform overlap assumption, i.e., the propensities\nof exploring all actions for all individual characteristics are lower bounded\nin the offline dataset; put differently, the performance of the existing\nmethods depends on the worst-case propensity in the offline dataset. As one has\nno control over the data collection process, this assumption can be unrealistic\nin many situations, especially when the behavior policies are allowed to evolve\nover time with diminishing propensities for certain actions.\n  In this paper, we propose a new algorithm that optimizes lower confidence\nbounds (LCBs) -- instead of point estimates -- of the policy values. The LCBs\nare constructed using knowledge of the behavior policies for collecting the\noffline data. Without assuming any uniform overlap condition, we establish a\ndata-dependent upper bound for the suboptimality of our algorithm, which only\ndepends on (i) the overlap for the optimal policy, and (ii) the complexity of\nthe policy class we optimize over. As an implication, for adaptively collected\ndata, we ensure efficient policy learning as long as the propensities for\noptimal actions are lower bounded over time, while those for suboptimal ones\nare allowed to diminish arbitrarily fast. In our theoretical analysis, we\ndevelop a new self-normalized type concentration inequality for\ninverse-propensity-weighting estimators, generalizing the well-known empirical\nBernstein's inequality to unbounded and non-i.i.d. data.\n","authors":["Ying Jin","Zhimei Ren","Zhuoran Yang","Zhaoran Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.09006v2","updated":"2022-12-19T22:29:03Z","published":"2022-02-18T03:32:08Z","title":"KINet: Keypoint Interaction Networks for Unsupervised Forward Modeling","summary":"  Object-centric representation is an essential abstraction for forward\nprediction. Most existing forward models learn this representation through\nextensive supervision (e.g., object class and bounding box) although such\nground-truth information is not readily accessible in reality. To address this,\nwe introduce KINet (Keypoint Interaction Network) -- an end-to-end unsupervised\nframework to reason about object interactions based on a keypoint\nrepresentation. Using visual observations, our model learns to associate\nobjects with keypoint coordinates and discovers a graph representation of the\nsystem as a set of keypoint embeddings and their relations. It then learns an\naction-conditioned forward model using contrastive estimation to predict future\nkeypoint states. By learning to perform physical reasoning in the keypoint\nspace, our model automatically generalizes to scenarios with a different number\nof objects, novel backgrounds, and unseen object geometries. Experiments\ndemonstrate the effectiveness of our model in accurately performing forward\nprediction and learning plannable object-centric representations which can also\nbe used in downstream robotic manipulation tasks.\n","authors":["Alireza Rezazadeh","Changhyun Choi"],"pdf_url":"https://arxiv.org/pdf/2202.09006v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.01875v2","updated":"2022-12-19T22:20:54Z","published":"2022-05-04T03:35:12Z","title":"Machine Learning based Framework for Robust Price-Sensitivity Estimation\n  with Application to Airline Pricing","summary":"  We consider the problem of dynamic pricing of a product in the presence of\nfeature-dependent price sensitivity. Developing practical algorithms that can\nestimate price elasticities robustly, especially when information about no\npurchases (losses) is not available, to drive such automated pricing systems is\na challenge faced by many industries. Based on the Poisson semi-parametric\napproach, we construct a flexible yet interpretable demand model where the\nprice related part is parametric while the remaining (nuisance) part of the\nmodel is non-parametric and can be modeled via sophisticated machine learning\n(ML) techniques. The estimation of price-sensitivity parameters of this model\nvia direct one-stage regression techniques may lead to biased estimates due to\nregularization. To address this concern, we propose a two-stage estimation\nmethodology which makes the estimation of the price-sensitivity parameters\nrobust to biases in the estimators of the nuisance parameters of the model. In\nthe first-stage we construct estimators of observed purchases and prices given\nthe feature vector using sophisticated ML estimators such as deep neural\nnetworks. Utilizing the estimators from the first-stage, in the second-stage we\nleverage a Bayesian dynamic generalized linear model to estimate the\nprice-sensitivity parameters. We test the performance of the proposed\nestimation schemes on simulated and real sales transaction data from the\nAirline industry. Our numerical studies demonstrate that our proposed two-stage\napproach reduces the estimation error in price-sensitivity parameters from 25\\%\nto 4\\% in realistic simulation settings. The two-stage estimation techniques\nproposed in this work allows practitioners to leverage modern ML techniques to\nrobustly estimate price-sensitivities while still maintaining interpretability\nand allowing ease of validation of its various constituent parts.\n","authors":["Ravi Kumar","Shahin Boluki","Karl Isler","Jonas Rauch","Darius Walczak"],"pdf_url":"https://arxiv.org/pdf/2205.01875v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2107.14228v3","updated":"2022-12-19T22:15:58Z","published":"2021-07-29T17:59:05Z","title":"Open-World Entity Segmentation","summary":"  We introduce a new image segmentation task, called Entity Segmentation (ES),\nwhich aims to segment all visual entities (objects and stuffs) in an image\nwithout predicting their semantic labels. By removing the need of class label\nprediction, the models trained for such task can focus more on improving\nsegmentation quality. It has many practical applications such as image\nmanipulation and editing where the quality of segmentation masks is crucial but\nclass labels are less important. We conduct the first-ever study to investigate\nthe feasibility of convolutional center-based representation to segment things\nand stuffs in a unified manner, and show that such representation fits\nexceptionally well in the context of ES. More specifically, we propose a\nCondInst-like fully-convolutional architecture with two novel modules\nspecifically designed to exploit the class-agnostic and non-overlapping\nrequirements of ES. Experiments show that the models designed and trained for\nES significantly outperforms popular class-specific panoptic segmentation\nmodels in terms of segmentation quality. Moreover, an ES model can be easily\ntrained on a combination of multiple datasets without the need to resolve label\nconflicts in dataset merging, and the model trained for ES on one or more\ndatasets can generalize very well to other test datasets of unseen domains. The\ncode has been released at https://github.com/dvlab-research/Entity/.\n","authors":["Lu Qi","Jason Kuen","Yi Wang","Jiuxiang Gu","Hengshuang Zhao","Zhe Lin","Philip Torr","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2107.14228v3.pdf","comment":"Project page: http://luqi.info/Entity_Web"},{"id":"http://arxiv.org/abs/2209.05408v3","updated":"2022-12-19T22:12:07Z","published":"2022-09-12T16:59:45Z","title":"Deterministic Sequencing of Exploration and Exploitation for\n  Reinforcement Learning","summary":"  We propose Deterministic Sequencing of Exploration and Exploitation (DSEE)\nalgorithm with interleaving exploration and exploitation epochs for model-based\nRL problems that aim to simultaneously learn the system model, i.e., a Markov\ndecision process (MDP), and the associated optimal policy. During exploration,\nDSEE explores the environment and updates the estimates for expected reward and\ntransition probabilities. During exploitation, the latest estimates of the\nexpected reward and transition probabilities are used to obtain a robust policy\nwith high probability. We design the lengths of the exploration and\nexploitation epochs such that the cumulative regret grows as a sub-linear\nfunction of time.\n","authors":["Piyush Gupta","Vaibhav Srivastava"],"pdf_url":"https://arxiv.org/pdf/2209.05408v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.00698v2","updated":"2022-12-19T21:35:14Z","published":"2022-07-02T00:22:49Z","title":"Uncertainty Quantification for Deep Unrolling-Based Computational\n  Imaging","summary":"  Deep unrolling is an emerging deep learning-based image reconstruction\nmethodology that bridges the gap between model-based and purely deep\nlearning-based image reconstruction methods. Although deep unrolling methods\nachieve state-of-the-art performance for imaging problems and allow the\nincorporation of the observation model into the reconstruction process, they do\nnot provide any uncertainty information about the reconstructed image, which\nseverely limits their use in practice, especially for safety-critical imaging\napplications. In this paper, we propose a learning-based image reconstruction\nframework that incorporates the observation model into the reconstruction task\nand that is capable of quantifying epistemic and aleatoric uncertainties, based\non deep unrolling and Bayesian neural networks. We demonstrate the uncertainty\ncharacterization capability of the proposed framework on magnetic resonance\nimaging and computed tomography reconstruction problems. We investigate the\ncharacteristics of the epistemic and aleatoric uncertainty information provided\nby the proposed framework to motivate future research on utilizing uncertainty\ninformation to develop more accurate, robust, trustworthy, uncertainty-aware,\nlearning-based image reconstruction and analysis methods for imaging problems.\nWe show that the proposed framework can provide uncertainty information while\nachieving comparable reconstruction performance to state-of-the-art deep\nunrolling methods.\n","authors":["Canberk Ekmekci","Mujdat Cetin"],"pdf_url":"https://arxiv.org/pdf/2207.00698v2.pdf","comment":"23 pages, revised manuscript, accepted for publication as a regular\n  paper in the IEEE Transactions on Computational Imaging"},{"id":"http://arxiv.org/abs/2212.09858v1","updated":"2022-12-19T21:07:27Z","published":"2022-12-19T21:07:27Z","title":"Continuous Semi-Supervised Nonnegative Matrix Factorization","summary":"  Nonnegative matrix factorization can be used to automatically detect topics\nwithin a corpus in an unsupervised fashion. The technique amounts to an\napproximation of a nonnegative matrix as the product of two nonnegative\nmatrices of lower rank. In this paper, we show this factorization can be\ncombined with regression on a continuous response variable. In practice, the\nmethod performs better than regression done after topics are identified and\nretrains interpretability.\n","authors":["Michael R. Lindstrom","Xiaofu Ding","Feng Liu","Anand Somayajula","Deanna Needell"],"pdf_url":"https://arxiv.org/pdf/2212.09858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09849v1","updated":"2022-12-19T20:46:43Z","published":"2022-12-19T20:46:43Z","title":"Dataless Knowledge Fusion by Merging Weights of Language Models","summary":"  Fine-tuning pre-trained language models has become the prevalent paradigm for\nbuilding downstream NLP models. Oftentimes fine-tuned models are readily\navailable but their training data is not, due to data privacy or intellectual\nproperty concerns. This creates a barrier to fusing knowledge across individual\nmodels to yield a better single model. In this paper, we study the problem of\nmerging individual models built on different training data sets to obtain a\nsingle model that performs well both across all data set domains and can\ngeneralize on out-of-domain data. We propose a dataless knowledge fusion method\nthat merges models in their parameter space, guided by weights that minimize\nprediction differences between the merged model and the individual models. Over\na battery of evaluation settings, we show that the proposed method\nsignificantly outperforms baselines such as Fisher-weighted averaging or model\nensembling. Further, we find that our method is a promising alternative to\nmulti-task learning that can preserve or sometimes improve over the individual\nmodels without access to the training data. Finally, model merging is more\nefficient than training a multi-task model, thus making it applicable to a\nwider set of scenarios.\n","authors":["Xisen Jin","Xiang Ren","Daniel Preotiuc-Pietro","Pengxiang Cheng"],"pdf_url":"https://arxiv.org/pdf/2212.09849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09844v1","updated":"2022-12-19T20:41:44Z","published":"2022-12-19T20:41:44Z","title":"Counterfactual Risk Assessments under Unmeasured Confounding","summary":"  Statistical risk assessments inform consequential decisions such as pretrial\nrelease in criminal justice, and loan approvals in consumer finance. Such risk\nassessments make counterfactual predictions, predicting the likelihood of an\noutcome under a proposed decision (e.g., what would happen if we approved this\nloan?). A central challenge, however, is that there may have been unmeasured\nconfounders that jointly affected past decisions and outcomes in the historical\ndata. This paper proposes a tractable mean outcome sensitivity model that\nbounds the extent to which unmeasured confounders could affect outcomes on\naverage. The mean outcome sensitivity model partially identifies the\nconditional likelihood of the outcome under the proposed decision, popular\npredictive performance metrics (e.g., accuracy, calibration, TPR, FPR), and\ncommonly-used predictive disparities. We derive their sharp identified sets,\nand we then solve three tasks that are essential to deploying statistical risk\nassessments in high-stakes settings. First, we propose a doubly-robust learning\nprocedure for the bounds on the conditional likelihood of the outcome under the\nproposed decision. Second, we translate our estimated bounds on the conditional\nlikelihood of the outcome under the proposed decision into a robust, plug-in\ndecision-making policy. Third, we develop doubly-robust estimators of the\nbounds on the predictive performance of an existing risk assessment.\n","authors":["Ashesh Rambachan","Amanda Coston","Edward Kennedy"],"pdf_url":"https://arxiv.org/pdf/2212.09844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09840v1","updated":"2022-12-19T20:32:27Z","published":"2022-12-19T20:32:27Z","title":"Dynamic Sparse Network for Time Series Classification: Learning What to\n  \"see''","summary":"  The receptive field (RF), which determines the region of time series to be\n``seen'' and used, is critical to improve the performance for time series\nclassification (TSC). However, the variation of signal scales across and within\ntime series data, makes it challenging to decide on proper RF sizes for TSC. In\nthis paper, we propose a dynamic sparse network (DSN) with sparse connections\nfor TSC, which can learn to cover various RF without cumbersome\nhyper-parameters tuning. The kernels in each sparse layer are sparse and can be\nexplored under the constraint regions by dynamic sparse training, which makes\nit possible to reduce the resource cost. The experimental results show that the\nproposed DSN model can achieve state-of-art performance on both univariate and\nmultivariate TSC datasets with less than 50\\% computational cost compared with\nrecent baseline methods, opening the path towards more accurate resource-aware\nmethods for time series analyses. Our code is publicly available at:\nhttps://github.com/QiaoXiao7282/DSN.\n","authors":["Qiao Xiao","Boqian Wu","Yu Zhang","Shiwei Liu","Mykola Pechenizkiy","Elena Mocanu","Decebal Constantin Mocanu"],"pdf_url":"https://arxiv.org/pdf/2212.09840v1.pdf","comment":"Accepted at Neural Information Processing Systems (NeurIPS 2022)"},{"id":"http://arxiv.org/abs/2109.11897v2","updated":"2022-12-19T20:08:50Z","published":"2021-09-24T11:36:58Z","title":"Adaptivity for clustering-based reduced-order modeling of localized\n  history-dependent phenomena","summary":"  This paper proposes a novel Adaptive Clustering-based Reduced-Order Modeling\n(ACROM) framework to significantly improve and extend the recent family of\nclustering-based reduced-order models (CROMs). This adaptive framework enables\nthe clustering-based domain decomposition to evolve dynamically throughout the\nproblem solution, ensuring optimum refinement in regions where the relevant\nfields present steeper gradients. It offers a new route to fast and accurate\nmaterial modeling of history-dependent nonlinear problems involving highly\nlocalized plasticity and damage phenomena. The overall approach is composed of\nthree main building blocks: target clusters selection criterion, adaptive\ncluster analysis, and computation of cluster interaction tensors. In addition,\nan adaptive clustering solution rewinding procedure and a dynamic adaptivity\nsplit factor strategy are suggested to further enhance the adaptive process.\nThe coined Adaptive Self-Consistent Clustering Analysis (ASCA) is shown to\nperform better than its static counterpart when capturing the multi-scale\nelasto-plastic behavior of a particle-matrix composite and predicting the\nassociated fracture and toughness. Given the encouraging results shown in this\npaper, the ACROM framework sets the stage and opens new avenues to explore\nadaptivity in the context of CROMs.\n","authors":["Bernardo P. Ferreira","F. M. Andrade Pires","Miguel A. Bessa"],"pdf_url":"https://arxiv.org/pdf/2109.11897v2.pdf","comment":"The code associated to this publication is planned to be released as\n  open source in 2022"},{"id":"http://arxiv.org/abs/2212.09832v1","updated":"2022-12-19T20:08:40Z","published":"2022-12-19T20:08:40Z","title":"Denoising instrumented mouthguard measurements of head impact kinematics\n  with a convolutional neural network","summary":"  Wearable sensors for measuring head kinematics can be noisy due to imperfect\ninterfaces with the body. Mouthguards are used to measure head kinematics\nduring impacts in traumatic brain injury (TBI) studies, but deviations from\nreference kinematics can still occur due to potential looseness. In this study,\ndeep learning is used to compensate for the imperfect interface and improve\nmeasurement accuracy. A set of one-dimensional convolutional neural network\n(1D-CNN) models was developed to denoise mouthguard kinematics measurements\nalong three spatial axes of linear acceleration and angular velocity. The\ndenoised kinematics had significantly reduced errors compared to reference\nkinematics, and reduced errors in brain injury criteria and tissue strain and\nstrain rate calculated via finite element modeling. The 1D-CNN models were also\ntested on an on-field dataset of college football impacts and a post-mortem\nhuman subject dataset, with similar denoising effects observed. The models can\nbe used to improve detection of head impacts and TBI risk evaluation, and\npotentially extended to other sensors measuring kinematics.\n","authors":["Xianghao Zhan","Yuzhe Liu","Nicholas J. Cecchi","Ashlyn A. Callan","Enora Le Flao","Olivier Gevaert","Michael M. Zeineh","Gerald A. Grant","David B. Camarillo"],"pdf_url":"https://arxiv.org/pdf/2212.09832v1.pdf","comment":"39 pages, 9 figures, 4 tables"},{"id":"http://arxiv.org/abs/2206.05442v3","updated":"2022-12-19T19:37:45Z","published":"2022-06-11T06:38:06Z","title":"Automatically Answering and Generating Machine Learning Final Exams","summary":"  Can a machine learn machine learning? We propose to answer this question\nusing the same criteria we use to answer a similar question: can a human learn\nmachine learning? We automatically answer final exams in MIT's, Harvard's and\nCornell's large machine learning courses and generate new questions at a human\nlevel. Recently, program synthesis and few-shot learning solved\nuniversity-level problem set questions in mathematics and STEM courses at a\nhuman level. In this work, we solve questions from final exams that differ from\nproblem sets in several ways: the questions are longer, have multiple parts,\nare more complicated, and span a broader set of topics. We provide a new\ndataset and benchmark of questions from machine learning final exams and code\nfor automatically answering these questions and generating new questions. To\nmake our dataset a reproducible benchmark, we use automatic checkers for\nmultiple choice questions, questions with numeric answers, and questions with\nexpression answers, and evaluate a large free language model, Meta's OPT, and\ncompare the results with Open AI's GPT-3, ChatGPT, and Codex. A student survey\ncomparing the quality, appropriateness, and difficulty of machine-generated\nquestions with human-written questions shows that across multiple aspects,\nmachine-generated questions are indistinguishable from human-generated\nquestions and are suitable for final exams. We perform ablation studies\ncomparing zero-shot learning with few-shot learning, chain-of-thought\nprompting, GPT-3, ChatGPT, and OPT pre-trained on text and Codex fine-tuned on\ncode on a range of machine learning topics and find that few-shot learning\nmethods perform best. We make our data and code publicly available for the\nmachine learning community.\n","authors":["Sarah Zhang","Reece Shuttleworth","Derek Austin","Yann Hicke","Leonard Tang","Sathwik Karnik","Darnell Granberry","Iddo Drori"],"pdf_url":"https://arxiv.org/pdf/2206.05442v3.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2212.09811v1","updated":"2022-12-19T19:29:40Z","published":"2022-12-19T19:29:40Z","title":"Memory-efficient NLLB-200: Language-specific Expert Pruning of a\n  Massively Multilingual Machine Translation Model","summary":"  Compared to conventional bilingual translation systems, massively\nmultilingual machine translation is appealing because a single model can\ntranslate into multiple languages and benefit from knowledge transfer for low\nresource languages. On the other hand, massively multilingual models suffer\nfrom the curse of multilinguality, unless scaling their size massively, which\nincreases their training and inference costs. Sparse Mixture-of-Experts models\nare a way to drastically increase model capacity without the need for a\nproportional amount of computing. The recently released NLLB-200 is an example\nof such a model. It covers 202 languages but requires at least four 32GB GPUs\njust for inference. In this work, we propose a pruning method that allows the\nremoval of up to 80\\% of experts with a negligible loss in translation quality,\nwhich makes it feasible to run the model on a single 32GB GPU. Further analysis\nsuggests that our pruning metrics allow to identify language-specific experts\nand prune non-relevant experts for a given language pair.\n","authors":["Yeskendir Koishekenov","Vassilina Nikoulina","Alexandre Berard"],"pdf_url":"https://arxiv.org/pdf/2212.09811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.06049v3","updated":"2022-12-19T19:21:47Z","published":"2022-08-11T21:58:36Z","title":"MILAN: Masked Image Pretraining on Language Assisted Representation","summary":"  Self-attention based transformer models have been dominating many computer\nvision tasks in the past few years. Their superb model qualities heavily depend\non the excessively large labeled image datasets. In order to reduce the\nreliance on large labeled datasets, reconstruction based masked autoencoders\nare gaining popularity, which learn high quality transferable representations\nfrom unlabeled images. For the same purpose, recent weakly supervised image\npretraining methods explore language supervision from text captions\naccompanying the images. In this work, we propose masked image pretraining on\nlanguage assisted representation, dubbed as MILAN. Instead of predicting raw\npixels or low level features, our pretraining objective is to reconstruct the\nimage features with substantial semantic signals that are obtained using\ncaption supervision. Moreover, to accommodate our reconstruction target, we\npropose a more effective prompting decoder architecture and a semantic aware\nmask sampling mechanism, which further advance the transfer performance of the\npretrained model. Experimental results demonstrate that MILAN delivers higher\naccuracy than the previous works. When the masked autoencoder is pretrained and\nfinetuned on ImageNet-1K dataset with an input resolution of 224x224, MILAN\nachieves a top-1 accuracy of 85.4% on ViT-Base, surpassing previous\nstate-of-the-arts by 1%. In the downstream semantic segmentation task, MILAN\nachieves 52.7 mIoU using ViT-Base on ADE20K dataset, outperforming previous\nmasked pretraining results by 4 points.\n","authors":["Zejiang Hou","Fei Sun","Yen-Kuang Chen","Yuan Xie","Sun-Yuan Kung"],"pdf_url":"https://arxiv.org/pdf/2208.06049v3.pdf","comment":"add new experiments and improved results. provide repo link"},{"id":"http://arxiv.org/abs/2212.09803v1","updated":"2022-12-19T19:16:29Z","published":"2022-12-19T19:16:29Z","title":"Training Trajectories of Language Models Across Scales","summary":"  Scaling up language models has led to unprecedented performance gains, but\nlittle is understood about how the training dynamics change as models get\nlarger. How do language models of different sizes learn during pre-training?\nWhy do larger language models demonstrate more desirable behaviors? In this\npaper, we analyze the intermediate training checkpoints of differently sized\nOPT models (Zhang et al.,2022)--from 125M to 175B parameters--on next-token\nprediction, sequence-level generation, and downstream tasks. We find that 1) at\na given perplexity and independent of model sizes, a similar subset of training\ntokens see the most significant reduction in loss, with the rest stagnating or\nshowing double-descent behavior; 2) early in training, all models learn to\nreduce the perplexity of grammatical sequences that contain hallucinations,\nwith small models halting at this suboptimal distribution and larger ones\neventually learning to assign these sequences lower probabilities; 3)\nperplexity is a strong predictor of in-context learning performance on 74\nmultiple-choice tasks from BIG-Bench, and this holds independent of the model\nsize. Together, these results show that perplexity is more predictive of model\nbehaviors than model size or training computation.\n","authors":["Mengzhou Xia","Mikel Artetxe","Chunting Zhou","Xi Victoria Lin","Ramakanth Pasunuru","Danqi Chen","Luke Zettlemoyer","Ves Stoyanov"],"pdf_url":"https://arxiv.org/pdf/2212.09803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09802v1","updated":"2022-12-19T19:15:36Z","published":"2022-12-19T19:15:36Z","title":"Panoptic Lifting for 3D Scene Understanding with Neural Fields","summary":"  We propose Panoptic Lifting, a novel approach for learning panoptic 3D\nvolumetric representations from images of in-the-wild scenes. Once trained, our\nmodel can render color images together with 3D-consistent panoptic segmentation\nfrom novel viewpoints.\n  Unlike existing approaches which use 3D input directly or indirectly, our\nmethod requires only machine-generated 2D panoptic segmentation masks inferred\nfrom a pre-trained network. Our core contribution is a panoptic lifting scheme\nbased on a neural field representation that generates a unified and multi-view\nconsistent, 3D panoptic representation of the scene. To account for\ninconsistencies of 2D instance identifiers across views, we solve a linear\nassignment with a cost based on the model's current predictions and the\nmachine-generated segmentation masks, thus enabling us to lift 2D instances to\n3D in a consistent way. We further propose and ablate contributions that make\nour method more robust to noisy, machine-generated labels, including test-time\naugmentations for confidence estimates, segment consistency loss, bounded\nsegmentation fields, and gradient stopping.\n  Experimental results validate our approach on the challenging Hypersim,\nReplica, and ScanNet datasets, improving by 8.4, 13.8, and 10.6% in scene-level\nPQ over state of the art.\n","authors":["Yawar Siddiqui","Lorenzo Porzi","Samuel Rota Buló","Norman Müller","Matthias Nießner","Angela Dai","Peter Kontschieder"],"pdf_url":"https://arxiv.org/pdf/2212.09802v1.pdf","comment":"Project Page: https://nihalsid.github.io/panoptic-lifting/, Video:\n  https://youtu.be/QtsiL-6rSuM"},{"id":"http://arxiv.org/abs/2104.13227v2","updated":"2022-12-19T19:05:09Z","published":"2021-04-24T22:45:50Z","title":"Quantum causal inference in the presence of hidden common causes: An\n  entropic approach","summary":"  Quantum causality is an emerging field of study which has the potential to\ngreatly advance our understanding of quantum systems. In this paper, we put\nforth a theoretical framework for merging quantum information science and\ncausal inference by exploiting entropic principles. For this purpose, we\nleverage the tradeoff between the entropy of hidden cause and the conditional\nmutual information of observed variables to develop a scalable algorithmic\napproach for inferring causality in the presence of latent confounders (common\ncauses) in quantum systems. As an application, we consider a system of three\nentangled qubits and transmit the second and third qubits over separate noisy\nquantum channels. In this model, we validate that the first qubit is a latent\nconfounder and the common cause of the second and third qubits. In contrast,\nwhen two entangled qubits are prepared and one of them is sent over a noisy\nchannel, there is no common confounder. We also demonstrate that the proposed\napproach outperforms the results of classical causal inference for the Tubingen\ndatabase when the variables are classical by exploiting quantum dependence\nbetween variables through density matrices rather than joint probability\ndistributions. Thus, the proposed approach unifies classical and quantum causal\ninference in a principled way.\n","authors":["Mohammad Ali Javidian","Vaneet Aggarwal","Zubin Jacob"],"pdf_url":"https://arxiv.org/pdf/2104.13227v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2102.11764"},{"id":"http://arxiv.org/abs/2105.04090v3","updated":"2022-12-19T18:27:36Z","published":"2021-05-10T03:44:03Z","title":"MuseMorphose: Full-Song and Fine-Grained Piano Music Style Transfer with\n  One Transformer VAE","summary":"  Transformers and variational autoencoders (VAE) have been extensively\nemployed for symbolic (e.g., MIDI) domain music generation. While the former\nboast an impressive capability in modeling long sequences, the latter allow\nusers to willingly exert control over different parts (e.g., bars) of the music\nto be generated. In this paper, we are interested in bringing the two together\nto construct a single model that exhibits both strengths. The task is split\ninto two steps. First, we equip Transformer decoders with the ability to accept\nsegment-level, time-varying conditions during sequence generation.\nSubsequently, we combine the developed and tested in-attention decoder with a\nTransformer encoder, and train the resulting MuseMorphose model with the VAE\nobjective to achieve style transfer of long pop piano pieces, in which users\ncan specify musical attributes including rhythmic intensity and polyphony\n(i.e., harmonic fullness) they desire, down to the bar level. Experiments show\nthat MuseMorphose outperforms recurrent neural network (RNN) based baselines on\nnumerous widely-used metrics for style transfer tasks.\n","authors":["Shih-Lun Wu","Yi-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2105.04090v3.pdf","comment":"Accepted for Publication at IEEE/ACM Transactions on Audio, Speech,\n  and Language Processing (TASLP). Online supplemental materials are attached\n  to the end of this arXiv version"}],"Multimedia":[{"id":"http://arxiv.org/abs/2105.04090v3","updated":"2022-12-19T18:27:36Z","published":"2021-05-10T03:44:03Z","title":"MuseMorphose: Full-Song and Fine-Grained Piano Music Style Transfer with\n  One Transformer VAE","summary":"  Transformers and variational autoencoders (VAE) have been extensively\nemployed for symbolic (e.g., MIDI) domain music generation. While the former\nboast an impressive capability in modeling long sequences, the latter allow\nusers to willingly exert control over different parts (e.g., bars) of the music\nto be generated. In this paper, we are interested in bringing the two together\nto construct a single model that exhibits both strengths. The task is split\ninto two steps. First, we equip Transformer decoders with the ability to accept\nsegment-level, time-varying conditions during sequence generation.\nSubsequently, we combine the developed and tested in-attention decoder with a\nTransformer encoder, and train the resulting MuseMorphose model with the VAE\nobjective to achieve style transfer of long pop piano pieces, in which users\ncan specify musical attributes including rhythmic intensity and polyphony\n(i.e., harmonic fullness) they desire, down to the bar level. Experiments show\nthat MuseMorphose outperforms recurrent neural network (RNN) based baselines on\nnumerous widely-used metrics for style transfer tasks.\n","authors":["Shih-Lun Wu","Yi-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2105.04090v3.pdf","comment":"Accepted for Publication at IEEE/ACM Transactions on Audio, Speech,\n  and Language Processing (TASLP). Online supplemental materials are attached\n  to the end of this arXiv version"}]},"2022-12-18T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2212.09180v1","updated":"2022-12-18T22:07:55Z","published":"2022-12-18T22:07:55Z","title":"Don't Forget Your ABC's: Evaluating the State-of-the-Art in\n  Chat-Oriented Dialogue Systems","summary":"  There has been great recent advancement in human-computer chat. However,\nproper evaluation currently requires human judgements that produce notoriously\nhigh-variance metrics due to their inherent subjectivity. Furthermore, there is\nlittle standardization in the methods and labels used for evaluation, with an\noverall lack of work to compare and assess the validity of various evaluation\napproaches. As a consequence, existing evaluation results likely leave an\nincomplete picture of the strengths and weaknesses of open-domain chatbots. We\naim towards a dimensional evaluation of human-computer chat that can reliably\nmeasure several distinct aspects of chat quality. To this end, we present our\nnovel human evaluation method that quantifies the rate of several\nquality-related chatbot behaviors. Our results demonstrate our method to be\nmore suitable for dimensional chat evaluation than alternative likert-style or\ncomparative methods. We then use our validated method and existing methods to\nevaluate four open-domain chat models from the recent literature.\n","authors":["Sarah E. Finch","James D. Finch","Jinho D. Choi"],"pdf_url":"https://arxiv.org/pdf/2212.09180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09171v1","updated":"2022-12-18T21:22:28Z","published":"2022-12-18T21:22:28Z","title":"Rainproof: An Umbrella To Shield Text Generators From\n  Out-Of-Distribution Data","summary":"  As more and more conversational and translation systems are deployed in\nproduction, it is essential to implement and to develop effective control\nmechanisms guaranteeing their proper functioning and security. An essential\ncomponent to ensure safe system behavior is out-of-distribution (OOD)\ndetection, which aims at detecting whether an input sample is statistically far\nfrom the training distribution. Although OOD detection is a widely covered\ntopic in classification tasks, it has received much less attention in text\ngeneration. This paper addresses the problem of OOD detection for machine\ntranslation and dialog generation from an operational perspective. Our\ncontributions include: (i) RAINPROOF a Relative informAItioN Projection ODD\ndetection framework; and (ii) a more operational evaluation setting for OOD\ndetection. Surprisingly, we find that OOD detection is not necessarily aligned\nwith task-specific measures. The OOD detector may filter out samples that are\nwell processed by the model and keep samples that are not, leading to weaker\nperformance. Our results show that RAINPROOF breaks this curse and achieve good\nresults in OOD detection while increasing performance.\n","authors":["Maxime Darrin","Pablo Piantanida","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2212.09171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09170v1","updated":"2022-12-18T21:11:49Z","published":"2022-12-18T21:11:49Z","title":"On Isotropy and Learning Dynamics of Contrastive-based Sentence\n  Representation Learning","summary":"  Incorporating contrastive learning objectives in sentence representation\nlearning (SRL) has yielded significant improvements on many sentence-level NLP\ntasks. However, It is not well understood why contrastive learning works for\nlearning sentence-level semantics. In this paper, we take a closer look at\ncontrastive sentence representation learning through the lens of isotropy and\nlearning dynamics. We interpret its success stories through the geometry of the\nrepresentation shifts. We show that contrastive learning brings isotropy, and\nsurprisingly learns to converge tokens to similar positions in the semantic\nspace if given the signal that they are in the same sentence. Also, what we\nformalize as \"spurious contextualization\" is mitigated for semantically\nmeaningful tokens, while augmented for functional ones. The embedding space is\npushed toward the origin during training, with more areas now better defined.\nWe ablate these findings by observing the learning dynamic with different\ntraining temperatures, batch sizes and pooling methods. With these findings, we\naim to shed light on future designs of sentence representation learning\nmethods.\n","authors":["Chenghao Xiao","Yang Long","Noura Al Moubayed"],"pdf_url":"https://arxiv.org/pdf/2212.09170v1.pdf","comment":"17 pages, 24 figures"},{"id":"http://arxiv.org/abs/2212.09146v1","updated":"2022-12-18T19:27:41Z","published":"2022-12-18T19:27:41Z","title":"Can Retriever-Augmented Language Models Reason? The Blame Game Between\n  the Retriever and the Language Model","summary":"  The emergence of large pretrained models has enabled language models to\nachieve superior performance in common NLP tasks, including language modeling\nand question answering, compared to previous static word representation\nmethods. Augmenting these models with a retriever to retrieve the related text\nand documents as supporting information has shown promise in effectively\nsolving NLP problems in a more interpretable way given that the additional\nknowledge is injected explicitly rather than being captured in the models'\nparameters. In spite of the recent progress, our analysis on\nretriever-augmented language models shows that this class of language models\nstill lack reasoning over the retrieved documents. In this paper, we study the\nstrengths and weaknesses of different retriever-augmented language models such\nas REALM, kNN-LM, FiD, ATLAS, and Flan-T5 in reasoning over the selected\ndocuments in different tasks. In particular, we analyze the reasoning failures\nof each of these models and study how the models' failures in reasoning are\nrooted in the retriever module as well as the language model.\n","authors":["Parishad BehnamGhader","Santiago Miret","Siva Reddy"],"pdf_url":"https://arxiv.org/pdf/2212.09146v1.pdf","comment":"14 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.09140v1","updated":"2022-12-18T18:10:45Z","published":"2022-12-18T18:10:45Z","title":"Unsupervised Discontinuous Constituency Parsing with Mildly\n  Context-Sensitive Grammars","summary":"  We study grammar induction with mildly context-sensitive grammars for\nunsupervised discontinuous parsing. Using the probabilistic linear context-free\nrewriting system (LCFRS) formalism, our approach fixes the rule structure in\nadvance and focuses on parameter learning with maximum likelihood. To reduce\nthe computational complexity of both parsing and parameter estimation, we\nrestrict the grammar formalism to LCFRS-2 (i.e., binary LCFRS with fan-out two)\nand further discard rules that require O(n^6) time to parse, reducing inference\nto O(n^5). We find that using a large number of nonterminals is beneficial and\nthus make use of tensor decomposition-based rank-space dynamic programming with\nan embedding-based parameterization of rule probabilities to scale up the\nnumber of nonterminals. Experiments on German and Dutch show that our approach\nis able to induce linguistically meaningful trees with continuous and\ndiscontinuous structures\n","authors":["Songlin Yang","Roger P. Levy","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2212.09140v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.09125v1","updated":"2022-12-18T16:42:52Z","published":"2022-12-18T16:42:52Z","title":"Recall, Expand and Multi-Candidate Cross-Encode: Fast and Accurate\n  Ultra-Fine Entity Typing","summary":"  Ultra-fine entity typing (UFET) predicts extremely free-formed types (e.g.,\npresident, politician) of a given entity mention (e.g., Joe Biden) in context.\nState-of-the-art (SOTA) methods use the cross-encoder (CE) based architecture.\nCE concatenates the mention (and its context) with each type and feeds the\npairs into a pretrained language model (PLM) to score their relevance. It\nbrings deeper interaction between mention and types to reach better performance\nbut has to perform N (type set size) forward passes to infer types of a single\nmention. CE is therefore very slow in inference when the type set is large\n(e.g., N = 10k for UFET). To this end, we propose to perform entity typing in a\nrecall-expand-filter manner. The recall and expand stages prune the large type\nset and generate K (K is typically less than 256) most relevant type candidates\nfor each mention. At the filter stage, we use a novel model called MCCE to\nconcurrently encode and score these K candidates in only one forward pass to\nobtain the final type prediction. We investigate different variants of MCCE and\nextensive experiments show that MCCE under our paradigm reaches SOTA\nperformance on ultra-fine entity typing and is thousands of times faster than\nthe cross-encoder. We also found MCCE is very effective in fine-grained (130\ntypes) and coarse-grained (9 types) entity typing. Our code is available at\n\\url{https://github.com/modelscope/AdaSeq/tree/master/examples/MCCE}.\n","authors":["Chengyue Jiang","Wenyang Hui","Yong Jiang","Xiaobin Wang","Pengjun Xie","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2212.09125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09114v1","updated":"2022-12-18T15:57:46Z","published":"2022-12-18T15:57:46Z","title":"Curriculum Sampling for Dense Retrieval with Document Expansion","summary":"  The dual-encoder has become the de facto architecture for dense retrieval.\nTypically, it computes the latent representations of the query and document\nindependently, thus failing to fully capture the interactions between the query\nand document. To alleviate this, recent work expects to get query-informed\nrepresentations of documents. During training, it expands the document with a\nreal query, while replacing the real query with a generated pseudo query at\ninference. This discrepancy between training and inference makes the dense\nretrieval model pay more attention to the query information but ignore the\ndocument when computing the document representation. As a result, it even\nperforms worse than the vanilla dense retrieval model, since its performance\ndepends heavily on the relevance between the generated queries and the real\nquery. In this paper, we propose a curriculum sampling strategy, which also\nresorts to the pseudo query at training and gradually increases the relevance\nof the generated query to the real query. In this way, the retrieval model can\nlearn to extend its attention from the document only to both the document and\nquery, hence getting high-quality query-informed document representations.\nExperimental results on several passage retrieval datasets show that our\napproach outperforms the previous dense retrieval methods1.\n","authors":["Xingwei He","Yeyun Gong","A-Long Jin","Hang Zhang","Anlei Dong","Jian Jiao","Siu Ming Yiu","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2212.09114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09104v1","updated":"2022-12-18T15:10:05Z","published":"2022-12-18T15:10:05Z","title":"LaSQuE: Improved Zero-Shot Classification from Explanations Through\n  Quantifier Modeling and Curriculum Learning","summary":"  A hallmark of human intelligence is the ability to learn new concepts purely\nfrom language. Several recent approaches have explored training machine\nlearning models via natural language supervision. However, these approaches\nfall short in leveraging linguistic quantifiers (such as 'always' or 'rarely')\nand mimicking humans in compositionally learning complex tasks. Here, we\npresent LaSQuE, a method that can learn zero-shot classifiers from language\nexplanations by using three new strategies - (1) modeling the semantics of\nlinguistic quantifiers in explanations (including exploiting ordinal strength\nrelationships, such as 'always' > 'likely'), (2) aggregating information from\nmultiple explanations using an attention-based mechanism, and (3) model\ntraining via curriculum learning. With these strategies, LaSQuE outperforms\nprior work, showing an absolute gain of up to 7% in generalizing to unseen\nreal-world classification tasks.\n","authors":["Sayan Ghosh","Rakesh R Menon","Shashank Srivastava"],"pdf_url":"https://arxiv.org/pdf/2212.09104v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2202.05786v2","updated":"2022-12-18T14:52:44Z","published":"2022-02-11T17:31:12Z","title":"Multi-Modal Knowledge Graph Construction and Application: A Survey","summary":"  Recent years have witnessed the resurgence of knowledge engineering which is\nfeatured by the fast growth of knowledge graphs. However, most of existing\nknowledge graphs are represented with pure symbols, which hurts the machine's\ncapability to understand the real world. The multi-modalization of knowledge\ngraphs is an inevitable key step towards the realization of human-level machine\nintelligence. The results of this endeavor are Multi-modal Knowledge Graphs\n(MMKGs). In this survey on MMKGs constructed by texts and images, we first give\ndefinitions of MMKGs, followed with the preliminaries on multi-modal tasks and\ntechniques. We then systematically review the challenges, progresses and\nopportunities on the construction and application of MMKGs respectively, with\ndetailed analyses of the strength and weakness of different solutions. We\nfinalize this survey with open research problems relevant to MMKGs.\n","authors":["Xiangru Zhu","Zhixu Li","Xiaodan Wang","Xueyao Jiang","Penglei Sun","Xuwu Wang","Yanghua Xiao","Nicholas Jing Yuan"],"pdf_url":"https://arxiv.org/pdf/2202.05786v2.pdf","comment":"20 pages, 8 figures, 6 tables. Accepted by TKDE 2022"},{"id":"http://arxiv.org/abs/2212.09097v1","updated":"2022-12-18T14:41:13Z","published":"2022-12-18T14:41:13Z","title":"Continually Learning from Existing Models: Knowledge Accumulation for\n  Neural Machine Translation","summary":"  Although continually extending an existing NMT model to new domains or\nlanguages has attracted intensive interest in recent years, the equally\nvaluable problem of continually improving a given NMT model in its domain by\nleveraging knowledge from an unlimited number of existing NMT models is not\nexplored yet. To facilitate the study, we propose a formal definition for the\nproblem named knowledge accumulation for NMT (KA-NMT) with corresponding\ndatasets and evaluation metrics and develop a novel method for KA-NMT. We\ninvestigate a novel knowledge detection algorithm to identify beneficial\nknowledge from existing models at token level, and propose to learn from\nbeneficial knowledge and learn against other knowledge simultaneously to\nimprove learning efficiency. To alleviate catastrophic forgetting, we further\npropose to transfer knowledge from previous to current version of the given\nmodel. Extensive experiments show that our proposed method significantly and\nconsistently outperforms representative baselines under homogeneous,\nheterogeneous, and malicious model settings for different language pairs.\n","authors":["Yuanchi Zhang","Peng Li","Maosong Sun","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2212.09097v1.pdf","comment":"18 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.09095v1","updated":"2022-12-18T14:36:07Z","published":"2022-12-18T14:36:07Z","title":"Rethinking the Role of Scale for In-Context Learning: An\n  Interpretability-based Case Study at 66 Billion Scale","summary":"  Language models have been shown to perform better with an increase in scale\non a wide variety of tasks via the in-context learning paradigm. In this paper,\nwe investigate the hypothesis that the ability of a large language model to\nin-context learn-perform a task is not uniformly spread across all of its\nunderlying components. Using a 66 billion parameter language model (OPT-66B)\nacross a diverse set of 14 downstream tasks, we find this is indeed the case:\n$\\sim$70% of attention heads and $\\sim$20% of feed forward networks can be\nremoved with minimal decline in task performance. We find substantial overlap\nin the set of attention heads (un)important for in-context learning across\ntasks and number of in-context examples. We also address our hypothesis through\na task-agnostic lens, finding that a small set of attention heads in OPT-66B\nscore highly on their ability to perform primitive induction operations\nassociated with in-context learning, namely, prefix matching and copying. These\ninduction heads overlap with task-specific important heads, suggesting that\ninduction heads are among the heads capable of more sophisticated behaviors\nassociated with in-context learning. Overall, our study provides several\ninsights that indicate large language models may be under-trained to perform\nin-context learning and opens up questions on how to pre-train language models\nto more effectively perform in-context learning.\n","authors":["Hritik Bansal","Karthik Gopalakrishnan","Saket Dingliwal","Sravan Bodapati","Katrin Kirchhoff","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2212.09095v1.pdf","comment":"21 pages, 19 figures, 1 table, 2 algorithms"},{"id":"http://arxiv.org/abs/2212.09086v1","updated":"2022-12-18T13:36:07Z","published":"2022-12-18T13:36:07Z","title":"PVGRU: Generating Diverse and Relevant Dialogue Responses via\n  Pseudo-Variational Mechanism","summary":"  We investigate response generation for multi-turn dialogue in\ngenerative-based chatbots. Existing generative models based on RNNs (Recurrent\nNeural Networks) usually employ the last hidden state to summarize the\nsequences, which makes models unable to capture the subtle variability observed\nin different dialogues and cannot distinguish the differences between dialogues\nthat are similar in composition. In this paper, we propose a Pseudo-Variational\nGated Recurrent Unit (PVGRU) component without posterior knowledge through\nintroducing a recurrent summarizing variable into the GRU, which can aggregate\nthe accumulated distribution variations of subsequences. PVGRU can perceive the\nsubtle semantic variability through summarizing variables that are optimized by\nthe devised distribution consistency and reconstruction objectives. In\naddition, we build a Pseudo-Variational Hierarchical Dialogue (PVHD) model\nbased on PVGRU. Experimental results demonstrate that PVGRU can broadly improve\nthe diversity and relevance of responses on two benchmark datasets.\n","authors":["Yongkang Liu","Shi Feng","Daling Wang","Hinrich Schütze","Yifei Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.09086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09080v1","updated":"2022-12-18T12:54:45Z","published":"2022-12-18T12:54:45Z","title":"Synthesis and Evaluation of a Domain-specific Large Data Set for\n  Dungeons & Dragons","summary":"  This paper introduces the Forgotten Realms Wiki (FRW) data set and domain\nspecific natural language generation using FRW along with related analyses.\nForgotten Realms is the de-facto default setting of the popular open ended\ntabletop fantasy role playing game, Dungeons & Dragons. The data set was\nextracted from the Forgotten Realms Fandom wiki consisting of more than over\n45,200 articles. The FRW data set is constituted of 11 sub-data sets in a\nnumber of formats: raw plain text, plain text annotated by article title,\ndirected link graphs, wiki info-boxes annotated by the wiki article title,\nPoincar\\'e embedding of first link graph, multiple Word2Vec and Doc2Vec models\nof the corpus. This is the first data set of this size for the Dungeons &\nDragons domain. We then present a pairwise similarity comparison benchmark\nwhich utilizes similarity measures. In addition, we perform D&D domain specific\nnatural language generation using the corpus and evaluate the named entity\nclassification with respect to the lore of Forgotten Realms.\n","authors":["Akila Peiris","Nisansa de Silva"],"pdf_url":"https://arxiv.org/pdf/2212.09080v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09072v1","updated":"2022-12-18T12:03:53Z","published":"2022-12-18T12:03:53Z","title":"Let's Negotiate! A Survey of Negotiation Dialogue Systems","summary":"  Negotiation is one of the crucial abilities in human communication, and there\nhas been a resurgent research interest in negotiation dialogue systems\nrecently, which goal is to empower intelligent agents with such ability that\ncan efficiently help humans resolve conflicts or reach beneficial agreements.\nAlthough there have been many explorations in negotiation dialogue systems, a\nsystematic review of this task has to date remained notably absent. To this\nend, we aim to fill this gap by reviewing contemporary studies in the emerging\nfield of negotiation dialogue systems, covering benchmarks, evaluations, and\nmethodologies. Furthermore, we also discuss potential future directions,\nincluding multi-modal, multi-party, and cross-cultural negotiation scenarios.\nOur goal is to provide the community with a systematic overview of negotiation\ndialogue systems and to inspire future research.\n","authors":["Haolan Zhan","Yufei Wang","Tao Feng","Yuncheng Hua","Suraj Sharma","Zhuang Li","Lizhen Qu","Gholamreza Haffari"],"pdf_url":"https://arxiv.org/pdf/2212.09072v1.pdf","comment":"An early version, work in progress"},{"id":"http://arxiv.org/abs/2212.09058v1","updated":"2022-12-18T10:41:55Z","published":"2022-12-18T10:41:55Z","title":"BEATs: Audio Pre-Training with Acoustic Tokenizers","summary":"  The massive growth of self-supervised learning (SSL) has been witnessed in\nlanguage, vision, speech, and audio domains over the past few years. While\ndiscrete label prediction is widely adopted for other modalities, the\nstate-of-the-art audio SSL models still employ reconstruction loss for\npre-training. Compared with reconstruction loss, semantic-rich discrete label\nprediction encourages the SSL model to abstract the high-level audio semantics\nand discard the redundant details as in human perception. However, a\nsemantic-rich acoustic tokenizer for general audio pre-training is usually not\nstraightforward to obtain, due to the continuous property of audio and\nunavailable phoneme sequences like speech. To tackle this challenge, we propose\nBEATs, an iterative audio pre-training framework to learn Bidirectional Encoder\nrepresentation from Audio Transformers, where an acoustic tokenizer and an\naudio SSL model are optimized by iterations. In the first iteration, we use\nrandom projection as the acoustic tokenizer to train an audio SSL model in a\nmask and label prediction manner. Then, we train an acoustic tokenizer for the\nnext iteration by distilling the semantic knowledge from the pre-trained or\nfine-tuned audio SSL model. The iteration is repeated with the hope of mutual\npromotion of the acoustic tokenizer and audio SSL model. The experimental\nresults demonstrate our acoustic tokenizers can generate discrete labels with\nrich audio semantics and our audio SSL models achieve state-of-the-art results\nacross various audio classification benchmarks, even outperforming previous\nmodels that use more training data and model parameters significantly.\nSpecifically, we set a new state-of-the-art mAP 50.6% on AudioSet-2M for\naudio-only models without using any external data, and 98.1% accuracy on\nESC-50. The code and pre-trained models are available at https://aka.ms/beats.\n","authors":["Sanyuan Chen","Yu Wu","Chengyi Wang","Shujie Liu","Daniel Tompkins","Zhuo Chen","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.09058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09056v1","updated":"2022-12-18T10:18:15Z","published":"2022-12-18T10:18:15Z","title":"Beyond Digital \"Echo Chambers\": The Role of Viewpoint Diversity in\n  Political Discussion","summary":"  Increasingly taking place in online spaces, modern political conversations\nare typically perceived to be unproductively affirming -- siloed in so called\n``echo chambers'' of exclusively like-minded discussants. Yet, to date we lack\nsufficient means to measure viewpoint diversity in conversations. To this end,\nin this paper, we operationalize two viewpoint metrics proposed for recommender\nsystems and adapt them to the context of social media conversations. This is\nthe first study to apply these two metrics (Representation and Fragmentation)\nto real world data and to consider the implications for online conversations\nspecifically. We apply these measures to two topics -- daylight savings time\n(DST), which serves as a control, and the more politically polarized topic of\nimmigration. We find that the diversity scores for both Fragmentation and\nRepresentation are lower for immigration than for DST. Further, we find that\nwhile pro-immigrant views receive consistent pushback on the platform,\nanti-immigrant views largely operate within echo chambers. We observe less\nsevere yet similar patterns for DST. Taken together, Representation and\nFragmentation paint a meaningful and important new picture of viewpoint\ndiversity.\n","authors":["Rishav Hada","Amir Ebrahimi Fard","Sarah Shugars","Federico Bianchi","Patricia Rossini","Dirk Hovy","Rebekah Tromble","Nava Tintarev"],"pdf_url":"https://arxiv.org/pdf/2212.09056v1.pdf","comment":"Camera-ready version in WSDM 2023"},{"id":"http://arxiv.org/abs/2212.09052v1","updated":"2022-12-18T09:57:40Z","published":"2022-12-18T09:57:40Z","title":"A Better Choice: Entire-space Datasets for Aspect Sentiment Triplet\n  Extraction","summary":"  Aspect sentiment triplet extraction (ASTE) aims to extract aspect term,\nsentiment and opinion term triplets from sentences. Since the initial datasets\nused to evaluate models on ASTE had flaws, several studies later corrected the\ninitial datasets and released new versions of the datasets independently. As a\nresult, different studies select different versions of datasets to evaluate\ntheir methods, which makes ASTE-related works hard to follow. In this paper, we\nanalyze the relation between different versions of datasets and suggest that\nthe entire-space version should be used for ASTE. Besides the sentences\ncontaining triplets and the triplets in the sentences, the entire-space version\nadditionally includes the sentences without triplets and the aspect terms which\ndo not belong to any triplets. Hence, the entire-space version is consistent\nwith real-world scenarios and evaluating models on the entire-space version can\nbetter reflect the models' performance in real-world scenarios. In addition,\nexperimental results show that evaluating models on non-entire-space datasets\ninflates the performance of existing models and models trained on the\nentire-space version can obtain better performance.\n","authors":["Yuncong Li","Fang Wang","Sheng-Hua Zhong"],"pdf_url":"https://arxiv.org/pdf/2212.09052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09045v1","updated":"2022-12-18T09:37:20Z","published":"2022-12-18T09:37:20Z","title":"Task Preferences across Languages on Community Question Answering\n  Platforms","summary":"  With the steady emergence of community question answering (CQA) platforms\nlike Quora, StackExchange, and WikiHow, users now have an unprecedented access\nto information on various kind of queries and tasks. Moreover, the rapid\nproliferation and localization of these platforms spanning geographic and\nlinguistic boundaries offer a unique opportunity to study the task requirements\nand preferences of users in different socio-linguistic groups. In this study,\nwe implement an entity-embedding model trained on a large longitudinal dataset\nof multi-lingual and task-oriented question-answer pairs to uncover and\nquantify the (i) prevalence and distribution of various online tasks across\nlinguistic communities, and (ii) emerging and receding trends in task\npopularity over time in these communities. Our results show that there exists\nsubstantial variance in task preference as well as popularity trends across\nlinguistic communities on the platform. Findings from this study will help Q&A\nplatforms better curate and personalize content for non-English users, while\nalso offering valuable insights to businesses looking to target non-English\nspeaking communities online.\n","authors":["Sebastin Santy","Prasanta Bhattacharya","Rishabh Mehrotra"],"pdf_url":"https://arxiv.org/pdf/2212.09045v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2212.09028v1","updated":"2022-12-18T07:36:35Z","published":"2022-12-18T07:36:35Z","title":"Neural Coreference Resolution based on Reinforcement Learning","summary":"  The target of a coreference resolution system is to cluster all mentions that\nrefer to the same entity in a given context. All coreference resolution systems\nneed to solve two subtasks; one task is to detect all of the potential\nmentions, and the other is to learn the linking of an antecedent for each\npossible mention. In this paper, we propose a reinforcement learning\nactor-critic-based neural coreference resolution system, which can achieve both\nmention detection and mention clustering by leveraging an actor-critic deep\nreinforcement learning technique and a joint training algorithm. We experiment\non the BERT model to generate different input span representations. Our model\nwith the BERT span representation achieves the state-of-the-art performance\namong the models on the CoNLL-2012 Shared Task English Test Set.\n","authors":["Yu Wang","Hongxia Jin"],"pdf_url":"https://arxiv.org/pdf/2212.09028v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2212.05421v2","updated":"2022-12-18T06:32:39Z","published":"2022-12-11T06:16:14Z","title":"Feature-Level Debiased Natural Language Understanding","summary":"  Natural language understanding (NLU) models often rely on dataset biases\nrather than intended task-relevant features to achieve high performance on\nspecific datasets. As a result, these models perform poorly on datasets outside\nthe training distribution. Some recent studies address this issue by reducing\nthe weights of biased samples during the training process. However, these\nmethods still encode biased latent features in representations and neglect the\ndynamic nature of bias, which hinders model prediction. We propose an NLU\ndebiasing method, named debiasing contrastive learning (DCT), to simultaneously\nalleviate the above problems based on contrastive learning. We devise a\ndebiasing, positive sampling strategy to mitigate biased latent features by\nselecting the least similar biased positive samples. We also propose a dynamic\nnegative sampling strategy to capture the dynamic influence of biases by\nemploying a bias-only model to dynamically select the most similar biased\nnegative samples. We conduct experiments on three NLU benchmark datasets.\nExperimental results show that DCT outperforms state-of-the-art baselines on\nout-of-distribution datasets while maintaining in-distribution performance. We\nalso verify that DCT can reduce biased latent features from the model's\nrepresentation.\n","authors":["Yougang Lyu","Piji Li","Yechang Yang","Maarten de Rijke","Pengjie Ren","Yukun Zhao","Dawei Yin","Zhaochun Ren"],"pdf_url":"https://arxiv.org/pdf/2212.05421v2.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2212.04068v2","updated":"2022-12-18T04:21:45Z","published":"2022-12-08T04:37:29Z","title":"Investigating Glyph Phonetic Information for Chinese Spell Checking:\n  What Works and What's Next","summary":"  While pre-trained Chinese language models have demonstrated impressive\nperformance on a wide range of NLP tasks, the Chinese Spell Checking (CSC) task\nremains a challenge. Previous research has explored using information such as\nglyphs and phonetics to improve the ability to distinguish misspelled\ncharacters, with good results. However, the generalization ability of these\nmodels is not well understood: it is unclear whether they incorporate\nglyph-phonetic information and, if so, whether this information is fully\nutilized. In this paper, we aim to better understand the role of glyph-phonetic\ninformation in the CSC task and suggest directions for improvement.\nAdditionally, we propose a new, more challenging, and practical setting for\ntesting the generalizability of CSC models. All code is made publicly\navailable.\n","authors":["Xiaotian Zhang","Yanjun Zheng","Hang Yan","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2212.04068v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.05337v2","updated":"2022-12-18T04:06:17Z","published":"2022-01-14T08:32:20Z","title":"A Survey of Controllable Text Generation using Transformer-based\n  Pre-trained Language Models","summary":"  Controllable Text Generation (CTG) is emerging area in the field of natural\nlanguage generation (NLG). It is regarded as crucial for the development of\nadvanced text generation technologies that are more natural and better meet the\nspecific constraints in practical applications. In recent years, methods using\nlarge-scale pre-trained language models (PLMs), in particular the widely used\ntransformer-based PLMs, have become a new paradigm of NLG, allowing generation\nof more diverse and fluent text. However, due to the lower level of\ninterpretability of deep neural networks, the controllability of these methods\nneed to be guaranteed. To this end, controllable text generation using\ntransformer-based PLMs has become a rapidly growing yet challenging new\nresearch hotspot. A diverse range of approaches have emerged in the recent 3-4\nyears, targeting different CTG tasks which may require different types of\ncontrolled constraints. In this paper, we present a systematic critical review\non the common tasks, main approaches and evaluation methods in this area.\nFinally, we discuss the challenges that the field is facing, and put forward\nvarious promising future directions. To the best of our knowledge, this is the\nfirst survey paper to summarize CTG techniques from the perspective of PLMs. We\nhope it can help researchers in related fields to quickly track the academic\nfrontier, providing them with a landscape of the area and a roadmap for future\nresearch.\n","authors":["Hanqing Zhang","Haolin Song","Shaoyu Li","Ming Zhou","Dawei Song"],"pdf_url":"https://arxiv.org/pdf/2201.05337v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08999v1","updated":"2022-12-18T03:53:44Z","published":"2022-12-18T03:53:44Z","title":"Sentence-level Feedback Generation for English Language Learners: Does\n  Data Augmentation Help?","summary":"  In this paper, we present strong baselines for the task of Feedback Comment\nGeneration for Writing Learning. Given a sentence and an error span, the task\nis to generate a feedback comment explaining the error. Sentences and feedback\ncomments are both in English. We experiment with LLMs and also create multiple\npseudo datasets for the task, investigating how it affects the performance of\nour system. We present our results for the task along with extensive analysis\nof the generated comments with the aim of aiding future studies in feedback\ncomment generation for English language learners.\n","authors":["Shabnam Behzad","Amir Zeldes","Nathan Schneider"],"pdf_url":"https://arxiv.org/pdf/2212.08999v1.pdf","comment":"GenChal 2022: FCG, INLG 2023"},{"id":"http://arxiv.org/abs/2211.15076v2","updated":"2022-12-18T03:21:40Z","published":"2022-11-28T05:45:17Z","title":"Refined Semantic Enhancement towards Frequency Diffusion for Video\n  Captioning","summary":"  Video captioning aims to generate natural language sentences that describe\nthe given video accurately. Existing methods obtain favorable generation by\nexploring richer visual representations in encode phase or improving the\ndecoding ability. However, the long-tailed problem hinders these attempts at\nlow-frequency tokens, which rarely occur but carry critical semantics, playing\na vital role in the detailed generation. In this paper, we introduce a novel\nRefined Semantic enhancement method towards Frequency Diffusion (RSFD), a\ncaptioning model that constantly perceives the linguistic representation of the\ninfrequent tokens. Concretely, a Frequency-Aware Diffusion (FAD) module is\nproposed to comprehend the semantics of low-frequency tokens to break through\ngeneration limitations. In this way, the caption is refined by promoting the\nabsorption of tokens with insufficient occurrence. Based on FAD, we design a\nDivergent Semantic Supervisor (DSS) module to compensate for the information\nloss of high-frequency tokens brought by the diffusion process, where the\nsemantics of low-frequency tokens is further emphasized to alleviate the\nlong-tailed problem. Extensive experiments indicate that RSFD outperforms the\nstate-of-the-art methods on two benchmark datasets, i.e., MSR-VTT and MSVD,\ndemonstrate that the enhancement of low-frequency tokens semantics can obtain a\ncompetitive generation effect. Code is available at\nhttps://github.com/lzp870/RSFD.\n","authors":["Xian Zhong","Zipeng Li","Shuqin Chen","Kui Jiang","Chen Chen","Mang Ye"],"pdf_url":"https://arxiv.org/pdf/2211.15076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08995v1","updated":"2022-12-18T03:17:47Z","published":"2022-12-18T03:17:47Z","title":"Impact of Sentiment Analysis in Fake Review Detection","summary":"  Fake review identification is an important topic and has gained the interest\nof experts all around the world. Identifying fake reviews is challenging for\nresearchers, and there are several primary challenges to fake review detection.\nWe propose developing an initial research paper for investigating fake reviews\nby using sentiment analysis. Ten research papers are identified that show fake\nreviews, and they discuss currently available solutions for predicting or\ndetecting fake reviews. They also show the distribution of fake and truthful\nreviews through the analysis of sentiment. We summarize and compare previous\nstudies related to fake reviews. We highlight the most significant challenges\nin the sentiment evaluation process and demonstrate that there is a significant\nimpact on sentiment scores used to identify fake feedback.\n","authors":["Amira Yousif","James Buckley"],"pdf_url":"https://arxiv.org/pdf/2212.08995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08992v1","updated":"2022-12-18T02:26:50Z","published":"2022-12-18T02:26:50Z","title":"PoE: a Panel of Experts for Generalized Automatic Dialogue Assessment","summary":"  Chatbots are expected to be knowledgeable across multiple domains, e.g. for\ndaily chit-chat, exchange of information, and grounding in emotional\nsituations. To effectively measure the quality of such conversational agents, a\nmodel-based automatic dialogue evaluation metric (ADEM) is expected to perform\nwell across multiple domains. Despite significant progress, an ADEM that works\nwell in one domain does not necessarily generalize to another. This calls for a\ndedicated network architecture for domain generalization. To tackle the\nmulti-domain dialogue evaluation task, we propose a Panel of Experts (PoE), a\nmultitask network that consists of a shared transformer encoder and a\ncollection of lightweight adapters. The shared encoder captures the general\nknowledge of dialogues across domains, while each adapter specializes in one\nspecific domain and serves as a domain expert. To validate the idea, we\nconstruct a high-quality multi-domain dialogue dataset leveraging data\naugmentation and pseudo-labeling. The PoE network is comprehensively assessed\non 16 dialogue evaluation datasets spanning a wide range of dialogue domains.\nIt achieves state-of-the-art performance in terms of mean Spearman correlation\nover all the evaluation datasets. It exhibits better zero-shot generalization\nthan existing state-of-the-art ADEMs and the ability to easily adapt to new\ndomains with few-shot transfer learning.\n","authors":["Chen Zhang","Luis Fernando D'Haro","Qiquan Zhang","Thomas Friedrichs","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2212.08992v1.pdf","comment":"Currently under review at TASLP, upload to arxiv for easy\n  cross-reference"},{"id":"http://arxiv.org/abs/2212.08987v1","updated":"2022-12-18T01:59:49Z","published":"2022-12-18T01:59:49Z","title":"A Robust Semantic Frame Parsing Pipeline on a New Complex Twitter\n  Dataset","summary":"  Most recent semantic frame parsing systems for spoken language understanding\n(SLU) are designed based on recurrent neural networks. These systems display\ndecent performance on benchmark SLU datasets such as ATIS or SNIPS, which\ncontain short utterances with relatively simple patterns. However, the current\nsemantic frame parsing models lack a mechanism to handle out-of-distribution\n(\\emph{OOD}) patterns and out-of-vocabulary (\\emph{OOV}) tokens. In this paper,\nwe introduce a robust semantic frame parsing pipeline that can handle both\n\\emph{OOD} patterns and \\emph{OOV} tokens in conjunction with a new complex\nTwitter dataset that contains long tweets with more \\emph{OOD} patterns and\n\\emph{OOV} tokens. The new pipeline demonstrates much better results in\ncomparison to state-of-the-art baseline SLU models on both the SNIPS dataset\nand the new Twitter dataset (Our new Twitter dataset can be downloaded from\nhttps://1drv.ms/u/s!AroHb-W6_OAlavK4begsDsMALfE?e=c8f2XX ). Finally, we also\nbuild an E2E application to demo the feasibility of our algorithm and show why\nit is useful in real application.\n","authors":["Yu Wang","Hongxia Jin"],"pdf_url":"https://arxiv.org/pdf/2212.08987v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.08986v1","updated":"2022-12-18T01:57:30Z","published":"2022-12-18T01:57:30Z","title":"Low-Resource Authorship Style Transfer with In-Context Learning","summary":"  Authorship style transfer involves altering the style of text to match the\nstyle of some target author whilst preserving the semantic meaning of the\noriginal text. Existing approaches to unsupervised authorship style transfer\nlike STRAP have largely focused on style transfer for target authors with many\nexamples of their writing style through books, speeches, or other published\nworks (Krishna et al., 2020). Due to this high-resource training data\nrequirement (often greater than 100,000 words), these approaches are often only\nuseful for style transfer to the style of published authors, politicians, or\nother well-known figures and authorship styles. In this paper, we attempt to\nperform low-resource authorship style transfer, a more challenging class of\nauthorship style transfer where only a limited amount of text in the target\nauthor's style may exist. In our experiments, we specifically choose source and\ntarget authors from Reddit to perform style transfer over their Reddit posts,\nlimiting ourselves to just 16 posts (on average $\\approx$ 500 words) of the\ntarget author's style. We then propose a method for automatic evaluation on the\nlow-resource authorship style transfer task utilizing authorship and style\nrepresentation embeddings (Rivera-Soto et al., 2021; Wegmann et al., 2022). We\nevaluate our style transferred outputs with the proposed automatic evaluation\nmethod and find that our method, STYLL, is able to outperform STRAP and a\ncomprehensive set of baselines.\n","authors":["Ajay Patel","Nicholas Andrews","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2212.08986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08979v1","updated":"2022-12-18T00:11:06Z","published":"2022-12-18T00:11:06Z","title":"Language model acceptability judgements are not always robust to context","summary":"  Targeted syntactic evaluations of language models ask whether models show\nstable preferences for syntactically acceptable content over minimal-pair\nunacceptable inputs. Most targeted syntactic evaluation datasets ask models to\nmake these judgements with just a single context-free sentence as input. This\ndoes not match language models' training regime, in which input sentences are\nalways highly contextualized by the surrounding corpus. This mismatch raises an\nimportant question: how robust are models' syntactic judgements in different\ncontexts? In this paper, we investigate the stability of language models'\nperformance on targeted syntactic evaluations as we vary properties of the\ninput context: the length of the context, the types of syntactic phenomena it\ncontains, and whether or not there are violations of grammaticality. We find\nthat model judgements are generally robust when placed in randomly sampled\nlinguistic contexts. However, they are substantially unstable for contexts\ncontaining syntactic structures matching those in the critical test content.\nAmong all tested models (GPT-2 and five variants of OPT), we significantly\nimprove models' judgements by providing contexts with matching syntactic\nstructures, and conversely significantly worsen them using unacceptable\ncontexts with matching but violated syntactic structures. This effect is\namplified by the length of the context, except for unrelated inputs. We show\nthat these changes in model performance are not explainable by simple features\nmatching the context and the test inputs, such as lexical overlap and\ndependency overlap. This sensitivity to highly specific syntactic features of\nthe context can only be explained by the models' implicit in-context learning\nabilities.\n","authors":["Koustuv Sinha","Jon Gauthier","Aaron Mueller","Kanishka Misra","Keren Fuentes","Roger Levy","Adina Williams"],"pdf_url":"https://arxiv.org/pdf/2212.08979v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2210.00379v3","updated":"2022-12-18T23:41:26Z","published":"2022-10-01T21:35:11Z","title":"NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review","summary":"  Neural Radiance Field (NeRF), a new novel view synthesis with implicit scene\nrepresentation has taken the field of Computer Vision by storm. As a novel view\nsynthesis and 3D reconstruction method, NeRF models find applications in\nrobotics, urban mapping, autonomous navigation, virtual reality/augmented\nreality, and more. Since the original paper by Mildenhall et al., more than 250\npreprints were published, with more than 100 eventually being accepted in tier\none Computer Vision Conferences. Given NeRF popularity and the current interest\nin this research area, we believe it necessary to compile a comprehensive\nsurvey of NeRF papers from the past two years, which we organized into both\narchitecture, and application based taxonomies. We also provide an introduction\nto the theory of NeRF based novel view synthesis, and a benchmark comparison of\nthe performance and speed of key NeRF models. By creating this survey, we hope\nto introduce new researchers to NeRF, provide a helpful reference for\ninfluential works in this field, as well as motivate future research directions\nwith our discussion section.\n","authors":["Kyle Gao","Yina Gao","Hongjie He","Dening Lu","Linlin Xu","Jonathan Li"],"pdf_url":"https://arxiv.org/pdf/2210.00379v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09083v3","updated":"2022-12-18T21:18:27Z","published":"2022-10-17T13:32:52Z","title":"Nish: A Novel Negative Stimulated Hybrid Activation Function","summary":"  An activation function has a significant impact on the efficiency and\nrobustness of the neural networks. As an alternative, we evolved a cutting-edge\nnon-monotonic activation function, Negative Stimulated Hybrid Activation\nFunction (Nish). It acts as a Rectified Linear Unit (ReLU) function for the\npositive region and a sinus-sigmoidal function for the negative region. In\nother words, it incorporates a sigmoid and a sine function and gaining new\ndynamics over classical ReLU. We analyzed the consistency of the Nish for\ndifferent combinations of essential networks and most common activation\nfunctions using on several most popular benchmarks. From the experimental\nresults, we reported that the accuracy rates achieved by the Nish is slightly\nbetter than compared to the Mish in classification.\n","authors":["Yildiray Anagun","Sahin Isik"],"pdf_url":"https://arxiv.org/pdf/2210.09083v3.pdf","comment":"10 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2212.09144v1","updated":"2022-12-18T18:53:35Z","published":"2022-12-18T18:53:35Z","title":"Performance Analysis of YOLO-based Architectures for Vehicle Detection\n  from Traffic Images in Bangladesh","summary":"  The task of locating and classifying different types of vehicles has become a\nvital element in numerous applications of automation and intelligent systems\nranging from traffic surveillance to vehicle identification and many more. In\nrecent times, Deep Learning models have been dominating the field of vehicle\ndetection. Yet, Bangladeshi vehicle detection has remained a relatively\nunexplored area. One of the main goals of vehicle detection is its real-time\napplication, where `You Only Look Once' (YOLO) models have proven to be the\nmost effective architecture. In this work, intending to find the best-suited\nYOLO architecture for fast and accurate vehicle detection from traffic images\nin Bangladesh, we have conducted a performance analysis of different variants\nof the YOLO-based architectures such as YOLOV3, YOLOV5s, and YOLOV5x. The\nmodels were trained on a dataset containing 7390 images belonging to 21 types\nof vehicles comprising samples from the DhakaAI dataset, the Poribohon-BD\ndataset, and our self-collected images. After thorough quantitative and\nqualitative analysis, we found the YOLOV5x variant to be the best-suited model,\nperforming better than YOLOv3 and YOLOv5s models respectively by 7 & 4 percent\nin mAP, and 12 & 8.5 percent in terms of Accuracy.\n","authors":["Refaat Mohammad Alamgir","Ali Abir Shuvro","Mueeze Al Mushabbir","Mohammed Ashfaq Raiyan","Nusrat Jahan Rani","Md. Mushfiqur Rahman","Md. Hasanul Kabir","Sabbir Ahmed"],"pdf_url":"https://arxiv.org/pdf/2212.09144v1.pdf","comment":"Accepted in 25th ICCIT (6 pages, 5 figures, 1 table)"},{"id":"http://arxiv.org/abs/2212.09129v1","updated":"2022-12-18T16:53:13Z","published":"2022-12-18T16:53:13Z","title":"SUCRe: Leveraging Scene Structure for Underwater Color Restoration","summary":"  Underwater images are altered by the physical characteristics of the medium\nthrough which light rays pass before reaching the optical sensor. Scattering\nand strong wavelength-dependent absorption significantly modify the captured\ncolors depending on the distance of observed elements to the image plane. In\nthis paper, we aim to recover the original colors of the scene as if the water\nhad no effect on them. We propose two novel methods that rely on different sets\nof inputs. The first assumes that pixel intensities in the restored image are\nnormally distributed within each color channel, leading to an alternative\noptimization of the well-known \\textit{Sea-thru} method which acts on single\nimages and their distance maps. We additionally introduce SUCRe, a new method\nthat further exploits the scene's 3D Structure for Underwater Color\nRestoration. By following points in multiple images and tracking their\nintensities at different distances to the sensor we constrain the optimization\nof the image formation model parameters. When compared to similar existing\napproaches, SUCRe provides clear improvements in a variety of scenarios ranging\nfrom natural light to deep-sea environments. The code for both approaches is\npublicly available at https://github.com/clementinboittiaux/sucre .\n","authors":["Clémentin Boittiaux","Ricard Marxer","Claire Dune","Aurélien Arnaubec","Maxime Ferrera","Vincent Hugel"],"pdf_url":"https://arxiv.org/pdf/2212.09129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09107v1","updated":"2022-12-18T15:26:08Z","published":"2022-12-18T15:26:08Z","title":"A Generalized Framework for Critical Heat Flux Detection Using\n  Unsupervised Image-to-Image Translation","summary":"  This work proposes a framework developed to generalize Critical Heat Flux\n(CHF) detection classification models using an Unsupervised Image-to-Image\n(UI2I) translation model. The framework enables a typical classification model\nthat was trained and tested on boiling images from domain A to predict boiling\nimages coming from domain B that was never seen by the classification model.\nThis is done by using the UI2I model to transform the domain B images to look\nlike domain A images that the classification model is familiar with. Although\nCNN was used as the classification model and Fixed-Point GAN (FP-GAN) was used\nas the UI2I model, the framework is model agnostic. Meaning, that the framework\ncan generalize any image classification model type, making it applicable to a\nvariety of similar applications and not limited to the boiling crisis detection\nproblem. It also means that the more the UI2I models advance, the better the\nperformance of the framework.\n","authors":["Firas Al-Hindawi","Tejaswi Soorib","Han Hu","Md Siddiquee","Hyunsoo Yoon","Teresa Wu","Ying Sun"],"pdf_url":"https://arxiv.org/pdf/2212.09107v1.pdf","comment":"This work has been submitted to the Expert Systems With Applications\n  Journal on Sep 25, 2022"},{"id":"http://arxiv.org/abs/2212.09102v1","updated":"2022-12-18T15:04:31Z","published":"2022-12-18T15:04:31Z","title":"Face Generation and Editing with StyleGAN: A Survey","summary":"  Our goal with this survey is to provide an overview of the state of the art\ndeep learning technologies for face generation and editing. We will cover\npopular latest architectures and discuss key ideas that make them work, such as\ninversion, latent representation, loss functions, training procedures, editing\nmethods, and cross domain style transfer. We particularly focus on GAN-based\narchitectures that have culminated in the StyleGAN approaches, which allow\ngeneration of high-quality face images and offer rich interfaces for\ncontrollable semantics editing and preserving photo quality. We aim to provide\nan entry point into the field for readers that have basic knowledge about the\nfield of deep learning and are looking for an accessible introduction and\noverview.\n","authors":["Andrew Melnik","Maksim Miasayedzenkau","Dzianis Makarovets","Dzianis Pirshtuk","Eren Akbulut","Dennis Holzmann","Tarek Renusch","Gustav Reichert","Helge Ritter"],"pdf_url":"https://arxiv.org/pdf/2212.09102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09100v1","updated":"2022-12-18T14:56:22Z","published":"2022-12-18T14:56:22Z","title":"SPARF: Large-Scale Learning of 3D Sparse Radiance Fields from Few Input\n  Images","summary":"  Recent advances in Neural Radiance Fields (NeRFs) treat the problem of novel\nview synthesis as Sparse Radiance Field (SRF) optimization using sparse voxels\nfor efficient and fast rendering (plenoxels,InstantNGP). In order to leverage\nmachine learning and adoption of SRFs as a 3D representation, we present SPARF,\na large-scale ShapeNet-based synthetic dataset for novel view synthesis\nconsisting of $\\sim$ 17 million images rendered from nearly 40,000 shapes at\nhigh resolution (400 X 400 pixels). The dataset is orders of magnitude larger\nthan existing synthetic datasets for novel view synthesis and includes more\nthan one million 3D-optimized radiance fields with multiple voxel resolutions.\nFurthermore, we propose a novel pipeline (SuRFNet) that learns to generate\nsparse voxel radiance fields from only few views. This is done by using the\ndensely collected SPARF dataset and 3D sparse convolutions. SuRFNet employs\npartial SRFs from few/one images and a specialized SRF loss to learn to\ngenerate high-quality sparse voxel radiance fields that can be rendered from\nnovel views. Our approach achieves state-of-the-art results in the task of\nunconstrained novel view synthesis based on few views on ShapeNet as compared\nto recent baselines. The SPARF dataset will be made public with the code and\nmodels on the project website https://abdullahamdi.com/sparf/ .\n","authors":["Abdullah Hamdi","Bernard Ghanem","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2212.09100v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2202.05786v2","updated":"2022-12-18T14:52:44Z","published":"2022-02-11T17:31:12Z","title":"Multi-Modal Knowledge Graph Construction and Application: A Survey","summary":"  Recent years have witnessed the resurgence of knowledge engineering which is\nfeatured by the fast growth of knowledge graphs. However, most of existing\nknowledge graphs are represented with pure symbols, which hurts the machine's\ncapability to understand the real world. The multi-modalization of knowledge\ngraphs is an inevitable key step towards the realization of human-level machine\nintelligence. The results of this endeavor are Multi-modal Knowledge Graphs\n(MMKGs). In this survey on MMKGs constructed by texts and images, we first give\ndefinitions of MMKGs, followed with the preliminaries on multi-modal tasks and\ntechniques. We then systematically review the challenges, progresses and\nopportunities on the construction and application of MMKGs respectively, with\ndetailed analyses of the strength and weakness of different solutions. We\nfinalize this survey with open research problems relevant to MMKGs.\n","authors":["Xiangru Zhu","Zhixu Li","Xiaodan Wang","Xueyao Jiang","Penglei Sun","Xuwu Wang","Yanghua Xiao","Nicholas Jing Yuan"],"pdf_url":"https://arxiv.org/pdf/2202.05786v2.pdf","comment":"20 pages, 8 figures, 6 tables. Accepted by TKDE 2022"},{"id":"http://arxiv.org/abs/2212.09098v1","updated":"2022-12-18T14:51:46Z","published":"2022-12-18T14:51:46Z","title":"Mask-FPAN: Semi-Supervised Face Parsing in the Wild With De-Occlusion\n  and UV GAN","summary":"  Fine-grained semantic segmentation of a person's face and head, including\nfacial parts and head components, has progressed a great deal in recent years.\nHowever, it remains a challenging task, whereby considering ambiguous\nocclusions and large pose variations are particularly difficult. To overcome\nthese difficulties, we propose a novel framework termed Mask-FPAN. It uses a\nde-occlusion module that learns to parse occluded faces in a semi-supervised\nway. In particular, face landmark localization, face occlusionstimations, and\ndetected head poses are taken into account. A 3D morphable face model combined\nwith the UV GAN improves the robustness of 2D face parsing. In addition, we\nintroduce two new datasets named FaceOccMask-HQ and CelebAMaskOcc-HQ for face\nparing work. The proposed Mask-FPAN framework addresses the face parsing\nproblem in the wild and shows significant performance improvements with MIOU\nfrom 0.7353 to 0.9013 compared to the state-of-the-art on challenging face\ndatasets.\n","authors":["Lei Li","Tianfang Zhang","Stefan Oehmcke","Fabian Gieseke","Christian Igel"],"pdf_url":"https://arxiv.org/pdf/2212.09098v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2212.09088v1","updated":"2022-12-18T13:54:11Z","published":"2022-12-18T13:54:11Z","title":"LR-CSNet: Low-Rank Deep Unfolding Network for Image Compressive Sensing","summary":"  Deep unfolding networks (DUNs) have proven to be a viable approach to\ncompressive sensing (CS). In this work, we propose a DUN called low-rank CS\nnetwork (LR-CSNet) for natural image CS. Real-world image patches are often\nwell-represented by low-rank approximations. LR-CSNet exploits this property by\nadding a low-rank prior to the CS optimization task. We derive a corresponding\niterative optimization procedure using variable splitting, which is then\ntranslated to a new DUN architecture. The architecture uses low-rank generation\nmodules (LRGMs), which learn low-rank matrix factorizations, as well as\ngradient descent and proximal mappings (GDPMs), which are proposed to extract\nhigh-frequency features to refine image details. In addition, the deep features\ngenerated at each reconstruction stage in the DUN are transferred between\nstages to boost the performance. Our extensive experiments on three widely\nconsidered datasets demonstrate the promising performance of LR-CSNet compared\nto state-of-the-art methods in natural image CS.\n","authors":["Tianfang Zhang","Lei Li","Christian Igel","Stefan Oehmcke","Fabian Gieseke","Zhenming Peng"],"pdf_url":"https://arxiv.org/pdf/2212.09088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.06916v2","updated":"2022-12-18T12:46:26Z","published":"2021-07-14T18:07:38Z","title":"Training Compact CNNs for Image Classification using Dynamic-coded\n  Filter Fusion","summary":"  The mainstream approach for filter pruning is usually either to force a\nhard-coded importance estimation upon a computation-heavy pretrained model to\nselect \"important\" filters, or to impose a hyperparameter-sensitive sparse\nconstraint on the loss objective to regularize the network training. In this\npaper, we present a novel filter pruning method, dubbed dynamic-coded filter\nfusion (DCFF), to derive compact CNNs in a computation-economical and\nregularization-free manner for efficient image classification. Each filter in\nour DCFF is firstly given an inter-similarity distribution with a temperature\nparameter as a filter proxy, on top of which, a fresh Kullback-Leibler\ndivergence based dynamic-coded criterion is proposed to evaluate the filter\nimportance. In contrast to simply keeping high-score filters in other methods,\nwe propose the concept of filter fusion, i.e., the weighted averages using the\nassigned proxies, as our preserved filters. We obtain a one-hot\ninter-similarity distribution as the temperature parameter approaches infinity.\nThus, the relative importance of each filter can vary along with the training\nof the compact CNN, leading to dynamically changeable fused filters without\nboth the dependency on the pretrained model and the introduction of sparse\nconstraints. Extensive experiments on classification benchmarks demonstrate the\nsuperiority of our DCFF over the compared counterparts. For example, our DCFF\nderives a compact VGGNet-16 with only 72.77M FLOPs and 1.06M parameters while\nreaching top-1 accuracy of 93.47% on CIFAR-10. A compact ResNet-50 is obtained\nwith 63.8% FLOPs and 58.6% parameter reductions, retaining 75.60% top-1\naccuracy on ILSVRC-2012. Our code, narrower models and training logs are\navailable at https://github.com/lmbxmu/DCFF.\n","authors":["Mingbao Lin","Bohong Chen","Fei Chao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2107.06916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09069v1","updated":"2022-12-18T11:43:32Z","published":"2022-12-18T11:43:32Z","title":"Masked Wavelet Representation for Compact Neural Radiance Fields","summary":"  Neural radiance fields (NeRF) have demonstrated the potential of\ncoordinate-based neural representation (neural fields or implicit neural\nrepresentation) in neural rendering. However, using a multi-layer perceptron\n(MLP) to represent a 3D scene or object requires enormous computational\nresources and time. There have been recent studies on how to reduce these\ncomputational inefficiencies by using additional data structures, such as grids\nor trees. Despite the promising performance, the explicit data structure\nnecessitates a substantial amount of memory. In this work, we present a method\nto reduce the size without compromising the advantages of having additional\ndata structures. In detail, we propose using the wavelet transform on\ngrid-based neural fields. Grid-based neural fields are for fast convergence,\nand the wavelet transform, whose efficiency has been demonstrated in\nhigh-performance standard codecs, is to improve the parameter efficiency of\ngrids. Furthermore, in order to achieve a higher sparsity of grid coefficients\nwhile maintaining reconstruction quality, we present a novel trainable masking\napproach. Experimental results demonstrate that non-spatial grid coefficients,\nsuch as wavelet coefficients, are capable of attaining a higher level of\nsparsity than spatial grid coefficients, resulting in a more compact\nrepresentation. With our proposed mask and compression pipeline, we achieved\nstate-of-the-art performance within a memory budget of 2 MB. Our code is\navailable at https://github.com/daniel03c1/masked_wavelet_nerf.\n","authors":["Daniel Rho","Byeonghyeon Lee","Seungtae Nam","Joo Chan Lee","Jong Hwan Ko","Eunbyung Park"],"pdf_url":"https://arxiv.org/pdf/2212.09069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09068v1","updated":"2022-12-18T11:42:51Z","published":"2022-12-18T11:42:51Z","title":"Style-Hallucinated Dual Consistency Learning: A Unified Framework for\n  Visual Domain Generalization","summary":"  Domain shift widely exists in the visual world, while modern deep neural\nnetworks commonly suffer from severe performance degradation under domain shift\ndue to the poor generalization ability, which limits the real-world\napplications. The domain shift mainly lies in the limited source environmental\nvariations and the large distribution gap between source and unseen target\ndata. To this end, we propose a unified framework, Style-HAllucinated Dual\nconsistEncy learning (SHADE), to handle such domain shift in various visual\ntasks. Specifically, SHADE is constructed based on two consistency constraints,\nStyle Consistency (SC) and Retrospection Consistency (RC). SC enriches the\nsource situations and encourages the model to learn consistent representation\nacross style-diversified samples. RC leverages general visual knowledge to\nprevent the model from overfitting to source data and thus largely keeps the\nrepresentation consistent between the source and general visual models.\nFurthermore, we present a novel style hallucination module (SHM) to generate\nstyle-diversified samples that are essential to consistency learning. SHM\nselects basis styles from the source distribution, enabling the model to\ndynamically generate diverse and realistic samples during training. Extensive\nexperiments demonstrate that our versatile SHADE can significantly enhance the\ngeneralization in various visual recognition tasks, including image\nclassification, semantic segmentation and object detection, with different\nmodels, i.e., ConvNets and Transformer.\n","authors":["Yuyang Zhao","Zhun Zhong","Na Zhao","Nicu Sebe","Gim Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2212.09068v1.pdf","comment":"Journal extension of arXiv:2204.02548. Code is available at\n  https://github.com/HeliosZhao/SHADE-VisualDG"},{"id":"http://arxiv.org/abs/2212.09067v1","updated":"2022-12-18T11:30:59Z","published":"2022-12-18T11:30:59Z","title":"Fine-Tuning Is All You Need to Mitigate Backdoor Attacks","summary":"  Backdoor attacks represent one of the major threats to machine learning\nmodels. Various efforts have been made to mitigate backdoors. However, existing\ndefenses have become increasingly complex and often require high computational\nresources or may also jeopardize models' utility. In this work, we show that\nfine-tuning, one of the most common and easy-to-adopt machine learning training\noperations, can effectively remove backdoors from machine learning models while\nmaintaining high model utility. Extensive experiments over three machine\nlearning paradigms show that fine-tuning and our newly proposed\nsuper-fine-tuning achieve strong defense performance. Furthermore, we coin a\nnew term, namely backdoor sequela, to measure the changes in model\nvulnerabilities to other attacks before and after the backdoor has been\nremoved. Empirical evaluation shows that, compared to other defense methods,\nsuper-fine-tuning leaves limited backdoor sequela. We hope our results can help\nmachine learning model owners better protect their models from backdoor\nthreats. Also, it calls for the design of more advanced attacks in order to\ncomprehensively assess machine learning models' backdoor vulnerabilities.\n","authors":["Zeyang Sha","Xinlei He","Pascal Berrang","Mathias Humbert","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.09067v1.pdf","comment":"17 pages, 17 figures"},{"id":"http://arxiv.org/abs/2112.14768v2","updated":"2022-12-18T11:13:47Z","published":"2021-12-28T02:06:44Z","title":"Video Reconstruction from a Single Motion Blurred Image using Learned\n  Dynamic Phase Coding","summary":"  Video reconstruction from a single motion-blurred image is a challenging\nproblem, which can enhance the capabilities of existing cameras. Recently,\nseveral works addressed this task using conventional imaging and deep learning.\nYet, such purely-digital methods are inherently limited, due to direction\nambiguity and noise sensitivity. Some works proposed to address these\nlimitations using non-conventional image sensors, however, such sensors are\nextremely rare and expensive. To circumvent these limitations with simpler\nmeans, we propose a hybrid optical-digital method for video reconstruction that\nrequires only simple modifications to existing optical systems. We use a\nlearned dynamic phase-coding in the lens aperture during the image acquisition\nto encode the motion trajectories, which serve as prior information for the\nvideo reconstruction process. The proposed computational camera generates a\nsharp frame burst of the scene at various frame rates from a single coded\nmotion-blurred image, using an image-to-video convolutional neural network. We\npresent advantages and improved performance compared to existing methods, using\nboth simulations and a real-world camera prototype. We extend our optical\ncoding also to video frame interpolation and present robust and improved\nresults for noisy videos.\n","authors":["Erez Yosef","Shay Elmalem","Raja Giryes"],"pdf_url":"https://arxiv.org/pdf/2112.14768v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09062v1","updated":"2022-12-18T11:02:50Z","published":"2022-12-18T11:02:50Z","title":"Bort: Towards Explainable Neural Networks with Bounded Orthogonal\n  Constraint","summary":"  Deep learning has revolutionized human society, yet the black-box nature of\ndeep neural networks hinders further application to reliability-demanded\nindustries. In the attempt to unpack them, many works observe or impact\ninternal variables to improve the model's comprehensibility and transparency.\nHowever, existing methods rely on intuitive assumptions and lack mathematical\nguarantees. To bridge this gap, we introduce Bort, an optimizer for improving\nmodel explainability with boundedness and orthogonality constraints on model\nparameters, derived from the sufficient conditions of model comprehensibility\nand transparency. We perform reconstruction and backtracking on the model\nrepresentations optimized by Bort and observe an evident improvement in model\nexplainability. Based on Bort, we are able to synthesize explainable\nadversarial samples without additional parameters and training. Surprisingly,\nwe find Bort constantly improves the classification accuracy of various\narchitectures including ResNet and DeiT on MNIST, CIFAR-10, and ImageNet.\n","authors":["Borui Zhang","Wenzhao Zheng","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2212.09062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05853v2","updated":"2022-12-18T10:38:35Z","published":"2022-12-12T12:31:46Z","title":"DeepCut: Unsupervised Segmentation using Graph Neural Networks\n  Clustering","summary":"  Image segmentation is a fundamental task in computer vision. Data annotation\nfor training supervised methods can be labor-intensive, motivating unsupervised\nmethods. Some existing approaches extract deep features from pre-trained\nnetworks and build a graph to apply classical clustering methods (e.g.,\n$k$-means and normalized-cuts) as a post-processing stage. These techniques\nreduce the high-dimensional information encoded in the features to pair-wise\nscalar affinities. In this work, we replace classical clustering algorithms\nwith a lightweight Graph Neural Network (GNN) trained to achieve the same\nclustering objective function. However, in contrast to existing approaches, we\nfeed the GNN not only the pair-wise affinities between local image features but\nalso the raw features themselves. Maintaining this connection between the raw\nfeature and the clustering goal allows to perform part semantic segmentation\nimplicitly, without requiring additional post-processing steps. We demonstrate\nhow classical clustering objectives can be formulated as self-supervised loss\nfunctions for training our image segmentation GNN. Additionally, we use the\nCorrelation-Clustering (CC) objective to perform clustering without defining\nthe number of clusters ($k$-less clustering). We apply the proposed method for\nobject localization, segmentation, and semantic part segmentation tasks,\nsurpassing state-of-the-art performance on multiple benchmarks.\n","authors":["Amit Aflalo","Shai Bagon","Tamar Kashti","Yonina Eldar"],"pdf_url":"https://arxiv.org/pdf/2212.05853v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00613v3","updated":"2022-12-18T09:32:03Z","published":"2022-09-01T17:27:25Z","title":"ID and OOD Performance Are Sometimes Inversely Correlated on Real-world\n  Datasets","summary":"  Several studies have empirically compared in-distribution (ID) and\nout-of-distribution (OOD) performance of various models. They report frequent\npositive correlations on benchmarks in computer vision and NLP. Surprisingly,\nthey never observe inverse correlations suggesting necessary trade-offs. This\nmatters to determine whether ID performance can serve as a proxy for OOD\ngeneralization. This paper shows that inverse correlations between ID and OOD\nperformance do happen in real-world benchmarks. They could be missed in past\nstudies because of a biased selection of models. We show an example on the\nWILDS-Camelyon17 dataset, using models from multiple training epochs and random\nseeds. Our observations are particularly striking with models trained with a\nregularizer that diversifies the solutions to the ERM objective. We nuance\nrecommendations and conclusions made in past studies. (1) High OOD performance\nmay sometimes require trading off ID performance.(2) Focusing on ID performance\nalone may not lead to optimal OOD performance: it can lead to diminishing and\neventually negative returns in OOD performance. (3) Our example reminds that\nempirical studies only chart regimes achievable with existing methods: care is\nwarranted in deriving prescriptive recommendations.\n","authors":["Damien Teney","Yong Lin","Seong Joon Oh","Ehsan Abbasnejad"],"pdf_url":"https://arxiv.org/pdf/2209.00613v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09042v1","updated":"2022-12-18T09:27:00Z","published":"2022-12-18T09:27:00Z","title":"Gait Recognition Using 3-D Human Body Shape Inference","summary":"  Gait recognition, which identifies individuals based on their walking\npatterns, is an important biometric technique since it can be observed from a\ndistance and does not require the subject's cooperation. Recognizing a person's\ngait is difficult because of the appearance variants in human silhouette\nsequences produced by varying viewing angles, carrying objects, and clothing.\nRecent research has produced a number of ways for coping with these variants.\nIn this paper, we present the usage of inferring 3-D body shapes distilled from\nlimited images, which are, in principle, invariant to the specified variants.\nInference of 3-D shape is a difficult task, especially when only silhouettes\nare provided in a dataset. We provide a method for learning 3-D body inference\nfrom silhouettes by transferring knowledge from 3-D shape prior from RGB\nphotos. We use our method on multiple existing state-of-the-art gait baselines\nand obtain consistent improvements for gait identification on two public\ndatasets, CASIA-B and OUMVLP, on several variants and settings, including a new\nsetting of novel views not seen during training.\n","authors":["Haidong Zhu","Zhaoheng Zheng","Ram Nevatia"],"pdf_url":"https://arxiv.org/pdf/2212.09042v1.pdf","comment":"Accepted to WACV 2023"},{"id":"http://arxiv.org/abs/2209.14169v2","updated":"2022-12-18T08:55:25Z","published":"2022-09-28T15:22:11Z","title":"CALIP: Zero-Shot Enhancement of CLIP with Parameter-free Attention","summary":"  Contrastive Language-Image Pre-training (CLIP) has been shown to learn visual\nrepresentations with great transferability, which achieves promising accuracy\nfor zero-shot classification. To further improve its downstream performance,\nexisting works propose additional learnable modules upon CLIP and fine-tune\nthem by few-shot training sets. However, the resulting extra training cost and\ndata requirement severely hinder the efficiency for model deployment and\nknowledge transfer. In this paper, we introduce a free-lunch enhancement\nmethod, CALIP, to boost CLIP's zero-shot performance via a parameter-free\nAttention module. Specifically, we guide visual and textual representations to\ninteract with each other and explore cross-modal informative features via\nattention. As the pre-training has largely reduced the embedding distances\nbetween two modalities, we discard all learnable parameters in the attention\nand bidirectionally update the multi-modal features, enabling the whole process\nto be parameter-free and training-free. In this way, the images are blended\nwith textual-aware signals and the text representations become visual-guided\nfor better adaptive zero-shot alignment. We evaluate CALIP on various\nbenchmarks of 14 datasets for both 2D image and 3D point cloud few-shot\nclassification, showing consistent zero-shot performance improvement over CLIP.\nBased on that, we further insert a small number of linear layers in CALIP's\nattention module and verify our robustness under the few-shot settings, which\nalso achieves leading performance compared to existing methods. Those extensive\nexperiments demonstrate the superiority of our approach for efficient\nenhancement of CLIP.\n","authors":["Ziyu Guo","Renrui Zhang","Longtian Qiu","Xianzheng Ma","Xupeng Miao","Xuming He","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2209.14169v2.pdf","comment":"Accepted by AAAI 2023, 12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2212.09039v1","updated":"2022-12-18T08:34:05Z","published":"2022-12-18T08:34:05Z","title":"Automated Optical Inspection of FAST's Reflector Surface using Drones\n  and Computer Vision","summary":"  The Five-hundred-meter Aperture Spherical radio Telescope (FAST) is the\nworld's largest single-dish radio telescope. Its large reflecting surface\nachieves unprecedented sensitivity but is prone to damage, such as dents and\nholes, caused by naturally-occurring falling objects. Hence, the timely and\naccurate detection of surface defects is crucial for FAST's stable operation.\nConventional manual inspection involves human inspectors climbing up and\nexamining the large surface visually, a time-consuming and potentially\nunreliable process. To accelerate the inspection process and increase its\naccuracy, this work makes the first step towards automating the inspection of\nFAST by integrating deep-learning techniques with drone technology. First, a\ndrone flies over the surface along a predetermined route. Since surface defects\nsignificantly vary in scale and show high inter-class similarity, directly\napplying existing deep detectors to detect defects on the drone imagery is\nhighly prone to missing and misidentifying defects. As a remedy, we introduce\ncross-fusion, a dedicated plug-in operation for deep detectors that enables the\nadaptive fusion of multi-level features in a point-wise selective fashion,\ndepending on local defect patterns. Consequently, strong semantics and\nfine-grained details are dynamically fused at different positions to support\nthe accurate detection of defects of various scales and types. Our AI-powered\ndrone-based automated inspection is time-efficient, reliable, and has good\naccessibility, which guarantees the long-term and stable operation of FAST.\n","authors":["Jianan Li","Shenwang Jiang","Liqiang Song","Peiran Peng","Feng Mu","Hui Li","Peng Jiang","Tingfa Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09039v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08010v3","updated":"2022-12-18T08:27:37Z","published":"2022-06-16T09:06:25Z","title":"MoDi: Unconditional Motion Synthesis from Diverse Data","summary":"  The emergence of neural networks has revolutionized the field of motion\nsynthesis. Yet, learning to unconditionally synthesize motions from a given\ndistribution remains challenging, especially when the motions are highly\ndiverse. In this work, we present MoDi -- a generative model trained in an\nunsupervised setting from an extremely diverse, unstructured and unlabeled\ndataset. During inference, MoDi can synthesize high-quality, diverse motions.\nDespite the lack of any structure in the dataset, our model yields a\nwell-behaved and highly structured latent space, which can be semantically\nclustered, constituting a strong motion prior that facilitates various\napplications including semantic editing and crowd simulation. In addition, we\npresent an encoder that inverts real motions into MoDi's natural motion\nmanifold, issuing solutions to various ill-posed challenges such as completion\nfrom prefix and spatial editing. Our qualitative and quantitative experiments\nachieve state-of-the-art results that outperform recent SOTA techniques. Code\nand trained models are available at https://sigal-raab.github.io/MoDi.\n","authors":["Sigal Raab","Inbal Leibovitch","Peizhuo Li","Kfir Aberman","Olga Sorkine-Hornung","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2206.08010v3.pdf","comment":"Video: https://youtu.be/O1sVzwrsNUg, Project page:\n  https://sigal-raab.github.io/MoDi, Code: https://github.com/sigal-raab/MoDi"},{"id":"http://arxiv.org/abs/2212.09035v1","updated":"2022-12-18T08:19:08Z","published":"2022-12-18T08:19:08Z","title":"Minimizing Maximum Model Discrepancy for Transferable Black-box Targeted\n  Attacks","summary":"  In this work, we study the black-box targeted attack problem from the model\ndiscrepancy perspective. On the theoretical side, we present a generalization\nerror bound for black-box targeted attacks, which gives a rigorous theoretical\nanalysis for guaranteeing the success of the attack. We reveal that the attack\nerror on a target model mainly depends on empirical attack error on the\nsubstitute model and the maximum model discrepancy among substitute models. On\nthe algorithmic side, we derive a new algorithm for black-box targeted attacks\nbased on our theoretical analysis, in which we additionally minimize the\nmaximum model discrepancy(M3D) of the substitute models when training the\ngenerator to generate adversarial examples. In this way, our model is capable\nof crafting highly transferable adversarial examples that are robust to the\nmodel variation, thus improving the success rate for attacking the black-box\nmodel. We conduct extensive experiments on the ImageNet dataset with different\nclassification models, and our proposed approach outperforms existing\nstate-of-the-art methods by a significant margin. Our codes will be released.\n","authors":["Anqi Zhao","Tong Chu","Yahao Liu","Wen Li","Jingjing Li","Lixin Duan"],"pdf_url":"https://arxiv.org/pdf/2212.09035v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09027v1","updated":"2022-12-18T07:36:32Z","published":"2022-12-18T07:36:32Z","title":"2D Pose Estimation based Child Action Recognition","summary":"  We present a graph convolutional network with 2D pose estimation for the\nfirst time on child action recognition task achieving on par results with an\nRGB modality based model on a novel benchmark dataset containing unconstrained\nenvironment based videos.\n","authors":["Sanka Mohottala","Sandun Abeygunawardana","Pradeepa Samarasinghe","Dharshana Kasthurirathna","Charith Abhayaratne"],"pdf_url":"https://arxiv.org/pdf/2212.09027v1.pdf","comment":"Paper Accepted for the IEEE TENCON Conference (2022). 7 pages, 5\n  figures"},{"id":"http://arxiv.org/abs/2212.09013v1","updated":"2022-12-18T05:07:11Z","published":"2022-12-18T05:07:11Z","title":"Graph Neural Network based Child Activity Recognition","summary":"  This paper presents an implementation on child activity recognition (CAR)\nwith a graph convolution network (GCN) based deep learning model since prior\nimplementations in this domain have been dominated by CNN, LSTM and other\nmethods despite the superior performance of GCN. To the best of our knowledge,\nwe are the first to use a GCN model in child activity recognition domain. In\novercoming the challenges of having small size publicly available child action\ndatasets, several learning methods such as feature extraction, fine-tuning and\ncurriculum learning were implemented to improve the model performance. Inspired\nby the contradicting claims made on the use of transfer learning in CAR, we\nconducted a detailed implementation and analysis on transfer learning together\nwith a study on negative transfer learning effect on CAR as it hasn't been\naddressed previously. As the principal contribution, we were able to develop a\nST-GCN based CAR model which, despite the small size of the dataset, obtained\naround 50% accuracy on vanilla implementations. With feature extraction and\nfine-tuning methods, accuracy was improved by 20%-30% with the highest accuracy\nbeing 82.24%. Furthermore, the results provided on activity datasets\nempirically demonstrate that with careful selection of pre-train model datasets\nthrough methods such as curriculum learning could enhance the accuracy levels.\nFinally, we provide preliminary evidence on possible frame rate effect on the\naccuracy of CAR models, a direction future research can explore.\n","authors":["Sanka Mohottala","Pradeepa Samarasinghe","Dharshana Kasthurirathna","Charith Abhayaratne"],"pdf_url":"https://arxiv.org/pdf/2212.09013v1.pdf","comment":"Accepted to 23rd IEEE ICIT Conference (2022), 8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2212.08996v1","updated":"2022-12-18T03:23:38Z","published":"2022-12-18T03:23:38Z","title":"Smart Face Shield: A Sensor-Based Wearable Face Shield Utilizing\n  Computer Vision Algorithms","summary":"  The study aims the development of a wearable device to combat the onslaught\nof covid-19. Likewise, to enhance the regular face shield available in the\nmarket. Furthermore, to raise awareness of the health and safety protocols\ninitiated by the government and its affiliates in the enforcement of social\ndistancing with the integration of computer vision algorithms. The wearable\ndevice was composed of various hardware and software components such as a\ntransparent polycarbonate face shield, microprocessor, sensors, camera,\nthin-film transistor on-screen display, jumper wires, power bank, and python\nprogramming language. The algorithm incorporated in the study was object\ndetection under computer vision machine learning. The front camera with OpenCV\ntechnology determines the distance of a person in front of the user. Utilizing\nTensorFlow, the target object identifies and detects the image or live feed to\nget its bounding boxes. The focal length lens requires the determination of the\ndistance from the camera to the target object. To get the focal length,\nmultiply the pixel width by the known distance and divide it by the known width\n(Rosebrock, 2020). The deployment of unit testing ensures that the parameters\nare valid in terms of design and specifications.\n","authors":["Manuel Luis C. Delos Santos","Ronaldo S. Tinio","Darwin B. Diaz","Karlene Emily I. Tolosa"],"pdf_url":"https://arxiv.org/pdf/2212.08996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15076v2","updated":"2022-12-18T03:21:40Z","published":"2022-11-28T05:45:17Z","title":"Refined Semantic Enhancement towards Frequency Diffusion for Video\n  Captioning","summary":"  Video captioning aims to generate natural language sentences that describe\nthe given video accurately. Existing methods obtain favorable generation by\nexploring richer visual representations in encode phase or improving the\ndecoding ability. However, the long-tailed problem hinders these attempts at\nlow-frequency tokens, which rarely occur but carry critical semantics, playing\na vital role in the detailed generation. In this paper, we introduce a novel\nRefined Semantic enhancement method towards Frequency Diffusion (RSFD), a\ncaptioning model that constantly perceives the linguistic representation of the\ninfrequent tokens. Concretely, a Frequency-Aware Diffusion (FAD) module is\nproposed to comprehend the semantics of low-frequency tokens to break through\ngeneration limitations. In this way, the caption is refined by promoting the\nabsorption of tokens with insufficient occurrence. Based on FAD, we design a\nDivergent Semantic Supervisor (DSS) module to compensate for the information\nloss of high-frequency tokens brought by the diffusion process, where the\nsemantics of low-frequency tokens is further emphasized to alleviate the\nlong-tailed problem. Extensive experiments indicate that RSFD outperforms the\nstate-of-the-art methods on two benchmark datasets, i.e., MSR-VTT and MSVD,\ndemonstrate that the enhancement of low-frequency tokens semantics can obtain a\ncompetitive generation effect. Code is available at\nhttps://github.com/lzp870/RSFD.\n","authors":["Xian Zhong","Zipeng Li","Shuqin Chen","Kui Jiang","Chen Chen","Mang Ye"],"pdf_url":"https://arxiv.org/pdf/2211.15076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06655v2","updated":"2022-12-18T02:37:01Z","published":"2022-12-13T15:37:53Z","title":"The Hateful Memes Challenge Next Move","summary":"  State-of-the-art image and text classification models, such as Convolutional\nNeural Networks and Transformers, have long been able to classify their\nrespective unimodal reasoning satisfactorily with accuracy close to or\nexceeding human accuracy. However, images embedded with text, such as hateful\nmemes, are hard to classify using unimodal reasoning when difficult examples,\nsuch as benign confounders, are incorporated into the data set. We attempt to\ngenerate more labeled memes in addition to the Hateful Memes data set from\nFacebook AI, based on the framework of a winning team from the Hateful Meme\nChallenge. To increase the number of labeled memes, we explore semi-supervised\nlearning using pseudo-labels for newly introduced, unlabeled memes gathered\nfrom the Memotion Dataset 7K. We find that the semi-supervised learning task on\nunlabeled data required human intervention and filtering and that adding a\nlimited amount of new data yields no extra classification performance.\n","authors":["Weijun Jin","Lance Wilhelm"],"pdf_url":"https://arxiv.org/pdf/2212.06655v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08615v5","updated":"2022-12-18T02:22:11Z","published":"2022-11-16T02:03:20Z","title":"GLFF: Global and Local Feature Fusion for Face Forgery Detection","summary":"  With the rapid development of deep generative models (such as Generative\nAdversarial Networks and Auto-encoders), AI-synthesized images of the human\nface are now of such high quality that humans can hardly distinguish them from\npristine ones. Although existing detection methods have shown high performance\nin specific evaluation settings, e.g., on images from seen models or on images\nwithout real-world post-processings, they tend to suffer serious performance\ndegradation in real-world scenarios where testing images can be generated by\nmore powerful generation models or combined with various post-processing\noperations. To address this issue, we propose a Global and Local Feature Fusion\n(GLFF) to learn rich and discriminative representations by combining\nmulti-scale global features from the whole image with refined local features\nfrom informative patches for face forgery detection. GLFF fuses information\nfrom two branches: the global branch to extract multi-scale semantic features\nand the local branch to select informative patches for detailed local artifacts\nextraction. Due to the lack of a face forgery dataset simulating real-world\napplications for evaluation, we further create a challenging face forgery\ndataset, named DeepFakeFaceForensics (DF^3), which contains 6 state-of-the-art\ngeneration models and a variety of post-processing techniques to approach the\nreal-world scenarios. Experimental results demonstrate the superiority of our\nmethod to the state-of-the-art methods on the proposed DF^3 dataset and three\nother open-source datasets.\n","authors":["Yan Ju","Shan Jia","Jialing Cai","Haiying Guan","Siwei Lyu"],"pdf_url":"https://arxiv.org/pdf/2211.08615v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08990v1","updated":"2022-12-18T02:11:03Z","published":"2022-12-18T02:11:03Z","title":"Plankton-FL: Exploration of Federated Learning for Privacy-Preserving\n  Training of Deep Neural Networks for Phytoplankton Classification","summary":"  Creating high-performance generalizable deep neural networks for\nphytoplankton monitoring requires utilizing large-scale data coming from\ndiverse global water sources. A major challenge to training such networks lies\nin data privacy, where data collected at different facilities are often\nrestricted from being transferred to a centralized location. A promising\napproach to overcome this challenge is federated learning, where training is\ndone at site level on local data, and only the model parameters are exchanged\nover the network to generate a global model. In this study, we explore the\nfeasibility of leveraging federated learning for privacy-preserving training of\ndeep neural networks for phytoplankton classification. More specifically, we\nsimulate two different federated learning frameworks, federated learning (FL)\nand mutually exclusive FL (ME-FL), and compare their performance to a\ntraditional centralized learning (CL) framework. Experimental results from this\nstudy demonstrate the feasibility and potential of federated learning for\nphytoplankton monitoring.\n","authors":["Daniel Zhang","Vikram Voleti","Alexander Wong","Jason Deglint"],"pdf_url":"https://arxiv.org/pdf/2212.08990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08985v1","updated":"2022-12-18T01:56:33Z","published":"2022-12-18T01:56:33Z","title":"Efficient Image Captioning for Edge Devices","summary":"  Recent years have witnessed the rapid progress of image captioning. However,\nthe demands for large memory storage and heavy computational burden prevent\nthese captioning models from being deployed on mobile devices. The main\nobstacles lie in the heavyweight visual feature extractors (i.e., object\ndetectors) and complicated cross-modal fusion networks. To this end, we propose\nLightCap, a lightweight image captioner for resource-limited devices. The core\ndesign is built on the recent CLIP model for efficient image captioning. To be\nspecific, on the one hand, we leverage the CLIP model to extract the compact\ngrid features without relying on the time-consuming object detectors. On the\nother hand, we transfer the image-text retrieval design of CLIP to image\ncaptioning scenarios by devising a novel visual concept extractor and a\ncross-modal modulator. We further optimize the cross-modal fusion model and\nparallel prediction heads via sequential and ensemble distillations. With the\ncarefully designed architecture, our model merely contains 40M parameters,\nsaving the model size by more than 75% and the FLOPs by more than 98% in\ncomparison with the current state-of-the-art methods. In spite of the low\ncapacity, our model still exhibits state-of-the-art performance on prevalent\ndatasets, e.g., 136.6 CIDEr on COCO Karpathy test split. Testing on the\nsmartphone with only a single CPU, the proposed LightCap exhibits a fast\ninference speed of 188ms per image, which is ready for practical applications.\n","authors":["Ning Wang","Jiangrong Xie","Hang Luo","Qinglin Cheng","Jihao Wu","Mingbo Jia","Linlin Li"],"pdf_url":"https://arxiv.org/pdf/2212.08985v1.pdf","comment":"To appear in AAAI 2023"},{"id":"http://arxiv.org/abs/2212.08983v1","updated":"2022-12-18T01:07:20Z","published":"2022-12-18T01:07:20Z","title":"Adaptive Uncertainty Distribution in Deep Learning for Unsupervised\n  Underwater Image Enhancement","summary":"  One of the main challenges in deep learning-based underwater image\nenhancement is the limited availability of high-quality training data.\nUnderwater images are difficult to capture and are often of poor quality due to\nthe distortion and loss of colour and contrast in water. This makes it\ndifficult to train supervised deep learning models on large and diverse\ndatasets, which can limit the model's performance. In this paper, we explore an\nalternative approach to supervised underwater image enhancement. Specifically,\nwe propose a novel unsupervised underwater image enhancement framework that\nemploys a conditional variational autoencoder (cVAE) to train a deep learning\nmodel with probabilistic adaptive instance normalization (PAdaIN) and\nstatistically guided multi-colour space stretch that produces realistic\nunderwater images. The resulting framework is composed of a U-Net as a feature\nextractor and a PAdaIN to encode the uncertainty, which we call UDnet. To\nimprove the visual quality of the images generated by UDnet, we use a\nstatistically guided multi-colour space stretch module that ensures visual\nconsistency with the input image and provides an alternative to training using\na ground truth image. The proposed model does not need manual human annotation\nand can learn with a limited amount of data and achieves state-of-the-art\nresults on underwater images. We evaluated our proposed framework on eight\npublicly-available datasets. The results show that our proposed framework\nyields competitive performance compared to other state-of-the-art approaches in\nquantitative as well as qualitative metrics. Code available at\nhttps://github.com/alzayats/UDnet .\n","authors":["Alzayat Saleh","Marcus Sheaves","Dean Jerry","Mostafa Rahimi Azghadi"],"pdf_url":"https://arxiv.org/pdf/2212.08983v1.pdf","comment":"18 pages, 8 figures, 4 tables"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.09044v1","updated":"2022-12-18T09:31:36Z","published":"2022-12-18T09:31:36Z","title":"Text2Struct: A Machine Learning Pipeline for Mining Structured Data from\n  Text","summary":"  Many analysis and prediction tasks require the extraction of structured data\nfrom unstructured texts. To solve it, this paper presents an end-to-end machine\nlearning pipeline, Text2Struct, including a text annotation scheme, training\ndata processing, and machine learning implementation. We formulated the mining\nproblems as the extraction of metrics and units associated with numerals in the\ntext. Text2Struct was evaluated on an annotated text dataset collected from\nabstracts of medical publications regarding thrombectomy. In terms of\nprediction performance, a dice coefficient of 0.82 was achieved on the test\ndataset. By random sampling, most predicted relations between numerals and\nentities were well matched to the ground-truth annotations. These results\nshowed that the Text2Struct is viable for the mining of structured data from\ntext without special templates or patterns. It is anticipated to further\nimprove the pipeline by expanding the dataset and investigating other machine\nlearning models. A code demonstration can be found at:\nhttps://github.com/zcc861007/CourseProject\n","authors":["Chaochao Zhou","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2212.09044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09031v1","updated":"2022-12-18T07:44:33Z","published":"2022-12-18T07:44:33Z","title":"Marginal-Certainty-aware Fair Ranking Algorithm","summary":"  Ranking systems are ubiquitous in modern Internet services, including online\nmarketplaces, social media, and search engines. Traditionally, ranking systems\nonly focus on how to get better relevance estimation. When relevance estimation\nis available, they usually adopt a user-centric optimization strategy where\nranked lists are generated by sorting items according to their estimated\nrelevance. However, such user-centric optimization ignores the fact that item\nproviders also draw utility from ranking systems. It has been shown in existing\nresearch that such user-centric optimization will cause much unfairness to item\nproviders, followed by unfair opportunities and unfair economic gains for item\nproviders.\n  To address ranking fairness, many fair ranking methods have been proposed.\nHowever, as we show in this paper, these methods could be suboptimal as they\ndirectly rely on the relevance estimation without being aware of the\nuncertainty (i.e., the variance of the estimated relevance). To address this\nuncertainty, we propose a novel Marginal-Certainty-aware Fair algorithm named\nMCFair. MCFair jointly optimizes fairness and user utility, while relevance\nestimation is constantly updated in an online manner.\n  In MCFair, we first develop a ranking objective that includes uncertainty,\nfairness, and user utility. Then we directly use the gradient of the ranking\nobjective as the ranking score. We theoretically prove that MCFair based on\ngradients is optimal for the aforementioned ranking objective. Empirically, we\nfind that on semi-synthesized datasets, MCFair is effective and practical and\ncan deliver superior performance compared to state-of-the-art fair ranking\nmethods. To facilitate reproducibility, we release our code\nhttps://github.com/Taosheng-ty/WSDM22-MCFair.\n","authors":["Tao Yang","Zhichao Xu","Zhenduo Wang","Anh Tran","Qingyao Ai"],"pdf_url":"https://arxiv.org/pdf/2212.09031v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.09018v1","updated":"2022-12-18T05:32:19Z","published":"2022-12-18T05:32:19Z","title":"MeSH Suggester: A Library and System for MeSH Term Suggestion for\n  Systematic Review Boolean Query Construction","summary":"  Boolean query construction is often critical for medical systematic review\nliterature search. To create an effective Boolean query, systematic review\nresearchers typically spend weeks coming up with effective query terms and\ncombinations. One challenge to creating an effective systematic review Boolean\nquery is the selection of effective MeSH Terms to include in the query. In our\nprevious work, we created neural MeSH term suggestion methods and compared them\nto state-of-the-art MeSH term suggestion methods. We found neural MeSH term\nsuggestion methods to be highly effective.\n  In this demonstration, we build upon our previous work by creating (1) a\nWeb-based MeSH term suggestion prototype system that allows users to obtain\nsuggestions from a number of underlying methods and (2) a Python library that\nimplements ours and others' MeSH term suggestion methods and that is aimed at\nresearchers who want to further investigate, create or deploy such type of\nmethods. We describe the architecture of the web-based system and how to use it\nfor the MeSH term suggestion task. For the Python library, we describe how the\nlibrary can be used for advancing further research and experimentation, and we\nvalidate the results of the methods contained in the library on standard\ndatasets. Our web-based prototype system is available at\nhttp://ielab-mesh-suggest.uqcloud.net, while our Python library is at\nhttps://github.com/ielab/meshsuggestlib.\n","authors":["Shuai Wang","Hang Li","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2212.09018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09017v1","updated":"2022-12-18T05:26:40Z","published":"2022-12-18T05:26:40Z","title":"Neural Rankers for Effective Screening Prioritisation in Medical\n  Systematic Review Literature Search","summary":"  Medical systematic reviews typically require assessing all the documents\nretrieved by a search. The reason is two-fold: the task aims for ``total\nrecall''; and documents retrieved using Boolean search are an unordered set,\nand thus it is unclear how an assessor could examine only a subset. Screening\nprioritisation is the process of ranking the (unordered) set of retrieved\ndocuments, allowing assessors to begin the downstream processes of the\nsystematic review creation earlier, leading to earlier completion of the\nreview, or even avoiding screening documents ranked least relevant.\n  Screening prioritisation requires highly effective ranking methods.\nPre-trained language models are state-of-the-art on many IR tasks but have yet\nto be applied to systematic review screening prioritisation. In this paper, we\napply several pre-trained language models to the systematic review document\nranking task, both directly and fine-tuned. An empirical analysis compares how\neffective neural methods compare to traditional methods for this task. We also\ninvestigate different types of document representations for neural methods and\ntheir impact on ranking performance.\n  Our results show that BERT-based rankers outperform the current\nstate-of-the-art screening prioritisation methods. However, BERT rankers and\nexisting methods can actually be complementary, and thus, further improvements\nmay be achieved if used in conjunction.\n","authors":["Shuai Wang","Harrisen Scells","Bevan Koopman","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2212.09017v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2011.12216v3","updated":"2022-12-18T23:06:52Z","published":"2020-11-24T17:08:13Z","title":"Energy-Based Models for Continual Learning","summary":"  We motivate Energy-Based Models (EBMs) as a promising model class for\ncontinual learning problems. Instead of tackling continual learning via the use\nof external memory, growing models, or regularization, EBMs change the\nunderlying training objective to cause less interference with previously\nlearned information. Our proposed version of EBMs for continual learning is\nsimple, efficient, and outperforms baseline methods by a large margin on\nseveral benchmarks. Moreover, our proposed contrastive divergence-based\ntraining objective can be combined with other continual learning methods,\nresulting in substantial boosts in their performance. We further show that EBMs\nare adaptable to a more general continual learning setting where the data\ndistribution changes without the notion of explicitly delineated tasks. These\nobservations point towards EBMs as a useful building block for future continual\nlearning methods.\n","authors":["Shuang Li","Yilun Du","Gido M. van de Ven","Igor Mordatch"],"pdf_url":"https://arxiv.org/pdf/2011.12216v3.pdf","comment":"Project page:\n  https://energy-based-model.github.io/Energy-Based-Models-for-Continual-Learning"},{"id":"http://arxiv.org/abs/2205.13496v3","updated":"2022-12-18T22:37:33Z","published":"2022-05-26T17:10:28Z","title":"Censored Quantile Regression Neural Networks for Distribution-Free\n  Survival Analysis","summary":"  This paper considers doing quantile regression on censored data using neural\nnetworks (NNs). This adds to the survival analysis toolkit by allowing direct\nprediction of the target variable, along with a distribution-free\ncharacterisation of uncertainty, using a flexible function approximator. We\nbegin by showing how an algorithm popular in linear models can be applied to\nNNs. However, the resulting procedure is inefficient, requiring sequential\noptimisation of an individual NN at each desired quantile. Our major\ncontribution is a novel algorithm that simultaneously optimises a grid of\nquantiles output by a single NN. To offer theoretical insight into our\nalgorithm, we show firstly that it can be interpreted as a form of\nexpectation-maximisation, and secondly that it exhibits a desirable\n`self-correcting' property. Experimentally, the algorithm produces quantiles\nthat are better calibrated than existing methods on 10 out of 12 real datasets.\n","authors":["Tim Pearce","Jong-Hyeon Jeong","Yichen Jia","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2205.13496v3.pdf","comment":"Published in NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.09184v1","updated":"2022-12-18T22:34:42Z","published":"2022-12-18T22:34:42Z","title":"Faithful Heteroscedastic Regression with Neural Networks","summary":"  Heteroscedastic regression models a Gaussian variable's mean and variance as\na function of covariates. Parametric methods that employ neural networks for\nthese parameter maps can capture complex relationships in the data. Yet,\noptimizing network parameters via log likelihood gradients can yield suboptimal\nmean and uncalibrated variance estimates. Current solutions side-step this\noptimization problem with surrogate objectives or Bayesian treatments. Instead,\nwe make two simple modifications to optimization. Notably, their combination\nproduces a heteroscedastic model with mean estimates that are provably as\naccurate as those from its homoscedastic counterpart (i.e.~fitting the mean\nunder squared error loss). For a wide variety of network and task complexities,\nwe find that mean estimates from existing heteroscedastic solutions can be\nsignificantly less accurate than those from an equivalently expressive\nmean-only model. Our approach provably retains the accuracy of an equally\nflexible mean-only model while also offering best-in-class variance\ncalibration. Lastly, we show how to leverage our method to recover the\nunderlying heteroscedastic noise variance.\n","authors":["Andrew Stirn","Hans-Hermann Wessels","Megan Schertzer","Laura Pereira","Neville E. Sanjana","David A. Knowles"],"pdf_url":"https://arxiv.org/pdf/2212.09184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.11489v2","updated":"2022-12-18T22:33:13Z","published":"2022-10-20T18:00:04Z","title":"Machine-Learning Compression for Particle Physics Discoveries","summary":"  In collider-based particle and nuclear physics experiments, data are produced\nat such extreme rates that only a subset can be recorded for later analysis.\nTypically, algorithms select individual collision events for preservation and\nstore the complete experimental response. A relatively new alternative strategy\nis to additionally save a partial record for a larger subset of events,\nallowing for later specific analysis of a larger fraction of events. We propose\na strategy that bridges these paradigms by compressing entire events for\ngeneric offline analysis but at a lower fidelity. An optimal-transport-based\n$\\beta$ Variational Autoencoder (VAE) is used to automate the compression and\nthe hyperparameter $\\beta$ controls the compression fidelity. We introduce a\nnew approach for multi-objective learning functions by simultaneously learning\na VAE appropriate for all values of $\\beta$ through parameterization. We\npresent an example use case, a di-muon resonance search at the Large Hadron\nCollider (LHC), where we show that simulated data compressed by our $\\beta$-VAE\nhas enough fidelity to distinguish distinct signal morphologies.\n","authors":["Jack H. Collins","Yifeng Huang","Simon Knapen","Benjamin Nachman","Daniel Whiteson"],"pdf_url":"https://arxiv.org/pdf/2210.11489v2.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.08049v2","updated":"2022-12-18T22:10:06Z","published":"2022-12-15T18:55:23Z","title":"Sliced Optimal Partial Transport","summary":"  Optimal transport (OT) has become exceedingly popular in machine learning,\ndata science, and computer vision. The core assumption in the OT problem is the\nequal total amount of mass in source and target measures, which limits its\napplication. Optimal Partial Transport (OPT) is a recently proposed solution to\nthis limitation. Similar to the OT problem, the computation of OPT relies on\nsolving a linear programming problem (often in high dimensions), which can\nbecome computationally prohibitive. In this paper, we propose an efficient\nalgorithm for calculating the OPT problem between two non-negative measures in\none dimension. Next, following the idea of sliced OT distances, we utilize\nslicing to define the sliced OPT distance. Finally, we demonstrate the\ncomputational and accuracy benefits of the sliced OPT-based method in various\nnumerical experiments. In particular, we show an application of our proposed\nSliced-OPT in noisy point cloud registration.\n","authors":["Yikun Bai","Bernard Schmitzer","Mathew Thorpe","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2212.08049v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11690v2","updated":"2022-12-18T22:06:46Z","published":"2022-11-21T18:07:14Z","title":"Learn to explain yourself, when you can: Equipping Concept Bottleneck\n  Models with the ability to abstain on their concept predictions","summary":"  The Concept Bottleneck Models (CBMs) of Koh et al. [2020] provide a means to\nensure that a neural network based classifier bases its predictions solely on\nhuman understandable concepts. The concept labels, or rationales as we refer to\nthem, are learned by the concept labeling component of the CBM. Another\ncomponent learns to predict the target classification label from these\npredicted concept labels. Unfortunately, these models are heavily reliant on\nhuman provided concept labels for each datapoint. To enable CBMs to behave\nrobustly when these labels are not readily available, we show how to equip them\nwith the ability to abstain from predicting concepts when the concept labeling\ncomponent is uncertain. In other words, our model learns to provide rationales\nfor its predictions, but only whenever it is sure the rationale is correct.\n","authors":["Joshua Lockhart","Daniele Magazzeni","Manuela Veloso"],"pdf_url":"https://arxiv.org/pdf/2211.11690v2.pdf","comment":"Changed LaTeX template"},{"id":"http://arxiv.org/abs/2212.09178v1","updated":"2022-12-18T21:53:33Z","published":"2022-12-18T21:53:33Z","title":"Support Vector Regression: Risk Quadrangle Framework","summary":"  This paper investigates Support Vector Regression (SVR) in the context of the\nfundamental risk quadrangle paradigm. It is shown that both formulations of\nSVR, $\\varepsilon$-SVR and $\\nu$-SVR, correspond to the minimization of\nequivalent regular error measures (Vapnik error and superquantile (CVaR) norm,\nrespectively) with a regularization penalty. These error measures, in turn,\ngive rise to corresponding risk quadrangles. Additionally, the technique used\nfor the construction of quadrangles serves as a powerful tool in proving the\nequivalence between $\\varepsilon$-SVR and $\\nu$-SVR.\n  By constructing the fundamental risk quadrangle, which corresponds to SVR, we\nshow that SVR is the asymptotically unbiased estimator of the average of two\nsymmetric conditional quantiles. Additionally, SVR is formulated as a regular\ndeviation minimization problem with a regularization penalty by invoking Error\nShaping Decomposition of Regression. Finally, the dual formulation of SVR in\nthe risk quadrangle framework is derived.\n","authors":["Anton Malandii","Stan Uryasev"],"pdf_url":"https://arxiv.org/pdf/2212.09178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09175v1","updated":"2022-12-18T21:43:27Z","published":"2022-12-18T21:43:27Z","title":"Predicting Citi Bike Demand Evolution Using Dynamic Graphs","summary":"  Bike sharing systems often suffer from poor capacity management as a result\nof variable demand. These bike sharing systems would benefit from models to\npredict demand in order to moderate the number of bikes stored at each station.\nIn this paper, we attempt to apply a graph neural network model to predict bike\ndemand in the New York City, Citi Bike dataset.\n","authors":["Alexander Saff","Mayur Bhandary","Siddharth Srivastava"],"pdf_url":"https://arxiv.org/pdf/2212.09175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09083v3","updated":"2022-12-18T21:18:27Z","published":"2022-10-17T13:32:52Z","title":"Nish: A Novel Negative Stimulated Hybrid Activation Function","summary":"  An activation function has a significant impact on the efficiency and\nrobustness of the neural networks. As an alternative, we evolved a cutting-edge\nnon-monotonic activation function, Negative Stimulated Hybrid Activation\nFunction (Nish). It acts as a Rectified Linear Unit (ReLU) function for the\npositive region and a sinus-sigmoidal function for the negative region. In\nother words, it incorporates a sigmoid and a sine function and gaining new\ndynamics over classical ReLU. We analyzed the consistency of the Nish for\ndifferent combinations of essential networks and most common activation\nfunctions using on several most popular benchmarks. From the experimental\nresults, we reported that the accuracy rates achieved by the Nish is slightly\nbetter than compared to the Mish in classification.\n","authors":["Yildiray Anagun","Sahin Isik"],"pdf_url":"https://arxiv.org/pdf/2210.09083v3.pdf","comment":"10 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2212.09162v1","updated":"2022-12-18T20:43:37Z","published":"2022-12-18T20:43:37Z","title":"Medical Diagnosis with Large Scale Multimodal Transformers -- Leveraging\n  Diverse Data for More Accurate Diagnosis","summary":"  Multimodal deep learning has been used to predict clinical endpoints and\ndiagnoses from clinical routine data. However, these models suffer from scaling\nissues: they have to learn pairwise interactions between each piece of\ninformation in each data type, thereby escalating model complexity beyond\nmanageable scales. This has so far precluded a widespread use of multimodal\ndeep learning. Here, we present a new technical approach of \"learnable\nsynergies\", in which the model only selects relevant interactions between data\nmodalities and keeps an \"internal memory\" of relevant data. Our approach is\neasily scalable and naturally adapts to multimodal data inputs from clinical\nroutine. We demonstrate this approach on three large multimodal datasets from\nradiology and ophthalmology and show that it outperforms state-of-the-art\nmodels in clinically relevant diagnosis tasks. Our new approach is transferable\nand will allow the application of multimodal deep learning to a broad set of\nclinically relevant problems.\n","authors":["Firas Khader","Gustav Mueller-Franzes","Tianci Wang","Tianyu Han","Soroosh Tayebi Arasteh","Christoph Haarburger","Johannes Stegmaier","Keno Bressem","Christiane Kuhl","Sven Nebelung","Jakob Nikolas Kather","Daniel Truhn"],"pdf_url":"https://arxiv.org/pdf/2212.09162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09155v1","updated":"2022-12-18T20:18:59Z","published":"2022-12-18T20:18:59Z","title":"Estimating the Adversarial Robustness of Attributions in Text with\n  Transformers","summary":"  Explanations are crucial parts of deep neural network (DNN) classifiers. In\nhigh stakes applications, faithful and robust explanations are important to\nunderstand and gain trust in DNN classifiers. However, recent work has shown\nthat state-of-the-art attribution methods in text classifiers are susceptible\nto imperceptible adversarial perturbations that alter explanations\nsignificantly while maintaining the correct prediction outcome. If undetected,\nthis can critically mislead the users of DNNs. Thus, it is crucial to\nunderstand the influence of such adversarial perturbations on the networks'\nexplanations and their perceptibility. In this work, we establish a novel\ndefinition of attribution robustness (AR) in text classification, based on\nLipschitz continuity. Crucially, it reflects both attribution change induced by\nadversarial input alterations and perceptibility of such alterations. Moreover,\nwe introduce a wide set of text similarity measures to effectively capture\nlocality between two text samples and imperceptibility of adversarial\nperturbations in text. We then propose our novel TransformerExplanationAttack\n(TEA), a strong adversary that provides a tight estimation for attribution\nrobustness in text classification. TEA uses state-of-the-art language models to\nextract word substitutions that result in fluent, contextual adversarial\nsamples. Finally, with experiments on several text classification\narchitectures, we show that TEA consistently outperforms current\nstate-of-the-art AR estimators, yielding perturbations that alter explanations\nto a greater extent while being more fluent and less perceptible.\n","authors":["Adam Ivankay","Mattia Rigotti","Ivan Girardi","Chiara Marchiori","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2212.09155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09154v1","updated":"2022-12-18T20:12:20Z","published":"2022-12-18T20:12:20Z","title":"Empirical Analysis of AI-based Energy Management in Electric Vehicles: A\n  Case Study on Reinforcement Learning","summary":"  Reinforcement learning-based (RL-based) energy management strategy (EMS) is\nconsidered a promising solution for the energy management of electric vehicles\nwith multiple power sources. It has been shown to outperform conventional\nmethods in energy management problems regarding energy-saving and real-time\nperformance. However, previous studies have not systematically examined the\nessential elements of RL-based EMS. This paper presents an empirical analysis\nof RL-based EMS in a Plug-in Hybrid Electric Vehicle (PHEV) and Fuel Cell\nElectric Vehicle (FCEV). The empirical analysis is developed in four aspects:\nalgorithm, perception and decision granularity, hyperparameters, and reward\nfunction. The results show that the Off-policy algorithm effectively develops a\nmore fuel-efficient solution within the complete driving cycle compared with\nother algorithms. Improving the perception and decision granularity does not\nproduce a more desirable energy-saving solution but better balances battery\npower and fuel consumption. The equivalent energy optimization objective based\non the instantaneous state of charge (SOC) variation is parameter sensitive and\ncan help RL-EMSs to achieve more efficient energy-cost strategies.\n","authors":["Jincheng Hu","Yang Lin","Jihao Li","Zhuoran Hou","Dezong Zhao","Quan Zhou","Jingjing Jiang","Yuanjian Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.09154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09132v1","updated":"2022-12-18T17:04:14Z","published":"2022-12-18T17:04:14Z","title":"JEMMA: An Extensible Java Dataset for ML4Code Applications","summary":"  Machine Learning for Source Code (ML4Code) is an active research field in\nwhich extensive experimentation is needed to discover how to best use source\ncode's richly structured information. With this in mind, we introduce JEMMA, an\nExtensible Java Dataset for ML4Code Applications, which is a large-scale,\ndiverse, and high-quality dataset targeted at ML4Code. Our goal with JEMMA is\nto lower the barrier to entry in ML4Code by providing the building blocks to\nexperiment with source code models and tasks. JEMMA comes with a considerable\namount of pre-processed information such as metadata, representations (e.g.,\ncode tokens, ASTs, graphs), and several properties (e.g., metrics, static\nanalysis results) for 50,000 Java projects from the 50KC dataset, with over 1.2\nmillion classes and over 8 million methods. JEMMA is also extensible allowing\nusers to add new properties and representations to the dataset, and evaluate\ntasks on them. Thus, JEMMA becomes a workbench that researchers can use to\nexperiment with novel representations and tasks operating on source code. To\ndemonstrate the utility of the dataset, we also report results from two\nempirical studies on our data, ultimately showing that significant work lies\nahead in the design of context-aware source code models that can reason over a\nbroader network of source code entities in a software project, the very task\nthat JEMMA is designed to help with.\n","authors":["Anjan Karmakar","Miltiadis Allamanis","Romain Robbes"],"pdf_url":"https://arxiv.org/pdf/2212.09132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.02363v3","updated":"2022-12-18T16:35:53Z","published":"2021-07-06T02:54:53Z","title":"Asymptotics of Network Embeddings Learned via Subsampling","summary":"  Network data are ubiquitous in modern machine learning, with tasks of\ninterest including node classification, node clustering and link prediction. A\nfrequent approach begins by learning an Euclidean embedding of the network, to\nwhich algorithms developed for vector-valued data are applied. For large\nnetworks, embeddings are learned using stochastic gradient methods where the\nsub-sampling scheme can be freely chosen. Despite the strong empirical\nperformance of such methods, they are not well understood theoretically. Our\nwork encapsulates representation methods using a subsampling approach, such as\nnode2vec, into a single unifying framework. We prove, under the assumption that\nthe graph is exchangeable, that the distribution of the learned embedding\nvectors asymptotically decouples. Moreover, we characterize the asymptotic\ndistribution and provided rates of convergence, in terms of the latent\nparameters, which includes the choice of loss function and the embedding\ndimension. This provides a theoretical foundation to understand what the\nembedding vectors represent and how well these methods perform on downstream\ntasks. Notably, we observe that typically used loss functions may lead to\nshortcomings, such as a lack of Fisher consistency.\n","authors":["Andrew Davison","Morgane Austern"],"pdf_url":"https://arxiv.org/pdf/2107.02363v3.pdf","comment":"Under review at JMLR. 120 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2206.00145v2","updated":"2022-12-18T16:23:17Z","published":"2022-05-31T23:09:35Z","title":"CASSOCK: Viable Backdoor Attacks against DNN in The Wall of\n  Source-Specific Backdoor Defences","summary":"  As a critical threat to deep neural networks (DNNs), backdoor attacks can be\ncategorized into two types, i.e., source-agnostic backdoor attacks (SABAs) and\nsource-specific backdoor attacks (SSBAs). Compared to traditional SABAs, SSBAs\nare more advanced in that they have superior stealthier in bypassing mainstream\ncountermeasures that are effective against SABAs. Nonetheless, existing SSBAs\nsuffer from two major limitations. First, they can hardly achieve a good\ntrade-off between ASR (attack success rate) and FPR (false positive rate).\nBesides, they can be effectively detected by the state-of-the-art (SOTA)\ncountermeasures (e.g., SCAn). To address the limitations above, we propose a\nnew class of viable source-specific backdoor attacks, coined as CASSOCK. Our\nkey insight is that trigger designs when creating poisoned data and cover data\nin SSBAs play a crucial role in demonstrating a viable source-specific attack,\nwhich has not been considered by existing SSBAs. With this insight, we focus on\ntrigger transparency and content when crafting triggers for poisoned dataset\nwhere a sample has an attacker-targeted label and cover dataset where a sample\nhas a ground-truth label. Specifically, we implement $CASSOCK_{Trans}$ and\n$CASSOCK_{Cont}$. While both they are orthogonal, they are complementary to\neach other, generating a more powerful attack, called $CASSOCK_{Comp}$, with\nfurther improved attack performance and stealthiness. We perform a\ncomprehensive evaluation of the three $CASSOCK$-based attacks on four popular\ndatasets and three SOTA defenses. Compared with a representative SSBA as a\nbaseline ($SSBA_{Base}$), $CASSOCK$-based attacks have significantly advanced\nthe attack performance, i.e., higher ASR and lower FPR with comparable CDA\n(clean data accuracy). Besides, $CASSOCK$-based attacks have effectively\nbypassed the SOTA defenses, and $SSBA_{Base}$ cannot.\n","authors":["Shang Wang","Yansong Gao","Anmin Fu","Zhi Zhang","Yuqing Zhang","Willy Susilo","Dongxi Liu"],"pdf_url":"https://arxiv.org/pdf/2206.00145v2.pdf","comment":"13 pages,14 figures"},{"id":"http://arxiv.org/abs/2201.01689v3","updated":"2022-12-18T16:14:56Z","published":"2022-01-05T16:33:14Z","title":"Asymptotics of $\\ell_2$ Regularized Network Embeddings","summary":"  A common approach to solving prediction tasks on large networks, such as node\nclassification or link prediction, begin by learning a Euclidean embedding of\nthe nodes of the network, from which traditional machine learning methods can\nthen be applied. This includes methods such as DeepWalk and node2vec, which\nlearn embeddings by optimizing stochastic losses formed over subsamples of the\ngraph at each iteration of stochastic gradient descent. In this paper, we study\nthe effects of adding an $\\ell_2$ penalty of the embedding vectors to the\ntraining loss of these types of methods. We prove that, under some\nexchangeability assumptions on the graph, this asymptotically leads to learning\na graphon with a nuclear-norm-type penalty, and give guarantees for the\nasymptotic distribution of the learned embedding vectors. In particular, the\nexact form of the penalty depends on the choice of subsampling method used as\npart of stochastic gradient descent. We also illustrate empirically that\nconcatenating node covariates to $\\ell_2$ regularized node2vec embeddings leads\nto comparable, when not superior, performance to methods which incorporate node\ncovariates and the network structure in a non-linear manner.\n","authors":["Andrew Davison"],"pdf_url":"https://arxiv.org/pdf/2201.01689v3.pdf","comment":"Accepted in Neural Information Processing Systems 2022. 44 pages, 2\n  figures, 2 tables"},{"id":"http://arxiv.org/abs/2212.09108v1","updated":"2022-12-18T15:28:16Z","published":"2022-12-18T15:28:16Z","title":"A Permutation-Free Kernel Independence Test","summary":"  In nonparametric independence testing, we observe i.i.d.\\ data\n$\\{(X_i,Y_i)\\}_{i=1}^n$, where $X \\in \\mathcal{X}, Y \\in \\mathcal{Y}$ lie in\nany general spaces, and we wish to test the null that $X$ is independent of\n$Y$. Modern test statistics such as the kernel Hilbert-Schmidt Independence\nCriterion (HSIC) and Distance Covariance (dCov) have intractable null\ndistributions due to the degeneracy of the underlying U-statistics. Thus, in\npractice, one often resorts to using permutation testing, which provides a\nnonasymptotic guarantee at the expense of recalculating the quadratic-time\nstatistics (say) a few hundred times. This paper provides a simple but\nnontrivial modification of HSIC and dCov (called xHSIC and xdCov, pronounced\n``cross'' HSIC/dCov) so that they have a limiting Gaussian distribution under\nthe null, and thus do not require permutations. This requires building on the\nnewly developed theory of cross U-statistics by Kim and Ramdas (2020), and in\nparticular developing several nontrivial extensions of the theory in Shekhar et\nal. (2022), which developed an analogous permutation-free kernel two-sample\ntest. We show that our new tests, like the originals, are consistent against\nfixed alternatives, and minimax rate optimal against smooth local alternatives.\nNumerical simulations demonstrate that compared to the full dCov or HSIC, our\nvariants have the same power up to a $\\sqrt 2$ factor, giving practitioners a\nnew option for large problems or data-analysis pipelines where computation, not\nsample size, could be the bottleneck.\n","authors":["Shubhanshu Shekhar","Ilmun Kim","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2212.09108v1.pdf","comment":"52 pages, 4 figures"},{"id":"http://arxiv.org/abs/2212.09102v1","updated":"2022-12-18T15:04:31Z","published":"2022-12-18T15:04:31Z","title":"Face Generation and Editing with StyleGAN: A Survey","summary":"  Our goal with this survey is to provide an overview of the state of the art\ndeep learning technologies for face generation and editing. We will cover\npopular latest architectures and discuss key ideas that make them work, such as\ninversion, latent representation, loss functions, training procedures, editing\nmethods, and cross domain style transfer. We particularly focus on GAN-based\narchitectures that have culminated in the StyleGAN approaches, which allow\ngeneration of high-quality face images and offer rich interfaces for\ncontrollable semantics editing and preserving photo quality. We aim to provide\nan entry point into the field for readers that have basic knowledge about the\nfield of deep learning and are looking for an accessible introduction and\noverview.\n","authors":["Andrew Melnik","Maksim Miasayedzenkau","Dzianis Makarovets","Dzianis Pirshtuk","Eren Akbulut","Dennis Holzmann","Tarek Renusch","Gustav Reichert","Helge Ritter"],"pdf_url":"https://arxiv.org/pdf/2212.09102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09100v1","updated":"2022-12-18T14:56:22Z","published":"2022-12-18T14:56:22Z","title":"SPARF: Large-Scale Learning of 3D Sparse Radiance Fields from Few Input\n  Images","summary":"  Recent advances in Neural Radiance Fields (NeRFs) treat the problem of novel\nview synthesis as Sparse Radiance Field (SRF) optimization using sparse voxels\nfor efficient and fast rendering (plenoxels,InstantNGP). In order to leverage\nmachine learning and adoption of SRFs as a 3D representation, we present SPARF,\na large-scale ShapeNet-based synthetic dataset for novel view synthesis\nconsisting of $\\sim$ 17 million images rendered from nearly 40,000 shapes at\nhigh resolution (400 X 400 pixels). The dataset is orders of magnitude larger\nthan existing synthetic datasets for novel view synthesis and includes more\nthan one million 3D-optimized radiance fields with multiple voxel resolutions.\nFurthermore, we propose a novel pipeline (SuRFNet) that learns to generate\nsparse voxel radiance fields from only few views. This is done by using the\ndensely collected SPARF dataset and 3D sparse convolutions. SuRFNet employs\npartial SRFs from few/one images and a specialized SRF loss to learn to\ngenerate high-quality sparse voxel radiance fields that can be rendered from\nnovel views. Our approach achieves state-of-the-art results in the task of\nunconstrained novel view synthesis based on few views on ShapeNet as compared\nto recent baselines. The SPARF dataset will be made public with the code and\nmodels on the project website https://abdullahamdi.com/sparf/ .\n","authors":["Abdullah Hamdi","Bernard Ghanem","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2212.09100v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.09083v1","updated":"2022-12-18T13:27:01Z","published":"2022-12-18T13:27:01Z","title":"Influence-Based Mini-Batching for Graph Neural Networks","summary":"  Using graph neural networks for large graphs is challenging since there is no\nclear way of constructing mini-batches. To solve this, previous methods have\nrelied on sampling or graph clustering. While these approaches often lead to\ngood training convergence, they introduce significant overhead due to expensive\nrandom data accesses and perform poorly during inference. In this work we\ninstead focus on model behavior during inference. We theoretically model batch\nconstruction via maximizing the influence score of nodes on the outputs. This\nformulation leads to optimal approximation of the output when we do not have\nknowledge of the trained model. We call the resulting method influence-based\nmini-batching (IBMB). IBMB accelerates inference by up to 130x compared to\nprevious methods that reach similar accuracy. Remarkably, with adaptive\noptimization and the right training schedule IBMB can also substantially\naccelerate training, thanks to precomputed batches and consecutive memory\naccesses. This results in up to 18x faster training per epoch and up to 17x\nfaster convergence per runtime compared to previous methods.\n","authors":["Johannes Gasteiger","Chendi Qian","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2212.09083v1.pdf","comment":"Published as a proceedings paper at LoG 2022"},{"id":"http://arxiv.org/abs/2212.09082v1","updated":"2022-12-18T13:13:44Z","published":"2022-12-18T13:13:44Z","title":"On the Connection between Invariant Learning and Adversarial Training\n  for Out-of-Distribution Generalization","summary":"  Despite impressive success in many tasks, deep learning models are shown to\nrely on spurious features, which will catastrophically fail when generalized to\nout-of-distribution (OOD) data. Invariant Risk Minimization (IRM) is proposed\nto alleviate this issue by extracting domain-invariant features for OOD\ngeneralization. Nevertheless, recent work shows that IRM is only effective for\na certain type of distribution shift (e.g., correlation shift) while it fails\nfor other cases (e.g., diversity shift). Meanwhile, another thread of method,\nAdversarial Training (AT), has shown better domain transfer performance,\nsuggesting that it has the potential to be an effective candidate for\nextracting domain-invariant features. This paper investigates this possibility\nby exploring the similarity between the IRM and AT objectives. Inspired by this\nconnection, we propose Domainwise Adversarial Training (DAT), an AT-inspired\nmethod for alleviating distribution shift by domain-specific perturbations.\nExtensive experiments show that our proposed DAT can effectively remove\ndomain-varying features and improve OOD generalization under both correlation\nshift and diversity shift.\n","authors":["Shiji Xin","Yifei Wang","Jingtong Su","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09082v1.pdf","comment":"To appear in AAAI-23"},{"id":"http://arxiv.org/abs/2212.09081v1","updated":"2022-12-18T13:08:45Z","published":"2022-12-18T13:08:45Z","title":"Riemannian Optimization for Variance Estimation in Linear Mixed Models","summary":"  Variance parameter estimation in linear mixed models is a challenge for many\nclassical nonlinear optimization algorithms due to the positive-definiteness\nconstraint of the random effects covariance matrix. We take a completely novel\nview on parameter estimation in linear mixed models by exploiting the intrinsic\ngeometry of the parameter space. We formulate the problem of residual maximum\nlikelihood estimation as an optimization problem on a Riemannian manifold.\nBased on the introduced formulation, we give geometric higher-order information\non the problem via the Riemannian gradient and the Riemannian Hessian. Based on\nthat, we test our approach with Riemannian optimization algorithms numerically.\nOur approach yields a higher quality of the variance parameter estimates\ncompared to existing approaches.\n","authors":["Lena Sembach","Jan Pablo Burgard","Volker H. Schulz"],"pdf_url":"https://arxiv.org/pdf/2212.09081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01126v2","updated":"2022-12-18T12:57:06Z","published":"2022-10-03T12:57:45Z","title":"Wheel Impact Test by Deep Learning: Prediction of Location and Magnitude\n  of Maximum Stress","summary":"  For ensuring vehicle safety, the impact performance of wheels during wheel\ndevelopment must be ensured through a wheel impact test. However, manufacturing\nand testing a real wheel requires a significant time and money because\ndeveloping an optimal wheel design requires numerous iterative processes to\nmodify the wheel design and verify the safety performance. Accordingly, wheel\nimpact tests have been replaced by computer simulations such as finite element\nanalysis (FEA); however, it still incurs high computational costs for modeling\nand analysis, and requires FEA experts. In this study, we present an aluminum\nroad wheel impact performance prediction model based on deep learning that\nreplaces computationally expensive and time-consuming 3D FEA. For this purpose,\n2D disk-view wheel image data, 3D wheel voxel data, and barrier mass values\nused for the wheel impact test were utilized as the inputs to predict the\nmagnitude of the maximum von Mises stress, corresponding location, and the\nstress distribution of the 2D disk-view. The input data were first compressed\ninto a latent space with a 3D convolutional variational autoencoder (cVAE) and\n2D convolutional autoencoder (cAE). Subsequently, the fully connected layers\nwere used to predict the impact performance, and a decoder was used to predict\nthe stress distribution heatmap of the 2D disk-view. The proposed model can\nreplace the impact test in the early wheel-development stage by predicting the\nimpact performance in real-time and can be used without domain knowledge. The\ntime required for the wheel development process can be reduced by using this\nmechanism.\n","authors":["Seungyeon Shin","Ah-hyeon Jin","Soyoung Yoo","Sunghee Lee","ChangGon Kim","Sungpil Heo","Namwoo Kang"],"pdf_url":"https://arxiv.org/pdf/2210.01126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09080v1","updated":"2022-12-18T12:54:45Z","published":"2022-12-18T12:54:45Z","title":"Synthesis and Evaluation of a Domain-specific Large Data Set for\n  Dungeons & Dragons","summary":"  This paper introduces the Forgotten Realms Wiki (FRW) data set and domain\nspecific natural language generation using FRW along with related analyses.\nForgotten Realms is the de-facto default setting of the popular open ended\ntabletop fantasy role playing game, Dungeons & Dragons. The data set was\nextracted from the Forgotten Realms Fandom wiki consisting of more than over\n45,200 articles. The FRW data set is constituted of 11 sub-data sets in a\nnumber of formats: raw plain text, plain text annotated by article title,\ndirected link graphs, wiki info-boxes annotated by the wiki article title,\nPoincar\\'e embedding of first link graph, multiple Word2Vec and Doc2Vec models\nof the corpus. This is the first data set of this size for the Dungeons &\nDragons domain. We then present a pairwise similarity comparison benchmark\nwhich utilizes similarity measures. In addition, we perform D&D domain specific\nnatural language generation using the corpus and evaluate the named entity\nclassification with respect to the lore of Forgotten Realms.\n","authors":["Akila Peiris","Nisansa de Silva"],"pdf_url":"https://arxiv.org/pdf/2212.09080v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.04437v2","updated":"2022-12-18T12:13:02Z","published":"2022-01-12T12:25:02Z","title":"Multi-task Joint Strategies of Self-supervised Representation Learning\n  on Biomedical Networks for Drug Discovery","summary":"  Self-supervised representation learning (SSL) on biomedical networks provides\nnew opportunities for drug discovery. However, how to effectively combine\nmultiple SSL models is still challenging and has been rarely explored.\nTherefore, we propose multi-task joint strategies of self-supervised\nrepresentation learning on biomedical networks for drug discovery, named\nMSSL2drug. We design six basic SSL tasks inspired by various modality features\nincluding structures, semantics, and attributes in heterogeneous biomedical\nnetworks. Importantly, fifteen combinations of multiple tasks are evaluated by\na graph attention-based multi-task adversarial learning framework in two drug\ndiscovery scenarios. The results suggest two important findings. (1)\nCombinations of multimodal tasks achieve the best performance compared to other\nmulti-task joint models. (2) The local-global combination models yield higher\nperformance than random two-task combinations when there are the same size of\nmodalities. Therefore, we conjecture that the multimodal and local-global\ncombination strategies can be treated as the guideline of multi-task SSL for\ndrug discovery.\n","authors":["Xiaoqi Wang","Yingjie Cheng","Yaning Yang","Yue Yu","Fei Li","Shaoliang Peng"],"pdf_url":"https://arxiv.org/pdf/2201.04437v2.pdf","comment":"44 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.09071v1","updated":"2022-12-18T12:00:12Z","published":"2022-12-18T12:00:12Z","title":"Disentangling Learnable and Memorizable Data via Contrastive Learning\n  for Semantic Communications","summary":"  Achieving artificially intelligent-native wireless networks is necessary for\nthe operation of future 6G applications such as the metaverse. Nonetheless,\ncurrent communication schemes are, at heart, a mere reconstruction process that\nlacks reasoning. One key solution that enables evolving wireless communication\nto a human-like conversation is semantic communications. In this paper, a novel\nmachine reasoning framework is proposed to pre-process and disentangle source\ndata so as to make it semantic-ready. In particular, a novel contrastive\nlearning framework is proposed, whereby instance and cluster discrimination are\nperformed on the data. These two tasks enable increasing the cohesiveness\nbetween data points mapping to semantically similar content elements and\ndisentangling data points of semantically different content elements.\nSubsequently, the semantic deep clusters formed are ranked according to their\nlevel of confidence. Deep semantic clusters of highest confidence are\nconsidered learnable, semantic-rich data, i.e., data that can be used to build\na language in a semantic communications system. The least confident ones are\nconsidered, random, semantic-poor, and memorizable data that must be\ntransmitted classically. Our simulation results showcase the superiority of our\ncontrastive learning approach in terms of semantic impact and minimalism. In\nfact, the length of the semantic representation achieved is minimized by 57.22%\ncompared to vanilla semantic communication systems, thus achieving minimalist\nsemantic representations.\n","authors":["Christina Chaccour","Walid Saad"],"pdf_url":"https://arxiv.org/pdf/2212.09071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09067v1","updated":"2022-12-18T11:30:59Z","published":"2022-12-18T11:30:59Z","title":"Fine-Tuning Is All You Need to Mitigate Backdoor Attacks","summary":"  Backdoor attacks represent one of the major threats to machine learning\nmodels. Various efforts have been made to mitigate backdoors. However, existing\ndefenses have become increasingly complex and often require high computational\nresources or may also jeopardize models' utility. In this work, we show that\nfine-tuning, one of the most common and easy-to-adopt machine learning training\noperations, can effectively remove backdoors from machine learning models while\nmaintaining high model utility. Extensive experiments over three machine\nlearning paradigms show that fine-tuning and our newly proposed\nsuper-fine-tuning achieve strong defense performance. Furthermore, we coin a\nnew term, namely backdoor sequela, to measure the changes in model\nvulnerabilities to other attacks before and after the backdoor has been\nremoved. Empirical evaluation shows that, compared to other defense methods,\nsuper-fine-tuning leaves limited backdoor sequela. We hope our results can help\nmachine learning model owners better protect their models from backdoor\nthreats. Also, it calls for the design of more advanced attacks in order to\ncomprehensively assess machine learning models' backdoor vulnerabilities.\n","authors":["Zeyang Sha","Xinlei He","Pascal Berrang","Mathias Humbert","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.09067v1.pdf","comment":"17 pages, 17 figures"},{"id":"http://arxiv.org/abs/2212.09062v1","updated":"2022-12-18T11:02:50Z","published":"2022-12-18T11:02:50Z","title":"Bort: Towards Explainable Neural Networks with Bounded Orthogonal\n  Constraint","summary":"  Deep learning has revolutionized human society, yet the black-box nature of\ndeep neural networks hinders further application to reliability-demanded\nindustries. In the attempt to unpack them, many works observe or impact\ninternal variables to improve the model's comprehensibility and transparency.\nHowever, existing methods rely on intuitive assumptions and lack mathematical\nguarantees. To bridge this gap, we introduce Bort, an optimizer for improving\nmodel explainability with boundedness and orthogonality constraints on model\nparameters, derived from the sufficient conditions of model comprehensibility\nand transparency. We perform reconstruction and backtracking on the model\nrepresentations optimized by Bort and observe an evident improvement in model\nexplainability. Based on Bort, we are able to synthesize explainable\nadversarial samples without additional parameters and training. Surprisingly,\nwe find Bort constantly improves the classification accuracy of various\narchitectures including ResNet and DeiT on MNIST, CIFAR-10, and ImageNet.\n","authors":["Borui Zhang","Wenzhao Zheng","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2212.09062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.01693v2","updated":"2022-12-18T10:51:57Z","published":"2022-09-04T21:03:14Z","title":"Variational Inference for Model-Free and Model-Based Reinforcement\n  Learning","summary":"  Variational inference (VI) is a specific type of approximate Bayesian\ninference that approximates an intractable posterior distribution with a\ntractable one. VI casts the inference problem as an optimization problem, more\nspecifically, the goal is to maximize a lower bound of the logarithm of the\nmarginal likelihood with respect to the parameters of the approximate\nposterior. Reinforcement learning (RL) on the other hand deals with autonomous\nagents and how to make them act optimally such as to maximize some notion of\nexpected future cumulative reward. In the non-sequential setting where agents'\nactions do not have an impact on future states of the environment, RL is\ncovered by contextual bandits and Bayesian optimization. In a proper sequential\nscenario, however, where agents' actions affect future states, instantaneous\nrewards need to be carefully traded off against potential long-term rewards.\nThis manuscript shows how the apparently different subjects of VI and RL are\nlinked in two fundamental ways. First, the optimization objective of RL to\nmaximize future cumulative rewards can be recovered via a VI objective under a\nsoft policy constraint in both the non-sequential and the sequential setting.\nThis policy constraint is not just merely artificial but has proven as a useful\nregularizer in many RL tasks yielding significant improvements in agent\nperformance. And second, in model-based RL where agents aim to learn about the\nenvironment they are operating in, the model-learning part can be naturally\nphrased as an inference problem over the process that governs environment\ndynamics. We are going to distinguish between two scenarios for the latter: VI\nwhen environment states are fully observable by the agent and VI when they are\nonly partially observable through an observation distribution.\n","authors":["Felix Leibfried"],"pdf_url":"https://arxiv.org/pdf/2209.01693v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2012.13962"},{"id":"http://arxiv.org/abs/2212.09058v1","updated":"2022-12-18T10:41:55Z","published":"2022-12-18T10:41:55Z","title":"BEATs: Audio Pre-Training with Acoustic Tokenizers","summary":"  The massive growth of self-supervised learning (SSL) has been witnessed in\nlanguage, vision, speech, and audio domains over the past few years. While\ndiscrete label prediction is widely adopted for other modalities, the\nstate-of-the-art audio SSL models still employ reconstruction loss for\npre-training. Compared with reconstruction loss, semantic-rich discrete label\nprediction encourages the SSL model to abstract the high-level audio semantics\nand discard the redundant details as in human perception. However, a\nsemantic-rich acoustic tokenizer for general audio pre-training is usually not\nstraightforward to obtain, due to the continuous property of audio and\nunavailable phoneme sequences like speech. To tackle this challenge, we propose\nBEATs, an iterative audio pre-training framework to learn Bidirectional Encoder\nrepresentation from Audio Transformers, where an acoustic tokenizer and an\naudio SSL model are optimized by iterations. In the first iteration, we use\nrandom projection as the acoustic tokenizer to train an audio SSL model in a\nmask and label prediction manner. Then, we train an acoustic tokenizer for the\nnext iteration by distilling the semantic knowledge from the pre-trained or\nfine-tuned audio SSL model. The iteration is repeated with the hope of mutual\npromotion of the acoustic tokenizer and audio SSL model. The experimental\nresults demonstrate our acoustic tokenizers can generate discrete labels with\nrich audio semantics and our audio SSL models achieve state-of-the-art results\nacross various audio classification benchmarks, even outperforming previous\nmodels that use more training data and model parameters significantly.\nSpecifically, we set a new state-of-the-art mAP 50.6% on AudioSet-2M for\naudio-only models without using any external data, and 98.1% accuracy on\nESC-50. The code and pre-trained models are available at https://aka.ms/beats.\n","authors":["Sanyuan Chen","Yu Wu","Chengyi Wang","Shujie Liu","Daniel Tompkins","Zhuo Chen","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.09058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05853v2","updated":"2022-12-18T10:38:35Z","published":"2022-12-12T12:31:46Z","title":"DeepCut: Unsupervised Segmentation using Graph Neural Networks\n  Clustering","summary":"  Image segmentation is a fundamental task in computer vision. Data annotation\nfor training supervised methods can be labor-intensive, motivating unsupervised\nmethods. Some existing approaches extract deep features from pre-trained\nnetworks and build a graph to apply classical clustering methods (e.g.,\n$k$-means and normalized-cuts) as a post-processing stage. These techniques\nreduce the high-dimensional information encoded in the features to pair-wise\nscalar affinities. In this work, we replace classical clustering algorithms\nwith a lightweight Graph Neural Network (GNN) trained to achieve the same\nclustering objective function. However, in contrast to existing approaches, we\nfeed the GNN not only the pair-wise affinities between local image features but\nalso the raw features themselves. Maintaining this connection between the raw\nfeature and the clustering goal allows to perform part semantic segmentation\nimplicitly, without requiring additional post-processing steps. We demonstrate\nhow classical clustering objectives can be formulated as self-supervised loss\nfunctions for training our image segmentation GNN. Additionally, we use the\nCorrelation-Clustering (CC) objective to perform clustering without defining\nthe number of clusters ($k$-less clustering). We apply the proposed method for\nobject localization, segmentation, and semantic part segmentation tasks,\nsurpassing state-of-the-art performance on multiple benchmarks.\n","authors":["Amit Aflalo","Shai Bagon","Tamar Kashti","Yonina Eldar"],"pdf_url":"https://arxiv.org/pdf/2212.05853v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11822v2","updated":"2022-12-18T10:08:48Z","published":"2022-11-21T19:44:00Z","title":"CONFIG: Constrained Efficient Global Optimization for Closed-Loop\n  Control System Optimization with Unmodeled Constraints","summary":"  In this paper, the CONFIG algorithm, a simple and provably efficient\nconstrained global optimization algorithm, is applied to optimize the\nclosed-loop control performance of an unknown system with unmodeled\nconstraints. Existing Gaussian process based closed-loop optimization methods,\neither can only guarantee local convergence (e.g., SafeOPT), or have no known\noptimality guarantee (e.g., constrained expected improvement) at all, whereas\nthe recently introduced CONFIG algorithm has been proven to enjoy a theoretical\nglobal optimality guarantee. In this study, we demonstrate the effectiveness of\nCONFIG algorithm in the applications. The algorithm is first applied to an\nartificial numerical benchmark problem to corroborate its effectiveness. It is\nthen applied to a classical constrained steady-state optimization problem of a\ncontinuous stirred-tank reactor. Simulation results show that our CONFIG\nalgorithm can achieve performance competitive with the popular CEI (Constrained\nExpected Improvement) algorithm, which has no known optimality guarantee. As\nsuch, the CONFIG algorithm offers a new tool, with both a provable global\noptimality guarantee and competitive empirical performance, to optimize the\nclosed-loop control performance for a system with soft unmodeled constraints.\nLast, but not least, the open-source code is available as a python package to\nfacilitate future applications.\n","authors":["Wenjie Xu","Yuning Jiang","Bratislav Svetozarevic","Colin N. Jones"],"pdf_url":"https://arxiv.org/pdf/2211.11822v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13817v3","updated":"2022-12-18T09:50:58Z","published":"2022-05-27T08:07:39Z","title":"Iso-Dream: Isolating and Leveraging Noncontrollable Visual Dynamics in\n  World Models","summary":"  World models learn the consequences of actions in vision-based interactive\nsystems. However, in practical scenarios such as autonomous driving, there\ncommonly exists noncontrollable dynamics independent of the action signals,\nmaking it difficult to learn effective world models. To tackle this problem, we\npresent a novel reinforcement learning approach named Iso-Dream, which improves\nthe Dream-to-Control framework in two aspects. First, by optimizing the inverse\ndynamics, we encourage the world model to learn controllable and\nnoncontrollable sources of spatiotemporal changes on isolated state transition\nbranches. Second, we optimize the behavior of the agent on the decoupled latent\nimaginations of the world model. Specifically, to estimate state values, we\nroll-out the noncontrollable states into the future and associate them with the\ncurrent controllable state. In this way, the isolation of dynamics sources can\ngreatly benefit long-horizon decision-making of the agent, such as a\nself-driving car that can avoid potential risks by anticipating the movement of\nother vehicles. Experiments show that Iso-Dream is effective in decoupling the\nmixed dynamics and remarkably outperforms existing approaches in a wide range\nof visual control and prediction domains.\n","authors":["Minting Pan","Xiangming Zhu","Yunbo Wang","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2205.13817v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06757v2","updated":"2022-12-18T09:34:55Z","published":"2022-12-13T17:39:18Z","title":"Gradient flow in the gaussian covariate model: exact solution of\n  learning curves and multiple descent structures","summary":"  A recent line of work has shown remarkable behaviors of the generalization\nerror curves in simple learning models. Even the least-squares regression has\nshown atypical features such as the model-wise double descent, and further\nworks have observed triple or multiple descents. Another important\ncharacteristic are the epoch-wise descent structures which emerge during\ntraining. The observations of model-wise and epoch-wise descents have been\nanalytically derived in limited theoretical settings (such as the random\nfeature model) and are otherwise experimental. In this work, we provide a full\nand unified analysis of the whole time-evolution of the generalization curve,\nin the asymptotic large-dimensional regime and under gradient-flow, within a\nwider theoretical setting stemming from a gaussian covariate model. In\nparticular, we cover most cases already disparately observed in the literature,\nand also provide examples of the existence of multiple descent structures as a\nfunction of a model parameter or time. Furthermore, we show that our\ntheoretical predictions adequately match the learning curves obtained by\ngradient descent over realistic datasets. Technically we compute averages of\nrational expressions involving random matrices using recent developments in\nrandom matrix theory based on \"linear pencils\". Another contribution, which is\nalso of independent interest in random matrix theory, is a new derivation of\nrelated fixed point equations (and an extension there-off) using Dyson brownian\nmotions.\n","authors":["Antoine Bodin","Nicolas Macris"],"pdf_url":"https://arxiv.org/pdf/2212.06757v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00613v3","updated":"2022-12-18T09:32:03Z","published":"2022-09-01T17:27:25Z","title":"ID and OOD Performance Are Sometimes Inversely Correlated on Real-world\n  Datasets","summary":"  Several studies have empirically compared in-distribution (ID) and\nout-of-distribution (OOD) performance of various models. They report frequent\npositive correlations on benchmarks in computer vision and NLP. Surprisingly,\nthey never observe inverse correlations suggesting necessary trade-offs. This\nmatters to determine whether ID performance can serve as a proxy for OOD\ngeneralization. This paper shows that inverse correlations between ID and OOD\nperformance do happen in real-world benchmarks. They could be missed in past\nstudies because of a biased selection of models. We show an example on the\nWILDS-Camelyon17 dataset, using models from multiple training epochs and random\nseeds. Our observations are particularly striking with models trained with a\nregularizer that diversifies the solutions to the ERM objective. We nuance\nrecommendations and conclusions made in past studies. (1) High OOD performance\nmay sometimes require trading off ID performance.(2) Focusing on ID performance\nalone may not lead to optimal OOD performance: it can lead to diminishing and\neventually negative returns in OOD performance. (3) Our example reminds that\nempirical studies only chart regimes achievable with existing methods: care is\nwarranted in deriving prescriptive recommendations.\n","authors":["Damien Teney","Yong Lin","Seong Joon Oh","Ehsan Abbasnejad"],"pdf_url":"https://arxiv.org/pdf/2209.00613v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09044v1","updated":"2022-12-18T09:31:36Z","published":"2022-12-18T09:31:36Z","title":"Text2Struct: A Machine Learning Pipeline for Mining Structured Data from\n  Text","summary":"  Many analysis and prediction tasks require the extraction of structured data\nfrom unstructured texts. To solve it, this paper presents an end-to-end machine\nlearning pipeline, Text2Struct, including a text annotation scheme, training\ndata processing, and machine learning implementation. We formulated the mining\nproblems as the extraction of metrics and units associated with numerals in the\ntext. Text2Struct was evaluated on an annotated text dataset collected from\nabstracts of medical publications regarding thrombectomy. In terms of\nprediction performance, a dice coefficient of 0.82 was achieved on the test\ndataset. By random sampling, most predicted relations between numerals and\nentities were well matched to the ground-truth annotations. These results\nshowed that the Text2Struct is viable for the mining of structured data from\ntext without special templates or patterns. It is anticipated to further\nimprove the pipeline by expanding the dataset and investigating other machine\nlearning models. A code demonstration can be found at:\nhttps://github.com/zcc861007/CourseProject\n","authors":["Chaochao Zhou","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2212.09044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09040v1","updated":"2022-12-18T08:34:11Z","published":"2022-12-18T08:34:11Z","title":"The Underlying Correlated Dynamics in Neural Training","summary":"  Training of neural networks is a computationally intensive task. The\nsignificance of understanding and modeling the training dynamics is growing as\nincreasingly larger networks are being trained. We propose in this work a model\nbased on the correlation of the parameters' dynamics, which dramatically\nreduces the dimensionality. We refer to our algorithm as \\emph{correlation mode\ndecomposition} (CMD). It splits the parameter space into groups of parameters\n(modes) which behave in a highly correlated manner through the epochs.\n  We achieve a remarkable dimensionality reduction with this approach, where\nnetworks like ResNet-18, transformers and GANs, containing millions of\nparameters, can be modeled well using just a few modes. We observe each typical\ntime profile of a mode is spread throughout the network in all layers.\nMoreover, our model induces regularization which yields better generalization\ncapacity on the test set. This representation enhances the understanding of the\nunderlying training dynamics and can pave the way for designing better\nacceleration techniques.\n","authors":["Rotem Turjeman","Tom Berkov","Ido Cohen","Guy Gilboa"],"pdf_url":"https://arxiv.org/pdf/2212.09040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08010v3","updated":"2022-12-18T08:27:37Z","published":"2022-06-16T09:06:25Z","title":"MoDi: Unconditional Motion Synthesis from Diverse Data","summary":"  The emergence of neural networks has revolutionized the field of motion\nsynthesis. Yet, learning to unconditionally synthesize motions from a given\ndistribution remains challenging, especially when the motions are highly\ndiverse. In this work, we present MoDi -- a generative model trained in an\nunsupervised setting from an extremely diverse, unstructured and unlabeled\ndataset. During inference, MoDi can synthesize high-quality, diverse motions.\nDespite the lack of any structure in the dataset, our model yields a\nwell-behaved and highly structured latent space, which can be semantically\nclustered, constituting a strong motion prior that facilitates various\napplications including semantic editing and crowd simulation. In addition, we\npresent an encoder that inverts real motions into MoDi's natural motion\nmanifold, issuing solutions to various ill-posed challenges such as completion\nfrom prefix and spatial editing. Our qualitative and quantitative experiments\nachieve state-of-the-art results that outperform recent SOTA techniques. Code\nand trained models are available at https://sigal-raab.github.io/MoDi.\n","authors":["Sigal Raab","Inbal Leibovitch","Peizhuo Li","Kfir Aberman","Olga Sorkine-Hornung","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2206.08010v3.pdf","comment":"Video: https://youtu.be/O1sVzwrsNUg, Project page:\n  https://sigal-raab.github.io/MoDi, Code: https://github.com/sigal-raab/MoDi"},{"id":"http://arxiv.org/abs/2212.09035v1","updated":"2022-12-18T08:19:08Z","published":"2022-12-18T08:19:08Z","title":"Minimizing Maximum Model Discrepancy for Transferable Black-box Targeted\n  Attacks","summary":"  In this work, we study the black-box targeted attack problem from the model\ndiscrepancy perspective. On the theoretical side, we present a generalization\nerror bound for black-box targeted attacks, which gives a rigorous theoretical\nanalysis for guaranteeing the success of the attack. We reveal that the attack\nerror on a target model mainly depends on empirical attack error on the\nsubstitute model and the maximum model discrepancy among substitute models. On\nthe algorithmic side, we derive a new algorithm for black-box targeted attacks\nbased on our theoretical analysis, in which we additionally minimize the\nmaximum model discrepancy(M3D) of the substitute models when training the\ngenerator to generate adversarial examples. In this way, our model is capable\nof crafting highly transferable adversarial examples that are robust to the\nmodel variation, thus improving the success rate for attacking the black-box\nmodel. We conduct extensive experiments on the ImageNet dataset with different\nclassification models, and our proposed approach outperforms existing\nstate-of-the-art methods by a significant margin. Our codes will be released.\n","authors":["Anqi Zhao","Tong Chu","Yahao Liu","Wen Li","Jingjing Li","Lixin Duan"],"pdf_url":"https://arxiv.org/pdf/2212.09035v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09034v1","updated":"2022-12-18T08:17:32Z","published":"2022-12-18T08:17:32Z","title":"Graph Neural Networks are Inherently Good Generalizers: Insights by\n  Bridging GNNs and MLPs","summary":"  Graph neural networks (GNNs), as the de-facto model class for representation\nlearning on graphs, are built upon the multi-layer perceptrons (MLP)\narchitecture with additional message passing layers to allow features to flow\nacross nodes. While conventional wisdom largely attributes the success of GNNs\nto their advanced expressivity for learning desired functions on nodes'\nego-graphs, we conjecture that this is \\emph{not} the main cause of GNNs'\nsuperiority in node prediction tasks. This paper pinpoints the major source of\nGNNs' performance gain to their intrinsic generalization capabilities, by\nintroducing an intermediate model class dubbed as P(ropagational)MLP, which is\nidentical to standard MLP in training, and then adopt GNN's architecture in\ntesting. Intriguingly, we observe that PMLPs consistently perform on par with\n(or even exceed) their GNN counterparts across ten benchmarks and different\nexperimental settings, despite the fact that PMLPs share the same (trained)\nweights with poorly-performed MLP. This critical finding opens a door to a\nbrand new perspective for understanding the power of GNNs, and allow bridging\nGNNs and MLPs for dissecting their generalization behaviors. As an initial step\nto analyze PMLP, we show its essential difference with MLP at infinite-width\nlimit lies in the NTK feature map in the post-training stage. Moreover, though\nMLP and PMLP cannot extrapolate non-linear functions for extreme OOD data, PMLP\nhas more freedom to generalize near the training support.\n","authors":["Chenxiao Yang","Qitian Wu","Jiahua Wang","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2212.09034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09032v1","updated":"2022-12-18T07:49:17Z","published":"2022-12-18T07:49:17Z","title":"AutoSlicer: Scalable Automated Data Slicing for ML Model Analysis","summary":"  Automated slicing aims to identify subsets of evaluation data where a trained\nmodel performs anomalously. This is an important problem for machine learning\npipelines in production since it plays a key role in model debugging and\ncomparison, as well as the diagnosis of fairness issues. Scalability has become\na critical requirement for any automated slicing system due to the large search\nspace of possible slices and the growing scale of data. We present Autoslicer,\na scalable system that searches for problematic slices through distributed\nmetric computation and hypothesis testing. We develop an efficient strategy\nthat reduces the search space through pruning and prioritization. In the\nexperiments, we show that our search strategy finds most of the anomalous\nslices by inspecting a small portion of the search space.\n","authors":["Zifan Liu","Evan Rosen","Paul Suganthan G. C"],"pdf_url":"https://arxiv.org/pdf/2212.09032v1.pdf","comment":"11 pages, 5 figures, NeurIPS 2022 Workshop on Challenges in Deploying\n  and Monitoring Machine Learning Systems"},{"id":"http://arxiv.org/abs/2212.09030v1","updated":"2022-12-18T07:42:48Z","published":"2022-12-18T07:42:48Z","title":"Contextually Enhanced ES-dRNN with Dynamic Attention for Short-Term Load\n  Forecasting","summary":"  In this paper, we propose a new short-term load forecasting (STLF) model\nbased on contextually enhanced hybrid and hierarchical architecture combining\nexponential smoothing (ES) and a recurrent neural network (RNN). The model is\ncomposed of two simultaneously trained tracks: the context track and the main\ntrack. The context track introduces additional information to the main track.\nIt is extracted from representative series and dynamically modulated to adjust\nto the individual series forecasted by the main track. The RNN architecture\nconsists of multiple recurrent layers stacked with hierarchical dilations and\nequipped with recently proposed attentive dilated recurrent cells. These cells\nenable the model to capture short-term, long-term and seasonal dependencies\nacross time series as well as to weight dynamically the input information. The\nmodel produces both point forecasts and predictive intervals. The experimental\npart of the work performed on 35 forecasting problems shows that the proposed\nmodel outperforms in terms of accuracy its predecessor as well as standard\nstatistical models and state-of-the-art machine learning models.\n","authors":["Slawek Smyl","Grzegorz Dudek","Paweł Pełka"],"pdf_url":"https://arxiv.org/pdf/2212.09030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09027v1","updated":"2022-12-18T07:36:32Z","published":"2022-12-18T07:36:32Z","title":"2D Pose Estimation based Child Action Recognition","summary":"  We present a graph convolutional network with 2D pose estimation for the\nfirst time on child action recognition task achieving on par results with an\nRGB modality based model on a novel benchmark dataset containing unconstrained\nenvironment based videos.\n","authors":["Sanka Mohottala","Sandun Abeygunawardana","Pradeepa Samarasinghe","Dharshana Kasthurirathna","Charith Abhayaratne"],"pdf_url":"https://arxiv.org/pdf/2212.09027v1.pdf","comment":"Paper Accepted for the IEEE TENCON Conference (2022). 7 pages, 5\n  figures"},{"id":"http://arxiv.org/abs/2212.09018v1","updated":"2022-12-18T05:32:19Z","published":"2022-12-18T05:32:19Z","title":"MeSH Suggester: A Library and System for MeSH Term Suggestion for\n  Systematic Review Boolean Query Construction","summary":"  Boolean query construction is often critical for medical systematic review\nliterature search. To create an effective Boolean query, systematic review\nresearchers typically spend weeks coming up with effective query terms and\ncombinations. One challenge to creating an effective systematic review Boolean\nquery is the selection of effective MeSH Terms to include in the query. In our\nprevious work, we created neural MeSH term suggestion methods and compared them\nto state-of-the-art MeSH term suggestion methods. We found neural MeSH term\nsuggestion methods to be highly effective.\n  In this demonstration, we build upon our previous work by creating (1) a\nWeb-based MeSH term suggestion prototype system that allows users to obtain\nsuggestions from a number of underlying methods and (2) a Python library that\nimplements ours and others' MeSH term suggestion methods and that is aimed at\nresearchers who want to further investigate, create or deploy such type of\nmethods. We describe the architecture of the web-based system and how to use it\nfor the MeSH term suggestion task. For the Python library, we describe how the\nlibrary can be used for advancing further research and experimentation, and we\nvalidate the results of the methods contained in the library on standard\ndatasets. Our web-based prototype system is available at\nhttp://ielab-mesh-suggest.uqcloud.net, while our Python library is at\nhttps://github.com/ielab/meshsuggestlib.\n","authors":["Shuai Wang","Hang Li","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2212.09018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09017v1","updated":"2022-12-18T05:26:40Z","published":"2022-12-18T05:26:40Z","title":"Neural Rankers for Effective Screening Prioritisation in Medical\n  Systematic Review Literature Search","summary":"  Medical systematic reviews typically require assessing all the documents\nretrieved by a search. The reason is two-fold: the task aims for ``total\nrecall''; and documents retrieved using Boolean search are an unordered set,\nand thus it is unclear how an assessor could examine only a subset. Screening\nprioritisation is the process of ranking the (unordered) set of retrieved\ndocuments, allowing assessors to begin the downstream processes of the\nsystematic review creation earlier, leading to earlier completion of the\nreview, or even avoiding screening documents ranked least relevant.\n  Screening prioritisation requires highly effective ranking methods.\nPre-trained language models are state-of-the-art on many IR tasks but have yet\nto be applied to systematic review screening prioritisation. In this paper, we\napply several pre-trained language models to the systematic review document\nranking task, both directly and fine-tuned. An empirical analysis compares how\neffective neural methods compare to traditional methods for this task. We also\ninvestigate different types of document representations for neural methods and\ntheir impact on ranking performance.\n  Our results show that BERT-based rankers outperform the current\nstate-of-the-art screening prioritisation methods. However, BERT rankers and\nexisting methods can actually be complementary, and thus, further improvements\nmay be achieved if used in conjunction.\n","authors":["Shuai Wang","Harrisen Scells","Bevan Koopman","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2212.09017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09015v1","updated":"2022-12-18T05:11:04Z","published":"2022-12-18T05:11:04Z","title":"GAN-based Tabular Data Generator for Constructing Synopsis in\n  Approximate Query Processing: Challenges and Solutions","summary":"  In data-driven systems, data exploration is imperative for making real-time\ndecisions. However, big data is stored in massive databases that are difficult\nto retrieve. Approximate Query Processing (AQP) is a technique for providing\napproximate answers to aggregate queries based on a summary of the data\n(synopsis) that closely replicates the behavior of the actual data, which can\nbe useful where an approximate answer to the queries would be acceptable in a\nfraction of the real execution time. In this paper, we discuss the use of\nGenerative Adversarial Networks (GANs) for generating tabular data that can be\nemployed in AQP for synopsis construction. We first discuss the challenges\nassociated with constructing synopses in relational databases and then\nintroduce solutions to those challenges. Following that, we organized\nstatistical metrics to evaluate the quality of the generated synopses. We\nconclude that tabular data complexity makes it difficult for algorithms to\nunderstand relational database semantics during training, and improved versions\nof tabular GANs are capable of constructing synopses to revolutionize\ndata-driven decision-making systems.\n","authors":["Mohammadali Fallahian","Mohsen Dorodchi","Kyle Kreth"],"pdf_url":"https://arxiv.org/pdf/2212.09015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09013v1","updated":"2022-12-18T05:07:11Z","published":"2022-12-18T05:07:11Z","title":"Graph Neural Network based Child Activity Recognition","summary":"  This paper presents an implementation on child activity recognition (CAR)\nwith a graph convolution network (GCN) based deep learning model since prior\nimplementations in this domain have been dominated by CNN, LSTM and other\nmethods despite the superior performance of GCN. To the best of our knowledge,\nwe are the first to use a GCN model in child activity recognition domain. In\novercoming the challenges of having small size publicly available child action\ndatasets, several learning methods such as feature extraction, fine-tuning and\ncurriculum learning were implemented to improve the model performance. Inspired\nby the contradicting claims made on the use of transfer learning in CAR, we\nconducted a detailed implementation and analysis on transfer learning together\nwith a study on negative transfer learning effect on CAR as it hasn't been\naddressed previously. As the principal contribution, we were able to develop a\nST-GCN based CAR model which, despite the small size of the dataset, obtained\naround 50% accuracy on vanilla implementations. With feature extraction and\nfine-tuning methods, accuracy was improved by 20%-30% with the highest accuracy\nbeing 82.24%. Furthermore, the results provided on activity datasets\nempirically demonstrate that with careful selection of pre-train model datasets\nthrough methods such as curriculum learning could enhance the accuracy levels.\nFinally, we provide preliminary evidence on possible frame rate effect on the\naccuracy of CAR models, a direction future research can explore.\n","authors":["Sanka Mohottala","Pradeepa Samarasinghe","Dharshana Kasthurirathna","Charith Abhayaratne"],"pdf_url":"https://arxiv.org/pdf/2212.09013v1.pdf","comment":"Accepted to 23rd IEEE ICIT Conference (2022), 8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2212.09010v1","updated":"2022-12-18T04:44:38Z","published":"2022-12-18T04:44:38Z","title":"Risk-Sensitive Reinforcement Learning with Exponential Criteria","summary":"  While risk-neutral reinforcement learning has shown experimental success in a\nnumber of applications, it is well-known to be non-robust with respect to noise\nand perturbations in the parameters of the system. For this reason,\nrisk-sensitive reinforcement learning algorithms have been studied to introduce\nrobustness and sample efficiency, and lead to better real-life performance. In\nthis work, we introduce new model-free risk-sensitive reinforcement learning\nalgorithms as variations of widely-used Policy Gradient algorithms with similar\nimplementation properties. In particular, we study the effect of exponential\ncriteria on the risk-sensitivity of the policy of a reinforcement learning\nagent, and develop variants of the Monte Carlo Policy Gradient algorithm and\nthe online (temporal-difference) Actor-Critic algorithm. Analytical results\nshowcase that the use of exponential criteria generalize commonly used ad-hoc\nregularization approaches. The implementation, performance, and robustness\nproperties of the proposed methods are evaluated in simulated experiments.\n","authors":["Erfaun Noorani","Christos Mavridis","John Baras"],"pdf_url":"https://arxiv.org/pdf/2212.09010v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09008v1","updated":"2022-12-18T04:31:45Z","published":"2022-12-18T04:31:45Z","title":"Hidden State Approximation in Recurrent Neural Networks Using Continuous\n  Particle Filtering","summary":"  Using historical data to predict future events has many applications in the\nreal world, such as stock price prediction; the robot localization. In the past\ndecades, the Convolutional long short-term memory (LSTM) networks have achieved\nextraordinary success with sequential data in the related field. However,\ntraditional recurrent neural networks (RNNs) keep the hidden states in a\ndeterministic way. In this paper, we use the particles to approximate the\ndistribution of the latent state and show how it can extend into a more complex\nform, i.e., the Encoder-Decoder mechanism. With the proposed continuous\ndifferentiable scheme, our model is capable of adaptively extracting valuable\ninformation and updating the latent state according to the Bayes rule. Our\nempirical studies demonstrate the effectiveness of our method in the prediction\ntasks.\n","authors":["Dexun Li"],"pdf_url":"https://arxiv.org/pdf/2212.09008v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09006v1","updated":"2022-12-18T04:21:35Z","published":"2022-12-18T04:21:35Z","title":"A Review of Speech-centric Trustworthy Machine Learning: Privacy,\n  Safety, and Fairness","summary":"  Speech-centric machine learning systems have revolutionized many leading\ndomains ranging from transportation and healthcare to education and defense,\nprofoundly changing how people live, work, and interact with each other.\nHowever, recent studies have demonstrated that many speech-centric ML systems\nmay need to be considered more trustworthy for broader deployment.\nSpecifically, concerns over privacy breaches, discriminating performance, and\nvulnerability to adversarial attacks have all been discovered in ML research\nfields. In order to address the above challenges and risks, a significant\nnumber of efforts have been made to ensure these ML systems are trustworthy,\nespecially private, safe, and fair. In this paper, we conduct the first\ncomprehensive survey on speech-centric trustworthy ML topics related to\nprivacy, safety, and fairness. In addition to serving as a summary report for\nthe research community, we point out several promising future research\ndirections to inspire the researchers who wish to explore further in this area.\n","authors":["Tiantian Feng","Rajat Hebbar","Nicholas Mehlman","Xuan Shi","Aditya Kommineni","and Shrikanth Narayanan"],"pdf_url":"https://arxiv.org/pdf/2212.09006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.12232v4","updated":"2022-12-18T04:21:08Z","published":"2022-02-24T17:54:15Z","title":"Bounding Membership Inference","summary":"  Differential Privacy (DP) is the de facto standard for reasoning about the\nprivacy guarantees of a training algorithm. Despite the empirical observation\nthat DP reduces the vulnerability of models to existing membership inference\n(MI) attacks, a theoretical underpinning as to why this is the case is largely\nmissing in the literature. In practice, this means that models need to be\ntrained with DP guarantees that greatly decrease their accuracy.\n  In this paper, we provide a tighter bound on the positive accuracy (i.e.,\nattack precision) of any MI adversary when a training algorithm provides\n$(\\varepsilon, \\delta)$-DP. Our bound informs the design of a novel privacy\namplification scheme: an effective training set is sub-sampled from a larger\nset prior to the beginning of training. We find this greatly reduces the bound\non MI positive accuracy. As a result, our scheme allows the use of looser DP\nguarantees to limit the success of any MI adversary; this ensures that the\nmodel's accuracy is less impacted by the privacy guarantee. While this clearly\nbenefits entities working with far more data than they need to train on, it can\nalso improve the accuracy-privacy trade-off on benchmarks studied in the\nacademic literature. Consequently, we also find that subsampling decreases the\neffectiveness of a state-of-the-art MI attack (LiRA) much more effectively than\ntraining with stronger DP guarantees on MNIST and CIFAR10. We conclude by\ndiscussing implications of our MI bound on the field of machine unlearning.\n","authors":["Anvith Thudi","Ilia Shumailov","Franziska Boenisch","Nicolas Papernot"],"pdf_url":"https://arxiv.org/pdf/2202.12232v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01529v2","updated":"2022-12-18T04:14:25Z","published":"2022-12-03T04:08:56Z","title":"Laplacian Convolutional Representation for Traffic Time Series\n  Imputation","summary":"  Spatiotemporal traffic data imputation is of great significance in\nintelligent transportation systems and data-driven decision-making processes.\nTo make an accurate reconstruction from partially observed traffic data, we\nassert the importance of characterizing both global and local trends in traffic\ntime series. In the literature, substantial prior works have demonstrated the\neffectiveness of utilizing low-rankness property of traffic data by\nmatrix/tensor completion models. In this study, we first introduce a Laplacian\nkernel to temporal regularization for characterizing local trends in traffic\ntime series, which can be formulated in the form of circular convolution. Then,\nwe develop a low-rank Laplacian convolutional representation (LCR) model by\nputting the nuclear norm of a circulant matrix and the Laplacian temporal\nregularization together, which is proved to meet a unified framework that takes\na fast Fourier transform (FFT) solution in a relatively low time complexity.\nThrough extensive experiments on some traffic datasets, we demonstrate the\nsuperiority of LCR for imputing traffic time series of various time series\nbehaviors (e.g., data noises and strong/weak periodicity). The proposed LCR\nmodel is an efficient and effective solution to large-scale traffic data\nimputation over the existing baseline models. Despite the LCR's application to\ntime series data, the key modeling idea lies in bridging the low-rank models\nand the Laplacian regularization through FFT, which is also applicable to image\ninpainting. The adapted datasets and Python implementation are publicly\navailable at https://github.com/xinychen/transdim.\n","authors":["Xinyu Chen","Zhanhong Cheng","Nicolas Saunier","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.01529v2.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2109.04228v3","updated":"2022-12-18T04:06:37Z","published":"2021-09-09T12:44:06Z","title":"Coordinate Descent Methods for DC Minimization: Optimality Conditions\n  and Global Convergence","summary":"  Difference-of-Convex (DC) minimization, referring to the problem of\nminimizing the difference of two convex functions, has been found rich\napplications in statistical learning and studied extensively for decades.\nHowever, existing methods are primarily based on multi-stage convex relaxation,\nonly leading to weak optimality of critical points. This paper proposes a\ncoordinate descent method for minimizing a class of DC functions based on\nsequential nonconvex approximation. Our approach iteratively solves a nonconvex\none-dimensional subproblem globally, and it is guaranteed to converge to a\ncoordinate-wise stationary point. We prove that this new optimality condition\nis always stronger than the standard critical point condition and directional\npoint condition under a mild \\textit{locally bounded nonconvexity assumption}.\nFor comparisons, we also include a naive variant of coordinate descent methods\nbased on sequential convex approximation in our study. When the objective\nfunction satisfies a \\textit{globally bounded nonconvexity assumption} and\n\\textit{Luo-Tseng error bound assumption}, coordinate descent methods achieve\n\\textit{Q-linear} convergence rate. Also, for many applications of interest, we\nshow that the nonconvex one-dimensional subproblem can be computed exactly and\nefficiently using a breakpoint searching method. Finally, we have conducted\nextensive experiments on several statistical learning tasks to show the\nsuperiority of our approach.\n  Keywords: Coordinate Descent, DC Minimization, DC Programming,\nDifference-of-Convex Programs, Nonconvex Optimization, Sparse Optimization,\nBinary Optimization.\n","authors":["Ganzhao Yuan"],"pdf_url":"https://arxiv.org/pdf/2109.04228v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09000v1","updated":"2022-12-18T03:57:12Z","published":"2022-12-18T03:57:12Z","title":"Confidence-aware Training of Smoothed Classifiers for Certified\n  Robustness","summary":"  Any classifier can be \"smoothed out\" under Gaussian noise to build a new\nclassifier that is provably robust to $\\ell_2$-adversarial perturbations, viz.,\nby averaging its predictions over the noise via randomized smoothing. Under the\nsmoothed classifiers, the fundamental trade-off between accuracy and\n(adversarial) robustness has been well evidenced in the literature: i.e.,\nincreasing the robustness of a classifier for an input can be at the expense of\ndecreased accuracy for some other inputs. In this paper, we propose a simple\ntraining method leveraging this trade-off to obtain robust smoothed\nclassifiers, in particular, through a sample-wise control of robustness over\nthe training samples. We make this control feasible by using \"accuracy under\nGaussian noise\" as an easy-to-compute proxy of adversarial robustness for an\ninput. Specifically, we differentiate the training objective depending on this\nproxy to filter out samples that are unlikely to benefit from the worst-case\n(adversarial) objective. Our experiments show that the proposed method, despite\nits simplicity, consistently exhibits improved certified robustness upon\nstate-of-the-art training methods. Somewhat surprisingly, we find these\nimprovements persist even for other notions of robustness, e.g., to various\ntypes of common corruptions.\n","authors":["Jongheon Jeong","Seojin Kim","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2212.09000v1.pdf","comment":"21 pages; Code is available at\n  https://github.com/alinlab/smoothing-catrs; AAAI 2023"},{"id":"http://arxiv.org/abs/2212.08997v1","updated":"2022-12-18T03:28:51Z","published":"2022-12-18T03:28:51Z","title":"Multi-Instance Partial-Label Learning: Towards Exploiting Dual Inexact\n  Supervision","summary":"  Weakly supervised machine learning algorithms are able to learn from\nambiguous samples or labels, e.g., multi-instance learning or partial-label\nlearning. However, in some real-world tasks, each training sample is associated\nwith not only multiple instances but also a candidate label set that contains\none ground-truth label and some false positive labels. Specifically, at least\none instance pertains to the ground-truth label while no instance belongs to\nthe false positive labels. In this paper, we formalize such problems as\nmulti-instance partial-label learning (MIPL). Existing multi-instance learning\nalgorithms and partial-label learning algorithms are suboptimal for solving\nMIPL problems since the former fail to disambiguate a candidate label set, and\nthe latter cannot handle a multi-instance bag. To address these issues, a\ntailored algorithm named MIPLGP, i.e., Multi-Instance Partial-Label learning\nwith Gaussian Processes, is proposed. MIPLGP first assigns each instance with a\ncandidate label set in an augmented label space, then transforms the candidate\nlabel set into a logarithmic space to yield the disambiguated and continuous\nlabels via an exclusive disambiguation strategy, and last induces a model based\non the Gaussian processes. Experimental results on various datasets validate\nthat MIPLGP is superior to well-established multi-instance learning and\npartial-label learning algorithms for solving MIPL problems. Our code and\ndatasets will be made publicly available.\n","authors":["Wei Tang","Weijia Zhang","Min-Ling Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.08997v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2212.09090v1","updated":"2022-12-18T14:01:35Z","published":"2022-12-18T14:01:35Z","title":"Exploring Workplace Behaviors through Speaking Patterns using\n  Large-scale Multimodal Wearable Recordings: A Study of Healthcare Providers","summary":"  Interpersonal spoken communication is central to human interaction and the\nexchange of information. Such interactive processes involve not only speech and\nspoken language but also non-verbal cues such as hand gestures, facial\nexpressions, and nonverbal vocalization, that are used to express feelings and\nprovide feedback. These multimodal communication signals carry a variety of\ninformation about the people: traits like gender and age as well as about\nphysical and psychological states and behavior. This work uses wearable\nmultimodal sensors to investigate interpersonal communication behaviors\nfocusing on speaking patterns among healthcare providers with a focus on\nnurses. We analyze longitudinal data collected from $99$ nurses in a large\nhospital setting over ten weeks. The results indicate that speaking pattern\ndifferences across shift schedules and working units. Moreover, results show\nthat speaking patterns combined with physiological measures can be used to\npredict affect measures and life satisfaction scores. The implementation of\nthis work can be accessed at https://github.com/usc-sail/tiles-audio-arousal.\n","authors":["Tiantian Feng","Shrikanth Narayanan"],"pdf_url":"https://arxiv.org/pdf/2212.09090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14169v2","updated":"2022-12-18T08:55:25Z","published":"2022-09-28T15:22:11Z","title":"CALIP: Zero-Shot Enhancement of CLIP with Parameter-free Attention","summary":"  Contrastive Language-Image Pre-training (CLIP) has been shown to learn visual\nrepresentations with great transferability, which achieves promising accuracy\nfor zero-shot classification. To further improve its downstream performance,\nexisting works propose additional learnable modules upon CLIP and fine-tune\nthem by few-shot training sets. However, the resulting extra training cost and\ndata requirement severely hinder the efficiency for model deployment and\nknowledge transfer. In this paper, we introduce a free-lunch enhancement\nmethod, CALIP, to boost CLIP's zero-shot performance via a parameter-free\nAttention module. Specifically, we guide visual and textual representations to\ninteract with each other and explore cross-modal informative features via\nattention. As the pre-training has largely reduced the embedding distances\nbetween two modalities, we discard all learnable parameters in the attention\nand bidirectionally update the multi-modal features, enabling the whole process\nto be parameter-free and training-free. In this way, the images are blended\nwith textual-aware signals and the text representations become visual-guided\nfor better adaptive zero-shot alignment. We evaluate CALIP on various\nbenchmarks of 14 datasets for both 2D image and 3D point cloud few-shot\nclassification, showing consistent zero-shot performance improvement over CLIP.\nBased on that, we further insert a small number of linear layers in CALIP's\nattention module and verify our robustness under the few-shot settings, which\nalso achieves leading performance compared to existing methods. Those extensive\nexperiments demonstrate the superiority of our approach for efficient\nenhancement of CLIP.\n","authors":["Ziyu Guo","Renrui Zhang","Longtian Qiu","Xianzheng Ma","Xupeng Miao","Xuming He","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2209.14169v2.pdf","comment":"Accepted by AAAI 2023, 12 pages, 6 figures"}]},"2022-12-17T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2212.08950v1","updated":"2022-12-17T20:45:59Z","published":"2022-12-17T20:45:59Z","title":"Beyond the C: Retargetable Decompilation using Neural Machine\n  Translation","summary":"  The problem of reversing the compilation process, decompilation, is an\nimportant tool in reverse engineering of computer software. Recently,\nresearchers have proposed using techniques from neural machine translation to\nautomate the process in decompilation. Although such techniques hold the\npromise of targeting a wider range of source and assembly languages, to date\nthey have primarily targeted C code. In this paper we argue that existing\nneural decompilers have achieved higher accuracy at the cost of requiring\nlanguage-specific domain knowledge such as tokenizers and parsers to build an\nabstract syntax tree (AST) for the source language, which increases the\noverhead of supporting new languages. We explore a different tradeoff that, to\nthe extent possible, treats the assembly and source languages as plain text,\nand show that this allows us to build a decompiler that is easily retargetable\nto new languages. We evaluate our prototype decompiler, Beyond The C (BTC), on\nGo, Fortran, OCaml, and C, and examine the impact of parameters such as\ntokenization and training data selection on the quality of decompilation,\nfinding that it achieves comparable decompilation results to prior work in\nneural decompilation with significantly less domain knowledge. We will release\nour training data, trained decompilation models, and code to help encourage\nfuture research into language-agnostic decompilation.\n","authors":["Iman Hosseini","Brendan Dolan-Gavitt"],"pdf_url":"https://arxiv.org/pdf/2212.08950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08946v1","updated":"2022-12-17T20:36:17Z","published":"2022-12-17T20:36:17Z","title":"Towards leveraging latent knowledge and Dialogue context for real-world\n  conversational question answering","summary":"  In many real-world scenarios, the absence of external knowledge source like\nWikipedia restricts question answering systems to rely on latent internal\nknowledge in limited dialogue data. In addition, humans often seek answers by\nasking several questions for more comprehensive information. As the dialog\nbecomes more extensive, machines are challenged to refer to previous\nconversation rounds to answer questions. In this work, we propose to leverage\nlatent knowledge in existing conversation logs via a neural Retrieval-Reading\nsystem, enhanced with a TFIDF-based text summarizer refining lengthy\nconversational history to alleviate the long context issue. Our experiments\nshow that our Retrieval-Reading system can exploit retrieved background\nknowledge to generate significantly better answers. The results also indicate\nthat our context summarizer significantly helps both the retriever and the\nreader by introducing more concise and less noisy contextual information.\n","authors":["Shaomu Tan","Denis Paperno"],"pdf_url":"https://arxiv.org/pdf/2212.08946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08929v1","updated":"2022-12-17T18:45:23Z","published":"2022-12-17T18:45:23Z","title":"Joint Information Extraction with Cross-Task and Cross-Instance\n  High-Order Modeling","summary":"  Prior works on Information Extraction (IE) typically predict different tasks\nand instances (e.g., event triggers, entities, roles, relations) independently,\nwhile neglecting their interactions and leading to model inefficiency. In this\nwork, we introduce a joint IE framework, HighIE, that learns and predicts\nmultiple IE tasks by integrating high-order cross-task and cross-instance\ndependencies. Specifically, we design two categories of high-order factors:\nhomogeneous factors and heterogeneous factors. Then, these factors are utilized\nto jointly predict labels of all instances. To address the intractability\nproblem of exact high-order inference, we incorporate a high-order neural\ndecoder that is unfolded from a mean-field variational inference method. The\nexperimental results show that our approach achieves consistent improvements on\nthree IE tasks compared with our baseline and prior work.\n","authors":["Zixia Jia","Zhaohui Yan","Wenjuan Han","Zilong Zheng","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2212.08929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08926v1","updated":"2022-12-17T18:22:20Z","published":"2022-12-17T18:22:20Z","title":"A Simple Baseline for Beam Search Reranking","summary":"  Reranking methods in machine translation aim to close the gap between common\nevaluation metrics (e.g. BLEU) and maximum likelihood learning and decoding\nalgorithms. Prior works address this challenge by training models to rerank\nbeam search candidates according to their predicted BLEU scores, building upon\nlarge models pretrained on massive monolingual corpora -- a privilege that was\nnever made available to the baseline translation model. In this work, we\nexamine a simple approach for training rerankers to predict translation\ncandidates' BLEU scores without introducing additional data or parameters. Our\napproach can be used as a clean baseline, decoupled from external factors, for\nfuture research in this area.\n","authors":["Lior Vassertail","Omer Levy"],"pdf_url":"https://arxiv.org/pdf/2212.08926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04899v3","updated":"2022-12-17T18:12:32Z","published":"2022-09-11T16:28:25Z","title":"Instruction-driven history-aware policies for robotic manipulations","summary":"  In human environments, robots are expected to accomplish a variety of\nmanipulation tasks given simple natural language instructions. Yet, robotic\nmanipulation is extremely challenging as it requires fine-grained motor\ncontrol, long-term memory as well as generalization to previously unseen tasks\nand environments. To address these challenges, we propose a unified\ntransformer-based approach that takes into account multiple inputs. In\nparticular, our transformer architecture integrates (i) natural language\ninstructions and (ii) multi-view scene observations while (iii) keeping track\nof the full history of observations and actions. Such an approach enables\nlearning dependencies between history and instructions and improves\nmanipulation precision using multiple views. We evaluate our method on the\nchallenging RLBench benchmark and on a real-world robot. Notably, our approach\nscales to 74 diverse RLBench tasks and outperforms the state of the art. We\nalso address instruction-conditioned tasks and demonstrate excellent\ngeneralization to previously unseen variations.\n","authors":["Pierre-Louis Guhur","Shizhe Chen","Ricardo Garcia","Makarand Tapaswi","Ivan Laptev","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2209.04899v3.pdf","comment":"Accepted in CoRL 2022 (oral); project page at\n  https://guhur.github.io/hiveformer/"},{"id":"http://arxiv.org/abs/2212.08913v1","updated":"2022-12-17T16:30:27Z","published":"2022-12-17T16:30:27Z","title":"Claim Optimization in Computational Argumentation","summary":"  An optimal delivery of arguments is key to persuasion in any debate, both for\nhumans and for AI systems. This requires the use of clear and fluent claims\nrelevant to the given debate. Prior work has studied the automatic assessment\nof argument quality extensively. Yet, no approach actually improves the quality\nso far. Our work is the first step towards filling this gap. We propose the\ntask of claim optimization: to rewrite argumentative claims to optimize their\ndelivery. As an initial approach, we first generate a candidate set of\noptimized claims using a sequence-to-sequence model, such as BART, while taking\ninto account contextual information. Our key idea is then to rerank generated\ncandidates with respect to different quality metrics to find the best\noptimization. In automatic and human evaluation, we outperform different\nreranking baselines on an English corpus, improving 60% of all claims\n(worsening 16% only). Follow-up analyses reveal that, beyond copy editing, our\napproach often specifies claims with details, whereas it adds less evidence\nthan humans do. Moreover, its capabilities generalize well to other domains,\nsuch as instructional texts.\n","authors":["Gabriella Skitalinskaya","Maximilian Spliethöver","Henning Wachsmuth"],"pdf_url":"https://arxiv.org/pdf/2212.08913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08911v1","updated":"2022-12-17T16:14:30Z","published":"2022-12-17T16:14:30Z","title":"AdaTranS: Adapting with Boundary-based Shrinking for End-to-End Speech\n  Translation","summary":"  To alleviate the data scarcity problem in End-to-end speech translation (ST),\npre-training on data for speech recognition and machine translation is\nconsidered as an important technique. However, the modality gap between speech\nand text prevents the ST model from efficiently inheriting knowledge from the\npre-trained models. In this work, we propose AdaTranS for end-to-end ST. It\nadapts the speech features with a new shrinking mechanism to mitigate the\nlength mismatch between speech and text features by predicting word boundaries.\nExperiments on the MUST-C dataset demonstrate that AdaTranS achieves better\nperformance than the other shrinking-based methods, with higher inference speed\nand lower memory usage. Further experiments also show that AdaTranS can be\nequipped with additional alignment losses to further improve performance.\n","authors":["Xingshan Zeng","Liangyou Li","Qun Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08911v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08909v1","updated":"2022-12-17T16:05:50Z","published":"2022-12-17T16:05:50Z","title":"Controlling Styles in Neural Machine Translation with Activation Prompt","summary":"  Neural machine translation(NMT) has aroused wide attention due to its\nimpressive quality. Beyond quality, controlling translation styles is also an\nimportant demand for many languages. Previous related studies mainly focus on\ncontrolling formality and gain some improvements. However, they still face two\nchallenges. The first is the evaluation limitation. Style contains abundant\ninformation including lexis, syntax, etc. But only formality is well studied.\nThe second is the heavy reliance on iterative fine-tuning when new styles are\nrequired. Correspondingly, this paper contributes in terms of the benchmark and\napproach. First, we re-visit this task and propose a multiway stylized machine\ntranslation (MSMT) benchmark, which includes multiple categories of styles in\nfour language directions to push the boundary of this task. Second, we propose\na method named style activation prompt (StyleAP) by retrieving prompts from\nstylized monolingual corpus, which needs no extra fine-tuning. Experiments show\nthat StyleAP could effectively control the style of translation and achieve\nremarkable performance. All of our data and code are released at\nhttps://github.com/IvanWang0730/StyleAP.\n","authors":["Yifan Wang","Zewei Sun","Shanbo Cheng","Weiguo Zheng","Mingxuan Wang"],"pdf_url":"https://arxiv.org/pdf/2212.08909v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08902v1","updated":"2022-12-17T15:32:00Z","published":"2022-12-17T15:32:00Z","title":"Know What I don't Know: Handling Ambiguous and Unanswerable Questions\n  for Text-to-SQL","summary":"  The task of text-to-SQL is to convert a natural language question to its\ncorresponding SQL query in the context of relational tables. Existing\ntext-to-SQL parsers generate a \"plausible\" SQL query for an arbitrary user\nquestion, thereby failing to correctly handle problematic user questions. To\nformalize this problem, we conduct a preliminary study on the observed\nambiguous and unanswerable cases in text-to-SQL and summarize them into 6\nfeature categories. Correspondingly, we identify the causes behind each\ncategory and propose requirements for handling ambiguous and unanswerable\nquestions. Following this study, we propose a simple yet effective\ncounterfactual example generation approach for the automatic generation of\nambiguous and unanswerable text-to-SQL examples. Furthermore, we propose a\nweakly supervised model DTE (Detecting-Then-Explaining) for error detection,\nlocalization, and explanation. Experimental results show that our model\nachieves the best result on both real-world examples and generated examples\ncompared with various baselines. We will release data and code for future\nresearch.\n","authors":["Bing Wang","Yan Gao","Zhoujun Li","Jian-Guang Lou"],"pdf_url":"https://arxiv.org/pdf/2212.08902v1.pdf","comment":"DTE"},{"id":"http://arxiv.org/abs/2212.08897v1","updated":"2022-12-17T15:20:18Z","published":"2022-12-17T15:20:18Z","title":"Improving Question Answering Performance through Manual Annotation:\n  Costs, Benefits and Strategies","summary":"  Recently proposed systems for open-domain question answering (OpenQA) require\nlarge amounts of training data to achieve state-of-the-art performance.\nHowever, data annotation is known to be time-consuming and therefore expensive\nto acquire. As a result, the appropriate datasets are available only for a\nhandful of languages (mainly English and Chinese). In this work, we introduce\nand publicly release PolQA, the first Polish dataset for OpenQA. It consists of\n7,000 questions, 87,525 manually labeled evidence passages, and a corpus of\nover 7,097,322 candidate passages. Each question is classified according to its\nformulation, type, as well as entity type of the answer. This resource allows\nus to evaluate the impact of different annotation choices on the performance of\nthe QA system and propose an efficient annotation strategy that increases the\npassage retrieval performance by 10.55 p.p. while reducing the annotation cost\nby 82%.\n","authors":["Piotr Rybak","Piotr Przybyła","Maciej Ogrodniczuk"],"pdf_url":"https://arxiv.org/pdf/2212.08897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08888v1","updated":"2022-12-17T14:57:52Z","published":"2022-12-17T14:57:52Z","title":"Exploiting Rich Textual User-Product Context for Improving Sentiment\n  Analysis","summary":"  User and product information associated with a review is useful for sentiment\npolarity prediction. Typical approaches incorporating such information focus on\nmodeling users and products as implicitly learned representation vectors. Most\ndo not exploit the potential of historical reviews, or those that currently do\nrequire unnecessary modifications to model architecture or do not make full use\nof user/product associations. The contribution of this work is twofold: i) a\nmethod to explicitly employ historical reviews belonging to the same\nuser/product to initialize representations, and ii) efficient incorporation of\ntextual associations between users and products via a user-product\ncross-context module. Experiments on IMDb, Yelp-2013 and Yelp-2014 benchmarks\nshow that our approach substantially outperforms previous state-of-the-art.\nSince we employ BERT-base as the encoder, we additionally provide experiments\nin which our approach performs well with Span-BERT and Longformer. Furthermore,\nexperiments where the reviews of each user/product in the training data are\ndownsampled demonstrate the effectiveness of our approach under a low-resource\nsetting.\n","authors":["Chenyang Lyu","Linyi Yang","Yue Zhang","Yvette Graham","Jennifer Foster"],"pdf_url":"https://arxiv.org/pdf/2212.08888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.03648v2","updated":"2022-12-17T14:43:32Z","published":"2022-11-07T15:59:49Z","title":"Reranking Overgenerated Responses for End-to-End Task-Oriented Dialogue\n  Systems","summary":"  End-to-end (E2E) task-oriented dialogue (ToD) systems are prone to fall into\nthe so-called \"likelihood trap\", resulting in generated responses which are\ndull, repetitive, and often inconsistent with dialogue history. Comparing\nranked lists of multiple generated responses against the \"gold response\" (from\nevaluation data) reveals a wide diversity in response quality, with many good\nresponses placed lower in the ranked list. The main challenge, addressed in\nthis work, is then how to reach beyond greedily generated system responses,\nthat is, how to obtain and select such high-quality responses from the list of\novergenerated responses at inference without availability of the gold response.\nTo this end, we propose a simple yet effective reranking method which aims to\nselect high-quality items from the lists of responses initially overgenerated\nby the system. The idea is to use any sequence-level (similarity) scoring\nfunction to divide the semantic space of responses into high-scoring versus\nlow-scoring partitions. At training, the high-scoring partition comprises all\ngenerated responses whose similarity to the gold response is higher than the\nsimilarity of the greedy response to the gold response. At inference, the aim\nis to estimate the probability that each overgenerated response belongs to the\nhigh-scoring partition, given only previous dialogue history. We validate the\nrobustness and versatility of our proposed method on the standard MultiWOZ\ndataset: our methods improve a state-of-the-art E2E ToD system by 2.0 BLEU, 1.6\nROUGE, and 1.3 METEOR scores, achieving new peak results. Additional\nexperiments on the BiTOD dataset and human evaluation further ascertain the\ngeneralisability and effectiveness of the proposed framework.\n","authors":["Songbo Hu","Ivan Vulić","Fangyu Liu","Anna Korhonen"],"pdf_url":"https://arxiv.org/pdf/2211.03648v2.pdf","comment":"23 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.08864v1","updated":"2022-12-17T13:08:39Z","published":"2022-12-17T13:08:39Z","title":"'If you build they will come': Automatic Identification of\n  News-Stakeholders to detect Party Preference in News Coverage","summary":"  The coverage of different stakeholders mentioned in the news articles\nsignificantly impacts the slant or polarity detection of the concerned news\npublishers. For instance, the pro-government media outlets would give more\ncoverage to the government stakeholders to increase their accessibility to the\nnews audiences. In contrast, the anti-government news agencies would focus more\non the views of the opponent stakeholders to inform the readers about the\nshortcomings of government policies. In this paper, we address the problem of\nstakeholder extraction from news articles and thereby determine the inherent\nbias present in news reporting. Identifying potential stakeholders in\nmulti-topic news scenarios is challenging because each news topic has different\nstakeholders. The research presented in this paper utilizes both contextual\ninformation and external knowledge to identify the topic-specific stakeholders\nfrom news articles. We also apply a sequential incremental clustering algorithm\nto group the entities with similar stakeholder types. We carried out all our\nexperiments on news articles on four Indian government policies published by\nnumerous national and international news agencies. We also further generalize\nour system, and the experimental results show that the proposed model can be\nextended to other news topics.\n","authors":["Alapan Kuila","Sudeshna Sarkar"],"pdf_url":"https://arxiv.org/pdf/2212.08864v1.pdf","comment":"Accepted in AAAI-2023 Workshop, AI for Credible Elections"},{"id":"http://arxiv.org/abs/2212.06468v2","updated":"2022-12-17T12:37:29Z","published":"2022-12-13T10:37:10Z","title":"Lisan: Yemeni, Iraqi, Libyan, and Sudanese Arabic Dialect Copora with\n  Morphological Annotations","summary":"  This article presents morphologically-annotated Yemeni, Sudanese, Iraqi, and\nLibyan Arabic dialects Lisan corpora. Lisan features around 1.2 million tokens.\nWe collected the content of the corpora from several social media platforms.\nThe Yemeni corpus (~ 1.05M tokens) was collected automatically from Twitter.\nThe corpora of the other three dialects (~ 50K tokens each) came manually from\nFacebook and YouTube posts and comments.\n  Thirty five (35) annotators who are native speakers of the target dialects\ncarried out the annotations. The annotators segemented all words in the four\ncorpora into prefixes, stems and suffixes and labeled each with different\nmorphological features such as part of speech, lemma, and a gloss in English.\nAn Arabic Dialect Annotation Toolkit ADAT was developped for the purpose of the\nannation. The annotators were trained on a set of guidelines and on how to use\nADAT. We developed ADAT to assist the annotators and to ensure compatibility\nwith SAMA and Curras tagsets. The tool is open source, and the four corpora are\nalso available online.\n","authors":["Mustafa Jarrar","Fadi A Zaraket","Tymaa Hammouda","Daanish Masood Alavi","Martin Waahlisch"],"pdf_url":"https://arxiv.org/pdf/2212.06468v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.12010v3","updated":"2022-12-17T12:20:08Z","published":"2021-10-22T18:47:34Z","title":"ClimateBert: A Pretrained Language Model for Climate-Related Text","summary":"  Over the recent years, large pretrained language models (LM) have\nrevolutionized the field of natural language processing (NLP). However, while\npretraining on general language has been shown to work very well for common\nlanguage, it has been observed that niche language poses problems. In\nparticular, climate-related texts include specific language that common LMs can\nnot represent accurately. We argue that this shortcoming of today's LMs limits\nthe applicability of modern NLP to the broad field of text processing of\nclimate-related texts. As a remedy, we propose CLIMATEBERT, a transformer-based\nlanguage model that is further pretrained on over 2 million paragraphs of\nclimate-related texts, crawled from various sources such as common news,\nresearch articles, and climate reporting of companies. We find that CLIMATEBERT\nleads to a 48% improvement on a masked language model objective which, in turn,\nleads to lowering error rates by 3.57% to 35.71% for various climate-related\ndownstream tasks like text classification, sentiment analysis, and\nfact-checking.\n","authors":["Nicolas Webersinke","Mathias Kraus","Julia Anna Bingler","Markus Leippold"],"pdf_url":"https://arxiv.org/pdf/2110.12010v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08853v1","updated":"2022-12-17T11:56:21Z","published":"2022-12-17T11:56:21Z","title":"HyPe: Better Pre-trained Language Model Fine-tuning with Hidden\n  Representation Perturbation","summary":"  Language models with the Transformers structure have shown great performance\nin natural language processing. However, there still poses problems when\nfine-tuning pre-trained language models on downstream tasks, such as\nover-fitting or representation collapse. In this work, we propose HyPe, a\nsimple yet effective fine-tuning technique to alleviate such problems by\nperturbing hidden representations of Transformers layers. Unlike previous works\nthat only add noise to inputs or parameters, we argue that the hidden\nrepresentations of Transformers layers convey more diverse and meaningful\nlanguage information. Therefore, making the Transformers layers more robust to\nhidden representation perturbations can further benefit the fine-tuning of PLMs\nen bloc. We conduct extensive experiments and analyses on GLUE and other\nnatural language inference datasets. Results demonstrate that HyPe outperforms\nvanilla fine-tuning and enhances generalization of hidden representations from\ndifferent layers. In addition, HyPe acquires negligible computational\noverheads, and is better than and compatible with previous state-of-the-art\nfine-tuning techniques.\n","authors":["Hongyi Yuan","Zheng Yuan","Chuanqi Tan","Fei Huang","Songfang Huang"],"pdf_url":"https://arxiv.org/pdf/2212.08853v1.pdf","comment":"17 pages; 5 figures"},{"id":"http://arxiv.org/abs/2212.08841v1","updated":"2022-12-17T10:43:25Z","published":"2022-12-17T10:43:25Z","title":"Unsupervised Dense Retrieval Deserves Better Positive Pairs: Scalable\n  Augmentation with Query Extraction and Generation","summary":"  Dense retrievers have made significant strides in obtaining state-of-the-art\nresults on text retrieval and open-domain question answering (ODQA). Yet most\nof these achievements were made possible with the help of large annotated\ndatasets, unsupervised learning for dense retrieval models remains an open\nproblem. In this work, we explore two categories of methods for creating pseudo\nquery-document pairs, named query extraction (QExt) and transferred query\ngeneration (TQGen), to augment the retriever training in an annotation-free and\nscalable manner. Specifically, QExt extracts pseudo queries by document\nstructures or selecting salient random spans, and TQGen utilizes generation\nmodels trained for other NLP tasks (e.g., summarization) to produce pseudo\nqueries. Extensive experiments show that dense retrievers trained with\nindividual augmentation methods can perform comparably well with multiple\nstrong baselines, and combining them leads to further improvements, achieving\nstate-of-the-art performance of unsupervised dense retrieval on both BEIR and\nODQA datasets.\n","authors":["Rui Meng","Ye Liu","Semih Yavuz","Divyansh Agarwal","Lifu Tu","Ning Yu","Jianguo Zhang","Meghana Bhat","Yingbo Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.08841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08822v1","updated":"2022-12-17T08:34:20Z","published":"2022-12-17T08:34:20Z","title":"Better Datastore, Better Translation: Generating Datastores from\n  Pre-Trained Models for Nearest Neural Machine Translation","summary":"  Nearest Neighbor Machine Translation (kNNMT) is a simple and effective method\nof augmenting neural machine translation (NMT) with a token-level nearest\nneighbor retrieval mechanism. The effectiveness of kNNMT directly depends on\nthe quality of retrieved neighbors. However, original kNNMT builds datastores\nbased on representations from NMT models, which would result in poor retrieval\naccuracy when NMT models are not good enough, leading to sub-optimal\ntranslation performance. In this paper, we propose PRED, a framework that\nleverages Pre-trained models for Datastores in kNN-MT. Better representations\nfrom pre-trained models allow us to build datastores of better quality. We also\ndesign a novel contrastive alignment objective to mitigate the representation\ngap between the NMT model and pre-trained models, enabling the NMT model to\nretrieve from better datastores. We conduct extensive experiments on both\nbilingual and multilingual translation benchmarks, including WMT17 English\n$\\leftrightarrow$ Chinese, WMT14 English $\\leftrightarrow$ German, IWSLT14\nGerman $\\leftrightarrow$ English, and IWSLT14 multilingual datasets. Empirical\nresults demonstrate the effectiveness of PRED.\n","authors":["Jiahuan Li","Shanbo Cheng","Zewei Sun","Mingxuan Wang","Shujian Huang"],"pdf_url":"https://arxiv.org/pdf/2212.08822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08802v1","updated":"2022-12-17T05:25:17Z","published":"2022-12-17T05:25:17Z","title":"Relational Sentence Embedding for Flexible Semantic Matching","summary":"  We present Relational Sentence Embedding (RSE), a new paradigm to further\ndiscover the potential of sentence embeddings. Prior work mainly models the\nsimilarity between sentences based on their embedding distance. Because of the\ncomplex semantic meanings conveyed, sentence pairs can have various relation\ntypes, including but not limited to entailment, paraphrasing, and\nquestion-answer. It poses challenges to existing embedding methods to capture\nsuch relational information. We handle the problem by learning associated\nrelational embeddings. Specifically, a relation-wise translation operation is\napplied to the source sentence to infer the corresponding target sentence with\na pre-trained Siamese-based encoder. The fine-grained relational similarity\nscores can be computed from learned embeddings. We benchmark our method on 19\ndatasets covering a wide range of tasks, including semantic textual similarity,\ntransfer, and domain-specific tasks. Experimental results show that our method\nis effective and flexible in modeling sentence relations and outperforms a\nseries of state-of-the-art sentence embedding methods.\nhttps://github.com/BinWang28/RSE\n","authors":["Bin Wang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2212.08802v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2211.10265v2","updated":"2022-12-17T04:12:48Z","published":"2022-11-18T14:44:09Z","title":"Context Variance Evaluation of Pretrained Language Models for\n  Prompt-based Biomedical Knowledge Probing","summary":"  Pretrained language models (PLMs) have motivated research on what kinds of\nknowledge these models learn. Fill-in-the-blanks problem (e.g., cloze tests) is\na natural approach for gauging such knowledge. BioLAMA generates prompts for\nbiomedical factual knowledge triples and uses the Top-k accuracy metric to\nevaluate different PLMs' knowledge. However, existing research has shown that\nsuch prompt-based knowledge probing methods can only probe a lower bound of\nknowledge. Many factors like prompt-based probing biases make the LAMA\nbenchmark unreliable and unstable. This problem is more prominent in BioLAMA.\nThe severe long-tailed distribution in vocabulary and large-N-M relation make\nthe performance gap between LAMA and BioLAMA remain notable. To address these,\nwe introduce context variance into the prompt generation and propose a new\nrank-change-based evaluation metric. Different from the previous known-unknown\nevaluation criteria, we propose the concept of \"Misunderstand\" in LAMA for the\nfirst time. Through experiments on 12 PLMs, our context variance prompts and\nUnderstand-Confuse-Misunderstand (UCM) metric makes BioLAMA more friendly to\nlarge-N-M relations and rare relations. We also conducted a set of control\nexperiments to disentangle \"understand\" from just \"read and copy\".\n","authors":["Zonghai Yao","Yi Cao","Zhichao Yang","Hong Yu"],"pdf_url":"https://arxiv.org/pdf/2211.10265v2.pdf","comment":"Presented at the AMIA 2023 Informatics Summit as an oral paper"},{"id":"http://arxiv.org/abs/2212.08785v1","updated":"2022-12-17T02:53:21Z","published":"2022-12-17T02:53:21Z","title":"Importance of Synthesizing High-quality Data for Text-to-SQL Parsing","summary":"  Recently, there has been increasing interest in synthesizing data to improve\ndownstream text-to-SQL tasks. In this paper, we first examined the existing\nsynthesized datasets and discovered that state-of-the-art text-to-SQL\nalgorithms did not further improve on popular benchmarks when trained with\naugmented synthetic data. We observed two shortcomings: illogical synthetic SQL\nqueries from independent column sampling and arbitrary table joins. To address\nthese issues, we propose a novel synthesis framework that incorporates key\nrelationships from schema, imposes strong typing, and conducts\nschema-distance-weighted column sampling. We also adopt an intermediate\nrepresentation (IR) for the SQL-to-text task to further improve the quality of\nthe generated natural language questions. When existing powerful semantic\nparsers are pre-finetuned on our high-quality synthesized data, our experiments\nshow that these models have significant accuracy boosts on popular benchmarks,\nincluding new state-of-the-art performance on Spider.\n","authors":["Yiyun Zhao","Jiarong Jiang","Yiqun Hu","Wuwei Lan","Henry Zhu","Anuj Chauhan","Alexander Li","Lin Pan","Jun Wang","Chung-Wei Hang","Sheng Zhang","Marvin Dong","Joe Lilien","Patrick Ng","Zhiguo Wang","Vittorio Castelli","Bing Xiang"],"pdf_url":"https://arxiv.org/pdf/2212.08785v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08780v1","updated":"2022-12-17T02:20:14Z","published":"2022-12-17T02:20:14Z","title":"Improving Cross-task Generalization of Unified Table-to-text Models with\n  Compositional Task Configurations","summary":"  There has been great progress in unifying various table-to-text tasks using a\nsingle encoder-decoder model trained via multi-task learning (Xie et al.,\n2022). However, existing methods typically encode task information with a\nsimple dataset name as a prefix to the encoder. This not only limits the\neffectiveness of multi-task learning, but also hinders the model's ability to\ngeneralize to new domains or tasks that were not seen during training, which is\ncrucial for real-world applications. In this paper, we propose compositional\ntask configurations, a set of prompts prepended to the encoder to improve\ncross-task generalization of unified models. We design the task configurations\nto explicitly specify the task type, as well as its input and output types. We\nshow that this not only allows the model to better learn shared knowledge\nacross different tasks at training, but also allows us to control the model by\ncomposing new configurations that apply novel input-output combinations in a\nzero-shot manner. We demonstrate via experiments over ten table-to-text tasks\nthat our method outperforms the UnifiedSKG baseline by noticeable margins in\nboth in-domain and zero-shot settings, with average improvements of +0.5 and\n+12.6 from using a T5-large backbone, respectively.\n","authors":["Jifan Chen","Yuhao Zhang","Lan Liu","Rui Dong","Xinchi Chen","Patrick Ng","William Yang Wang","Zhiheng Huang"],"pdf_url":"https://arxiv.org/pdf/2212.08780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08775v1","updated":"2022-12-17T01:09:22Z","published":"2022-12-17T01:09:22Z","title":"RISE: Leveraging Retrieval Techniques for Summarization Evaluation","summary":"  Evaluating automatically-generated text summaries is a challenging task.\nWhile there have been many interesting approaches, they still fall short of\nhuman evaluations. We present RISE, a new approach for evaluating summaries by\nleveraging techniques from information retrieval. RISE is first trained as a\nretrieval task using a dual-encoder retrieval setup, and can then be\nsubsequently utilized for evaluating a generated summary given an input\ndocument, without gold reference summaries. RISE is especially well suited when\nworking on new datasets where one may not have reference summaries available\nfor evaluation. We conduct comprehensive experiments on the SummEval benchmark\n(Fabbri et al., 2021) and the results show that RISE has higher correlation\nwith human evaluations compared to many past approaches to summarization\nevaluation. Furthermore, RISE also demonstrates data-efficiency and\ngeneralizability across languages.\n","authors":["David Uthus","Jianmo Ni"],"pdf_url":"https://arxiv.org/pdf/2212.08775v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2212.08974v1","updated":"2022-12-17T23:21:04Z","published":"2022-12-17T23:21:04Z","title":"3D Point Cloud Pre-training with Knowledge Distillation from 2D Images","summary":"  The recent success of pre-trained 2D vision models is mostly attributable to\nlearning from large-scale datasets. However, compared with 2D image datasets,\nthe current pre-training data of 3D point cloud is limited. To overcome this\nlimitation, we propose a knowledge distillation method for 3D point cloud\npre-trained models to acquire knowledge directly from the 2D representation\nlearning model, particularly the image encoder of CLIP, through concept\nalignment. Specifically, we introduce a cross-attention mechanism to extract\nconcept features from 3D point cloud and compare them with the semantic\ninformation from 2D images. In this scheme, the point cloud pre-trained models\nlearn directly from rich information contained in 2D teacher models. Extensive\nexperiments demonstrate that the proposed knowledge distillation scheme\nachieves higher accuracy than the state-of-the-art 3D pre-training methods for\nsynthetic and real-world datasets on downstream tasks, including object\nclassification, object detection, semantic segmentation, and part segmentation.\n","authors":["Yuan Yao","Yuanhan Zhang","Zhenfei Yin","Jiebo Luo","Wanli Ouyang","Xiaoshui Huang"],"pdf_url":"https://arxiv.org/pdf/2212.08974v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08969v1","updated":"2022-12-17T22:15:10Z","published":"2022-12-17T22:15:10Z","title":"A Brief Survey on Person Recognition at a Distance","summary":"  Person recognition at a distance entails recognizing the identity of an\nindividual appearing in images or videos collected by long-range imaging\nsystems such as drones or surveillance cameras. Despite recent advances in deep\nconvolutional neural networks (DCNNs), this remains challenging. Images or\nvideos collected by long-range cameras often suffer from atmospheric\nturbulence, blur, low-resolution, unconstrained poses, and poor illumination.\nIn this paper, we provide a brief survey of recent advances in person\nrecognition at a distance. In particular, we review recent work in\nmulti-spectral face verification, person re-identification, and gait-based\nanalysis techniques. Furthermore, we discuss the merits and drawbacks of\nexisting approaches and identify important, yet under explored challenges for\ndeploying remote person recognition systems in-the-wild.\n","authors":["Chrisopher B. Nalty","Neehar Peri","Joshua Gleason","Carlos D. Castillo","Shuowen Hu","Thirimachos Bourlai","Rama Chellappa"],"pdf_url":"https://arxiv.org/pdf/2212.08969v1.pdf","comment":"This work has been accepted to the IEEE Asilomar Conference on\n  Signals, Systems, and Computers (ACSSC) 2022"},{"id":"http://arxiv.org/abs/2110.04447v3","updated":"2022-12-17T21:49:37Z","published":"2021-10-09T03:51:26Z","title":"EfficientPhys: Enabling Simple, Fast and Accurate Camera-Based Vitals\n  Measurement","summary":"  Camera-based physiological measurement is a growing field with neural models\nproviding state-the-art-performance. Prior research have explored various\n\"end-to-end\" models; however these methods still require several preprocessing\nsteps. These additional operations are often non-trivial to implement making\nreplication and deployment difficult and can even have a higher computational\nbudget than the \"core\" network itself. In this paper, we propose two novel and\nefficient neural models for camera-based physiological measurement called\nEfficientPhys that remove the need for face detection, segmentation,\nnormalization, color space transformation or any other preprocessing steps.\nUsing an input of raw video frames, our models achieve strong performance on\nthree public datasets. We show that this is the case whether using a\ntransformer or convolutional backbone. We further evaluate the latency of the\nproposed networks and show that our most light weight network also achieves a\n33% improvement in efficiency.\n","authors":["Xin Liu","Brian L. Hill","Ziheng Jiang","Shwetak Patel","Daniel McDuff"],"pdf_url":"https://arxiv.org/pdf/2110.04447v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04899v3","updated":"2022-12-17T18:12:32Z","published":"2022-09-11T16:28:25Z","title":"Instruction-driven history-aware policies for robotic manipulations","summary":"  In human environments, robots are expected to accomplish a variety of\nmanipulation tasks given simple natural language instructions. Yet, robotic\nmanipulation is extremely challenging as it requires fine-grained motor\ncontrol, long-term memory as well as generalization to previously unseen tasks\nand environments. To address these challenges, we propose a unified\ntransformer-based approach that takes into account multiple inputs. In\nparticular, our transformer architecture integrates (i) natural language\ninstructions and (ii) multi-view scene observations while (iii) keeping track\nof the full history of observations and actions. Such an approach enables\nlearning dependencies between history and instructions and improves\nmanipulation precision using multiple views. We evaluate our method on the\nchallenging RLBench benchmark and on a real-world robot. Notably, our approach\nscales to 74 diverse RLBench tasks and outperforms the state of the art. We\nalso address instruction-conditioned tasks and demonstrate excellent\ngeneralization to previously unseen variations.\n","authors":["Pierre-Louis Guhur","Shizhe Chen","Ricardo Garcia","Makarand Tapaswi","Ivan Laptev","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2209.04899v3.pdf","comment":"Accepted in CoRL 2022 (oral); project page at\n  https://guhur.github.io/hiveformer/"},{"id":"http://arxiv.org/abs/1903.06262v5","updated":"2022-12-17T16:59:49Z","published":"2019-03-08T18:20:36Z","title":"Overlap Removal of Dimensionality Reduction Scatterplot Layouts","summary":"  Dimensionality Reduction (DR) scatterplot layouts have become a ubiquitous\nvisualization tool for analyzing multidimensional datasets. Despite their\npopularity, such scatterplots suffer from occlusion, especially when\ninformative glyphs are used to represent data instances, potentially\nobfuscating critical information for the analysis under execution. Different\nstrategies have been devised to address this issue, either producing\noverlap-free layouts which lack the powerful capabilities of contemporary DR\ntechniques in uncovering interesting data patterns or eliminating overlaps as a\npost-processing strategy. Despite the good results of post-processing\ntechniques, most of the best methods typically expand or distort the\nscatterplot area, thus reducing glyphs' size (sometimes) to unreadable\ndimensions, defeating the purpose of removing overlaps. This paper presents\nDistance Grid (DGrid), a novel post-processing strategy to remove overlaps from\nDR layouts that faithfully preserves the original layout's characteristics and\nbounds the minimum glyph sizes. We show that DGrid surpasses the\nstate-of-the-art in overlap removal (through an extensive comparative\nevaluation considering multiple different metrics) while also being 2 or 3\norders of magnitude faster for large datasets.\n","authors":["Gladys M. Hilasaca","Wilson E. Marcílio-Jr","Danilo M. Eler","Rafael M. Martins","Fernando V. Paulovich"],"pdf_url":"https://arxiv.org/pdf/1903.06262v5.pdf","comment":"11 pages and 10 figures"},{"id":"http://arxiv.org/abs/2212.08914v1","updated":"2022-12-17T16:32:15Z","published":"2022-12-17T16:32:15Z","title":"Are We Ready for Vision-Centric Driving Streaming Perception? The ASAP\n  Benchmark","summary":"  In recent years, vision-centric perception has flourished in various\nautonomous driving tasks, including 3D detection, semantic map construction,\nmotion forecasting, and depth estimation. Nevertheless, the latency of\nvision-centric approaches is too high for practical deployment (e.g., most\ncamera-based 3D detectors have a runtime greater than 300ms). To bridge the gap\nbetween ideal research and real-world applications, it is necessary to quantify\nthe trade-off between performance and efficiency. Traditionally,\nautonomous-driving perception benchmarks perform the offline evaluation,\nneglecting the inference time delay. To mitigate the problem, we propose the\nAutonomous-driving StreAming Perception (ASAP) benchmark, which is the first\nbenchmark to evaluate the online performance of vision-centric perception in\nautonomous driving. On the basis of the 2Hz annotated nuScenes dataset, we\nfirst propose an annotation-extending pipeline to generate high-frame-rate\nlabels for the 12Hz raw images. Referring to the practical deployment, the\nStreaming Perception Under constRained-computation (SPUR) evaluation protocol\nis further constructed, where the 12Hz inputs are utilized for streaming\nevaluation under the constraints of different computational resources. In the\nASAP benchmark, comprehensive experiment results reveal that the model rank\nalters under different constraints, suggesting that the model latency and\ncomputation budget should be considered as design choices to optimize the\npractical deployment. To facilitate further research, we establish baselines\nfor camera-based streaming 3D detection, which consistently enhance the\nstreaming performance across various hardware. ASAP project page:\nhttps://github.com/JeffWang987/ASAP.\n","authors":["Xiaofeng Wang","Zheng Zhu","Yunpeng Zhang","Guan Huang","Yun Ye","Wenbo Xu","Ziwei Chen","Xingang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.08914v1.pdf","comment":"code: https://github.com/JeffWang987/ASAP"},{"id":"http://arxiv.org/abs/2212.08904v1","updated":"2022-12-17T15:34:55Z","published":"2022-12-17T15:34:55Z","title":"Hyperbolic Hierarchical Contrastive Hashing","summary":"  Hierarchical semantic structures, naturally existing in real-world datasets,\ncan assist in capturing the latent distribution of data to learn robust hash\ncodes for retrieval systems. Although hierarchical semantic structures can be\nsimply expressed by integrating semantically relevant data into a high-level\ntaxon with coarser-grained semantics, the construction, embedding, and\nexploitation of the structures remain tricky for unsupervised hash learning. To\ntackle these problems, we propose a novel unsupervised hashing method named\nHyperbolic Hierarchical Contrastive Hashing (HHCH). We propose to embed\ncontinuous hash codes into hyperbolic space for accurate semantic expression\nsince embedding hierarchies in hyperbolic space generates less distortion than\nin hyper-sphere space and Euclidean space. In addition, we extend the K-Means\nalgorithm to hyperbolic space and perform the proposed hierarchical hyperbolic\nK-Means algorithm to construct hierarchical semantic structures adaptively. To\nexploit the hierarchical semantic structures in hyperbolic space, we designed\nthe hierarchical contrastive learning algorithm, including hierarchical\ninstance-wise and hierarchical prototype-wise contrastive learning. Extensive\nexperiments on four benchmark datasets demonstrate that the proposed method\noutperforms the state-of-the-art unsupervised hashing methods. Codes will be\nreleased.\n","authors":["Rukai Wei","Yu Liu","Jingkuan Song","Yanzhao Xie","Ke Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.08904v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.08896v1","updated":"2022-12-17T15:19:45Z","published":"2022-12-17T15:19:45Z","title":"Human Image Generation: A Comprehensive Survey","summary":"  Image and video synthesis has become a blooming topic in computer vision and\nmachine learning communities along with the developments of deep generative\nmodels, due to its great academic and application value. Many researchers have\nbeen devoted to synthesizing high-fidelity human images as one of the most\ncommonly seen object categories in daily lives, where a large number of studies\nare performed based on various deep generative models, task settings and\napplications. Thus, it is necessary to give a comprehensive overview on these\nvariant methods on human image generation. In this paper, we divide human image\ngeneration techniques into three paradigms, i.e., data-driven methods,\nknowledge-guided methods and hybrid methods. For each route, the most\nrepresentative models and the corresponding variants are presented, where the\nadvantages and characteristics of different methods are summarized in terms of\nmodel architectures and input/output requirements. Besides, the main public\nhuman image datasets and evaluation metrics in the literature are also\nsummarized. Furthermore, due to the wide application potentials, two typical\ndownstream usages of synthesized human images are covered, i.e., data\naugmentation for person recognition tasks and virtual try-on for fashion\ncustomers. Finally, we discuss the challenges and potential directions of human\nimage generation to shed light on future research.\n","authors":["Zhen Jia","Zhang Zhang","Liang Wang","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2212.08896v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2212.08892v1","updated":"2022-12-17T15:05:25Z","published":"2022-12-17T15:05:25Z","title":"Flattening-Net: Deep Regular 2D Representation for 3D Point Cloud\n  Analysis","summary":"  Point clouds are characterized by irregularity and unstructuredness, which\npose challenges in efficient data exploitation and discriminative feature\nextraction. In this paper, we present an unsupervised deep neural architecture\ncalled Flattening-Net to represent irregular 3D point clouds of arbitrary\ngeometry and topology as a completely regular 2D point geometry image (PGI)\nstructure, in which coordinates of spatial points are captured in colors of\nimage pixels. \\mr{Intuitively, Flattening-Net implicitly approximates a locally\nsmooth 3D-to-2D surface flattening process while effectively preserving\nneighborhood consistency.} \\mr{As a generic representation modality, PGI\ninherently encodes the intrinsic property of the underlying manifold structure\nand facilitates surface-style point feature aggregation.} To demonstrate its\npotential, we construct a unified learning framework directly operating on PGIs\nto achieve \\mr{diverse types of high-level and low-level} downstream\napplications driven by specific task networks, including classification,\nsegmentation, reconstruction, and upsampling. Extensive experiments demonstrate\nthat our methods perform favorably against the current state-of-the-art\ncompetitors. We will make the code and data publicly available at\nhttps://github.com/keeganhk/Flattening-Net.\n","authors":["Qijian Zhang","Junhui Hou","Yue Qian","Yiming Zeng","Juyong Zhang","Ying He"],"pdf_url":"https://arxiv.org/pdf/2212.08892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08883v1","updated":"2022-12-17T14:46:01Z","published":"2022-12-17T14:46:01Z","title":"Modeling Global Distribution for Federated Learning with Label\n  Distribution Skew","summary":"  Federated learning achieves joint training of deep models by connecting\ndecentralized data sources, which can significantly mitigate the risk of\nprivacy leakage. However, in a more general case, the distributions of labels\namong clients are different, called ``label distribution skew''. Directly\napplying conventional federated learning without consideration of label\ndistribution skew issue significantly hurts the performance of the global\nmodel. To this end, we propose a novel federated learning method, named FedMGD,\nto alleviate the performance degradation caused by the label distribution skew\nissue. It introduces a global Generative Adversarial Network to model the\nglobal data distribution without access to local datasets, so the global model\ncan be trained using the global information of data distribution without\nprivacy leakage. The experimental results demonstrate that our proposed method\nsignificantly outperforms the state-of-the-art on several public benchmarks.\nCode is available at \\url{https://github.com/Sheng-T/FedMGD}.\n","authors":["Tao Sheng","Chengchao Shen","Yuan Liu","Yeyu Ou","Zhe Qu","Jianxin Wang"],"pdf_url":"https://arxiv.org/pdf/2212.08883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08861v1","updated":"2022-12-17T12:47:19Z","published":"2022-12-17T12:47:19Z","title":"DAG: Depth-Aware Guidance with Denoising Diffusion Probabilistic Models","summary":"  In recent years, generative models have undergone significant advancement due\nto the success of diffusion models. The success of these models is often\nattributed to their use of guidance techniques, such as classifier and\nclassifier-free methods, which provides effective mechanisms to trade-off\nbetween fidelity and diversity. However, these methods are not capable of\nguiding a generated image to be aware of its geometric configuration, e.g.,\ndepth, which hinders the application of diffusion models to areas that require\na certain level of depth awareness. To address this limitation, we propose a\nnovel guidance approach for diffusion models that uses estimated depth\ninformation derived from the rich intermediate representations of diffusion\nmodels. To do this, we first present a label-efficient depth estimation\nframework using the internal representations of diffusion models. At the\nsampling phase, we utilize two guidance techniques to self-condition the\ngenerated image using the estimated depth map, the first of which uses\npseudo-labeling, and the subsequent one uses a depth-domain diffusion prior.\nExperiments and extensive ablation studies demonstrate the effectiveness of our\nmethod in guiding the diffusion models toward geometrically plausible image\ngeneration. Project page is available at https://ku-cvlab.github.io/DAG/.\n","authors":["Gyeongnyeon Kim","Wooseok Jang","Gyuseong Lee","Susung Hong","Junyoung Seo","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2212.08861v1.pdf","comment":"Project page is available at https://ku-cvlab.github.io/DAG/"},{"id":"http://arxiv.org/abs/2212.08859v1","updated":"2022-12-17T12:40:54Z","published":"2022-12-17T12:40:54Z","title":"iCub! Do you recognize what I am doing?: multimodal human action\n  recognition on multisensory-enabled iCub robot","summary":"  This study uses multisensory data (i.e., color and depth) to recognize human\nactions in the context of multimodal human-robot interaction. Here we employed\nthe iCub robot to observe the predefined actions of the human partners by using\nfour different tools on 20 objects. We show that the proposed multimodal\nensemble learning leverages complementary characteristics of three color\ncameras and one depth sensor that improves, in most cases, recognition accuracy\ncompared to the models trained with a single modality. The results indicate\nthat the proposed models can be deployed on the iCub robot that requires\nmultimodal action recognition, including social tasks such as partner-specific\nadaptation, and contextual behavior understanding, to mention a few.\n","authors":["Kas Kniesmeijer","Murat Kirtay"],"pdf_url":"https://arxiv.org/pdf/2212.08859v1.pdf","comment":"7 pages, 5 figures and 1 table. International Conference on Social\n  Robotics"},{"id":"http://arxiv.org/abs/2212.04875v2","updated":"2022-12-17T11:13:29Z","published":"2022-12-09T14:29:57Z","title":"Expeditious Saliency-guided Mix-up through Random Gradient Thresholding","summary":"  Mix-up training approaches have proven to be effective in improving the\ngeneralization ability of Deep Neural Networks. Over the years, the research\ncommunity expands mix-up methods into two directions, with extensive efforts to\nimprove saliency-guided procedures but minimal focus on the arbitrary path,\nleaving the randomization domain unexplored. In this paper, inspired by the\nsuperior qualities of each direction over one another, we introduce a novel\nmethod that lies at the junction of the two routes. By combining the best\nelements of randomness and saliency utilization, our method balances speed,\nsimplicity, and accuracy. We name our method R-Mix following the concept of\n\"Random Mix-up\". We demonstrate its effectiveness in generalization, weakly\nsupervised object localization, calibration, and robustness to adversarial\nattacks. Finally, in order to address the question of whether there exists a\nbetter decision protocol, we train a Reinforcement Learning agent that decides\nthe mix-up policies based on the classifier's performance, reducing dependency\non human-designed objectives and hyperparameter tuning. Extensive experiments\nfurther show that the agent is capable of performing at the cutting-edge level,\nlaying the foundation for a fully automatic mix-up. Our code is released at\n[https://github.com/minhlong94/Random-Mixup].\n","authors":["Minh-Long Luu","Zeyi Huang","Eric P. Xing","Yong Jae Lee","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2212.04875v2.pdf","comment":"Accepted Long paper at 2nd Practical-DL Workshop at AAAI 2023. V2 fix\n  typo"},{"id":"http://arxiv.org/abs/2212.08846v1","updated":"2022-12-17T11:00:34Z","published":"2022-12-17T11:00:34Z","title":"Painterly Image Harmonization in Dual Domains","summary":"  Image harmonization aims to produce visually harmonious composite images by\nadjusting the foreground appearance to be compatible with the background. When\nthe composite image has photographic foreground and painterly background, the\ntask is called painterly image harmonization. There are only few works on this\ntask, which are either time-consuming or weak in generating well-harmonized\nresults. In this work, we propose a novel painterly harmonization network\nconsisting of a dual-domain generator and a dual-domain discriminator, which\nharmonizes the composite image in both spatial domain and frequency domain. The\ndual-domain generator performs harmonization by using AdaIn modules in the\nspatial domain and our proposed ResFFT modules in the frequency domain. The\ndual-domain discriminator attempts to distinguish the inharmonious patches\nbased on the spatial feature and frequency feature of each patch, which can\nenhance the ability of generator in an adversarial manner. Extensive\nexperiments on the benchmark dataset show the effectiveness of our method. Our\ncode and model are available at\nhttps://github.com/bcmi/PHDNet-Painterly-Image-Harmonization.\n","authors":["Junyan Cao","Yan Hong","Li Niu"],"pdf_url":"https://arxiv.org/pdf/2212.08846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08834v1","updated":"2022-12-17T10:20:39Z","published":"2022-12-17T10:20:39Z","title":"Towards Robust Handwritten Text Recognition with On-the-fly User\n  Participation","summary":"  Long-term OCR services aim to provide high-quality output to their users at\ncompetitive costs. It is essential to upgrade the models because of the complex\ndata loaded by the users. The service providers encourage the users who provide\ndata where the OCR model fails by rewarding them based on data complexity,\nreadability, and available budget. Hitherto, the OCR works include preparing\nthe models on standard datasets without considering the end-users. We propose a\nstrategy of consistently upgrading an existing Handwritten Hindi OCR model\nthree times on the dataset of 15 users. We fix the budget of 4 users for each\niteration. For the first iteration, the model directly trains on the dataset\nfrom the first four users. For the rest iteration, all remaining users write a\npage each, which service providers later analyze to select the 4 (new) best\nusers based on the quality of predictions on the human-readable words. Selected\nusers write 23 more pages for upgrading the model. We upgrade the model with\nCurriculum Learning (CL) on the data available in the current iteration and\ncompare the subset from previous iterations. The upgraded model is tested on a\nheld-out set of one page each from all 23 users. We provide insights into our\ninvestigations on the effect of CL, user selection, and especially the data\nfrom unseen writing styles. Our work can be used for long-term OCR services in\ncrowd-sourcing scenarios for the service providers and end users.\n","authors":["Ajoy Mondal","Rohit saluja","C. V. Jawahar"],"pdf_url":"https://arxiv.org/pdf/2212.08834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08830v1","updated":"2022-12-17T09:51:17Z","published":"2022-12-17T09:51:17Z","title":"Inductive Attention for Video Action Anticipation","summary":"  Anticipating future actions based on video observations is an important task\nin video understanding, which would be useful for some precautionary systems\nthat require response time to react before an event occurs. Since the input in\naction anticipation is only pre-action frames, models do not have enough\ninformation about the target action; moreover, similar pre-action frames may\nlead to different futures. Consequently, any solution using existing action\nrecognition models can only be suboptimal. Recently, researchers have proposed\nusing a longer video context to remedy the insufficient information in\npre-action intervals, as well as the self-attention to query past relevant\nmoments to address the anticipation problem. However, the indirect use of video\ninput features as the query might be inefficient, as it only serves as the\nproxy to the anticipation goal. To this end, we propose an inductive attention\nmodel, which transparently uses prior prediction as the query to derive the\nanticipation result by induction from past experience. Our method naturally\nconsiders the uncertainty of multiple futures via the many-to-many association.\nOn the large-scale egocentric video datasets, our model not only shows\nconsistently better performance than state of the art using the same backbone,\nand is competitive to the methods that employ a stronger backbone, but also\nsuperior efficiency in less model parameters.\n","authors":["Tsung-Ming Tai","Giuseppe Fiameni","Cheng-Kuang Lee","Simon See","Oswald Lanz"],"pdf_url":"https://arxiv.org/pdf/2212.08830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05245v3","updated":"2022-12-17T08:29:47Z","published":"2022-12-10T08:49:19Z","title":"Joint Spatio-Temporal Modeling for the Semantic Change Detection in\n  Remote Sensing Images","summary":"  Semantic Change Detection (SCD) refers to the task of simultaneously\nextracting the changed areas and the semantic categories (before and after the\nchanges) in Remote Sensing Images (RSIs). This is more meaningful than Binary\nChange Detection (BCD) since it enables detailed change analysis in the\nobserved areas. Previous works established triple-branch Convolutional Neural\nNetwork (CNN) architectures as the paradigm for SCD. However, it remains\nchallenging to exploit semantic information with a limited amount of change\nsamples. In this work, we investigate to jointly consider the spatio-temporal\ndependencies to improve the accuracy of SCD. First, we propose a Semantic\nChange Transformer (SCanFormer) to explicitly model the 'from-to' semantic\ntransitions between the bi-temporal RSIs. Then, we introduce a semantic\nlearning scheme to leverage the spatio-temporal constraints, which are coherent\nto the SCD task, to guide the learning of semantic changes. The resulting\nnetwork (SCanNet) significantly outperforms the baseline method in terms of\nboth detection of critical semantic changes and semantic consistency in the\nobtained bi-temporal results. It achieves the SOTA accuracy on two benchmark\ndatasets for the SCD.\n","authors":["Lei Ding","Jing Zhang","Kai Zhang","Haitao Guo","Bing Liu","Lorenzo Bruzzone"],"pdf_url":"https://arxiv.org/pdf/2212.05245v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.06706v3","updated":"2022-12-17T08:12:09Z","published":"2021-08-15T09:50:42Z","title":"Temporal Action Segmentation with High-level Complex Activity Labels","summary":"  The temporal action segmentation task segments videos temporally and predicts\naction labels for all frames. Fully supervising such a segmentation model\nrequires dense frame-wise action annotations, which are expensive and tedious\nto collect.\n  This work is the first to propose a Constituent Action Discovery (CAD)\nframework that only requires the video-wise high-level complex activity label\nas supervision for temporal action segmentation. The proposed approach\nautomatically discovers constituent video actions using an activity\nclassification task. Specifically, we define a finite number of latent action\nprototypes to construct video-level dual representations with which these\nprototypes are learned collectively through the activity classification\ntraining. This setting endows our approach with the capability to discover\npotentially shared actions across multiple complex activities.\n  Due to the lack of action-level supervision, we adopt the Hungarian matching\nalgorithm to relate latent action prototypes to ground truth semantic classes\nfor evaluation. We show that with the high-level supervision, the Hungarian\nmatching can be extended from the existing video and activity levels to the\nglobal level. The global-level matching allows for action sharing across\nactivities, which has never been considered in the literature before. Extensive\nexperiments demonstrate that our discovered actions can help perform temporal\naction segmentation and activity recognition tasks.\n","authors":["Guodong Ding","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2108.06706v3.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2209.09464v3","updated":"2022-12-17T07:53:07Z","published":"2022-09-20T04:51:54Z","title":"Rethinking Dimensionality Reduction in Grid-based 3D Object Detection","summary":"  Bird's eye view (BEV) is widely adopted by most of the current point cloud\ndetectors due to the applicability of well-explored 2D detection techniques.\nHowever, existing methods obtain BEV features by simply collapsing voxel or\npoint features along the height dimension, which causes the heavy loss of 3D\nspatial information. To alleviate the information loss, we propose a novel\npoint cloud detection network based on a Multi-level feature dimensionality\nreduction strategy, called MDRNet. In MDRNet, the Spatial-aware Dimensionality\nReduction (SDR) is designed to dynamically focus on the valuable parts of the\nobject during voxel-to-BEV feature transformation. Furthermore, the Multi-level\nSpatial Residuals (MSR) is proposed to fuse the multi-level spatial information\nin the BEV feature maps. Extensive experiments on nuScenes show that the\nproposed method outperforms the state-of-the-art methods. The code will be\navailable upon publication.\n","authors":["Dihe Huang","Ying Chen","Yikang Ding","Jinli Liao","Jianlin Liu","Kai Wu","Qiang Nie","Yong Liu","Chengjie Wang","Zhiheng Li"],"pdf_url":"https://arxiv.org/pdf/2209.09464v3.pdf","comment":"Submitted to ICRA 2023"},{"id":"http://arxiv.org/abs/2203.03990v4","updated":"2022-12-17T06:50:32Z","published":"2022-03-08T10:36:55Z","title":"Skating-Mixer: Long-Term Sport Audio-Visual Modeling with MLPs","summary":"  Figure skating scoring is challenging because it requires judging the\ntechnical moves of the players as well as their coordination with the\nbackground music. Most learning-based methods cannot solve it well for two\nreasons: 1) each move in figure skating changes quickly, hence simply applying\ntraditional frame sampling will lose a lot of valuable information, especially\nin 3 to 5 minutes long videos; 2) prior methods rarely considered the critical\naudio-visual relationship in their models. Due to these reasons, we introduce a\nnovel architecture, named Skating-Mixer. It extends the MLP framework into a\nmultimodal fashion and effectively learns long-term representations through our\ndesigned memory recurrent unit (MRU). Aside from the model, we collected a\nhigh-quality audio-visual FS1000 dataset, which contains over 1000 videos on 8\ntypes of programs with 7 different rating metrics, overtaking other datasets in\nboth quantity and diversity. Experiments show the proposed method achieves\nSOTAs over all major metrics on the public Fis-V and our FS1000 dataset. In\naddition, we include an analysis applying our method to the recent competitions\nin Beijing 2022 Winter Olympic Games, proving our method has strong\napplicability.\n","authors":["Jingfei Xia","Mingchen Zhuge","Tiantian Geng","Shun Fan","Yuantai Wei","Zhenyu He","Feng Zheng"],"pdf_url":"https://arxiv.org/pdf/2203.03990v4.pdf","comment":"Our code is available at\n  https://github.com/AndyFrancesco29/Audio-Visual-Figure-Skating"},{"id":"http://arxiv.org/abs/2212.08816v1","updated":"2022-12-17T06:47:30Z","published":"2022-12-17T06:47:30Z","title":"Improving Unsupervised Video Object Segmentation with Motion-Appearance\n  Synergy","summary":"  We present IMAS, a method that segments the primary objects in videos without\nmanual annotation in training or inference. Previous methods in unsupervised\nvideo object segmentation (UVOS) have demonstrated the effectiveness of motion\nas either input or supervision for segmentation. However, motion signals may be\nuninformative or even misleading in cases such as deformable objects and\nobjects with reflections, causing unsatisfactory segmentation.\n  In contrast, IMAS achieves Improved UVOS with Motion-Appearance Synergy. Our\nmethod has two training stages: 1) a motion-supervised object discovery stage\nthat deals with motion-appearance conflicts through a learnable residual\npathway; 2) a refinement stage with both low- and high-level appearance\nsupervision to correct model misconceptions learned from misleading motion\ncues.\n  Additionally, we propose motion-semantic alignment as a model-agnostic\nannotation-free hyperparam tuning method. We demonstrate its effectiveness in\ntuning critical hyperparams previously tuned with human annotation or\nhand-crafted hyperparam-specific metrics.\n  IMAS greatly improves the segmentation quality on several common UVOS\nbenchmarks. For example, we surpass previous methods by 8.3% on DAVIS16\nbenchmark with only standard ResNet and convolutional heads. We intend to\nrelease our code for future research and applications.\n","authors":["Long Lian","Zhirong Wu","Stella X. Yu"],"pdf_url":"https://arxiv.org/pdf/2212.08816v1.pdf","comment":"15 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.08815v1","updated":"2022-12-17T06:44:58Z","published":"2022-12-17T06:44:58Z","title":"FSCNN: A Fast Sparse Convolution Neural Network Inference System","summary":"  Convolution neural networks (CNNs) have achieved remarkable success, but\ntypically accompany high computation cost and numerous redundant weight\nparameters. To reduce the FLOPs, structure pruning is a popular approach to\nremove the entire hidden structures via introducing coarse-grained sparsity.\nMeanwhile, plentiful pruning works leverage fine-grained sparsity instead\n(sparsity are randomly distributed), whereas their sparse models lack special\ndesigned computing library for potential speedup. In this technical report, we\nstudy and present an efficient convolution neural network inference system to\naccelerate its forward pass by utilizing the fine-grained sparsity of\ncompressed CNNs. Our developed FSCNN is established based on a set of\nspecialized designed sparse data structures, operators and associated\nalgorithms. Experimentally, we validate that FSCNN outperforms standard deep\nlearning library PyTorch on popular CNN architectures such as VGG16 if\nsufficiently high sparsity exhibits. However, due to the contiguity issue of\nsparse operators, FSCNN is typically not comparable with highly optimized dense\noperator. Therefore, coarse-grained (structured) sparsity is our recommendation\nfor generic model compression.\n","authors":["Bo Ji","Tianyi Chen"],"pdf_url":"https://arxiv.org/pdf/2212.08815v1.pdf","comment":"technical report, sparse CNN"},{"id":"http://arxiv.org/abs/2212.06206v2","updated":"2022-12-17T06:29:37Z","published":"2022-12-12T19:29:07Z","title":"Contextual Explainable Video Representation: Human Perception-based\n  Understanding","summary":"  Video understanding is a growing field and a subject of intense research,\nwhich includes many interesting tasks to understanding both spatial and\ntemporal information, e.g., action detection, action recognition, video\ncaptioning, video retrieval. One of the most challenging problems in video\nunderstanding is dealing with feature extraction, i.e. extract contextual\nvisual representation from given untrimmed video due to the long and\ncomplicated temporal structure of unconstrained videos. Different from existing\napproaches, which apply a pre-trained backbone network as a black-box to\nextract visual representation, our approach aims to extract the most contextual\ninformation with an explainable mechanism. As we observed, humans typically\nperceive a video through the interactions between three main factors, i.e., the\nactors, the relevant objects, and the surrounding environment. Therefore, it is\nvery crucial to design a contextual explainable video representation extraction\nthat can capture each of such factors and model the relationships between them.\nIn this paper, we discuss approaches, that incorporate the human perception\nprocess into modeling actors, objects, and the environment. We choose video\nparagraph captioning and temporal action detection to illustrate the\neffectiveness of human perception based-contextual representation in video\nunderstanding. Source code is publicly available at\nhttps://github.com/UARK-AICV/Video_Representation.\n","authors":["Khoa Vo","Kashu Yamazaki","Phong X. Nguyen","Phat Nguyen","Khoa Luu","Ngan Le"],"pdf_url":"https://arxiv.org/pdf/2212.06206v2.pdf","comment":"Accepted in Asilomar Conference 2022"},{"id":"http://arxiv.org/abs/2212.08810v1","updated":"2022-12-17T06:10:57Z","published":"2022-12-17T06:10:57Z","title":"Shape Aware Automatic Region-of-Interest Subdivisions","summary":"  In a wide variety of fields, analysis of images involves defining a region\nand measuring its inherent properties. Such measurements include a region's\nsurface area, curvature, volume, average gray and/or color scale, and so on.\nFurthermore, the subsequent subdivision of these regions is sometimes\nperformed. These subdivisions are then used to measure local information, at\neven finer scales. However, simple griding or manual editing methods are\ntypically used to subdivide a region into smaller units. The resulting\nsubdivisions can therefore either not relate well to the actual shape or\nproperty of the region being studied (i.e., gridding methods), or be time\nconsuming and based on user subjectivity (i.e., manual methods). The method\ndiscussed in this work extracts subdivisional units based on a region's general\nshape information. We present the results of applying our method to the medical\nimage analysis of nested regions-of-interest of myocardial wall, where the\nsubdivisions are used to study temporal and/or spatial heterogeneity of\nmyocardial perfusion. This method is of particular interest for creating\nsubdivision regions-of-interest (SROIs) when no variable intensity or other\ncriteria within a region need be used to separate a particular region into\nsubunits.\n","authors":["Timothy L. Kline"],"pdf_url":"https://arxiv.org/pdf/2212.08810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.08807v2","updated":"2022-12-17T05:55:33Z","published":"2022-09-19T07:26:45Z","title":"A Deep Learning Approach for Parallel Imaging and Compressed Sensing MRI\n  Reconstruction","summary":"  Parallel imaging accelerates MRI data acquisition by acquiring additional\nsensitivity information with an array of receiver coils, resulting in fewer\nphase encoding steps. Because of fewer data requirements than parallel imaging,\ncompressed sensing magnetic resonance imaging (CS-MRI) has gained popularity in\nthe field of medical imaging. Parallel imaging and compressed sensing (CS) both\nreduce the amount of data captured in the k-space, which speeds up traditional\nMRI acquisition. As acquisition time is inversely proportional to sample count,\nforming an image from reduced k-space samples results in faster acquisition but\nwith aliasing artifacts. For de-aliasing the reconstructed image, this paper\nproposes a novel Generative Adversarial Network (GAN) called RECGAN-GR that is\nsupervised with multi-modal losses. In comparison to existing GAN networks, our\nproposed method introduces a novel generator network, RemU-Net, which is\nintegrated with dual-domain loss functions such as weighted magnitude and phase\nloss functions, as well as parallel imaging-based loss, GRAPPA consistency\nloss. As refinement learning, a k-space correction block is proposed to make\nthe GAN network self-resistant to generating unnecessary data, which speeds up\nthe reconstruction process. Comprehensive results show that the proposed\nRECGAN-GR not only improves the PSNR by 4 dB over GAN-based methods but also by\n2 dB over conventional state-of-the-art CNN methods available in the literature\nfor single-coil data. The proposed work significantly improves image quality\nfor low-retained data, resulting in five to ten times faster acquisition.\n","authors":["Farhan Sadik","Md. Kamrul Hasan"],"pdf_url":"https://arxiv.org/pdf/2209.08807v2.pdf","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.08801v1","updated":"2022-12-17T05:23:54Z","published":"2022-12-17T05:23:54Z","title":"Comparison of Model-Free and Model-Based Learning-Informed Planning for\n  PointGoal Navigation","summary":"  In recent years several learning approaches to point goal navigation in\npreviously unseen environments have been proposed. They vary in the\nrepresentations of the environments, problem decomposition, and experimental\nevaluation. In this work, we compare the state-of-the-art Deep Reinforcement\nLearning based approaches with Partially Observable Markov Decision Process\n(POMDP) formulation of the point goal navigation problem. We adapt the (POMDP)\nsub-goal framework proposed by [1] and modify the component that estimates\nfrontier properties by using partial semantic maps of indoor scenes built from\nimages' semantic segmentation. In addition to the well-known completeness of\nthe model-based approach, we demonstrate that it is robust and efficient in\nthat it leverages informative, learned properties of the frontiers compared to\nan optimistic frontier-based planner. We also demonstrate its data efficiency\ncompared to the end-to-end deep reinforcement learning approaches. We compare\nour results against an optimistic planner, ANS and DD-PPO on Matterport3D\ndataset using the Habitat Simulator. We show comparable, though slightly worse\nperformance than the SOTA DD-PPO approach, yet with far fewer data.\n","authors":["Yimeng Li","Arnab Debnath","Gregory J. Stein","Jana Kosecka"],"pdf_url":"https://arxiv.org/pdf/2212.08801v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2211.07898"},{"id":"http://arxiv.org/abs/2103.15890v4","updated":"2022-12-17T05:17:13Z","published":"2021-03-29T18:59:48Z","title":"Learning Domain Invariant Representations for Generalizable Person\n  Re-Identification","summary":"  Generalizable person Re-Identification (ReID) has attracted growing attention\nin recent computer vision community. In this work, we construct a structural\ncausal model among identity labels, identity-specific factors (clothes/shoes\ncolor etc), and domain-specific factors (background, viewpoints etc). According\nto the causal analysis, we propose a novel Domain Invariant Representation\nLearning for generalizable person Re-Identification (DIR-ReID) framework.\nSpecifically, we first propose to disentangle the identity-specific and\ndomain-specific feature spaces, based on which we propose an effective\nalgorithmic implementation for backdoor adjustment, essentially serving as a\ncausal intervention towards the SCM. Extensive experiments have been conducted,\nshowing that DIR-ReID outperforms state-of-the-art methods on large-scale\ndomain generalization ReID benchmarks.\n","authors":["Yi-Fan Zhang","Zhang Zhang","Da Li","Zhen Jia","Liang Wang","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2103.15890v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16098v2","updated":"2022-12-17T04:42:03Z","published":"2022-11-29T11:17:34Z","title":"Three-stage binarization of color document images based on discrete\n  wavelet transform and generative adversarial networks","summary":"  The efficient segmentation of foreground text information from the background\nin degraded color document images is a hot research topic. Due to the imperfect\npreservation of ancient documents over a long period of time, various types of\ndegradation, including staining, yellowing, and ink seepage, have seriously\naffected the results of image binarization. In this paper, a three-stage method\nis proposed for image enhancement and binarization of degraded color document\nimages by using discrete wavelet transform (DWT) and generative adversarial\nnetwork (GAN). In Stage-1, we use DWT and retain the LL subband images to\nachieve the image enhancement. In Stage-2, the original input image is split\ninto four (Red, Green, Blue and Gray) single-channel images, each of which\ntrains the independent adversarial networks. The trained adversarial network\nmodels are used to extract the color foreground information from the images. In\nStage-3, in order to combine global and local features, the output image from\nStage-2 and the original input image are used to train the independent\nadversarial networks for document binarization. The experimental results\ndemonstrate that our proposed method outperforms many classical and\nstate-of-the-art (SOTA) methods on the Document Image Binarization Contest\n(DIBCO) dataset. We release our implementation code at\nhttps://github.com/abcpp12383/ThreeStageBinarization.\n","authors":["Yu-Shian Lin","Rui-Yang Ju","Chih-Chia Chen","Ting-Yu Lin","Jen-Shiun Chiang"],"pdf_url":"https://arxiv.org/pdf/2211.16098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08062v2","updated":"2022-12-17T02:38:01Z","published":"2022-12-15T18:59:33Z","title":"MetaPortrait: Identity-Preserving Talking Head Generation with Fast\n  Personalized Adaptation","summary":"  In this work, we propose an ID-preserving talking head generation framework,\nwhich advances previous methods in two aspects. First, as opposed to\ninterpolating from sparse flow, we claim that dense landmarks are crucial to\nachieving accurate geometry-aware flow fields. Second, inspired by\nface-swapping methods, we adaptively fuse the source identity during synthesis,\nso that the network better preserves the key characteristics of the image\nportrait. Although the proposed model surpasses prior generation fidelity on\nestablished benchmarks, to further make the talking head generation qualified\nfor real usage, personalized fine-tuning is usually needed. However, this\nprocess is rather computationally demanding that is unaffordable to standard\nusers. To solve this, we propose a fast adaptation model using a meta-learning\napproach. The learned model can be adapted to a high-quality personalized model\nas fast as 30 seconds. Last but not the least, a spatial-temporal enhancement\nmodule is proposed to improve the fine details while ensuring temporal\ncoherency. Extensive experiments prove the significant superiority of our\napproach over the state of the arts in both one-shot and personalized settings.\n","authors":["Bowen Zhang","Chenyang Qi","Pan Zhang","Bo Zhang","HsiangTao Wu","Dong Chen","Qifeng Chen","Yong Wang","Fang Wen"],"pdf_url":"https://arxiv.org/pdf/2212.08062v2.pdf","comment":"Project Page: https://meta-portrait.github.io"},{"id":"http://arxiv.org/abs/2212.08781v1","updated":"2022-12-17T02:26:42Z","published":"2022-12-17T02:26:42Z","title":"Multi-Scale Relational Graph Convolutional Network for Multiple Instance\n  Learning in Histopathology Images","summary":"  Graph convolutional neural networks have shown significant potential in\nnatural and histopathology images. However, their use has only been studied in\na single magnification or multi-magnification with late fusion. In order to\nleverage the multi-magnification information and early fusion with graph\nconvolutional networks, we handle different embedding spaces at each\nmagnification by introducing the Multi-Scale Relational Graph Convolutional\nNetwork (MS-RGCN) as a multiple instance learning method. We model\nhistopathology image patches and their relation with neighboring patches and\npatches at other scales (i.e., magnifications) as a graph. To pass the\ninformation between different magnification embedding spaces, we define\nseparate message-passing neural networks based on the node and edge type. We\nexperiment on prostate cancer histopathology images to predict the grade groups\nbased on the extracted features from patches. We also compare our MS-RGCN with\nmultiple state-of-the-art methods with evaluations on both source and held-out\ndatasets. Our method outperforms the state-of-the-art on both datasets and\nespecially on the classification of grade groups 2 and 3, which are significant\nfor clinical decisions for patient management. Through an ablation study, we\ntest and show the value of the pertinent design features of the MS-RGCN.\n","authors":["Roozbeh Bazargani","Ladan Fazli","Larry Goldenberg","Martin Gleave","Ali Bashashati","Septimiu Salcudean"],"pdf_url":"https://arxiv.org/pdf/2212.08781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08008v2","updated":"2022-12-17T02:24:40Z","published":"2022-12-15T18:14:51Z","title":"A New Deep Boosted CNN and Ensemble Learning based IoT Malware Detection","summary":"  Security issues are threatened in various types of networks, especially in\nthe Internet of Things (IoT) environment that requires early detection. IoT is\nthe network of real-time devices like home automation systems and can be\ncontrolled by open-source android devices, which can be an open ground for\nattackers. Attackers can access the network, initiate a different kind of\nsecurity breach, and compromises network control. Therefore, timely detecting\nthe increasing number of sophisticated malware attacks is the challenge to\nensure the credibility of network protection. In this regard, we have developed\na new malware detection framework, Deep Squeezed-Boosted and Ensemble Learning\n(DSBEL), comprised of novel Squeezed-Boosted Boundary-Region\nSplit-Transform-Merge (SB-BR-STM) CNN and ensemble learning. The proposed\nS.T.M. block employs multi-path dilated convolutional, Boundary, and regional\noperations to capture the homogenous and heterogeneous global malicious\npatterns. Moreover, diverse feature maps are achieved using transfer learning\nand multi-path-based squeezing and boosting at initial and final levels to\nlearn minute pattern variations. Finally, the boosted discriminative features\nare extracted from the developed deep SB-BR-STM CNN and provided to the\nensemble classifiers (SVM, M.L.P., and AdaboostM1) to improve the hybrid\nlearning generalization. The performance analysis of the proposed DSBEL\nframework and SB-BR-STM CNN against the existing techniques have been evaluated\nby the IOT_Malware dataset on standard performance measures. Evaluation results\nshow progressive performance as 98.50% accuracy, 97.12% F1-Score, 91.91% MCC,\n95.97 % Recall, and 98.42 % Precision. The proposed malware analysis framework\nis helpful for the timely detection of malicious activity and suggests future\nstrategies.\n","authors":["Saddam Hussain Khan","Wasi Ullah"],"pdf_url":"https://arxiv.org/pdf/2212.08008v2.pdf","comment":"20 pages, 10 figures, 6 tables; Corresponding saddamhkhan@ueas.edu.pk"},{"id":"http://arxiv.org/abs/2209.10285v2","updated":"2022-12-17T01:54:12Z","published":"2022-09-21T11:54:00Z","title":"AirFi: Empowering WiFi-based Passive Human Gesture Recognition to Unseen\n  Environment via Domain Generalization","summary":"  WiFi-based smart human sensing technology enabled by Channel State\nInformation (CSI) has received great attention in recent years. However,\nCSI-based sensing systems suffer from performance degradation when deployed in\ndifferent environments. Existing works solve this problem by domain adaptation\nusing massive unlabeled high-quality data from the new environment, which is\nusually unavailable in practice. In this paper, we propose a novel augmented\nenvironment-invariant robust WiFi gesture recognition system named AirFi that\ndeals with the issue of environment dependency from a new perspective. The\nAirFi is a novel domain generalization framework that learns the critical part\nof CSI regardless of different environments and generalizes the model to unseen\nscenarios, which does not require collecting any data for adaptation to the new\nenvironment. AirFi extracts the common features from several training\nenvironment settings and minimizes the distribution differences among them. The\nfeature is further augmented to be more robust to environments. Moreover, the\nsystem can be further improved by few-shot learning techniques. Compared to\nstate-of-the-art methods, AirFi is able to work in different environment\nsettings without acquiring any CSI data from the new environment. The\nexperimental results demonstrate that our system remains robust in the new\nenvironment and outperforms the compared systems.\n","authors":["Dazhuo Wang","Jianfei Yang","Wei Cui","Lihua Xie","Sumei Sun"],"pdf_url":"https://arxiv.org/pdf/2209.10285v2.pdf","comment":"The paper has been accepted by IEEE Transactions on Mobile Computing"},{"id":"http://arxiv.org/abs/2212.07613v2","updated":"2022-12-17T01:51:55Z","published":"2022-12-15T04:34:57Z","title":"DCS-RISR: Dynamic Channel Splitting for Efficient Real-world Image\n  Super-Resolution","summary":"  Real-world image super-resolution (RISR) has received increased focus for\nimproving the quality of SR images under unknown complex degradation. Existing\nmethods rely on the heavy SR models to enhance low-resolution (LR) images of\ndifferent degradation levels, which significantly restricts their practical\ndeployments on resource-limited devices. In this paper, we propose a novel\nDynamic Channel Splitting scheme for efficient Real-world Image\nSuper-Resolution, termed DCS-RISR. Specifically, we first introduce the light\ndegradation prediction network to regress the degradation vector to simulate\nthe real-world degradations, upon which the channel splitting vector is\ngenerated as the input for an efficient SR model. Then, a learnable octave\nconvolution block is proposed to adaptively decide the channel splitting scale\nfor low- and high-frequency features at each block, reducing computation\noverhead and memory cost by offering the large scale to low-frequency features\nand the small scale to the high ones. To further improve the RISR performance,\nNon-local regularization is employed to supplement the knowledge of patches\nfrom LR and HR subspace with free-computation inference. Extensive experiments\ndemonstrate the effectiveness of DCS-RISR on different benchmark datasets. Our\nDCS-RISR not only achieves the best trade-off between computation/parameter and\nPSNR/SSIM metric, and also effectively handles real-world images with different\ndegradation levels.\n","authors":["Junbo Qiao","Shaohui Lin","Yunlun Zhang","Wei Li","Jie Hu","Gaoqi He","Changbo Wang","Zhuangli Ma"],"pdf_url":"https://arxiv.org/pdf/2212.07613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08774v1","updated":"2022-12-17T01:07:21Z","published":"2022-12-17T01:07:21Z","title":"Annotation by Clicks: A Point-Supervised Contrastive Variance Method for\n  Medical Semantic Segmentation","summary":"  Medical image segmentation methods typically rely on numerous dense annotated\nimages for model training, which are notoriously expensive and time-consuming\nto collect. To alleviate this burden, weakly supervised techniques have been\nexploited to train segmentation models with less expensive annotations. In this\npaper, we propose a novel point-supervised contrastive variance method (PSCV)\nfor medical image semantic segmentation, which only requires one pixel-point\nfrom each organ category to be annotated. The proposed method trains the base\nsegmentation network by using a novel contrastive variance (CV) loss to exploit\nthe unlabeled pixels and a partial cross-entropy loss on the labeled pixels.\nThe CV loss function is designed to exploit the statistical spatial\ndistribution properties of organs in medical images and their variance\ndistribution map representations to enforce discriminative predictions over the\nunlabeled pixels. Experimental results on two standard medical image datasets\ndemonstrate that the proposed method outperforms the state-of-the-art weakly\nsupervised methods on point-supervised medical image semantic segmentation\ntasks.\n","authors":["Qing En","Yuhong Guo"],"pdf_url":"https://arxiv.org/pdf/2212.08774v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2210.10631v2","updated":"2022-12-17T16:24:33Z","published":"2022-10-12T21:53:15Z","title":"Simulated Contextual Bandits for Personalization Tasks from\n  Recommendation Datasets","summary":"  We propose a method for generating simulated contextual bandit environments\nfor personalization tasks from recommendation datasets like MovieLens, Netflix,\nLast.fm, Million Song, etc. This allows for personalization environments to be\ndeveloped based on real-life data to reflect the nuanced nature of real-world\nuser interactions. The obtained environments can be used to develop methods for\nsolving personalization tasks, algorithm benchmarking, model simulation, and\nmore. We demonstrate our approach with numerical examples on MovieLens and IMDb\ndatasets.\n","authors":["Anton Dereventsov","Anton Bibin"],"pdf_url":"https://arxiv.org/pdf/2210.10631v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08901v1","updated":"2022-12-17T15:31:21Z","published":"2022-12-17T15:31:21Z","title":"Learning with linear mixed model for group recommendation systems","summary":"  Accurate prediction of users' responses to items is one of the main aims of\nmany computational advising applications. Examples include recommending movies,\nnews articles, songs, jobs, clothes, books and so forth. Accurate prediction of\ninactive users' responses still remains a challenging problem for many\napplications. In this paper, we explore the linear mixed model in\nrecommendation system. The recommendation process is naturally modelled as the\nmixed process between objective effects (fixed effects) and subjective effects\n(random effects). The latent association between the subjective effects and the\nusers' responses can be mined through the restricted maximum likelihood method.\nIt turns out the linear mixed models can collaborate items' attributes and\nusers' characteristics naturally and effectively. While this model cannot\nproduce the most precisely individual level personalized recommendation, it is\nrelative fast and accurate for group (users)/class (items) recommendation.\nNumerical examples on GroupLens benchmark problems are presented to show the\neffectiveness of this method.\n","authors":["Baode Gao","Guangpeng Zhan","Hanzhang Wang","Yiming Wang","Shengxin Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.08901v1.pdf","comment":"5 pages, 9 figures, published"},{"id":"http://arxiv.org/abs/2212.08841v1","updated":"2022-12-17T10:43:25Z","published":"2022-12-17T10:43:25Z","title":"Unsupervised Dense Retrieval Deserves Better Positive Pairs: Scalable\n  Augmentation with Query Extraction and Generation","summary":"  Dense retrievers have made significant strides in obtaining state-of-the-art\nresults on text retrieval and open-domain question answering (ODQA). Yet most\nof these achievements were made possible with the help of large annotated\ndatasets, unsupervised learning for dense retrieval models remains an open\nproblem. In this work, we explore two categories of methods for creating pseudo\nquery-document pairs, named query extraction (QExt) and transferred query\ngeneration (TQGen), to augment the retriever training in an annotation-free and\nscalable manner. Specifically, QExt extracts pseudo queries by document\nstructures or selecting salient random spans, and TQGen utilizes generation\nmodels trained for other NLP tasks (e.g., summarization) to produce pseudo\nqueries. Extensive experiments show that dense retrievers trained with\nindividual augmentation methods can perform comparably well with multiple\nstrong baselines, and combining them leads to further improvements, achieving\nstate-of-the-art performance of unsupervised dense retrieval on both BEIR and\nODQA datasets.\n","authors":["Rui Meng","Ye Liu","Semih Yavuz","Divyansh Agarwal","Lifu Tu","Ning Yu","Jianguo Zhang","Meghana Bhat","Yingbo Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.08841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.01709v4","updated":"2022-12-17T05:20:04Z","published":"2022-08-02T19:44:47Z","title":"Adapting Triplet Importance of Implicit Feedback for Personalized\n  Recommendation","summary":"  Implicit feedback is frequently used for developing personalized\nrecommendation services due to its ubiquity and accessibility in real-world\nsystems. In order to effectively utilize such information, most research adopts\nthe pairwise ranking method on constructed training triplets (user, positive\nitem, negative item) and aims to distinguish between positive items and\nnegative items for each user. However, most of these methods treat all the\ntraining triplets equally, which ignores the subtle difference between\ndifferent positive or negative items. On the other hand, even though some other\nworks make use of the auxiliary information (e.g., dwell time) of user\nbehaviors to capture this subtle difference, such auxiliary information is hard\nto obtain. To mitigate the aforementioned problems, we propose a novel training\nframework named Triplet Importance Learning (TIL), which adaptively learns the\nimportance score of training triplets. We devise two strategies for the\nimportance score generation and formulate the whole procedure as a bilevel\noptimization, which does not require any rule-based design. We integrate the\nproposed training procedure with several Matrix Factorization (MF)- and Graph\nNeural Network (GNN)-based recommendation models, demonstrating the\ncompatibility of our framework. Via a comparison using three real-world\ndatasets with many state-of-the-art methods, we show that our proposed method\noutperforms the best existing models by 3-21\\% in terms of Recall@k for the\ntop-k recommendation.\n","authors":["Haolun Wu","Chen Ma","Yingxue Zhang","Xue Liu","Ruiming Tang","Mark Coates"],"pdf_url":"https://arxiv.org/pdf/2208.01709v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08779v1","updated":"2022-12-17T02:10:42Z","published":"2022-12-17T02:10:42Z","title":"Personalized Federated Recommender Systems with Private and Partially\n  Federated AutoEncoders","summary":"  Recommender Systems (RSs) have become increasingly important in many\napplication domains, such as digital marketing. Conventional RSs often need to\ncollect users' data, centralize them on the server-side, and form a global\nmodel to generate reliable recommendations. However, they suffer from two\ncritical limitations: the personalization problem that the RSs trained\ntraditionally may not be customized for individual users, and the privacy\nproblem that directly sharing user data is not encouraged. We propose\nPersonalized Federated Recommender Systems (PersonalFR), which introduces a\npersonalized autoencoder-based recommendation model with Federated Learning\n(FL) to address these challenges. PersonalFR guarantees that each user can\nlearn a personal model from the local dataset and other participating users'\ndata without sharing local data, data embeddings, or models. PersonalFR\nconsists of three main components, including AutoEncoder-based RSs (ARSs) that\nlearn the user-item interactions, Partially Federated Learning (PFL) that\nupdates the encoder locally and aggregates the decoder on the server-side, and\nPartial Compression (PC) that only computes and transmits active model\nparameters. Extensive experiments on two real-world datasets demonstrate that\nPersonalFR can achieve private and personalized performance comparable to that\ntrained by centralizing all users' data. Moreover, PersonalFR requires\nsignificantly less computation and communication overhead than standard FL\nbaselines.\n","authors":["Qi Le","Enmao Diao","Xinran Wang","Ali Anwar","Vahid Tarokh","Jie Ding"],"pdf_url":"https://arxiv.org/pdf/2212.08779v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2110.01010v2","updated":"2022-12-17T02:08:00Z","published":"2021-10-03T14:21:46Z","title":"High Capacity Reversible Data Hiding in Encrypted 3D Mesh Models Based\n  on Multi-MSB Prediction","summary":"  As a new generation of digital media for covert transmission, three-dimension\n(3D) mesh models are frequently used and distributed on the network. Facing the\nhuge massive of network data, it is urgent to study a method to protect and\nstore this large amounts of data. In this paper, we proposed a high capacity\nreversible data hiding in encrypted 3D mesh models. This method divides the\nvertices of all 3D mesh into \"embedded sets\" and \"prediction sets\" based on the\nparity of the index. In addition, the multiple most significant bit (Multi-MSB)\nprediction reserved space is used to adaptively embed secret message, and the\nauxiliary information is compressed by arithmetic coding to further free up\nredundant space of the 3D mesh models. We use the majority voting system(MSV)\nprinciple to restore the original mesh model with high quality. The\nexperimental results show that our method achieves a higher embedding capacity\ncompared with state-of-the-art RDH-ED methods on 3D mesh models and can restore\nthe original 3D mesh models with high quality.\n","authors":["Wanli Lv","Lulu Cheng","Zhaoxia Yin"],"pdf_url":"https://arxiv.org/pdf/2110.01010v2.pdf","comment":"Published in Signal Processing"}]},"2022-12-20T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2212.10564v1","updated":"2022-12-20T18:59:50Z","published":"2022-12-20T18:59:50Z","title":"Does unsupervised grammar induction need pixels?","summary":"  Are extralinguistic signals such as image pixels crucial for inducing\nconstituency grammars? While past work has shown substantial gains from\nmultimodal cues, we investigate whether such gains persist in the presence of\nrich information from large language models (LLMs). We find that our approach,\nLLM-based C-PCFG (LC-PCFG), outperforms previous multi-modal methods on the\ntask of unsupervised constituency parsing, achieving state-of-the-art\nperformance on a variety of datasets. Moreover, LC-PCFG results in an over 50%\nreduction in parameter count, and speedups in training time of 1.7x for\nimage-aided models and more than 5x for video-aided models, respectively. These\nresults challenge the notion that extralinguistic signals such as image pixels\nare needed for unsupervised grammar induction, and point to the need for better\ntext-only baselines in evaluating the need of multi-modality for the task.\n","authors":["Boyi Li","Rodolfo Corona","Karttikeya Mangalam","Catherine Chen","Daniel Flaherty","Serge Belongie","Kilian Q. Weinberger","Jitendra Malik","Trevor Darrell","Dan Klein"],"pdf_url":"https://arxiv.org/pdf/2212.10564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10563v1","updated":"2022-12-20T18:59:42Z","published":"2022-12-20T18:59:42Z","title":"Debiasing NLP Models Without Demographic Information","summary":"  Models trained from real-world data tend to imitate and amplify social\nbiases. Although there are many methods suggested to mitigate biases, they\nrequire a preliminary information on the types of biases that should be\nmitigated (e.g., gender or racial bias) and the social groups associated with\neach data sample. In this work, we propose a debiasing method that operates\nwithout any prior knowledge of the demographics in the dataset, detecting\nbiased examples based on an auxiliary model that predicts the main model's\nsuccess and down-weights them during the training process. Results on racial\nand gender bias demonstrate that it is possible to mitigate social biases\nwithout having to use a costly demographic annotation process.\n","authors":["Hadas Orgad","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2212.10563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10561v1","updated":"2022-12-20T18:59:23Z","published":"2022-12-20T18:59:23Z","title":"Parsel: A Unified Natural Language Framework for Algorithmic Reasoning","summary":"  Despite recent success in large language model (LLM) reasoning, LLMs still\nstruggle with hierarchical multi-step reasoning like generating complex\nprograms. In these cases, humans often start with a high-level algorithmic\ndesign and implement each part gradually. We introduce Parsel, a framework\nenabling automatic implementation and validation of complex algorithms with\ncode LLMs, based on hierarchical function descriptions in natural language.\nParsel can be used across domains requiring hierarchical reasoning, e.g. code\nsynthesis, theorem proving, and robotic planning. We demonstrate Parsel's\ncapabilities by using it to generate complex programs that cannot currently be\nautomatically implemented from one description and backtranslating Python\nprograms in the APPS dataset. Beyond modeling capabilities, Parsel allows\nproblem-solving with high-level algorithmic designs, benefiting both students\nand professional programmers.\n","authors":["Eric Zelikman","Qian Huang","Gabriel Poesia","Noah D. Goodman","Nick Haber"],"pdf_url":"https://arxiv.org/pdf/2212.10561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10562v1","updated":"2022-12-20T18:59:23Z","published":"2022-12-20T18:59:23Z","title":"Character-Aware Models Improve Visual Text Rendering","summary":"  Current image generation models struggle to reliably produce well-formed\nvisual text. In this paper, we investigate a key contributing factor: popular\ntext-to-image models lack character-level input features, making it much harder\nto predict a word's visual makeup as a series of glyphs. To quantify the extent\nof this effect, we conduct a series of controlled experiments comparing\ncharacter-aware vs. character-blind text encoders. In the text-only domain, we\nfind that character-aware models provide large gains on a novel spelling task\n(WikiSpell). Transferring these learnings onto the visual domain, we train a\nsuite of image generation models, and show that character-aware variants\noutperform their character-blind counterparts across a range of novel text\nrendering tasks (our DrawText benchmark). Our models set a much higher\nstate-of-the-art on visual spelling, with 30+ point accuracy gains over\ncompetitors on rare words, despite training on far fewer examples.\n","authors":["Rosanne Liu","Dan Garrette","Chitwan Saharia","William Chan","Adam Roberts","Sharan Narang","Irina Blok","RJ Mical","Mohammad Norouzi","Noah Constant"],"pdf_url":"https://arxiv.org/pdf/2212.10562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10560v1","updated":"2022-12-20T18:59:19Z","published":"2022-12-20T18:59:19Z","title":"Self-Instruct: Aligning Language Model with Self Generated Instructions","summary":"  Large \"instruction-tuned\" language models (finetuned to respond to\ninstructions) have demonstrated a remarkable ability to generalize zero-shot to\nnew tasks. Nevertheless, they depend heavily on human-written instruction data\nthat is limited in quantity, diversity, and creativity, therefore hindering the\ngenerality of the tuned model. We introduce Self-Instruct, a framework for\nimproving the instruction-following capabilities of pretrained language models\nby bootstrapping off its own generations. Our pipeline generates instruction,\ninput, and output samples from a language model, then prunes them before using\nthem to finetune the original model. Applying our method to vanilla GPT3, we\ndemonstrate a 33% absolute improvement over the original model on\nSuper-NaturalInstructions, on par with the performance of InstructGPT_001,\nwhich is trained with private user data and human annotations. For further\nevaluation, we curate a set of expert-written instructions for novel tasks, and\nshow through human evaluation that tuning GPT3 with Self-Instruct outperforms\nusing existing public instruction datasets by a large margin, leaving only a 5%\nabsolute gap behind InstructGPT_001. Self-Instruct provides an almost\nannotation-free method for aligning pre-trained language models with\ninstructions, and we release our large synthetic dataset to facilitate future\nstudies on instruction tuning.\n","authors":["Yizhong Wang","Yeganeh Kordi","Swaroop Mishra","Alisa Liu","Noah A. Smith","Daniel Khashabi","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2212.10560v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2212.10559v1","updated":"2022-12-20T18:58:48Z","published":"2022-12-20T18:58:48Z","title":"Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient\n  Descent as Meta Optimizers","summary":"  Large pretrained language models have shown surprising In-Context Learning\n(ICL) ability. With a few demonstration input-label pairs, they can predict the\nlabel for an unseen input without additional parameter updates. Despite the\ngreat success in performance, the working mechanism of ICL still remains an\nopen problem. In order to better understand how ICL works, this paper explains\nlanguage models as meta optimizers and understands ICL as a kind of implicit\nfinetuning. Theoretically, we figure out that the Transformer attention has a\ndual form of gradient descent based optimization. On top of it, we understand\nICL as follows: GPT first produces meta gradients according to the\ndemonstration examples, and then these meta gradients are applied to the\noriginal GPT to build an ICL model. Experimentally, we comprehensively compare\nthe behavior of ICL and explicit finetuning based on real tasks to provide\nempirical evidence that supports our understanding. The results prove that ICL\nbehaves similarly to explicit finetuning at the prediction level, the\nrepresentation level, and the attention behavior level. Further, inspired by\nour understanding of meta optimization, we design a momentum-based attention by\nanalogy with the momentum-based gradient descent algorithm. Its consistently\nbetter performance over vanilla attention supports our understanding again from\nanother aspect, and more importantly, it shows the potential to utilize our\nunderstanding for future model designing.\n","authors":["Damai Dai","Yutao Sun","Li Dong","Yaru Hao","Zhifang Sui","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.10559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10558v1","updated":"2022-12-20T18:58:33Z","published":"2022-12-20T18:58:33Z","title":"On-the-fly Denoising for Data Augmentation in Natural Language\n  Understanding","summary":"  Data Augmentation (DA) is frequently used to automatically provide additional\ntraining data without extra human annotation. However, data augmentation may\nintroduce noisy data that impairs training. To guarantee the quality of\naugmented data, existing methods either assume no noise exists in the augmented\ndata and adopt consistency training or use simple heuristics such as training\nloss and diversity constraints to filter out ``noisy'' data. However, those\nfiltered examples may still contain useful information, and dropping them\ncompletely causes loss of supervision signals. In this paper, based on the\nassumption that the original dataset is cleaner than the augmented data, we\npropose an on-the-fly denoising technique for data augmentation that learns\nfrom soft augmented labels provided by an organic teacher model trained on the\ncleaner original data. A simple self-regularization module is applied to force\nthe model prediction to be consistent across two distinct dropouts to further\nprevent overfitting on noisy labels. Our method can be applied to augmentation\ntechniques in general and can consistently improve the performance on both text\nclassification and question-answering tasks.\n","authors":["Tianqing Fang","Wenxuan Zhou","Fangyu Liu","Hongming Zhang","Yangqiu Song","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10558v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2212.10557v1","updated":"2022-12-20T18:57:18Z","published":"2022-12-20T18:57:18Z","title":"DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines","summary":"  Dialogue models are able to generate coherent and fluent responses, but they\ncan still be challenging to control and may produce non-engaging, unsafe\nresults. This unpredictability diminishes user trust and can hinder the use of\nthe models in the real world. To address this, we introduce DialGuide, a novel\nframework for controlling dialogue model behavior using natural language rules,\nor guidelines. These guidelines provide information about the context they are\napplicable to and what should be included in the response, allowing the models\nto generate responses that are more closely aligned with the developer's\nexpectations and intent. We evaluate DialGuide on three tasks in open-domain\ndialogue response generation: guideline selection, response generation, and\nresponse entailment verification. Our dataset contains 10,737 positive and\n15,467 negative dialogue context-response-guideline triplets across two domains\n- chit-chat and safety. We provide baseline models for the tasks and benchmark\ntheir performance. We also demonstrate that DialGuide is effective in the\ndialogue safety domain, producing safe and engaging responses that follow\ndeveloper guidelines.\n","authors":["Prakhar Gupta","Yang Liu","Di Jin","Behnam Hedayatnia","Spandana Gella","Sijia Liu","Patrick Lange","Julia Hirschberg","Dilek Hakkani-Tur"],"pdf_url":"https://arxiv.org/pdf/2212.10557v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10555v1","updated":"2022-12-20T18:56:57Z","published":"2022-12-20T18:56:57Z","title":"PairReranker: Pairwise Reranking for Natural Language Generation","summary":"  Pre-trained language models have been successful in natural language\ngeneration (NLG) tasks. While various decoding methods have been employed, they\noften produce suboptimal results. We first present an empirical analysis of\nthree NLG tasks: summarization, machine translation, and constrained text\ngeneration. We found that selecting the best output from the results of\nmultiple decoding methods can significantly improve performance. To further\nimprove reranking for NLG tasks, we proposed a novel method,\n\\textsc{PairReranker}, which uses a single encoder and a pairwise loss function\nto jointly encode a source input and a pair of candidates and compare them.\nExperiments on three NLG tasks demonstrated the effectiveness and flexibility\nof \\textsc{PairReranker}, showing strong results, compared with previous\nbaselines. In addition, our \\textsc{PairReranker} can generalize to\nsignificantly improve GPT-3 (text-davinci-003) results (e.g., 24.55\\% on\nCommonGen and 11.35\\% on WMT18 zh-en), even though our rerankers are not\ntrained with any GPT-3 candidates.\n","authors":["Dongfu Jiang","Bill Yuchen Lin","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.10555v1.pdf","comment":"We will release our code and data at\n  https://inklab.usc.edu/PairReranker"},{"id":"http://arxiv.org/abs/2212.10554v1","updated":"2022-12-20T18:56:20Z","published":"2022-12-20T18:56:20Z","title":"A Length-Extrapolatable Transformer","summary":"  Position modeling plays a critical role in Transformers. In this paper, we\nfocus on length extrapolation, i.e., training on short texts while evaluating\nlonger sequences. We define attention resolution as an indicator of\nextrapolation. Then we propose two designs to improve the above metric of\nTransformers. Specifically, we introduce a relative position embedding to\nexplicitly maximize attention resolution. Moreover, we use blockwise causal\nattention during inference for better resolution. We evaluate different\nTransformer variants with language modeling. Experimental results show that our\nmodel achieves strong performance in both interpolation and extrapolation\nsettings. The code will be available at https://aka.ms/LeX-Transformer.\n","authors":["Yutao Sun","Li Dong","Barun Patra","Shuming Ma","Shaohan Huang","Alon Benhaim","Vishrav Chaudhary","Xia Song","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.10554v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2212.10551v1","updated":"2022-12-20T18:54:08Z","published":"2022-12-20T18:54:08Z","title":"Lego-MT: Towards Detachable Models in Massively Multilingual Machine\n  Translation","summary":"  Traditional multilingual neural machine translation (MNMT) uses a single\nmodel to translate all directions. However, with the increasing scale of\nlanguage pairs, simply using a single model for massive MNMT brings new\nchallenges: parameter tension and large computations. In this paper, we revisit\nmulti-way structures by assigning an individual branch for each language\n(group). Despite being a simple architecture, it is challenging to train\nde-centralized models due to the lack of constraints to align representations\nfrom all languages. We propose a localized training recipe to map different\nbranches into a unified space, resulting in an efficient detachable model,\nLego-MT. For a fair comparison, we collect data from OPUS and build the first\nlarge-scale open-source translation benchmark covering 7 language-centric data,\neach containing 445 language pairs. Experiments show that Lego-MT (1.2B) brings\ngains of more than 4 BLEU while outperforming M2M-100 (12B) (We will public all\ntraining data, models, and checkpoints)\n","authors":["Fei Yuan","Yinquan Lu","WenHao Zhu","Lingpeng Kong","Lei Li","Jingjing Xu"],"pdf_url":"https://arxiv.org/pdf/2212.10551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09746v2","updated":"2022-12-20T18:53:53Z","published":"2022-12-19T18:59:45Z","title":"Evaluating Human-Language Model Interaction","summary":"  Many real-world applications of language models (LMs), such as code\nautocomplete and writing assistance, involve human-LM interaction. However, the\nmain LM benchmarks are non-interactive in that a system produces output without\nhuman involvement. To evaluate human-LM interaction, we develop a new\nframework, Human-AI Language-based Interaction Evaluation (HALIE), that expands\nnon-interactive evaluation along three dimensions, capturing (i) the\ninteractive process, not only the final output; (ii) the first-person\nsubjective experience, not just a third-party assessment; and (iii) notions of\npreference beyond quality. We then design five tasks ranging from goal-oriented\nto open-ended to capture different forms of interaction. On four\nstate-of-the-art LMs (three variants of OpenAI's GPT-3 and AI21's J1-Jumbo), we\nfind that non-interactive performance does not always result in better human-LM\ninteraction and that first-person and third-party metrics can diverge,\nsuggesting the importance of examining the nuances of human-LM interaction.\n","authors":["Mina Lee","Megha Srivastava","Amelia Hardy","John Thickstun","Esin Durmus","Ashwin Paranjape","Ines Gerard-Ursin","Xiang Lisa Li","Faisal Ladhak","Frieda Rong","Rose E. Wang","Minae Kwon","Joon Sung Park","Hancheng Cao","Tony Lee","Rishi Bommasani","Michael Bernstein","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2212.09746v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10549v1","updated":"2022-12-20T18:53:14Z","published":"2022-12-20T18:53:14Z","title":"Cross-modal Attention Congruence Regularization for Vision-Language\n  Relation Alignment","summary":"  Despite recent progress towards scaling up multimodal vision-language models,\nthese models are still known to struggle on compositional generalization\nbenchmarks such as Winoground. We find that a critical component lacking from\ncurrent vision-language models is relation-level alignment: the ability to\nmatch directional semantic relations in text (e.g., \"mug in grass\") with\nspatial relationships in the image (e.g., the position of the mug relative to\nthe grass). To tackle this problem, we show that relation alignment can be\nenforced by encouraging the directed language attention from 'mug' to 'grass'\n(capturing the semantic relation 'in') to match the directed visual attention\nfrom the mug to the grass. Tokens and their corresponding objects are softly\nidentified using the cross-modal attention. We prove that this notion of soft\nrelation alignment is equivalent to enforcing congruence between vision and\nlanguage attention matrices under a 'change of basis' provided by the\ncross-modal attention matrix. Intuitively, our approach projects visual\nattention into the language attention space to calculate its divergence from\nthe actual language attention, and vice versa. We apply our Cross-modal\nAttention Congruence Regularization (CACR) loss to UNITER and improve on the\nstate-of-the-art approach to Winoground.\n","authors":["Rohan Pandey","Rulin Shao","Paul Pu Liang","Ruslan Salakhutdinov","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2212.10549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10548v1","updated":"2022-12-20T18:51:48Z","published":"2022-12-20T18:51:48Z","title":"T-Projection: High Quality Annotation Projection for Sequence Labeling\n  Tasks","summary":"  In the absence of readily available labeled data for a given task and\nlanguage, annotation projection has been proposed as one of the possible\nstrategies to automatically generate annotated data which may then be used to\ntrain supervised systems. Annotation projection has often been formulated as\nthe task of projecting, on parallel corpora, some labels from a source into a\ntarget language. In this paper we present T-Projection, a new approach for\nannotation projection that leverages large pretrained text2text language models\nand state-of-the-art machine translation technology. T-Projection decomposes\nthe label projection task into two subtasks: (i) The candidate generation step,\nin which a set of projection candidates using a multilingual T5 model is\ngenerated and, (ii) the candidate selection step, in which the candidates are\nranked based on translation probabilities. We evaluate our method in three\ndownstream tasks and five different languages. Our results show that\nT-projection improves the average F1 score of previous methods by more than 8\npoints.\n","authors":["Iker García-Ferrero","Rodrigo Agerri","German Rigau"],"pdf_url":"https://arxiv.org/pdf/2212.10548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10547v1","updated":"2022-12-20T18:51:23Z","published":"2022-12-20T18:51:23Z","title":"Semantically-informed Hierarchical Event Modeling","summary":"  Prior work has shown that coupling sequential latent variable models with\nsemantic ontological knowledge can improve the representational capabilities of\nevent modeling approaches. In this work, we present a novel, doubly\nhierarchical, semi-supervised event modeling framework that provides structural\nhierarchy while also accounting for ontological hierarchy. Our approach\nconsists of multiple layers of structured latent variables, where each\nsuccessive layer compresses and abstracts the previous layers. We guide this\ncompression through the injection of structured ontological knowledge that is\ndefined at the type level of events: importantly, our model allows for partial\ninjection of semantic knowledge and it does not depend on observing instances\nat any particular level of the semantic ontology. Across two different datasets\nand four different evaluation metrics, we demonstrate that our approach is able\nto out-perform the previous state-of-the-art approaches, demonstrating the\nbenefits of structured and semantic hierarchical knowledge for event modeling.\n","authors":["Shubhashis Roy Dipta","Mehdi Rezaee","Francis Feraro"],"pdf_url":"https://arxiv.org/pdf/2212.10547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10545v1","updated":"2022-12-20T18:50:29Z","published":"2022-12-20T18:50:29Z","title":"DimonGen: Diversified Generative Commonsense Reasoning for Explaining\n  Concept Relationships","summary":"  In this paper, we propose DimonGen, which aims to generate diverse sentences\ndescribing concept relationships in various everyday scenarios. To support\nthis, we create a benchmark dataset for this task by adapting the existing\nCommonGen dataset and propose a two-stage model called MoREE (Mixture of\nRetrieval-Enhanced Experts) to generate the target sentences. MoREE consists of\na mixture of retriever models that retrieve diverse context sentences related\nto the given concepts, and a mixture of generator models that generate diverse\nsentences based on the retrieved contexts. We conduct experiments on the\nDimonGen task and show that MoREE outperforms strong baselines in terms of both\nthe quality and diversity of the generated sentences. Our results demonstrate\nthat MoREE is able to generate diverse sentences that reflect different\nrelationships between concepts, leading to a comprehensive understanding of\nconcept relationships.\n","authors":["Chenzhengyi Liu","Jie Huang","Kerui Zhu","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10544v1","updated":"2022-12-20T18:50:08Z","published":"2022-12-20T18:50:08Z","title":"Pretraining Without Attention","summary":"  Transformers have been essential to pretraining success in NLP. Other\narchitectures have been used, but require attention layers to match benchmark\naccuracy. This work explores pretraining without attention. We test recently\ndeveloped routing layers based on state-space models (SSM) and model\narchitectures based on multiplicative gating. Used together these modeling\nchoices have a large impact on pretraining accuracy. Empirically the proposed\nBidirectional Gated SSM (BiGS) replicates BERT pretraining results without\nattention and can be extended to long-form pretraining of 4096 tokens without\napproximation.\n","authors":["Junxiong Wang","Jing Nathan Yan","Albert Gu","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2212.10544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10543v1","updated":"2022-12-20T18:50:00Z","published":"2022-12-20T18:50:00Z","title":"Detoxifying Text with MaRCo: Controllable Revision with Experts and\n  Anti-Experts","summary":"  Text detoxification has the potential to mitigate the harms of toxicity by\nrephrasing text to remove offensive meaning, but subtle toxicity remains\nchallenging to tackle. We introduce MaRCo, a detoxification algorithm that\ncombines controllable generation and text rewriting methods using a Product of\nExperts with autoencoder language models (LMs). MaRCo uses likelihoods under a\nnon-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to\nmask and potentially replace. We evaluate our method on several subtle toxicity\nand microaggressions datasets, and show that it not only outperforms baselines\non automatic metrics, but MaRCo's rewrites are preferred 2.1 $\\times$ more in\nhuman evaluation. Its applicability to instances of subtle toxicity is\nespecially promising, demonstrating a path forward for addressing increasingly\nelusive online hate.\n","authors":["Skyler Hallinan","Alisa Liu","Yejin Choi","Maarten Sap"],"pdf_url":"https://arxiv.org/pdf/2212.10543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10539v1","updated":"2022-12-20T18:47:13Z","published":"2022-12-20T18:47:13Z","title":"Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good\n  movie, and a good prompt too?","summary":"  Large language models can perform new tasks in a zero-shot fashion, given\nnatural language prompts that specify the desired behavior. Such prompts are\ntypically hand engineered, but can also be learned with gradient-based methods\nfrom labeled data. However, it is underexplored what factors make the prompts\neffective, especially when the prompts are natural language. In this paper, we\ninvestigate common attributes shared by effective prompts. We first propose a\nhuman readable prompt tuning method (F LUENT P ROMPT) based on Langevin\ndynamics that incorporates a fluency constraint to find a diverse distribution\nof effective and fluent prompts. Our analysis reveals that effective prompts\nare topically related to the task domain and calibrate the prior probability of\nlabel words. Based on these findings, we also propose a method for generating\nprompts using only unlabeled data, outperforming strong baselines by an average\nof 7.0% accuracy across three tasks.\n","authors":["Weijia Shi","Xiaochuang Han","Hila Gonen","Ari Holtzman","Yulia Tsvetkov","Luke Zettlemoyer"],"pdf_url":"https://arxiv.org/pdf/2212.10539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10537v1","updated":"2022-12-20T18:46:28Z","published":"2022-12-20T18:46:28Z","title":"Does CLIP Bind Concepts? Probing Compositionality in Large Image Models","summary":"  Large-scale models combining text and images have made incredible progress in\nrecent years. However, they can still fail at tasks requiring compositional\nknowledge, such as correctly picking out a red cube from a picture of multiple\nshapes. We examine the ability of CLIP (Radford et al., 2021), to caption\nimages requiring compositional knowledge. We implement five compositional\nlanguage models to probe the kinds of structure that CLIP may be using, and\ndevelop a novel training algorithm, Compositional Skipgram for Images (CoSI),\nto train these models. We look at performance in attribute-based tasks,\nrequiring the identification of a particular combination of attribute and\nobject (such as \"red cube\"), and in relational settings, where the spatial\nrelation between two shapes (such as \"cube behind sphere\") must be identified.\nWe find that in some conditions, CLIP is able to learn attribute-object\nlabellings, and to generalize to unseen attribute-object combinations. However,\nwe also see evidence that CLIP is not able to bind features together reliably.\nMoreover, CLIP is not able to reliably learn relations between objects, whereas\nsome compositional models are able to learn these perfectly. Of the five models\nwe developed, none were able to generalize to unseen relations.\n","authors":["Martha Lewis","Qinan Yu","Jack Merullo","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2212.10537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10536v1","updated":"2022-12-20T18:46:20Z","published":"2022-12-20T18:46:20Z","title":"Measure More, Question More: Experimental Studies on Transformer-based\n  Language Models and Complement Coercion","summary":"  Transformer-based language models have shown strong performance on an array\nof natural language understanding tasks. However, the question of how these\nmodels react to implicit meaning has been largely unexplored. We investigate\nthis using the complement coercion phenomenon, which involves sentences like\n\"The student finished the book about sailing\" where the action \"reading\" is\nimplicit. We compare LMs' surprisal estimates at various critical sentence\nregions in sentences with and without implicit meaning. Effects associated with\nrecovering implicit meaning were found at a critical region other than where\nsentences minimally differ. We then use follow-up experiments to factor out\npotential confounds, revealing different perspectives that offer a richer and\nmore accurate picture.\n","authors":["Yuling Gu"],"pdf_url":"https://arxiv.org/pdf/2212.10536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10535v1","updated":"2022-12-20T18:46:16Z","published":"2022-12-20T18:46:16Z","title":"A Survey of Deep Learning for Mathematical Reasoning","summary":"  Mathematical reasoning is a fundamental aspect of human intelligence and is\napplicable in various fields, including science, engineering, finance, and\neveryday life. The development of artificial intelligence (AI) systems capable\nof solving math problems and proving theorems has garnered significant interest\nin the fields of machine learning and natural language processing. For example,\nmathematics serves as a testbed for aspects of reasoning that are challenging\nfor powerful deep learning models, driving new algorithmic and modeling\nadvances. On the other hand, recent advances in large-scale neural language\nmodels have opened up new benchmarks and opportunities to use deep learning for\nmathematical reasoning. In this survey paper, we review the key tasks,\ndatasets, and methods at the intersection of mathematical reasoning and deep\nlearning over the past decade. We also evaluate existing benchmarks and\nmethods, and discuss future research directions in this domain.\n","authors":["Pan Lu","Liang Qiu","Wenhao Yu","Sean Welleck","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10535v1.pdf","comment":"24 pages, 2 figures, 8 tables. The repository is available at\n  https://github.com/lupantech/dl4math"},{"id":"http://arxiv.org/abs/2212.10534v1","updated":"2022-12-20T18:46:08Z","published":"2022-12-20T18:46:08Z","title":"DISCO: Distilling Phrasal Counterfactuals with Large Language Models","summary":"  Recent methods demonstrate that data augmentation using counterfactual\nknowledge can teach models the causal structure of a task, leading to robust\nand generalizable models. However, such counterfactual data often has a limited\nscale and diversity if crowdsourced and is computationally expensive to extend\nto new perturbation types if generated using supervised methods. To address\nthis, we introduce a new framework called DISCO for automatically generating\nhigh-quality counterfactual data at scale. DISCO engineers prompts to generate\nphrasal perturbations with a large general language model. Then, a\ntask-specific teacher model filters the generation to distill high-quality\ncounterfactual data. We show that learning with this counterfactual data yields\na comparatively small student model that is 6% (absolute) more robust and\ngeneralizes 5% better across distributions than baselines on various\nchallenging evaluations. This model is also 15% more sensitive in\ndifferentiating original and counterfactual examples, on three evaluation sets\nwritten by human workers and via human-AI collaboration.\n","authors":["Zeming Chen","Qiyue Gao","Kyle Richardson","Antoine Bosselut","Ashish Sabharwal"],"pdf_url":"https://arxiv.org/pdf/2212.10534v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2212.10529v1","updated":"2022-12-20T18:45:07Z","published":"2022-12-20T18:45:07Z","title":"Is GPT-3 a Psychopath? Evaluating Large Language Models from a\n  Psychological Perspective","summary":"  Are large language models (LLMs) like GPT-3 psychologically safe? In this\nwork, we design unbiased prompts to evaluate LLMs systematically from a\npsychological perspective. Firstly, we test the personality traits of three\ndifferent LLMs with Short Dark Triad (SD-3) and Big Five Inventory (BFI). We\nfind all of them show higher scores on SD-3 than the human average, indicating\na relatively darker personality. Furthermore, LLMs like InstructGPT and\nFLAN-T5, which are fine-tuned with safety metrics, do not necessarily have more\npositive personalities. They score higher on Machiavellianism and Narcissism\nthan GPT-3. Secondly, we test the LLMs in GPT-3 series on well-being tests to\nstudy the impact of fine-tuning with more training data. Interestingly, we\nobserve a continuous increase in well-being scores from GPT-3 to InstructGPT.\nFollowing the observations, we show that instruction-finetune FLAN-T5 with\npositive answers in BFI can effectively improve the model from a psychological\nperspective. Finally, we call on the community to evaluate and improve LLMs'\nsafety systematically instead of at the sentence level only.\n","authors":["Xingxuan Li","Yutong Li","Linlin Liu","Lidong Bing","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2212.10529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10528v1","updated":"2022-12-20T18:44:21Z","published":"2022-12-20T18:44:21Z","title":"HYRR: Hybrid Infused Reranking for Passage Retrieval","summary":"  We present Hybrid Infused Reranking for Passages Retrieval (HYRR), a\nframework for training rerankers based on a hybrid of BM25 and neural retrieval\nmodels. Retrievers based on hybrid models have been shown to outperform both\nBM25 and neural models alone. Our approach exploits this improved performance\nwhen training a reranker, leading to a robust reranking model. The reranker, a\ncross-attention neural model, is shown to be robust to different first-stage\nretrieval systems, achieving better performance than rerankers simply trained\nupon the first-stage retrievers in the multi-stage systems. We present\nevaluations on a supervised passage retrieval task using MS MARCO and zero-shot\nretrieval tasks using BEIR. The empirical results show strong performance on\nboth evaluations.\n","authors":["Jing Lu","Keith Hall","Ji Ma","Jianmo Ni"],"pdf_url":"https://arxiv.org/pdf/2212.10528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10526v1","updated":"2022-12-20T18:41:38Z","published":"2022-12-20T18:41:38Z","title":"Exploring the Challenges of Open Domain Multi-Document Summarization","summary":"  Multi-document summarization (MDS) has traditionally been studied assuming a\nset of ground-truth topic-related input documents is provided. In practice, the\ninput document set is unlikely to be available a priori and would need to be\nretrieved based on an information need, a setting we call open-domain MDS. We\nexperiment with current state-of-the-art retrieval and summarization models on\nseveral popular MDS datasets extended to the open-domain setting. We find that\nexisting summarizers suffer large reductions in performance when applied as-is\nto this more realistic task, though training summarizers with retrieved inputs\ncan reduce their sensitivity retrieval errors. To further probe these findings,\nwe conduct perturbation experiments on summarizer inputs to study the impact of\ndifferent types of document retrieval errors. Based on our results, we provide\npractical guidelines to help facilitate a shift to open-domain MDS. We release\nour code and experimental results alongside all data or model artifacts created\nduring our investigation.\n","authors":["John Giorgi","Luca Soldaini","Bo Wang","Gary Bader","Kyle Lo","Lucy Lu Wang","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2212.10526v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.10525v1","updated":"2022-12-20T18:39:59Z","published":"2022-12-20T18:39:59Z","title":"SLUE Phase-2: A Benchmark Suite of Diverse Spoken Language Understanding\n  Tasks","summary":"  Spoken language understanding (SLU) tasks have been studied for many decades\nin the speech research community, but have not received as much attention as\nlower-level tasks like speech and speaker recognition. In particular, there are\nnot nearly as many SLU task benchmarks, and many of the existing ones use data\nthat is not freely available to all researchers. Recent work has begun to\nintroduce such benchmark datasets for several tasks. In this work, we introduce\nseveral new annotated SLU benchmark tasks based on freely available speech\ndata, which complement existing benchmarks and address gaps in the SLU\nevaluation landscape. We contribute four tasks: question answering and\nsummarization involve inference over longer speech sequences; named entity\nlocalization addresses the speech-specific task of locating the targeted\ncontent in the signal; dialog act classification identifies the function of a\ngiven speech utterance. We follow the blueprint of the Spoken Language\nUnderstanding Evaluation (SLUE) benchmark suite. In order to facilitate the\ndevelopment of SLU models that leverage the success of pre-trained speech\nrepresentations, we will be publishing for each task (i) annotations for a\nrelatively small fine-tuning set, (ii) annotated development and test sets, and\n(iii) baseline models for easy reproducibility and comparisons. In this work,\nwe present the details of data collection and annotation and the performance of\nthe baseline models. We also perform sensitivity analysis of pipeline models'\nperformance (speech recognizer + text model) to the speech recognition\naccuracy, using more than 20 state-of-the-art speech recognition models.\n","authors":["Suwon Shon","Siddhant Arora","Chyi-Jiunn Lin","Ankita Pasad","Felix Wu","Roshan Sharma","Wei-Lun Wu","Hung-Yi Lee","Karen Livescu","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2212.10525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10522v1","updated":"2022-12-20T18:37:11Z","published":"2022-12-20T18:37:11Z","title":"Transformers Go for the LOLs: Generating (Humourous) Titles from\n  Scientific Abstracts End-to-End","summary":"  We consider the end-to-end abstract-to-title generation problem, exploring\nseven recent transformer based models (including ChatGPT) fine-tuned on more\nthan 30k abstract-title pairs from NLP and machine learning venues. As an\nextension, we also consider the harder problem of generating humorous paper\ntitles. For the latter, we compile the first large-scale humor annotated\ndataset for scientific papers in the NLP/ML domains, comprising almost 2.5k\ntitles. We evaluate all models using human and automatic metrics. Our human\nevaluation suggests that our best end-to-end system performs similarly to human\nauthors (but arguably slightly worse). Generating funny titles is more\ndifficult, however, and our automatic systems clearly underperform relative to\nhumans and often learn dataset artefacts of humor. Finally, ChatGPT, without\nany fine-tuning, performs on the level of our best fine-tuned system.\n","authors":["Yanran Chen","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2212.10522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10520v1","updated":"2022-12-20T18:35:21Z","published":"2022-12-20T18:35:21Z","title":"Privacy-Preserving Domain Adaptation of Semantic Parsers","summary":"  Task-oriented dialogue systems often assist users with personal or\nconfidential matters. For this reason, the developers of such a system are\ngenerally prohibited from observing actual usage. So how can they know where\nthe system is failing and needs more training data or new functionality? In\nthis work, we study ways in which realistic user utterances can be generated\nsynthetically, to help increase the linguistic and functional coverage of the\nsystem, without compromising the privacy of actual users. To this end, we\npropose a two-stage Differentially Private (DP) generation method which first\ngenerates latent semantic parses, and then generates utterances based on the\nparses. Our proposed approach improves MAUVE by 3.8$\\times$ and parse tree\nnode-type overlap by 1.4$\\times$ relative to current approaches for private\nsynthetic data generation, improving both on fluency and semantic coverage. We\nfurther validate our approach on a realistic domain adaptation task of adding\nnew functionality from private user data to a semantic parser, and show gains\nof 1.3$\\times$ on its accuracy with the new feature.\n","authors":["Fatemehsadat Mireshghallah","Richard Shin","Yu Su","Tatsunori Hashimoto","Jason Eisner"],"pdf_url":"https://arxiv.org/pdf/2212.10520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10515v1","updated":"2022-12-20T18:31:50Z","published":"2022-12-20T18:31:50Z","title":"CausalDialogue: Modeling Utterance-level Causality in Conversations","summary":"  Despite their widespread adoption, neural conversation models have yet to\nexhibit natural chat capabilities with humans. In this research, we examine\nuser utterances as causes and generated responses as effects, recognizing that\nchanges in a cause should produce a different effect. To further explore this\nconcept, we have compiled and expanded upon a new dataset called CausalDialogue\nthrough crowd-sourcing. This dataset includes multiple cause-effect pairs\nwithin a directed acyclic graph (DAG) structure. Our analysis reveals that\ntraditional loss functions can struggle to effectively incorporate the DAG\nstructure, leading us to propose a causality-enhanced method called Exponential\nMaximum Average Treatment Effect (ExMATE) to enhance the impact of causality at\nthe utterance level in training neural conversation models. To evaluate the\neffectiveness of this approach, we have built a comprehensive benchmark using\nthe CausalDialogue dataset leveraging large-scale pre-trained language models,\nand have assessed the results through both human and automatic evaluation\nmetrics for coherence, diversity, and agility. Our findings show that current\ntechniques are still unable to effectively address conversational DAGs, and\nthat the ExMATE method can improve the diversity and agility of conventional\nloss functions while maintaining coherence.\n","authors":["Yi-Lin Tuan","Alon Albalak","Wenda Xu","Michael Saxon","Connor Pryor","Lise Getoor","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10511v1","updated":"2022-12-20T18:30:15Z","published":"2022-12-20T18:30:15Z","title":"When Not to Trust Language Models: Investigating Effectiveness and\n  Limitations of Parametric and Non-Parametric Memories","summary":"  Despite their impressive performance on diverse tasks, large language models\n(LMs) still struggle with tasks requiring rich world knowledge, implying the\nlimitations of relying solely on their parameters to encode a wealth of world\nknowledge. This paper aims to understand LMs' strengths and limitations in\nmemorizing factual knowledge, by conducting large-scale knowledge probing\nexperiments of 10 models and 4 augmentation methods on PopQA, our new\nopen-domain QA dataset with 14k questions. We find that LMs struggle with less\npopular factual knowledge, and that scaling fails to appreciably improve\nmemorization of factual knowledge in the tail. We then show that\nretrieval-augmented LMs largely outperform orders of magnitude larger LMs,\nwhile unassisted LMs remain competitive in questions about high-popularity\nentities. Based on those findings, we devise a simple, yet effective, method\nfor powerful and efficient retrieval-augmented LMs, which retrieves\nnon-parametric memories only when necessary. Experimental results show that\nthis significantly improves models' performance while reducing the inference\ncosts.\n","authors":["Alex Mallen","Akari Asai","Victor Zhong","Rajarshi Das","Hannaneh Hajishirzi","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2212.10511v1.pdf","comment":"Code and data available at\n  https://github.com/AlexTMallen/adaptive-retrieval; work in progress"},{"id":"http://arxiv.org/abs/2212.10509v1","updated":"2022-12-20T18:26:34Z","published":"2022-12-20T18:26:34Z","title":"Interleaving Retrieval with Chain-of-Thought Reasoning for\n  Knowledge-Intensive Multi-Step Questions","summary":"  Recent work has shown that large language models are capable of generating\nnatural language reasoning steps or Chains-of-Thoughts (CoT) to answer a\nmulti-step question when prompted to do so. This is insufficient, however, when\nthe necessary knowledge is not available or up-to-date within a model's\nparameters. A straightforward approach to address this is to retrieve text from\nan external knowledge source using the question as a query and prepend it as\ncontext to the model's input. This, however, is also insufficient for\nmulti-step QA where \\textit{what to retrieve} depends on \\textit{what has\nalready been derived}. To address this issue we propose IRCoT, a new approach\nthat interleaves retrieval with CoT for multi-step QA, guiding the retrieval\nwith CoT and in turn using retrieved results to improve CoT. Our experiments\nwith GPT3 show substantial improvements in retrieval (up to 22 points) and\ndownstream QA (up to 16 points) over the baselines on four datasets: HotpotQA,\n2WikiMultihopQA, MuSiQue, and IIRC. Notably, our method also works well for\nmuch smaller models such as T5-Flan-large (0.7B) without any additional\ntraining.\n","authors":["Harsh Trivedi","Niranjan Balasubramanian","Tushar Khot","Ashish Sabharwal"],"pdf_url":"https://arxiv.org/pdf/2212.10509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10505v1","updated":"2022-12-20T18:20:50Z","published":"2022-12-20T18:20:50Z","title":"DePlot: One-shot visual language reasoning by plot-to-table translation","summary":"  Visual language such as charts and plots is ubiquitous in the human world.\nComprehending plots and charts requires strong reasoning skills. Prior\nstate-of-the-art (SOTA) models require at least tens of thousands of training\nexamples and their reasoning capabilities are still much limited, especially on\ncomplex human-written queries. This paper presents the first one-shot solution\nto visual language reasoning. We decompose the challenge of visual language\nreasoning into two steps: (1) plot-to-text translation, and (2) reasoning over\nthe translated text. The key in this method is a modality conversion module,\nnamed as DePlot, which translates the image of a plot or chart to a linearized\ntable. The output of DePlot can then be directly used to prompt a pretrained\nlarge language model (LLM), exploiting the few-shot reasoning capabilities of\nLLMs. To obtain DePlot, we standardize the plot-to-table task by establishing\nunified task formats and metrics, and train DePlot end-to-end on this task.\nDePlot can then be used off-the-shelf together with LLMs in a plug-and-play\nfashion. Compared with a SOTA model finetuned on more than >28k data points,\nDePlot+LLM with just one-shot prompting achieves a 24.0% improvement over\nfinetuned SOTA on human-written queries from the task of chart QA.\n","authors":["Fangyu Liu","Julian Martin Eisenschlos","Francesco Piccinno","Syrine Krichene","Chenxi Pang","Kenton Lee","Mandar Joshi","Wenhu Chen","Nigel Collier","Yasemin Altun"],"pdf_url":"https://arxiv.org/pdf/2212.10505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10504v1","updated":"2022-12-20T18:18:41Z","published":"2022-12-20T18:18:41Z","title":"Can Current Task-oriented Dialogue Models Automate Real-world Scenarios\n  in the Wild?","summary":"  Task-oriented dialogue (TOD) systems are mainly based on the\nslot-filling-based TOD (SF-TOD) framework, in which dialogues are broken down\ninto smaller, controllable units (i.e., slots) to fulfill a specific task. A\nseries of approaches based on this framework achieved remarkable success on\nvarious TOD benchmarks. However, we argue that the current TOD benchmarks are\nlimited to surrogate real-world scenarios and that the current TOD models are\nstill a long way from unraveling the scenarios. In this position paper, we\nfirst identify current status and limitations of SF-TOD systems. After that, we\nexplore the WebTOD framework, the alternative direction for building a scalable\nTOD system when a web/mobile interface is available. In WebTOD, the dialogue\nsystem learns how to understand the web/mobile interface that the human agent\ninteracts with, powered by a large-scale language model.\n","authors":["Sang-Woo Lee","Sungdong Kim","Donghyeon Ko","Donghoon Ham","Youngki Hong","Shin Ah Oh","Hyunhoon Jung","Wangkyo Jung","Kyunghyun Cho","Donghyun Kwak","Hyungsuk Noh","Woomyoung Park"],"pdf_url":"https://arxiv.org/pdf/2212.10504v1.pdf","comment":"Working in Progress"},{"id":"http://arxiv.org/abs/2212.10503v1","updated":"2022-12-20T18:17:28Z","published":"2022-12-20T18:17:28Z","title":"Mini-Model Adaptation: Efficiently Extending Pretrained Models to New\n  Languages via Aligned Shallow Training","summary":"  Prior work has shown that it is possible to expand pretrained Masked Language\nModels (MLMs) to new languages by learning a new set of embeddings, while\nkeeping the transformer body frozen. Despite learning a small subset of\nparameters, this approach is not compute-efficient, as training the new\nembeddings requires a full forward and backward pass over the entire model. In\nthis work, we propose mini-model adaptation, a compute-efficient alternative\nthat builds a shallow mini-model from a fraction of a large model's parameters.\nNew language-specific embeddings can then be efficiently trained over the\nmini-model, and plugged into the aligned large model for rapid cross-lingual\ntransfer. We explore two approaches to learn mini-models: MiniJoint, which\njointly pretrains the primary model and the mini-model using a single\ntransformer with a secondary MLM head at a middle layer; and MiniPost, where we\nstart from a regular pretrained model and build a mini-model by extracting and\nfreezing a few layers and learning a small number of parameters on top.\nExperiments on XNLI, MLQA and PAWS-X show that mini-model adaptation matches\nthe performance of the standard approach using up to 2.4x less compute.\n","authors":["Kelly Marchisio","Patrick Lewis","Yihong Chen","Mikel Artetxe"],"pdf_url":"https://arxiv.org/pdf/2212.10503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10502v1","updated":"2022-12-20T18:17:11Z","published":"2022-12-20T18:17:11Z","title":"A Measure-Theoretic Characterization of Tight Language Models","summary":"  Language modeling, a central task in natural language processing, involves\nestimating a probability distribution over strings. In most cases, the\nestimated distribution sums to 1 over all finite strings. However, in some\npathological cases, probability mass can ``leak'' onto the set of infinite\nsequences. In order to characterize the notion of leakage more precisely, this\npaper offers a measure-theoretic treatment of language modeling. We prove that\nmany popular language model families are in fact tight, meaning that they will\nnot leak in this sense. We also generalize characterizations of tightness\nproposed in previous works.\n","authors":["Li Du","Lucas Torroba Hennigen","Tiago Pimentel","Clara Meister","Jason Eisner","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2212.10502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.14268v2","updated":"2022-12-20T18:13:13Z","published":"2022-06-28T19:46:29Z","title":"BertNet: Harvesting Knowledge Graphs from Pretrained Language Models","summary":"  Symbolic knowledge graphs (KGs) have been constructed either by expensive\nhuman crowdsourcing or with complex text mining pipelines. The emerging large\npretrained language models (LMs), such as Bert, have shown to implicitly encode\nmassive knowledge which can be queried with properly designed prompts. However,\ncompared to the explicit KGs, the implict knowledge in the black-box LMs is\noften difficult to access or edit and lacks explainability. In this work, we\naim at harvesting symbolic KGs from the LMs, and propose a new framework for\nautomatic KG construction empowered by the neural LMs' flexibility and\nscalability. Compared to prior works that often rely on large human annotated\ndata or existing massive KGs, our approach requires only the minimal definition\nof relations as inputs, and hence is suitable for extracting knowledge of rich\nnew relations that are instantly assigned and not available before. The\nframework automatically generates diverse prompts, and performs efficient\nknowledge search within a given LM for consistent outputs. The knowledge\nharvested with our approach shows competitive quality, diversity, and novelty.\nAs a result, we derive from diverse LMs a family of new KGs (e.g., BertNet and\nRoBERTaNet) that contain a richer set of relations, including some complex ones\n(e.g., \"A is capable of but not good at B\") that cannot be extracted with\nprevious methods. Besides, the resulting KGs also serve as a vehicle to\ninterpret the respective source LMs, leading to new insights into the varying\nknowledge capability of different LMs.\n","authors":["Shibo Hao","Bowen Tan","Kaiwen Tang","Bin Ni","Hengzhe Zhang","Eric P Xing","Zhiting Hu"],"pdf_url":"https://arxiv.org/pdf/2206.14268v2.pdf","comment":"Code available at\n  https://github.com/tanyuqian/knowledge-harvest-from-lms"},{"id":"http://arxiv.org/abs/2212.10498v1","updated":"2022-12-20T18:12:49Z","published":"2022-12-20T18:12:49Z","title":"SimpleStyle: An Adaptable Style Transfer Approach","summary":"  Attribute Controlled Text Rewriting, also known as text style transfer, has\nreceived significant attention in the natural language generation community due\nto its crucial role in controllable natural language generation systems. In\nthis work we present SimpleStyle a minimalist yet effective approach for\nattribute controlled text rewriting based on a simple mechanism composed of two\ningredients. controlled denoising and output filtering. Despite the simplicity\nof our approach, which can be succinctly explained with just a few lines of\ncode, it is competitive with previous state-of-the-art methods both in\nautomatic and in human evaluations. Additionally, we demonstrate the practical\neffectiveness of our system, by applying it to real-world data from social\nnetworks. Additionally, we introduce a soft masking sampling technique that\nfurther improves the performance of the system. We also show that feeding the\noutput of our system into a text-to-text student model can produce high-quality\nresults without the need for additional filtering. Finally, we suggest that our\nmethod can solve the fundamental missing baseline absence that holding progress\nin the field by offering our protocol as a simple, adaptive and very strong\nbaseline for works wish to make incremental advancements in the field of\nattribute controlled text rewriting.\n","authors":["Elron Bandel","Yoav Katz","Noam Slonim","Liat Ein-Dor"],"pdf_url":"https://arxiv.org/pdf/2212.10498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10496v1","updated":"2022-12-20T18:09:52Z","published":"2022-12-20T18:09:52Z","title":"Precise Zero-Shot Dense Retrieval without Relevance Labels","summary":"  While dense retrieval has been shown effective and efficient across tasks and\nlanguages, it remains difficult to create effective fully zero-shot dense\nretrieval systems when no relevance label is available. In this paper, we\nrecognize the difficulty of zero-shot learning and encoding relevance. Instead,\nwe propose to pivot through Hypothetical Document Embeddings~(HyDE). Given a\nquery, HyDE first zero-shot instructs an instruction-following language model\n(e.g. InstructGPT) to generate a hypothetical document. The document captures\nrelevance patterns but is unreal and may contain false details. Then, an\nunsupervised contrastively learned encoder~(e.g. Contriever) encodes the\ndocument into an embedding vector. This vector identifies a neighborhood in the\ncorpus embedding space, where similar real documents are retrieved based on\nvector similarity. This second step ground the generated document to the actual\ncorpus, with the encoder's dense bottleneck filtering out the incorrect\ndetails. Our experiments show that HyDE significantly outperforms the\nstate-of-the-art unsupervised dense retriever Contriever and shows strong\nperformance comparable to fine-tuned retrievers, across various tasks (e.g. web\nsearch, QA, fact verification) and languages~(e.g. sw, ko, ja).\n","authors":["Luyu Gao","Xueguang Ma","Jimmy Lin","Jamie Callan"],"pdf_url":"https://arxiv.org/pdf/2212.10496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10481v1","updated":"2022-12-20T17:54:37Z","published":"2022-12-20T17:54:37Z","title":"Execution-Based Evaluation for Open-Domain Code Generation","summary":"  To extend the scope of coding queries to more realistic settings, we propose\nODEX, the first open-domain execution-based natural language (NL) to code\ngeneration dataset. ODEX has 945 NL-Code pairs spanning 79 diverse libraries,\nalong with 1,707 human-written test cases for execution. Our NL-Code pairs are\nharvested from StackOverflow forums to encourage natural and practical coding\nqueries, which are then carefully rephrased to ensure intent clarity and\nprevent potential data memorization. Moreover, ODEX supports four natural\nlanguages as intents, in English, Spanish, Japanese, and Russian. ODEX unveils\nintriguing behavioral differences between top-performing Code LMs: Codex\nperforms better on open-domain queries, yet CodeGen captures a better balance\nbetween open- and closed-domain. ODEX corroborates the merits of\nexecution-based evaluation over metrics without execution but also unveils\ntheir complementary effects. Powerful models such as CodeGen-6B only achieve an\n11.96 pass rate at top-1 prediction, suggesting plenty of headroom for\nimprovement. We release ODEX to facilitate research into open-domain problems\nfor the code generation community.\n","authors":["Zhiruo Wang","Shuyan Zhou","Daniel Fried","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2212.10481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09252v2","updated":"2022-12-20T17:52:24Z","published":"2022-12-19T05:17:33Z","title":"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems","summary":"  Many dialogue systems (DSs) lack characteristics humans have, such as emotion\nperception, factuality, and informativeness. Enhancing DSs with knowledge\nalleviates this problem, but, as many ways of doing so exist, keeping track of\nall proposed methods is difficult. Here, we present the first survey of\nknowledge-enhanced DSs. We define three categories of systems - internal,\nexternal, and hybrid - based on the knowledge they use. We survey the\nmotivation for enhancing DSs with knowledge, used datasets, and methods for\nknowledge search, knowledge encoding, and knowledge incorporation. Finally, we\npropose how to improve existing systems based on theories from linguistics and\ncognitive science.\n","authors":["Sagi Shaier","Lawrence Hunter","Katharina Kann"],"pdf_url":"https://arxiv.org/pdf/2212.09252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10474v1","updated":"2022-12-20T17:49:49Z","published":"2022-12-20T17:49:49Z","title":"ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free\n  Language Models","summary":"  State-of-the-art poetry generation systems are often complex. They either\nconsist of task-specific model pipelines, incorporate prior knowledge in the\nform of manually created constraints or both. In contrast, end-to-end models\nwould not suffer from the overhead of having to model prior knowledge and could\nlearn the nuances of poetry from data alone, reducing the degree of human\nsupervision required. In this work, we investigate end-to-end poetry generation\nconditioned on styles such as rhyme, meter, and alliteration. We identify and\naddress lack of training data and mismatching tokenization algorithms as\npossible limitations of past attempts. In particular, we successfully pre-train\nand release ByGPT5, a new token-free decoder-only language model, and fine-tune\nit on a large custom corpus of English and German quatrains annotated with our\nstyles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2\nand ChatGPT, while also being more parameter efficient and performing favorably\ncompared to humans. In addition, we analyze its runtime performance and\nintrospect the model's understanding of style conditions. We make our code,\nmodels, and datasets publicly available.\n","authors":["Jonas Belouadi","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2212.10474v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.10471v1","updated":"2022-12-20T17:42:16Z","published":"2022-12-20T17:42:16Z","title":"Little Red Riding Hood Goes Around the Globe:Crosslingual Story Planning\n  and Generation with Large Language Models","summary":"  We consider the problem of automatically generating stories in multiple\nlanguages. Compared to prior work in monolingual story generation, crosslingual\nstory generation allows for more universal research on story planning. We\npropose to use Prompting Large Language Models with Plans to study which plan\nis optimal for story generation. We consider 4 types of plans and\nsystematically analyse how the outputs differ for different planning\nstrategies. The study demonstrates that formulating the plans as\nquestion-answer pairs leads to more coherent generated stories while the plan\ngives more control to the story creators.\n","authors":["Evgeniia Razumovskaia","Joshua Maynez","Annie Louis","Mirella Lapata","Shashi Narayan"],"pdf_url":"https://arxiv.org/pdf/2212.10471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10469v1","updated":"2022-12-20T17:41:18Z","published":"2022-12-20T17:41:18Z","title":"BMX: Boosting Machine Translation Metrics with Explainability","summary":"  State-of-the-art machine translation evaluation metrics are based on\nblack-box language models. Hence, recent works consider their explainability\nwith the goals of better understandability for humans and better metric\nanalysis, including failure cases. In contrast, we explicitly leverage\nexplanations to boost the metrics' performance. In particular, we perceive\nexplanations as word-level scores, which we convert, via power means, into\nsentence-level scores. We combine this sentence-level score with the original\nmetric to obtain a better metric. Our extensive evaluation and analysis across\n5 datasets, 5 metrics and 4 explainability techniques shows that some\nconfigurations reliably improve the original metrics' correlation with human\njudgment. On two held datasets for testing, we obtain improvements in 15/18\nresp. 4/4 cases. The gains in Pearson correlation are up to 0.032 resp. 0.055.\nWe make our code available.\n","authors":["Christoph Leiter","Hoa Nguyen","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2212.10469v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2212.10467v1","updated":"2022-12-20T17:40:03Z","published":"2022-12-20T17:40:03Z","title":"Generic Temporal Reasoning with Differential Analysis and Explanation","summary":"  Temporal reasoning is the task of predicting temporal relations of event\npairs with corresponding contexts. While some temporal reasoning models perform\nreasonably well on in-domain benchmarks, we have little idea of the systems'\ngeneralizability due to existing datasets' limitations. In this work, we\nintroduce a novel task named TODAY that bridges this gap with temporal\ndifferential analysis, which as the name suggests, evaluates if systems can\ncorrectly understand the effect of incremental changes. Specifically, TODAY\nmakes slight context changes for given event pairs, and systems need to tell\nhow this subtle contextual change will affect temporal relation distributions.\nTo facilitate learning, TODAY also annotates human explanations. We show that\nexisting models, including GPT-3, drop to random guessing on TODAY, suggesting\nthat they heavily rely on spurious information rather than proper reasoning for\ntemporal predictions. On the other hand, we show that TODAY's supervision style\nand explanation annotations can be used in joint learning and encourage models\nto use more appropriate signals during training and outperform across several\nbenchmarks. TODAY can also be used to train models to solicit incidental\nsupervision from noisy sources such as GPT-3 and moves farther towards generic\ntemporal reasoning systems.\n","authors":["Yu Feng","Ben Zhou","Haoyu Wang","Helen Jin","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2212.10467v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10466v1","updated":"2022-12-20T17:39:21Z","published":"2022-12-20T17:39:21Z","title":"Controllable Text Generation with Language Constraints","summary":"  We consider the task of text generation in language models with constraints\nspecified in natural language. To this end, we first create a challenging\nbenchmark Cognac that provides as input to the model a topic with example text,\nalong with a constraint on text to be avoided. Unlike prior work, our benchmark\ncontains knowledge-intensive constraints sourced from databases like Wordnet\nand Wikidata, which allows for straightforward evaluation while striking a\nbalance between broad attribute-level and narrow lexical-level controls. We\nfind that even state-of-the-art language models like GPT-3 fail often on this\ntask, and propose a solution to leverage a language model's own internal\nknowledge to guide generation. Our method, called CognacGen, first queries the\nlanguage model to generate guidance terms for a specified topic or constraint,\nand uses the guidance to modify the model's token generation probabilities. We\npropose three forms of guidance (binary verifier, top-k tokens, textual\nexample), and employ prefix-tuning approaches to distill the guidance to tackle\ndiverse natural language constraints. Through extensive empirical evaluations,\nwe demonstrate that CognacGen can successfully generalize to unseen\ninstructions and outperform competitive baselines in generating constraint\nconforming text.\n","authors":["Howard Chen","Huihan Li","Danqi Chen","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2212.10466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10465v1","updated":"2022-12-20T17:38:47Z","published":"2022-12-20T17:38:47Z","title":"SODA: Million-scale Dialogue Distillation with Social Commonsense\n  Contextualization","summary":"  We present SODA: the first publicly available, million-scale high-quality\nsocial dialogue dataset. Using SODA, we train COSMO: a generalizable\nconversation agent outperforming previous best-performing agents on both in-\nand out-of-domain datasets.\n  In contrast to most existing crowdsourced, small-scale dialogue corpora, we\ndistill 1.5M socially-grounded dialogues from a pre-trained language model\n(InstructGPT; Ouyang et al., 2022). Dialogues are distilled by contextualizing\nsocial commonsense knowledge from a knowledge graph (Atomic10x; West et al.,\n2022). Human evaluation shows that dialogues in SODA are more consistent,\nspecific, and (surprisingly) natural than prior human-authored datasets - e.g.,\nDailyDialog (Li et al., 2017), BlendedSkillTalk (Smith et al., 2020).\n  In addition, extensive evaluations show that COSMO is significantly more\nnatural and consistent on unseen datasets than best-performing dialogue models\n- e.g., GODEL (Peng et al., 2022), BlenderBot (Roller et al., 2021), DialoGPT\n(Zhang et al., 2020). Furthermore, it is sometimes even preferred to the\noriginal human-written gold responses. We make our data, models, and code\npublic.\n","authors":["Hyunwoo Kim","Jack Hessel","Liwei Jiang","Ximing Lu","Youngjae Yu","Pei Zhou","Ronan Le Bras","Malihe Alikhani","Gunhee Kim","Maarten Sap","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2212.10465v1.pdf","comment":"Dataset, models, and code can be found at https://hyunw.kim/sodaverse"},{"id":"http://arxiv.org/abs/2212.10461v1","updated":"2022-12-20T17:36:49Z","published":"2022-12-20T17:36:49Z","title":"Go-tuning: Improving Zero-shot Learning Abilities of Smaller Language\n  Models","summary":"  With increasing scale, large language models demonstrate both quantitative\nimprovement and new qualitative capabilities, especially as zero-shot learners,\nlike GPT-3. However, these results rely heavily on delicate prompt design and\nlarge computation. In this work, we explore whether the strong zero-shot\nability could be achieved at a smaller model scale without any external\nsupervised data. To achieve this goal, we revisit masked language modeling and\npresent a geometry-guided self-supervised learning method (Go-tuningfor short)\nby taking a small number of task-aware self-supervised data to update language\nmodels further. Experiments show that Go-tuning can enable T5-small (80M)\ncompetitive zero-shot results compared with large language models, such as\nT5-XL (3B). We also apply Go-tuning on multi-task settings and develop a\nmulti-task model, mgo-T5 (250M). It can reach the average performance of OPT\n(175B) on 9 datasets.\n","authors":["Jingjing Xu","Qingxiu Dong","Hongyi Liu","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2212.10461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10455v1","updated":"2022-12-20T17:34:25Z","published":"2022-12-20T17:34:25Z","title":"MULTI3NLU++: A Multilingual, Multi-Intent, Multi-Domain Dataset for\n  Natural Language Understanding in Task-Oriented Dialogue","summary":"  Task-oriented dialogue (TOD) systems have been applied in a range of domains\nto support human users to achieve specific goals. Systems are typically\nconstructed for a single domain or language and do not generalise well beyond\nthis. Their extension to other languages in particular is restricted by the\nlack of available training data for many of the world's languages. To support\nwork on Natural Language Understanding (NLU) in TOD across multiple languages\nand domains simultaneously, we constructed MULTI3NLU++, a multilingual,\nmulti-intent, multi-domain dataset. MULTI3NLU++ extends the English-only NLU++\ndataset to include manual translations into a range of high, medium and low\nresource languages (Spanish, Marathi, Turkish and Amharic), in two domains\n(banking and hotels). MULTI3NLU++ inherits the multi-intent property of NLU++,\nwhere an utterance may be labelled with multiple intents, providing a more\nrealistic representation of a user's goals and aligning with the more complex\ntasks that commercial systems aim to model. We use MULTI3NLU++ to benchmark\nstate-of-the-art multilingual language models as well as Machine Translation\nand Question Answering systems for the NLU task of intent detection for TOD\nsystems in the multilingual setting. The results demonstrate the challenging\nnature of the dataset, particularly in the low-resource language setting.\n","authors":["Nikita Moghe","Evgeniia Razumovskaia","Liane Guillou","Ivan Vulić","Anna Korhonen","Alexandra Birch"],"pdf_url":"https://arxiv.org/pdf/2212.10455v1.pdf","comment":"Release of Dataset v1"},{"id":"http://arxiv.org/abs/2212.10450v1","updated":"2022-12-20T17:28:41Z","published":"2022-12-20T17:28:41Z","title":"Is GPT-3 a Good Data Annotator?","summary":"  GPT-3 (Generative Pre-trained Transformer 3) is a large-scale autoregressive\nlanguage model developed by OpenAI, which has demonstrated impressive few-shot\nperformance on a wide range of natural language processing (NLP) tasks. Hence,\nan intuitive application is to use it for data annotation. In this paper, we\ninvestigate whether GPT-3 can be used as a good data annotator for NLP tasks.\nData annotation is the process of labeling data that could be used to train\nmachine learning models. It is a crucial step in the development of NLP\nsystems, as it allows the model to learn the relationship between the input\ndata and the desired output. Given the impressive language capabilities of\nGPT-3, it is natural to wonder whether it can be used to effectively annotate\ndata for NLP tasks. In this paper, we evaluate the performance of GPT-3 as a\ndata annotator by comparing it with traditional data annotation methods and\nanalyzing its output on a range of tasks. Through this analysis, we aim to\nprovide insight into the potential of GPT-3 as a general-purpose data annotator\nin NLP.\n","authors":["Bosheng Ding","Chengwei Qin","Linlin Liu","Lidong Bing","Shafiq Joty","Boyang Li"],"pdf_url":"https://arxiv.org/pdf/2212.10450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10449v1","updated":"2022-12-20T17:27:10Z","published":"2022-12-20T17:27:10Z","title":"Socratic Pretraining: Question-Driven Pretraining for Controllable\n  Summarization","summary":"  In long document controllable summarization, where labeled data is scarce,\npretrained models struggle to adapt to the task and effectively respond to user\nqueries. In this paper, we introduce Socratic pretraining, a question-driven,\nunsupervised pretraining objective specifically designed to improve\ncontrollability in summarization tasks. By training a model to generate and\nanswer relevant questions in a given context, Socratic pretraining enables the\nmodel to more effectively adhere to user-provided queries and identify relevant\ncontent to be summarized. We demonstrate the effectiveness of this approach\nthrough extensive experimentation on two summarization domains, short stories\nand dialogue, and multiple control strategies: keywords, questions, and factoid\nQA pairs. Our pretraining method relies only on unlabeled documents and a\nquestion generation system and outperforms pre-finetuning approaches that use\nadditional supervised data. Furthermore, our results show that Socratic\npretraining cuts task-specific labeled data requirements in half, is more\nfaithful to user-provided queries, and achieves state-of-the-art performance on\nQMSum and SQuALITY.\n","authors":["Artidoro Pagnoni","Alexander R. Fabbri","Wojciech Kryściński","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2212.10449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10448v1","updated":"2022-12-20T17:25:04Z","published":"2022-12-20T17:25:04Z","title":"Parameter-efficient Zero-shot Transfer for Cross-Language Dense\n  Retrieval with Adapters","summary":"  A popular approach to creating a zero-shot cross-language retrieval model is\nto substitute a monolingual pretrained language model in the retrieval model\nwith a multilingual pretrained language model such as Multilingual BERT. This\nmultilingual model is fined-tuned to the retrieval task with monolingual data\nsuch as English MS MARCO using the same training recipe as the monolingual\nretrieval model used. However, such transferred models suffer from mismatches\nin the languages of the input text during training and inference. In this work,\nwe propose transferring monolingual retrieval models using adapters, a\nparameter-efficient component for a transformer network. By adding adapters\npretrained on language tasks for a specific language with task-specific\nadapters, prior work has shown that the adapter-enhanced models perform better\nthan fine-tuning the entire model when transferring across languages in various\nNLP tasks. By constructing dense retrieval models with adapters, we show that\nmodels trained with monolingual data are more effective than fine-tuning the\nentire model when transferring to a Cross Language Information Retrieval (CLIR)\nsetting. However, we found that the prior suggestion of replacing the language\nadapters to match the target language at inference time is suboptimal for dense\nretrieval models. We provide an in-depth analysis of this discrepancy between\nother cross-language NLP tasks and CLIR.\n","authors":["Eugene Yang","Suraj Nair","Dawn Lawrie","James Mayfield","Douglas W. Oard"],"pdf_url":"https://arxiv.org/pdf/2212.10448v1.pdf","comment":"15 pages, 1 figure"},{"id":"http://arxiv.org/abs/2212.10440v1","updated":"2022-12-20T17:14:45Z","published":"2022-12-20T17:14:45Z","title":"Perplexed by Quality: A Perplexity-based Method for Adult and Harmful\n  Content Detection in Multilingual Heterogeneous Web Data","summary":"  As demand for large corpora increases with the size of current\nstate-of-the-art language models, using web data as the main part of the\npre-training corpus for these models has become a ubiquitous practice. This, in\nturn, has introduced an important challenge for NLP practitioners, as they are\nnow confronted with the task of developing highly optimized models and\npipelines for pre-processing large quantities of textual data, which implies,\neffectively classifying and filtering multilingual, heterogeneous and noisy\ndata, at web scale. One of the main components of this pre-processing step for\nthe pre-training corpora of large language models, is the removal of adult and\nharmful content. In this paper we explore different methods for detecting adult\nand harmful of content in multilingual heterogeneous web data. We first show\nhow traditional methods in harmful content detection, that seemingly perform\nquite well in small and specialized datasets quickly break down when confronted\nwith heterogeneous noisy web data. We then resort to using a perplexity based\napproach but with a twist: Instead of using a so-called \"clean\" corpus to train\na small language model and then use perplexity so select the documents with low\nperplexity, i.e., the documents that resemble this so-called \"clean\" corpus the\nmost. We train solely with adult and harmful textual data, and then select the\ndocuments having a perplexity value above a given threshold. This approach will\nvirtually cluster our documents into two distinct groups, which will greatly\nfacilitate the choice of the threshold for the perplexity and will also allow\nus to obtain higher precision than with the traditional classification methods\nfor detecting adult and harmful content.\n","authors":["Tim Jansen","Yangling Tong","Victoria Zevallos","Pedro Ortiz Suarez"],"pdf_url":"https://arxiv.org/pdf/2212.10440v1.pdf","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2212.10423v1","updated":"2022-12-20T17:00:36Z","published":"2022-12-20T17:00:36Z","title":"Fine-Grained Distillation for Long Document Retrieval","summary":"  Long document retrieval aims to fetch query-relevant documents from a\nlarge-scale collection, where knowledge distillation has become de facto to\nimprove a retriever by mimicking a heterogeneous yet powerful cross-encoder.\nHowever, in contrast to passages or sentences, retrieval on long documents\nsuffers from the scope hypothesis that a long document may cover multiple\ntopics. This maximizes their structure heterogeneity and poses a\ngranular-mismatch issue, leading to an inferior distillation efficacy. In this\nwork, we propose a new learning framework, fine-grained distillation (FGD), for\nlong-document retrievers. While preserving the conventional dense retrieval\nparadigm, it first produces global-consistent representations crossing\ndifferent fine granularity and then applies multi-granular aligned distillation\nmerely during training. In experiments, we evaluate our framework on two\nlong-document retrieval benchmarks, which show state-of-the-art performance.\n","authors":["Yucheng Zhou","Tao Shen","Xiubo Geng","Chongyang Tao","Guodong Long","Can Xu","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2212.10423v1.pdf","comment":"13 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2212.10422v1","updated":"2022-12-20T16:59:56Z","published":"2022-12-20T16:59:56Z","title":"Localising In-Domain Adaptation of Transformer-Based Biomedical Language\n  Models","summary":"  In the era of digital healthcare, the huge volumes of textual information\ngenerated every day in hospitals constitute an essential but underused asset\nthat could be exploited with task-specific, fine-tuned biomedical language\nrepresentation models, improving patient care and management. For such\nspecialized domains, previous research has shown that fine-tuning models\nstemming from broad-coverage checkpoints can largely benefit additional\ntraining rounds over large-scale in-domain resources. However, these resources\nare often unreachable for less-resourced languages like Italian, preventing\nlocal medical institutions to employ in-domain adaptation. In order to reduce\nthis gap, our work investigates two accessible approaches to derive biomedical\nlanguage models in languages other than English, taking Italian as a concrete\nuse-case: one based on neural machine translation of English resources,\nfavoring quantity over quality; the other based on a high-grade, narrow-scoped\ncorpus natively in Italian, thus preferring quality over quantity. Our study\nshows that data quantity is a harder constraint than data quality for\nbiomedical adaptation, but the concatenation of high-quality data can improve\nmodel performance even when dealing with relatively size-limited corpora. The\nmodels published from our investigations have the potential to unlock important\nresearch opportunities for Italian hospitals and academia. Finally, the set of\nlessons learned from the study constitutes valuable insights towards a solution\nto build biomedical language models that are generalizable to other\nless-resourced languages and different domain settings.\n","authors":["Tommaso Mario Buonocore","Claudio Crema","Enea Parimbelli","Alberto Redolfi","Riccardo Bellazzi"],"pdf_url":"https://arxiv.org/pdf/2212.10422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10409v1","updated":"2022-12-20T16:33:09Z","published":"2022-12-20T16:33:09Z","title":"Reinforced Clarification Question Generation with Defeasibility Rewards\n  for Disambiguating Social and Moral Situations","summary":"  Context is vital for commonsense moral reasoning. \"Lying to a friend\" is\nwrong if it is meant to deceive them, but may be morally okay if it is intended\nto protect them. Such nuanced but salient contextual information can\npotentially flip the moral judgment of an action. Thus, we present\nClarifyDelphi, an interactive system that elicits missing contexts of a moral\nsituation by generating clarification questions such as \"Why did you lie to\nyour friend?\". Our approach is inspired by the observation that questions whose\npotential answers lead to diverging moral judgments are the most informative.\nWe learn to generate questions using Reinforcement Learning, by maximizing the\ndivergence between moral judgements of hypothetical answers to a question.\nHuman evaluation shows that our system generates more relevant, informative and\ndefeasible questions compared to other question generation baselines.\nClarifyDelphi assists informed moral reasoning processes by seeking additional\nmorally consequential context to disambiguate social and moral situations.\n","authors":["Valentina Pyatkin","Jena D. Hwang","Vivek Srikumar","Ximing Lu","Liwei Jiang","Yejin Choi","Chandra Bhagavatula"],"pdf_url":"https://arxiv.org/pdf/2212.10409v1.pdf","comment":"9 pages + bibliography + appendix"},{"id":"http://arxiv.org/abs/2212.10408v1","updated":"2022-12-20T16:32:54Z","published":"2022-12-20T16:32:54Z","title":"Geographic and Geopolitical Biases of Language Models","summary":"  Pretrained language models (PLMs) often fail to fairly represent target users\nfrom certain world regions because of the under-representation of those regions\nin training datasets. With recent PLMs trained on enormous data sources,\nquantifying their potential biases is difficult, due to their black-box nature\nand the sheer scale of the data sources. In this work, we devise an approach to\nstudy the geographic bias (and knowledge) present in PLMs, proposing a\nGeographic-Representation Probing Framework adopting a self-conditioning method\ncoupled with entity-country mappings. Our findings suggest PLMs'\nrepresentations map surprisingly well to the physical world in terms of\ncountry-to-country associations, but this knowledge is unequally shared across\nlanguages. Last, we explain how large PLMs despite exhibiting notions of\ngeographical proximity, over-amplify geopolitical favouritism at inference\ntime.\n","authors":["Fahim Faisal","Antonios Anastasopoulos"],"pdf_url":"https://arxiv.org/pdf/2212.10408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10405v1","updated":"2022-12-20T16:30:11Z","published":"2022-12-20T16:30:11Z","title":"AnnoBERT: Effectively Representing Multiple Annotators' Label Choices to\n  Improve Hate Speech Detection","summary":"  Supervised approaches generally rely on majority-based labels. However, it is\nhard to achieve high agreement among annotators in subjective tasks such as\nhate speech detection. Existing neural network models principally regard labels\nas categorical variables, while ignoring the semantic information in diverse\nlabel texts. In this paper, we propose AnnoBERT, a first-of-its-kind\narchitecture integrating annotator characteristics and label text with a\ntransformer-based model to detect hate speech, with unique representations\nbased on each annotator's characteristics via Collaborative Topic Regression\n(CTR) and integrate label text to enrich textual representations. During\ntraining, the model associates annotators with their label choices given a\npiece of text; during evaluation, when label information is not available, the\nmodel predicts the aggregated label given by the participating annotators by\nutilising the learnt association. The proposed approach displayed an advantage\nin detecting hate speech, especially in the minority class and edge cases with\nannotator disagreement. Improvement in the overall performance is the largest\nwhen the dataset is more label-imbalanced, suggesting its practical value in\nidentifying real-world hate speech, as the volume of hate speech in-the-wild is\nextremely small on social media, when compared with normal (non-hate) speech.\nThrough ablation studies, we show the relative contributions of annotator\nembeddings and label text to the model performance, and tested a range of\nalternative annotator embeddings and label text combinations.\n","authors":["Wenjie Yin","Vibhor Agarwal","Aiqi Jiang","Arkaitz Zubiaga","Nishanth Sastry"],"pdf_url":"https://arxiv.org/pdf/2212.10405v1.pdf","comment":"accepted at ICWSM 2023"},{"id":"http://arxiv.org/abs/2212.10403v1","updated":"2022-12-20T16:29:03Z","published":"2022-12-20T16:29:03Z","title":"Towards Reasoning in Large Language Models: A Survey","summary":"  Reasoning is a fundamental aspect of human intelligence that plays a crucial\nrole in activities such as problem solving, decision making, and critical\nthinking. In recent years, large language models (LLMs) have made significant\nprogress in natural language processing, and there is observation that these\nmodels may exhibit reasoning abilities when they are sufficiently large.\nHowever, it is not yet clear to what extent LLMs are capable of reasoning. This\npaper provides a comprehensive overview of the current state of knowledge on\nreasoning in LLMs, including techniques for improving and eliciting reasoning\nin these models, methods and benchmarks for evaluating reasoning abilities,\nfindings and implications of previous research in this field, and suggestions\non future directions. Our aim is to provide a detailed and up-to-date review of\nthis topic and stimulate meaningful discussion and future work.\n","authors":["Jie Huang","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10400v1","updated":"2022-12-20T16:26:18Z","published":"2022-12-20T16:26:18Z","title":"Contrastive Learning Reduces Hallucination in Conversations","summary":"  Pre-trained language models (LMs) store knowledge in their parameters and can\ngenerate informative responses when used in conversational systems. However,\nLMs suffer from the problem of \"hallucination:\" they may generate\nplausible-looking statements that are irrelevant or factually incorrect. To\naddress this problem, we propose a contrastive learning scheme, named MixCL. A\nnovel mixed contrastive objective is proposed to explicitly optimize the\nimplicit knowledge elicitation process of LMs, and thus reduce their\nhallucination in conversations. We also examine negative sampling strategies of\nretrieved hard negatives and model-generated negatives. We conduct experiments\non Wizard-of-Wikipedia, a public, open-domain knowledge-grounded dialogue\nbenchmark, and assess the effectiveness of MixCL. MixCL effectively reduces the\nhallucination of LMs in conversations and achieves the highest performance\namong LM-based dialogue agents in terms of relevancy and factuality. We show\nthat MixCL achieves comparable performance to state-of-the-art KB-based\napproaches while enjoying notable advantages in terms of efficiency and\nscalability.\n","authors":["Weiwei Sun","Zhengliang Shi","Shen Gao","Pengjie Ren","Maarten de Rijke","Zhaochun Ren"],"pdf_url":"https://arxiv.org/pdf/2212.10400v1.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2212.10397v1","updated":"2022-12-20T16:25:42Z","published":"2022-12-20T16:25:42Z","title":"Needle in a Haystack: An Analysis of Finding Qualified Workers on MTurk\n  for Summarization","summary":"  The acquisition of high-quality human annotations through crowdsourcing\nplatforms like Amazon Mechanical Turk (MTurk) is more challenging than\nexpected. The annotation quality might be affected by various aspects like\nannotation instructions, Human Intelligence Task (HIT) design, and wages paid\nto annotators, etc. To avoid potentially low-quality annotations which could\nmislead the evaluation of automatic summarization system outputs, we\ninvestigate the recruitment of high-quality MTurk workers via a three-step\nqualification pipeline. We show that we can successfully filter out bad workers\nbefore they carry out the evaluations and obtain high-quality annotations while\noptimizing the use of resources. This paper can serve as basis for the\nrecruitment of qualified annotators in other challenging annotation tasks.\n","authors":["Lining Zhang","João Sedoc","Simon Mille","Yufang Hou","Sebastian Gehrmann","Daniel Deutsch","Elizabeth Clark","Yixin Liu","Miruna Clinciu","Saad Mahamood","Khyathi Chandu"],"pdf_url":"https://arxiv.org/pdf/2212.10397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10392v1","updated":"2022-12-20T16:20:56Z","published":"2022-12-20T16:20:56Z","title":"Debiasing Stance Detection Models with Counterfactual Reasoning and\n  Adversarial Bias Learning","summary":"  Stance detection models may tend to rely on dataset bias in the text part as\na shortcut and thus fail to sufficiently learn the interaction between the\ntargets and texts. Recent debiasing methods usually treated features learned by\nsmall models or big models at earlier steps as bias features and proposed to\nexclude the branch learning those bias features during inference. However, most\nof these methods fail to disentangle the ``good'' stance features and ``bad''\nbias features in the text part. In this paper, we investigate how to mitigate\ndataset bias in stance detection. Motivated by causal effects, we leverage a\nnovel counterfactual inference framework, which enables us to capture the\ndataset bias in the text part as the direct causal effect of the text on\nstances and reduce the dataset bias in the text part by subtracting the direct\ntext effect from the total causal effect. We novelly model bias features as\nfeatures that correlate with the stance labels but fail on intermediate stance\nreasoning subtasks and propose an adversarial bias learning module to model the\nbias more accurately. To verify whether our model could better model the\ninteraction between texts and targets, we test our model on recently proposed\ntest sets to evaluate the understanding of the task from various aspects.\nExperiments demonstrate that our proposed method (1) could better model the\nbias features, and (2) outperforms existing debiasing baselines on both the\noriginal dataset and most of the newly constructed test sets.\n","authors":["Jianhua Yuan","Yanyan Zhao","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2212.10392v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2212.10391v1","updated":"2022-12-20T16:18:03Z","published":"2022-12-20T16:18:03Z","title":"TeSS: Zero-Shot Classification via Textual Similarity Comparison with\n  Prompting using Sentence Encoder","summary":"  We introduce TeSS (Text Similarity Comparison using Sentence Encoder), a\nframework for zero-shot classification where the assigned label is determined\nby the embedding similarity between the input text and each candidate label\nprompt. We leverage representations from sentence encoders optimized to locate\nsemantically similar samples closer to each other in embedding space during\npre-training. The label prompt embeddings serve as prototypes of their\ncorresponding class clusters. Furthermore, to compensate for the potentially\npoorly descriptive labels in their original format, we retrieve semantically\nsimilar sentences from external corpora and additionally use them with the\noriginal label prompt (TeSS-R). TeSS outperforms strong baselines on various\nclosed-set and open-set classification datasets under zero-shot setting, with\nfurther gains when combined with label prompt diversification through\nretrieval. These results are robustly attained to verbalizer variations, an\nancillary benefit of using a bi-encoder. Altogether, our method serves as a\nreliable baseline for zero-shot classification and a simple interface to assess\nthe quality of sentence encoders.\n","authors":["Jimin Hong","Jungsoo Park","Daeyoung Kim","Seongjae Choi","Bokyung Son","Jaewook Kang"],"pdf_url":"https://arxiv.org/pdf/2212.10391v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.08597v2","updated":"2022-12-20T16:11:02Z","published":"2022-12-16T17:24:49Z","title":"Detecting and Mitigating Hallucinations in Machine Translation: Model\n  Internal Workings Alone Do Well, Sentence Similarity Even Better","summary":"  While the problem of hallucinations in neural machine translation has long\nbeen recognized, so far the progress on its alleviation is very little. Indeed,\nrecently it turned out that without artificially encouraging models to\nhallucinate, previously existing methods fall short and even the standard\nsequence log-probability is more informative. It means that characteristics\ninternal to the model can give much more information than we expect, and before\nusing external models and measures, we first need to ask: how far can we go if\nwe use nothing but the translation model itself ? We propose to use a method\nthat evaluates the percentage of the source contribution to a generated\ntranslation. Intuitively, hallucinations are translations \"detached\" from the\nsource, hence they can be identified by low source contribution. This method\nimproves detection accuracy for the most severe hallucinations by a factor of 2\nand is able to alleviate hallucinations at test time on par with the previous\nbest approach that relies on external models. Next, if we move away from\ninternal model characteristics and allow external tools, we show that using\nsentence similarity from cross-lingual embeddings further improves these\nresults.\n","authors":["David Dale","Elena Voita","Loïc Barrault","Marta R. Costa-jussà"],"pdf_url":"https://arxiv.org/pdf/2212.08597v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10381v1","updated":"2022-12-20T16:06:09Z","published":"2022-12-20T16:06:09Z","title":"To Adapt or to Annotate: Challenges and Interventions for Domain\n  Adaptation in Open-Domain Question Answering","summary":"  Recent advances in open-domain question answering (ODQA) have demonstrated\nimpressive accuracy on standard Wikipedia style benchmarks. However, it is less\nclear how robust these models are and how well they perform when applied to\nreal-world applications in drastically different domains. While there has been\nsome work investigating how well ODQA models perform when tested for\nout-of-domain (OOD) generalization, these studies have been conducted only\nunder conservative shifts in data distribution and typically focus on a single\ncomponent (ie. retrieval) rather than an end-to-end system. In response, we\npropose a more realistic and challenging domain shift evaluation setting and,\nthrough extensive experiments, study end-to-end model performance. We find that\nnot only do models fail to generalize, but high retrieval scores often still\nyield poor answer prediction accuracy. We then categorize different types of\nshifts and propose techniques that, when presented with a new dataset, predict\nif intervention methods are likely to be successful. Finally, using insights\nfrom this analysis, we propose and evaluate several intervention methods which\nimprove end-to-end answer F1 score by up to 24 points.\n","authors":["Dheeru Dua","Emma Strubell","Sameer Singh","Pat Verga"],"pdf_url":"https://arxiv.org/pdf/2212.10381v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08073v2","updated":"2022-12-20T16:03:56Z","published":"2022-11-15T11:53:55Z","title":"GLUE-X: Evaluating Natural Language Understanding Models from an\n  Out-of-distribution Generalization Perspective","summary":"  Pre-trained language models (PLMs) are known to improve the generalization\nperformance of natural language understanding models by leveraging large\namounts of data during the pre-training phase. However, the out-of-distribution\n(OOD) generalization problem remains a challenge in many NLP tasks, limiting\nthe real-world deployment of these methods. This paper presents the first\nattempt at creating a unified benchmark named GLUE-X for evaluating OOD\nrobustness in NLP models, highlighting the importance of OOD robustness and\nproviding insights on how to measure the robustness of a model and how to\nimprove it. The benchmark includes 13 publicly available datasets for OOD\ntesting, and evaluations are conducted on 8 classic NLP tasks over 19 popularly\nused PLMs. Our findings confirm the need for improved OOD accuracy in NLP\ntasks, as significant performance degradation was observed in all settings\ncompared to in-distribution (ID) accuracy.\n","authors":["Linyi Yang","Shuibai Zhang","Libo Qin","Yafu Li","Yidong Wang","Hanmeng Liu","Jindong Wang","Xing Xie","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.08073v2.pdf","comment":"17 pages, GLUE-X, OOD Generalization"},{"id":"http://arxiv.org/abs/2212.10380v1","updated":"2022-12-20T16:03:25Z","published":"2022-12-20T16:03:25Z","title":"What Are You Token About? Dense Retrieval as Distributions Over the\n  Vocabulary","summary":"  Dual encoders are now the dominant architecture for dense retrieval. Yet, we\nhave little understanding of how they represent text, and why this leads to\ngood performance. In this work, we shed light on this question via\ndistributions over the vocabulary. We propose to interpret the vector\nrepresentations produced by dual encoders by projecting them into the model's\nvocabulary space. We show that the resulting distributions over vocabulary\ntokens are intuitive and contain rich semantic information. We find that this\nview can explain some of the failure cases of dense retrievers. For example,\nthe inability of models to handle tail entities can be explained via a tendency\nof the token distributions to forget some of the tokens of those entities. We\nleverage this insight and propose a simple way to enrich query and passage\nrepresentations with lexical information at inference time, and show that this\nsignificantly improves performance compared to the original model in\nout-of-domain settings.\n","authors":["Ori Ram","Liat Bezalel","Adi Zicher","Yonatan Belinkov","Jonathan Berant","Amir Globerson"],"pdf_url":"https://arxiv.org/pdf/2212.10380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10378v1","updated":"2022-12-20T15:58:54Z","published":"2022-12-20T15:58:54Z","title":"Careful Data Curation Stabilizes In-context Learning","summary":"  In-context learning (ICL) enables large language models (LLMs) to perform new\ntasks by prompting them with a sequence of training examples. However, ICL is\nvery sensitive to the choice of training examples: randomly sampling examples\nfrom a training set leads to high variance in performance. In this paper, we\nshow that curating a carefully chosen subset of training data greatly\nstabilizes ICL performance. We propose two methods to choose training subsets,\nboth of which score training examples individually and then select the\nhighest-scoring ones. CondAcc scores a training example by its average ICL\naccuracy when combined with random training examples, while Datamodels learns a\nlinear proxy model that estimates how the presence of each training example\ninfluences LLM accuracy. On average, CondAcc and Datamodels outperform sampling\nfrom the entire training set by 7.7% and 6.3%, respectively, across 5 tasks and\ntwo LLMs. Our analysis shows that stable subset examples are no more diverse\nthan average, and are not outliers in terms of sequence length and perplexity.\n","authors":["Ting-Yun Chang","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2212.10378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10375v1","updated":"2022-12-20T15:55:21Z","published":"2022-12-20T15:55:21Z","title":"Self-adaptive In-context Learning","summary":"  Despite the surprising few-shot performance of in-context learning (ICL), it\nis still a common practice to randomly sample examples to serve as context.\nThis paper advocates a new principle for ICL: self-adaptive in-context\nlearning. The self-adaption mechanism is introduced to help each sample find an\nin-context example permutation (i.e., selection and ordering) that can derive\nthe correct prediction, thus maximizing performance. To validate the\neffectiveness of self-adaptive ICL, we propose a general select-then-rank\nframework and instantiate it with new selection and ranking algorithms. Upon\nextensive evaluation on eight different NLP datasets, our self-adaptive ICL\nmethod achieves a 40% relative improvement over the common practice setting.\nFurther analysis reveals the enormous potential of self-adaptive ICL that it\nmight be able to close the gap between ICL and finetuning given more advanced\nalgorithms. Our code is released to facilitate future research in this area:\nhttps://github.com/Shark-NLP/self-adaptive-ICL\n","authors":["Zhiyong Wu","Yaoxiang Wang","Jiacheng Ye","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2212.10375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10356v1","updated":"2022-12-20T15:40:17Z","published":"2022-12-20T15:40:17Z","title":"Receptive Field Alignment Enables Transformer Length Extrapolation","summary":"  Length extrapolation is a desirable property that permits training a\ntransformer language model on short sequences and retaining similar\nperplexities when the model is tested on substantially longer sequences. A\nrelative positional embedding mechanism applied on the transformer\nself-attention matrix, ALiBi, demonstrates the length extrapolation property\nwith the widest usage to date. In this paper, we show that ALiBi surprisingly\ndoes not utilize tokens further than the training sequence length, which can be\nexplained by its implicit windowed attention effect that aligns the receptive\nfield during training and testing stages. Inspired by ALiBi and the receptive\nfiled alignment hypothesis, we propose another transformer positional embedding\ndesign named~\\textbf{Sandwich} that uses longer than training sequence length\ninformation, and it is a greatly simplified formulation of the earliest\nproposed Sinusoidal positional embedding. Finally, we show that both ALiBi and\nSandwich enable efficient inference thanks to their implicit windowed attention\neffect.\n","authors":["Ta-Chung Chi","Ting-Han Fan","Alexander I. Rudnicky"],"pdf_url":"https://arxiv.org/pdf/2212.10356v1.pdf","comment":"Work In progress"},{"id":"http://arxiv.org/abs/2212.10346v1","updated":"2022-12-20T15:31:58Z","published":"2022-12-20T15:31:58Z","title":"Does It Affect You? Social and Learning Implications of Using\n  Cognitive-Affective State Recognition for Proactive Human-Robot Tutoring","summary":"  Using robots in educational contexts has already shown to be beneficial for a\nstudent's learning and social behaviour. For levitating them to the next level\nof providing more effective and human-like tutoring, the ability to adapt to\nthe user and to express proactivity is fundamental. By acting proactively,\nintelligent robotic tutors anticipate possible situations where problems for\nthe student may arise and act in advance for preventing negative outcomes.\nStill, the decisions of when and how to behave proactively are open questions.\nTherefore, this paper deals with the investigation of how the student's\ncognitive-affective states can be used by a robotic tutor for triggering\nproactive tutoring dialogue. In doing so, it is aimed to improve the learning\nexperience. For this reason, a concept learning task scenario was observed\nwhere a robotic assistant proactively helped when negative user states were\ndetected. In a learning task, the user's states of frustration and confusion\nwere deemed to have negative effects on the outcome of the task and were used\nto trigger proactive behaviour. In an empirical user study with 40\nundergraduate and doctoral students, we studied whether the initiation of\nproactive behaviour after the detection of signs of confusion and frustration\nimproves the student's concentration and trust in the agent. Additionally, we\ninvestigated which level of proactive dialogue is useful for promoting the\nstudent's concentration and trust. The results show that high proactive\nbehaviour harms trust, especially when triggered during negative\ncognitive-affective states but contributes to keeping the student focused on\nthe task when triggered in these states. Based on our study results, we further\ndiscuss future steps for improving the proactive assistance of robotic tutoring\nsystems.\n","authors":["Matthias Kraus","Diana Betancourt","Wolfgang Minker"],"pdf_url":"https://arxiv.org/pdf/2212.10346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10341v1","updated":"2022-12-20T15:26:19Z","published":"2022-12-20T15:26:19Z","title":"CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Data\n  Limitation With Contrastive Learning","summary":"  Machine-Generated Text (MGT) detection, a task that discriminates MGT from\nHuman-Written Text (HWT), plays a crucial role in preventing misuse of text\ngenerative models, which excel in mimicking human writing style recently.\nLatest proposed detectors usually take coarse text sequence as input and output\nsome good results by fine-tune pretrained models with standard cross-entropy\nloss. However, these methods fail to consider the linguistic aspect of text\n(e.g., coherence) and sentence-level structures. Moreover, they lack the\nability to handle the low-resource problem which could often happen in practice\nconsidering the enormous amount of textual data online. In this paper, we\npresent a coherence-based contrastive learning model named CoCo to detect the\npossible MGT under low-resource scenario. Inspired by the distinctiveness and\npermanence properties of linguistic feature, we represent text as a coherence\ngraph to capture its entity consistency, which is further encoded by the\npretrained model and graph neural network. To tackle the challenges of data\nlimitations, we employ a contrastive learning framework and propose an improved\ncontrastive loss for making full use of hard negative samples in training\nstage. The experiment results on two public datasets prove our approach\noutperforms the state-of-art methods significantly.\n","authors":["Xiaoming Liu","Zhaohan Zhang","Yichen Wang","Yu Lan","Chao Shen"],"pdf_url":"https://arxiv.org/pdf/2212.10341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10325v1","updated":"2022-12-20T15:16:24Z","published":"2022-12-20T15:16:24Z","title":"SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers","summary":"  Diffusion model, a new generative modelling paradigm, has achieved great\nsuccess in image, audio, and video generation. However, considering the\ndiscrete categorical nature of text, it is not trivial to extend continuous\ndiffusion models to natural language, and text diffusion models are less\nstudied. Sequence-to-sequence text generation is one of the essential natural\nlanguage processing topics. In this work, we apply diffusion models to approach\nsequence-to-sequence text generation, and explore whether the superiority\ngeneration performance of diffusion model can transfer to natural language\ndomain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence\ngeneration. SeqDiffuSeq uses an encoder-decoder Transformers architecture to\nmodel denoising function. In order to improve generation quality, SeqDiffuSeq\ncombines the self-conditioning technique and a newly proposed adaptive noise\nschedule technique. The adaptive noise schedule has the difficulty of denoising\nevenly distributed across time steps, and considers exclusive noise schedules\nfor tokens at different positional order. Experiment results illustrate the\ngood performance on sequence-to-sequence generation in terms of text quality\nand inference time.\n","authors":["Hongyi Yuan","Zheng Yuan","Chuanqi Tan","Fei Huang","Songfang Huang"],"pdf_url":"https://arxiv.org/pdf/2212.10325v1.pdf","comment":"Working in progress; 9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2212.10315v1","updated":"2022-12-20T15:07:37Z","published":"2022-12-20T15:07:37Z","title":"HINT: Hypernetwork Instruction Tuning for Efficient Zero-Shot\n  Generalisation","summary":"  Recent NLP models have the great ability to generalise `zero-shot' to new\ntasks using only an instruction as guidance. However, these approaches usually\nrepeat their instructions with every input, requiring costly reprocessing of\nlengthy instructions for every inference example. To alleviate this, we\nintroduce Hypernetworks for INstruction Tuning (HINT), which convert task\ninstructions and examples using a pretrained text encoder into\nparameter-efficient modules inserted into an underlying model, eliminating the\nneed to include instructions in the model input. Compared to prior approaches\nthat concatenate instructions with every input instance, we find that HINT\nmodels are significantly more compute-efficient and consistently outperform\nthese approaches for a given inference budget.\n","authors":["Hamish Ivison","Akshita Bhagia","Yizhong Wang","Hannaneh Hajishirzi","Matthew Peters"],"pdf_url":"https://arxiv.org/pdf/2212.10315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10313v1","updated":"2022-12-20T15:02:38Z","published":"2022-12-20T15:02:38Z","title":"Beyond Triplet: Leveraging the Most Data for Multimodal Machine\n  Translation","summary":"  Multimodal machine translation (MMT) aims to improve translation quality by\nincorporating information from other modalities, such as vision. Previous MMT\nsystems mainly focus on better access and use of visual information and tend to\nvalidate their methods on image-related datasets. These studies face two\nchallenges. First, they can only utilize triple data (bilingual texts with\nimages), which is scarce; second, current benchmarks are relatively restricted\nand do not correspond to realistic scenarios. Therefore, this paper\ncorrespondingly establishes new methods and new datasets for MMT. First, we\npropose a framework 2/3-Triplet with two new approaches to enhance MMT by\nutilizing large-scale non-triple data: monolingual image-text data and parallel\ntext-only data. Second, we construct an English-Chinese {e}-commercial\n{m}ulti{m}odal {t}ranslation dataset (including training and testing), named\nEMMT, where its test set is carefully selected as some words are ambiguous and\nshall be translated mistakenly without the help of images. Experiments show\nthat our method is more suitable for real-world scenarios and can significantly\nimprove translation performance by using more non-triple data. In addition, our\nmodel also rivals various SOTA models in conventional multimodal translation\nbenchmarks.\n","authors":["Yaoming Zhu","Zewei Sun","Shanbo Cheng","Yuyang Huang","Liwei Wu","Mingxuan Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10313v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2212.10297v1","updated":"2022-12-20T14:39:58Z","published":"2022-12-20T14:39:58Z","title":"Extrinsic Evaluation of Machine Translation Metrics","summary":"  Automatic machine translation (MT) metrics are widely used to distinguish the\ntranslation qualities of machine translation systems across relatively large\ntest sets (system-level evaluation). However, it is unclear if automatic\nmetrics are reliable at distinguishing good translations from bad translations\nat the sentence level (segment-level evaluation). In this paper, we investigate\nhow useful MT metrics are at detecting the success of a machine translation\ncomponent when placed in a larger platform with a downstream task. We evaluate\nthe segment-level performance of the most widely used MT metrics (chrF, COMET,\nBERTScore, etc.) on three downstream cross-lingual tasks (dialogue state\ntracking, question answering, and semantic parsing). For each task, we only\nhave access to a monolingual task-specific model. We calculate the correlation\nbetween the metric's ability to predict a good/bad translation with the\nsuccess/failure on the final task for the Translate-Test setup. Our experiments\ndemonstrate that all metrics exhibit negligible correlation with the extrinsic\nevaluation of the downstream outcomes. We also find that the scores provided by\nneural metrics are not interpretable mostly because of undefined ranges. Our\nanalysis suggests that future MT metrics be designed to produce error labels\nrather than scores to facilitate extrinsic evaluation.\n","authors":["Nikita Moghe","Tom Sherborne","Mark Steedman","Alexandra Birch"],"pdf_url":"https://arxiv.org/pdf/2212.10297v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2212.00715v2","updated":"2022-12-20T14:29:43Z","published":"2022-12-01T18:21:36Z","title":"What do you MEME? Generating Explanations for Visual Semantic Role\n  Labelling in Memes","summary":"  Memes are powerful means for effective communication on social media. Their\neffortless amalgamation of viral visuals and compelling messages can have\nfar-reaching implications with proper marketing. Previous research on memes has\nprimarily focused on characterizing their affective spectrum and detecting\nwhether the meme's message insinuates any intended harm, such as hate, offense,\nracism, etc. However, memes often use abstraction, which can be elusive. Here,\nwe introduce a novel task - EXCLAIM, generating explanations for visual\nsemantic role labeling in memes. To this end, we curate ExHVV, a novel dataset\nthat offers natural language explanations of connotative roles for three types\nof entities - heroes, villains, and victims, encompassing 4,680 entities\npresent in 3K memes. We also benchmark ExHVV with several strong unimodal and\nmultimodal baselines. Moreover, we posit LUMEN, a novel multimodal, multi-task\nlearning framework that endeavors to address EXCLAIM optimally by jointly\nlearning to predict the correct semantic roles and correspondingly to generate\nsuitable natural language explanations. LUMEN distinctly outperforms the best\nbaseline across 18 standard natural language generation evaluation metrics. Our\nsystematic evaluation and analyses demonstrate that characteristic multimodal\ncues required for adjudicating semantic roles are also helpful for generating\nsuitable explanations.\n","authors":["Shivam Sharma","Siddhant Agarwal","Tharun Suresh","Preslav Nakov","Md. Shad Akhtar","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2212.00715v2.pdf","comment":"Accepted at AAAI 2023 (Main Track). 7 Pages (main content) + 2 Pages\n  (Refs.); 3 Figures; 6 Tables; Paper ID: 10326 (AAAI'23)"},{"id":"http://arxiv.org/abs/2209.11534v2","updated":"2022-12-20T14:13:12Z","published":"2022-09-23T11:47:37Z","title":"An Interdisciplinary Perspective on Evaluation and Experimental Design\n  for Visual Text Analytics: Position Paper","summary":"  Appropriate evaluation and experimental design are fundamental for empirical\nsciences, particularly in data-driven fields. Due to the successes in\ncomputational modeling of languages, for instance, research outcomes are having\nan increasingly immediate impact on end users. As the gap in adoption by end\nusers decreases, the need increases to ensure that tools and models developed\nby the research communities and practitioners are reliable, trustworthy, and\nsupportive of the users in their goals. In this position paper, we focus on the\nissues of evaluating visual text analytics approaches. We take an\ninterdisciplinary perspective from the visualization and natural language\nprocessing communities, as we argue that the design and validation of visual\ntext analytics include concerns beyond computational or visual/interactive\nmethods on their own. We identify four key groups of challenges for evaluating\nvisual text analytics approaches (data ambiguity, experimental design, user\ntrust, and \"big picture\" concerns) and provide suggestions for research\nopportunities from an interdisciplinary perspective.\n","authors":["Kostiantyn Kucher","Nicole Sultanum","Angel Daza","Vasiliki Simaki","Maria Skeppstedt","Barbara Plank","Jean-Daniel Fekete","Narges Mahyar"],"pdf_url":"https://arxiv.org/pdf/2209.11534v2.pdf","comment":"Published in Proceedings of the 2022 IEEE Workshop on Evaluation and\n  Beyond - Methodological Approaches to Visualization (BELIV '22). ACM 2012\n  CCS: Human-centered computing, Visualization, Visualization design and\n  evaluation methods"},{"id":"http://arxiv.org/abs/2212.10264v1","updated":"2022-12-20T14:11:31Z","published":"2022-12-20T14:11:31Z","title":"ReCode: Robustness Evaluation of Code Generation Models","summary":"  Code generation models have achieved impressive performance. However, they\ntend to be brittle as slight edits to a prompt could lead to very different\ngenerations; these robustness properties, critical for user experience when\ndeployed in real-life applications, are not well understood. Most existing\nworks on robustness in text or code tasks have focused on classification, while\nrobustness in generation tasks is an uncharted area and to date there is no\ncomprehensive benchmark for robustness in code generation. In this paper, we\npropose ReCode, a comprehensive robustness evaluation benchmark for code\ngeneration models. We customize over 30 transformations specifically for code\non docstrings, function and variable names, code syntax, and code format. They\nare carefully designed to be natural in real-life coding practice, preserve the\noriginal semantic meaning, and thus provide multifaceted assessments of a\nmodel's robustness performance. With human annotators, we verified that over\n90% of the perturbed prompts do not alter the semantic meaning of the original\nprompt. In addition, we define robustness metrics for code generation models\nconsidering the worst-case behavior under each type of perturbation, taking\nadvantage of the fact that executing the generated code can serve as objective\nevaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well\nas function completion tasks derived from them. Interesting observations\ninclude: better robustness for CodeGen over InCoder and GPT-J; models are most\nsensitive to syntax perturbations; more challenging robustness evaluation on\nMBPP over HumanEval.\n","authors":["Shiqi Wang","Zheng Li","Haifeng Qian","Chenghao Yang","Zijian Wang","Mingyue Shang","Varun Kumar","Samson Tan","Baishakhi Ray","Parminder Bhatia","Ramesh Nallapati","Murali Krishna Ramanathan","Dan Roth","Bing Xiang"],"pdf_url":"https://arxiv.org/pdf/2212.10264v1.pdf","comment":"Code and data available at https://github.com/amazon-science/recode"},{"id":"http://arxiv.org/abs/2212.10258v1","updated":"2022-12-20T14:06:50Z","published":"2022-12-20T14:06:50Z","title":"In and Out-of-Domain Text Adversarial Robustness via Label Smoothing","summary":"  Recently it has been shown that state-of-the-art NLP models are vulnerable to\nadversarial attacks, where the predictions of a model can be drastically\naltered by slight modifications to the input (such as synonym substitutions).\nWhile several defense techniques have been proposed, and adapted, to the\ndiscrete nature of text adversarial attacks, the benefits of general-purpose\nregularization methods such as label smoothing for language models, have not\nbeen studied. In this paper, we study the adversarial robustness provided by\nvarious label smoothing strategies in foundational models for diverse NLP tasks\nin both in-domain and out-of-domain settings. Our experiments show that label\nsmoothing significantly improves adversarial robustness in pre-trained models\nlike BERT, against various popular attacks. We also analyze the relationship\nbetween prediction confidence and robustness, showing that label smoothing\nreduces over-confident errors on adversarial examples.\n","authors":["Yahan Yang","Soham Dan","Dan Roth","Insup Lee"],"pdf_url":"https://arxiv.org/pdf/2212.10258v1.pdf","comment":"Preprint. Under Submission"},{"id":"http://arxiv.org/abs/2212.10257v1","updated":"2022-12-20T14:06:45Z","published":"2022-12-20T14:06:45Z","title":"Original or Translated? On the Use of Parallel Data for Translation\n  Quality Estimation","summary":"  Machine Translation Quality Estimation (QE) is the task of evaluating\ntranslation output in the absence of human-written references. Due to the\nscarcity of human-labeled QE data, previous works attempted to utilize the\nabundant unlabeled parallel corpora to produce additional training data with\npseudo labels. In this paper, we demonstrate a significant gap between parallel\ndata and real QE data: for QE data, it is strictly guaranteed that the source\nside is original texts and the target side is translated (namely\ntranslationese). However, for parallel data, it is indiscriminate and the\ntranslationese may occur on either source or target side. We compare the impact\nof parallel data with different translation directions in QE data augmentation,\nand find that using the source-original part of parallel corpus consistently\noutperforms its target-original counterpart. Moreover, since the WMT corpus\nlacks direction information for each parallel sentence, we train a classifier\nto distinguish source- and target-original bitext, and carry out an analysis of\ntheir difference in both style and domain. Together, these findings suggest\nusing source-original parallel data for QE data augmentation, which brings a\nrelative improvement of up to 4.0% and 6.4% compared to undifferentiated data\non sentence- and word-level QE tasks respectively.\n","authors":["Baopu Qiu","Liang Ding","Di Wu","Lin Shang","Yibing Zhan","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2212.10257v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2212.10240v1","updated":"2022-12-20T13:36:25Z","published":"2022-12-20T13:36:25Z","title":"Diff-Glat: Diffusion Glancing Transformer for Parallel Sequence to\n  Sequence Learning","summary":"  For sequence generation, both autoregressive models and non-autoregressive\nmodels have been developed in recent years. Autoregressive models can achieve\nhigh generation quality, but the sequential decoding scheme causes slow\ndecoding speed. Non-autoregressive models accelerate the inference speed with\nparallel decoding, while their generation quality still needs to be improved\ndue to the difficulty of modeling multi-modalities in data. To address the\nmulti-modality issue, we propose Diff-Glat, a non-autoregressive model featured\nwith a modality diffusion process and residual glancing training. The modality\ndiffusion process decomposes the modalities and reduces the modalities to learn\nfor each transition. And the residual glancing sampling further smooths the\nmodality learning procedures. Experiments demonstrate that, without using\nknowledge distillation data, Diff-Glat can achieve superior performance in both\ndecoding efficiency and accuracy compared with the autoregressive Transformer.\n","authors":["Lihua Qian","Mingxuan Wang","Yang Liu","Hao Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.10240v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2212.10233v1","updated":"2022-12-20T13:20:21Z","published":"2022-12-20T13:20:21Z","title":"Pre-trained Language Models for Keyphrase Generation: A Thorough\n  Empirical Study","summary":"  Neural models that do not rely on pre-training have excelled in the keyphrase\ngeneration task with large annotated datasets. Meanwhile, new approaches have\nincorporated pre-trained language models (PLMs) for their data efficiency.\nHowever, there lacks a systematic study of how the two types of approaches\ncompare and how different design choices can affect the performance of\nPLM-based models. To fill in this knowledge gap and facilitate a more informed\nuse of PLMs for keyphrase extraction and keyphrase generation, we present an\nin-depth empirical study. Formulating keyphrase extraction as sequence labeling\nand keyphrase generation as sequence-to-sequence generation, we perform\nextensive experiments in three domains. After showing that PLMs have\ncompetitive high-resource performance and state-of-the-art low-resource\nperformance, we investigate important design choices including in-domain PLMs,\nPLMs with different pre-training objectives, using PLMs with a parameter\nbudget, and different formulations for present keyphrases. Further results show\nthat (1) in-domain BERT-like PLMs can be used to build strong and\ndata-efficient keyphrase generation models; (2) with a fixed parameter budget,\nprioritizing model depth over width and allocating more layers in the encoder\nleads to better encoder-decoder models; and (3) introducing four in-domain\nPLMs, we achieve a competitive performance in the news domain and the\nstate-of-the-art performance in the scientific domain.\n","authors":["Di Wu","Wasi Uddin Ahmad","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10218v1","updated":"2022-12-20T12:51:11Z","published":"2022-12-20T12:51:11Z","title":"GanLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator","summary":"  Pre-trained models have achieved remarkable success in natural language\nprocessing (NLP). However, existing pre-training methods underutilize the\nbenefits of language understanding for generation. Inspired by the idea of\nGenerative Adversarial Networks (GANs), we propose a GAN-style model for\nencoder-decoder pre-training by introducing an auxiliary discriminator,\nunifying the ability of language understanding and generation in a single\nmodel. Our model, named as GanLM, is trained with two pre-training objectives:\nreplaced token detection and replaced token denoising. Specifically, given\nmasked source sentences, the generator outputs the target distribution and the\ndiscriminator predicts whether the target sampled tokens from distribution are\nincorrect. The target sentence is replaced with misclassified tokens to\nconstruct noisy previous context, which is used to generate the gold sentence.\nIn general, both tasks improve the ability of language understanding and\ngeneration by selectively using the denoising data. Extensive experiments in\nlanguage generation benchmarks show that GanLM with the powerful language\nunderstanding capability outperforms various strong pre-trained language models\n(PLMs) and achieves state-of-the-art performance.\n","authors":["Jian Yang","Shuming Ma","Li Dong","Shaohan Huang","Haoyang Huang","Yuwei Yin","Dongdong Zhang","Liqun Yang","Zhoujun Li","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.10218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10197v1","updated":"2022-12-20T12:16:46Z","published":"2022-12-20T12:16:46Z","title":"EIT: Enhanced Interactive Transformer","summary":"  In this paper, we propose a novel architecture, the Enhanced Interactive\nTransformer (EIT), to address the issue of head degradation in self-attention\nmechanisms. Our approach replaces the traditional multi-head self-attention\nmechanism with the Enhanced Multi-Head Attention (EMHA) mechanism, which\nrelaxes the one-to-one mapping constraint among queries and keys, allowing each\nquery to attend to multiple keys. Furthermore, we introduce two interaction\nmodels, Inner-Subspace Interaction and Cross-Subspace Interaction, to fully\nutilize the many-to-many mapping capabilities of EMHA. Extensive experiments on\na wide range of tasks (e.g. machine translation, abstractive summarization,\ngrammar correction, language modelling and brain disease automatic diagnosis)\nshow its superiority with a very modest increase in model size.\n","authors":["Tong Zheng","Bei Li","Huiwen Bao","Tong Xiao","Jingbo Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.10197v1.pdf","comment":"25 pages, 21 figures"},{"id":"http://arxiv.org/abs/2212.10192v1","updated":"2022-12-20T12:03:19Z","published":"2022-12-20T12:03:19Z","title":"Adam: Dense Retrieval Distillation with Adaptive Dark Examples","summary":"  To improve the performance of the dual-encoder retriever, one effective\napproach is knowledge distillation from the cross-encoder ranker. Existing\nworks construct the candidate passages following the supervised learning\nsetting where a query is paired with a positive passage and a batch of\nnegatives. However, through empirical observation, we find that even the hard\nnegatives from advanced methods are still too trivial for the teacher to\ndistinguish, preventing the teacher from transferring abundant dark knowledge\nto the student through its soft label. To alleviate this issue, we propose\nADAM, a knowledge distillation framework that can better transfer the dark\nknowledge held in the teacher with Adaptive Dark exAMples. Different from\nprevious works that only rely on one positive and hard negatives as candidate\npassages, we create dark examples that all have moderate relevance to the query\nthrough mixing-up and masking in discrete space. Furthermore, as the quality of\nknowledge held in different training instances varies as measured by the\nteacher's confidence score, we propose a self-paced distillation strategy that\nadaptively concentrates on a subset of high-quality instances to conduct our\ndark-example-based knowledge distillation to help the student learn better. We\nconduct experiments on two widely-used benchmarks and verify the effectiveness\nof our method.\n","authors":["Chang Liu","Chongyang Tao","Xiubo Geng","Tao Shen","Dongyan Zhao","Can Xu","Binxing Jiao","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2212.10192v1.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2212.10191v1","updated":"2022-12-20T12:02:40Z","published":"2022-12-20T12:02:40Z","title":"Emotion Selectable End-to-End Text-based Speech Editing","summary":"  Text-based speech editing allows users to edit speech by intuitively cutting,\ncopying, and pasting text to speed up the process of editing speech. In the\nprevious work, CampNet (context-aware mask prediction network) is proposed to\nrealize text-based speech editing, significantly improving the quality of\nedited speech. This paper aims at a new task: adding emotional effect to the\nediting speech during the text-based speech editing to make the generated\nspeech more expressive. To achieve this task, we propose Emo-CampNet (emotion\nCampNet), which can provide the option of emotional attributes for the\ngenerated speech in text-based speech editing and has the one-shot ability to\nedit unseen speakers' speech. Firstly, we propose an end-to-end\nemotion-selectable text-based speech editing model. The key idea of the model\nis to control the emotion of generated speech by introducing additional emotion\nattributes based on the context-aware mask prediction network. Secondly, to\nprevent the emotion of the generated speech from being interfered by the\nemotional components in the original speech, a neutral content generator is\nproposed to remove the emotion from the original speech, which is optimized by\nthe generative adversarial framework. Thirdly, two data augmentation methods\nare proposed to enrich the emotional and pronunciation information in the\ntraining set, which can enable the model to edit the unseen speaker's speech.\nThe experimental results that 1) Emo-CampNet can effectively control the\nemotion of the generated speech in the process of text-based speech editing;\nAnd can edit unseen speakers' speech. 2) Detailed ablation experiments further\nprove the effectiveness of emotional selectivity and data augmentation methods.\nThe demo page is available at https://hairuo55.github.io/Emo-CampNet/\n","authors":["Tao Wang","Jiangyan Yi","Ruibo Fu","Jianhua Tao","Zhengqi Wen","Chu Yuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.10191v1.pdf","comment":"Under review, 12 pages, 11 figures, demo page is available at\n  https://hairuo55.github.io/Emo-CampNet/"},{"id":"http://arxiv.org/abs/2212.10190v1","updated":"2022-12-20T12:02:34Z","published":"2022-12-20T12:02:34Z","title":"Pay Attention to Your Tone: Introducing a New Dataset for Polite\n  Language Rewrite","summary":"  We introduce \\textsc{PoliteRewrite} -- a dataset for polite language rewrite\nwhich is a novel sentence rewrite task. Compared with previous text style\ntransfer tasks that can be mostly addressed by slight token- or phrase-level\nedits, polite language rewrite requires deep understanding and extensive\nsentence-level edits over an offensive and impolite sentence to deliver the\nsame message euphemistically and politely, which is more challenging -- not\nonly for NLP models but also for human annotators to rewrite with effort. To\nalleviate the human effort for efficient annotation, we first propose a novel\nannotation paradigm by a collaboration of human annotators and GPT-3.5 to\nannotate \\textsc{PoliteRewrite}. The released dataset has 10K polite sentence\nrewrites annotated collaboratively by GPT-3.5 and human, which can be used as\ngold standard for training, validation and test; and 100K high-quality polite\nsentence rewrites by GPT-3.5 without human review. We wish this work (The\ndataset (10K+100K) will be released soon) could contribute to the research on\nmore challenging sentence rewrite, and provoke more thought in future on\nresource annotation paradigm with the help of the large-scaled pretrained\nmodels.\n","authors":["Xun Wang","Tao Ge","Allen Mao","Yuki Li","Furu Wei","Si-Qing Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10189v1","updated":"2022-12-20T12:00:26Z","published":"2022-12-20T12:00:26Z","title":"Do I have the Knowledge to Answer? Investigating Answerability of\n  Knowledge Base Questions","summary":"  When answering natural language questions over knowledge bases (KBs),\nincompleteness in the KB can naturally lead to many questions being\nunanswerable. While answerability has been explored in other QA settings, it\nhas not been studied for QA over knowledge bases (KBQA). We first identify\nvarious forms of KB incompleteness that can result in a question being\nunanswerable. We then propose GrailQAbility, a new benchmark dataset, which\nsystematically modifies GrailQA (a popular KBQA dataset) to represent all these\nincompleteness issues. Testing two state-of-the-art KBQA models (trained on\noriginal GrailQA as well as our GrailQAbility), we find that both models\nstruggle to detect unanswerable questions, or sometimes detect them for the\nwrong reasons. Consequently, both models suffer significant loss in\nperformance, underscoring the need for further research in making KBQA systems\nrobust to unanswerability.\n","authors":["Mayur Patidar","Avinash Singh","Prayushi Faldu","Lovekesh Vig","Indrajit Bhattacharya"," Mausam"],"pdf_url":"https://arxiv.org/pdf/2212.10189v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10180v1","updated":"2022-12-20T11:37:22Z","published":"2022-12-20T11:37:22Z","title":"IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for\n  Indian Languages","summary":"  The rapid growth of machine translation (MT) systems has necessitated\ncomprehensive studies to meta-evaluate evaluation metrics being used, which\nenables a better selection of metrics that best reflect MT quality.\nUnfortunately, most of the research focuses on high-resource languages, mainly\nEnglish, the observations for which may not always apply to other languages.\nIndian languages, having over a billion speakers, are linguistically different\nfrom English, and to date, there has not been a systematic study of evaluating\nMT systems from English into Indian languages. In this paper, we fill this gap\nby creating an MQM dataset consisting of 7000 fine-grained annotations,\nspanning 5 Indian languages and 7 MT systems, and use it to establish\ncorrelations between annotator scores and scores obtained using existing\nautomatic metrics. Our results show that pre-trained metrics, such as COMET,\nhave the highest correlations with annotator scores. Additionally, we find that\nthe metrics do not adequately capture fluency-based errors in Indian languages,\nand there is a need to develop metrics focused on Indian languages. We hope\nthat our dataset and analysis will help promote further research in this area.\n","authors":["Ananya B. Sai","Vignesh Nagarajan","Tanay Dixit","Raj Dabre","Anoop Kunchukuttan","Pratyush Kumar","Mitesh M. Khapra"],"pdf_url":"https://arxiv.org/pdf/2212.10180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10179v1","updated":"2022-12-20T11:36:22Z","published":"2022-12-20T11:36:22Z","title":"Toward Human-Like Evaluation for Natural Language Generation with Error\n  Analysis","summary":"  The state-of-the-art language model-based automatic metrics, e.g. BARTScore,\nbenefiting from large-scale contextualized pre-training, have been successfully\nused in a wide range of natural language generation (NLG) tasks, including\nmachine translation, text summarization, and data-to-text. Recent studies show\nthat considering both major errors (e.g. mistranslated tokens) and minor errors\n(e.g. imperfections in fluency) can produce high-quality human judgments. This\ninspires us to approach the final goal of the evaluation metrics (human-like\nevaluations) by automatic error analysis. To this end, we augment BARTScore by\nincorporating the human-like error analysis strategies, namely BARTScore++,\nwhere the final score consists of both the evaluations of major errors and\nminor errors. Experimental results show that BARTScore++ can consistently\nimprove the performance of vanilla BARTScore and outperform existing\ntop-scoring metrics in 20 out of 25 test settings. We hope our technique can\nalso be extended to other pre-trained model-based metrics. We will release our\ncode and scripts to facilitate the community.\n","authors":["Qingyu Lu","Liang Ding","Liping Xie","Kanjian Zhang","Derek F. Wong","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2212.10179v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2212.10173v1","updated":"2022-12-20T11:23:04Z","published":"2022-12-20T11:23:04Z","title":"On the Role of Parallel Data in Cross-lingual Transfer Learning","summary":"  While prior work has established that the use of parallel data is conducive\nfor cross-lingual learning, it is unclear if the improvements come from the\ndata itself, or if it is the modeling of parallel interactions that matters.\nExploring this, we examine the usage of unsupervised machine translation to\ngenerate synthetic parallel data, and compare it to supervised machine\ntranslation and gold parallel data. We find that even model generated parallel\ndata can be useful for downstream tasks, in both a general setting (continued\npretraining) as well as the task-specific setting (translate-train), although\nour best results are still obtained using real parallel data. Our findings\nsuggest that existing multilingual models do not exploit the full potential of\nmonolingual data, and prompt the community to reconsider the traditional\ncategorization of cross-lingual learning approaches.\n","authors":["Machel Reid","Mikel Artetxe"],"pdf_url":"https://arxiv.org/pdf/2212.10173v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.10171v1","updated":"2022-12-20T11:17:52Z","published":"2022-12-20T11:17:52Z","title":"Document-level Relation Extraction with Relation Correlations","summary":"  Document-level relation extraction faces two overlooked challenges: long-tail\nproblem and multi-label problem. Previous work focuses mainly on obtaining\nbetter contextual representations for entity pairs, hardly address the above\nchallenges. In this paper, we analyze the co-occurrence correlation of\nrelations, and introduce it into DocRE task for the first time. We argue that\nthe correlations can not only transfer knowledge between data-rich relations\nand data-scarce ones to assist in the training of tailed relations, but also\nreflect semantic distance guiding the classifier to identify semantically close\nrelations for multi-label entity pairs. Specifically, we use relation embedding\nas a medium, and propose two co-occurrence prediction sub-tasks from both\ncoarse- and fine-grained perspectives to capture relation correlations.\nFinally, the learned correlation-aware embeddings are used to guide the\nextraction of relational facts. Substantial experiments on two popular DocRE\ndatasets are conducted, and our method achieves superior results compared to\nbaselines. Insightful analysis also demonstrates the potential of relation\ncorrelations to address the above challenges.\n","authors":["Ridong Han","Tao Peng","Benyou Wang","Lu Liu","Xiang Wan"],"pdf_url":"https://arxiv.org/pdf/2212.10171v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2212.10168v1","updated":"2022-12-20T11:15:24Z","published":"2022-12-20T11:15:24Z","title":"Naamapadam: A Large-Scale Named Entity Annotated Data for Indic\n  Languages","summary":"  We present, Naamapadam, the largest publicly available Named Entity\nRecognition (NER) dataset for the 11 major Indian languages from two language\nfamilies. In each language, it contains more than 400k sentences annotated with\na total of at least 100k entities from three standard entity categories\n(Person, Location and Organization) for 9 out of the 11 languages. The training\ndataset has been automatically created from the Samanantar parallel corpus by\nprojecting automatically tagged entities from an English sentence to the\ncorresponding Indian language sentence. We also create manually annotated\ntestsets for 8 languages containing approximately 1000 sentences per language.\nWe demonstrate the utility of the obtained dataset on existing testsets and the\nNaamapadam-test data for 8 Indic languages. We also release IndicNER, a\nmultilingual mBERT model fine-tuned on the Naamapadam training set. IndicNER\nachieves the best F1 on the Naamapadam-test set compared to an mBERT model\nfine-tuned on existing datasets. IndicNER achieves an F1 score of more than 80\nfor 7 out of 11 Indic languages. The dataset and models are available under\nopen-source licenses at https://ai4bharat.iitm.ac.in/naamapadam.\n","authors":["Arnav Mhaske","Harshit Kedia","Sumanth Doddapaneni","Mitesh M. Khapra","Pratyush Kumar","Rudra Murthy V","Anoop Kunchukuttan"],"pdf_url":"https://arxiv.org/pdf/2212.10168v1.pdf","comment":"14 pages, 5 figures, Work in Progress"},{"id":"http://arxiv.org/abs/2212.06800v2","updated":"2022-12-20T10:54:21Z","published":"2022-12-13T18:34:15Z","title":"Diverse Demonstrations Improve In-context Compositional Generalization","summary":"  In-context learning has shown great success in i.i.d semantic parsing splits,\nwhere the training and test sets are drawn from the same distribution. In this\nsetup, models are typically prompted with demonstrations that are similar to\nthe input question. However, in the setup of compositional generalization,\nwhere models are tested on outputs with structures that are absent from the\ntraining set, selecting similar demonstrations is insufficient, as often no\nexample will be similar enough to the input. In this work, we propose a method\nto select diverse demonstrations that aims to collectively cover all of the\nstructures required in the output program, in order to encourage the model to\ngeneralize to new structures from these demonstrations. We empirically show\nthat combining diverse demonstrations with in-context learning substantially\nimproves performance across three compositional generalization semantic parsing\ndatasets in the pure in-context learning setup and when combined with\nfinetuning.\n","authors":["Itay Levy","Ben Bogin","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2212.06800v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10154v1","updated":"2022-12-20T10:46:40Z","published":"2022-12-20T10:46:40Z","title":"Human-Guided Fair Classification for Natural Language Processing","summary":"  Text classifiers have promising applications in high-stake tasks such as\nresume screening and content moderation. These classifiers must be fair and\navoid discriminatory decisions by being invariant to perturbations of sensitive\nattributes such as gender or ethnicity. However, there is a gap between human\nintuition about these perturbations and the formal similarity specifications\ncapturing them. While existing research has started to address this gap,\ncurrent methods are based on hardcoded word replacements, resulting in\nspecifications with limited expressivity or ones that fail to fully align with\nhuman intuition (e.g., in cases of asymmetric counterfactuals). This work\nproposes novel methods for bridging this gap by discovering expressive and\nintuitive individual fairness specifications. We show how to leverage\nunsupervised style transfer and GPT-3's zero-shot capabilities to automatically\ngenerate expressive candidate pairs of semantically similar sentences that\ndiffer along sensitive attributes. We then validate the generated pairs via an\nextensive crowdsourcing study, which confirms that a lot of these pairs align\nwith human intuition about fairness in the context of toxicity classification.\nFinally, we show how limited amounts of human feedback can be leveraged to\nlearn a similarity specification that can be used to train downstream\nfairness-aware models.\n","authors":["Florian E. Dorner","Momchil Peychev","Nikola Konstantinov","Naman Goel","Elliott Ash","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2212.10154v1.pdf","comment":"31 pages, 1 figure"},{"id":"http://arxiv.org/abs/2212.10152v1","updated":"2022-12-20T10:44:18Z","published":"2022-12-20T10:44:18Z","title":"Quirk or Palmer: A Comparative Study of Modal Verb Frameworks with\n  Annotated Datasets","summary":"  Modal verbs, such as \"can\", \"may\", and \"must\", are commonly used in daily\ncommunication to convey the speaker's perspective related to the likelihood\nand/or mode of the proposition. They can differ greatly in meaning depending on\nhow they're used and the context of a sentence (e.g. \"They 'must' help each\nother out.\" vs. \"They 'must' have helped each other out.\") Despite their\npractical importance in natural language understanding, linguists have yet to\nagree on a single, prominent framework for the categorization of modal verb\nsenses. This lack of agreement stems from high degrees of flexibility and\npolysemy from the modal verbs, making it more difficult for researchers to\nincorporate insights from this family of words into their work. This work\npresents Moverb dataset, which consists of 27,240 annotations of modal verb\nsenses over 4,540 utterances containing one or more sentences from social\nconversations. Each utterance is annotated by three annotators using two\ndifferent theoretical frameworks (i.e., Quirk and Palmer) of modal verb senses.\nWe observe that both frameworks have similar inter-annotator agreements,\ndespite having different numbers of sense types (8 for Quirk and 3 for Palmer).\nWith the RoBERTa-based classifiers fine-tuned on \\dataset, we achieve F1 scores\nof 82.2 and 78.3 on Quirk and Palmer, respectively, showing that modal verb\nsense disambiguation is not a trivial task. Our dataset will be publicly\navailable with our final version.\n","authors":["Risako Owan","Maria Gini","Dongyeop Kang"],"pdf_url":"https://arxiv.org/pdf/2212.10152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10140v1","updated":"2022-12-20T10:18:18Z","published":"2022-12-20T10:18:18Z","title":"Tackling Ambiguity with Images: Improved Multimodal Machine Translation\n  and Contrastive Evaluation","summary":"  One of the major challenges of machine translation (MT) is ambiguity, which\ncan in some cases be resolved by accompanying context such as an image.\nHowever, recent work in multimodal MT (MMT) has shown that obtaining\nimprovements from images is challenging, limited not only by the difficulty of\nbuilding effective cross-modal representations but also by the lack of specific\nevaluation and training data. We present a new MMT approach based on a strong\ntext-only MT model, which uses neural adapters and a novel guided\nself-attention mechanism and which is jointly trained on both visual masking\nand MMT. We also release CoMMuTE, a Contrastive Multilingual Multimodal\nTranslation Evaluation dataset, composed of ambiguous sentences and their\npossible translations, accompanied by disambiguating images corresponding to\neach translation. Our approach obtains competitive results over strong\ntext-only models on standard English-to-French benchmarks and outperforms these\nbaselines and state-of-the-art MMT systems with a large margin on our\ncontrastive test set.\n","authors":["Matthieu Futeral","Cordelia Schmid","Ivan Laptev","Benoît Sagot","Rachel Bawden"],"pdf_url":"https://arxiv.org/pdf/2212.10140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02535v2","updated":"2022-12-20T10:17:10Z","published":"2022-09-06T14:36:57Z","title":"Analyzing Transformers in Embedding Space","summary":"  Understanding Transformer-based models has attracted significant attention,\nas they lie at the heart of recent technological advances across machine\nlearning. While most interpretability methods rely on running models over\ninputs, recent work has shown that a zero-pass approach, where parameters are\ninterpreted directly without a forward/backward pass is feasible for some\nTransformer parameters, and for two-layer attention networks. In this work, we\npresent a theoretical analysis where all parameters of a trained Transformer\nare interpreted by projecting them into the embedding space, that is, the space\nof vocabulary items they operate on. We derive a simple theoretical framework\nto support our arguments and provide ample evidence for its validity. First, an\nempirical analysis showing that parameters of both pretrained and fine-tuned\nmodels can be interpreted in embedding space. Second, we present two\napplications of our framework: (a) aligning the parameters of different models\nthat share a vocabulary, and (b) constructing a classifier without training by\n``translating'' the parameters of a fine-tuned classifier to parameters of a\ndifferent model that was only pretrained. Overall, our findings open the door\nto interpretation methods that, at least in part, abstract away from model\nspecifics and operate in the embedding space only.\n","authors":["Guy Dar","Mor Geva","Ankit Gupta","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2209.02535v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10114v1","updated":"2022-12-20T09:34:43Z","published":"2022-12-20T09:34:43Z","title":"True Detective: A Challenging Benchmark for Deep Abductive Reasoning\n  \\\\in Foundation Models","summary":"  Large language models (LLMs) have demonstrated strong performance in\nzero-shot reasoning tasks, including abductive reasoning. This is reflected in\ntheir ability to perform well on current benchmarks in this area. However, to\ntruly test the limits of LLMs in abductive reasoning, a more challenging\nbenchmark is needed. In this paper, we present such a benchmark, consisting of\n191 long-form mystery stories, each approximately 1200 words in length and\npresented in the form of detective puzzles. Each puzzle includes a\nmultiple-choice question for evaluation sourced from the \"5 Minute Mystery\"\nplatform. Our results show that state-of-the-art GPT models perform\nsignificantly worse than human solvers on this benchmark, with an accuracy of\n28\\% compared to 47\\% for humans. This indicates that there is still a\nsignificant gap in the abductive reasoning abilities of LLMs and highlights the\nneed for further research in this area. Our work provides a challenging\nbenchmark for future studies on reasoning in language models and contributes to\na better understanding of the limits of LLMs' abilities.\n","authors":["Maksym Del","Mark Fishel"],"pdf_url":"https://arxiv.org/pdf/2212.10114v1.pdf","comment":"4 pages, preprint"},{"id":"http://arxiv.org/abs/2112.00284v2","updated":"2022-12-20T09:23:32Z","published":"2021-12-01T05:21:07Z","title":"Interactive Model with Structural Loss for Language-based Abductive\n  Reasoning","summary":"  The abductive natural language inference task ($\\alpha$NLI) is proposed to\ninfer the most plausible explanation between the cause and the event. In the\n$\\alpha$NLI task, two observations are given, and the most plausible hypothesis\nis asked to pick out from the candidates. Existing methods model the relation\nbetween each candidate hypothesis separately and penalize the inference network\nuniformly. In this paper, we argue that it is unnecessary to distinguish the\nreasoning abilities among correct hypotheses; and similarly, all wrong\nhypotheses contribute the same when explaining the reasons of the observations.\nTherefore, we propose to group instead of ranking the hypotheses and design a\nstructural loss called ``joint softmax focal loss'' in this paper. Based on the\nobservation that the hypotheses are generally semantically related, we have\ndesigned a novel interactive language model aiming at exploiting the rich\ninteraction among competing hypotheses. We name this new model for $\\alpha$NLI:\nInteractive Model with Structural Loss (IMSL). The experimental results show\nthat our IMSL has achieved the highest performance on the RoBERTa-large\npretrained model, with ACC and AUC results increased by about 1\\% and 5\\%\nrespectively.\n","authors":["Linhao Li","Ming Xu","Yongfeng Dong","Xin Li","Ao Wang"],"pdf_url":"https://arxiv.org/pdf/2112.00284v2.pdf","comment":"The paper is under consideration at Pattern Recognition Letters"},{"id":"http://arxiv.org/abs/2212.10097v1","updated":"2022-12-20T09:15:03Z","published":"2022-12-20T09:15:03Z","title":"Toward a Unified Framework for Unsupervised Complex Tabular Reasoning","summary":"  Structured tabular data exist across nearly all fields. Reasoning task over\nthese data aims to answer questions or determine the truthiness of hypothesis\nsentences by understanding the semantic meaning of a table. While previous\nworks have devoted significant efforts to the tabular reasoning task, they\nalways assume there are sufficient labeled data. However, constructing\nreasoning samples over tables (and related text) is labor-intensive, especially\nwhen the reasoning process is complex. When labeled data is insufficient, the\nperformance of models will suffer an unendurable decline. In this paper, we\npropose a unified framework for unsupervised complex tabular reasoning (UCTR),\nwhich generates sufficient and diverse synthetic data with complex logic for\ntabular reasoning tasks, assuming no human-annotated data at all. We first\nutilize a random sampling strategy to collect diverse programs of different\ntypes and execute them on tables based on a \"Program-Executor\" module. To\nbridge the gap between the programs and natural language sentences, we design a\npowerful \"NL-Generator\" module to generate natural language sentences with\ncomplex logic from these programs. Since a table often occurs with its\nsurrounding texts, we further propose novel \"Table-to-Text\" and \"Text-to-Table\"\noperators to handle joint table-text reasoning scenarios. This way, we can\nadequately exploit the unlabeled table resources to obtain a well-performed\nreasoning model under an unsupervised setting. Our experiments cover different\ntasks (question answering and fact verification) and different domains (general\nand specific), showing that our unsupervised methods can achieve at most 93%\nperformance compared to supervised models. We also find that it can\nsubstantially boost the supervised performance in low-resourced domains as a\ndata augmentation technique. Our code is available at\nhttps://github.com/leezythu/UCTR.\n","authors":["Zhenyu Li","Xiuxing Li","Zhichao Duan","Bowen Dong","Ning Liu","Jianyong Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10097v1.pdf","comment":"Accepted by ICDE 2023. Preprint Version"},{"id":"http://arxiv.org/abs/2212.10087v1","updated":"2022-12-20T08:55:47Z","published":"2022-12-20T08:55:47Z","title":"Hybrid Rule-Neural Coreference Resolution System based on Actor-Critic\n  Learning","summary":"  A coreference resolution system is to cluster all mentions that refer to the\nsame entity in a given context. All coreference resolution systems need to\ntackle two main tasks: one task is to detect all of the potential mentions, and\nthe other is to learn the linking of an antecedent for each possible mention.\nIn this paper, we propose a hybrid rule-neural coreference resolution system\nbased on actor-critic learning, such that it can achieve better coreference\nperformance by leveraging the advantages from both the heuristic rules and a\nneural conference model. This end-to-end system can also perform both mention\ndetection and resolution by leveraging a joint training algorithm. We\nexperiment on the BERT model to generate input span representations. Our model\nwith the BERT span representation achieves the state-of-the-art performance\namong the models on the CoNLL-2012 Shared Task English Test Set.\n","authors":["Yu Wang","Hongxia Jin"],"pdf_url":"https://arxiv.org/pdf/2212.10087v1.pdf","comment":"11 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:2212.09028"},{"id":"http://arxiv.org/abs/2211.04052v2","updated":"2022-12-20T08:52:42Z","published":"2022-11-08T07:23:09Z","title":"What Knowledge Is Needed? Towards Explainable Memory for kNN-MT Domain\n  Adaptation","summary":"  kNN-MT presents a new paradigm for domain adaptation by building an external\ndatastore, which usually saves all target language token occurrences in the\nparallel corpus. As a result, the constructed datastore is usually large and\npossibly redundant. In this paper, we investigate the interpretability issue of\nthis approach: what knowledge does the NMT model need? We propose the notion of\nlocal correctness (LAC) as a new angle, which describes the potential\ntranslation correctness for a single entry and for a given neighborhood.\nEmpirical study shows that our investigation successfully finds the conditions\nwhere the NMT model could easily fail and need related knowledge. Experiments\non six diverse target domains and two language-pairs show that pruning\naccording to local correctness brings a light and more explainable memory for\nkNN-MT domain adaptation.\n","authors":["Wenhao Zhu","Shujian Huang","Yunzhe Lv","Xin Zheng","Jiajun Chen"],"pdf_url":"https://arxiv.org/pdf/2211.04052v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10080v1","updated":"2022-12-20T08:43:10Z","published":"2022-12-20T08:43:10Z","title":"Rumour detection using graph neural network and oversampling in\n  benchmark Twitter dataset","summary":"  Recently, online social media has become a primary source for new information\nand misinformation or rumours. In the absence of an automatic rumour detection\nsystem the propagation of rumours has increased manifold leading to serious\nsocietal damages. In this work, we propose a novel method for building\nautomatic rumour detection system by focusing on oversampling to alleviating\nthe fundamental challenges of class imbalance in rumour detection task. Our\noversampling method relies on contextualised data augmentation to generate\nsynthetic samples for underrepresented classes in the dataset. The key idea\nexploits selection of tweets in a thread for augmentation which can be achieved\nby introducing a non-random selection criteria to focus the augmentation\nprocess on relevant tweets. Furthermore, we propose two graph neural\nnetworks(GNN) to model non-linear conversations on a thread. To enhance the\ntweet representations in our method we employed a custom feature selection\ntechnique based on state-of-the-art BERTweet model. Experiments of three\npublicly available datasets confirm that 1) our GNN models outperform the the\ncurrent state-of-the-art classifiers by more than 20%(F1-score); 2) our\noversampling technique increases the model performance by more than\n9%;(F1-score) 3) focusing on relevant tweets for data augmentation via\nnon-random selection criteria can further improve the results; and 4) our\nmethod has superior capabilities to detect rumours at very early stage.\n","authors":["Shaswat Patel","Prince Bansal","Preeti Kaur"],"pdf_url":"https://arxiv.org/pdf/2212.10080v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10079v1","updated":"2022-12-20T08:34:56Z","published":"2022-12-20T08:34:56Z","title":"A Survey on Pretrained Language Models for Neural Code Intelligence","summary":"  As the complexity of modern software continues to escalate, software\nengineering has become an increasingly daunting and error-prone endeavor. In\nrecent years, the field of Neural Code Intelligence (NCI) has emerged as a\npromising solution, leveraging the power of deep learning techniques to tackle\nanalytical tasks on source code with the goal of improving programming\nefficiency and minimizing human errors within the software industry. Pretrained\nlanguage models have become a dominant force in NCI research, consistently\ndelivering state-of-the-art results across a wide range of tasks, including\ncode summarization, generation, and translation. In this paper, we present a\ncomprehensive survey of the NCI domain, including a thorough review of\npretraining techniques, tasks, datasets, and model architectures. We hope this\npaper will serve as a bridge between the natural language and programming\nlanguage communities, offering insights for future research in this rapidly\nevolving field.\n","authors":["Yichen Xu","Yanqiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.10079v1.pdf","comment":"work in progress. 13 pages"},{"id":"http://arxiv.org/abs/2212.10077v1","updated":"2022-12-20T08:30:58Z","published":"2022-12-20T08:30:58Z","title":"DOC: Improving Long Story Coherence With Detailed Outline Control","summary":"  We propose the Detailed Outline Control (DOC) framework for improving\nlong-range plot coherence when automatically generating\nseveral-thousand-word-long stories. DOC consists of two complementary\ncomponents: a detailed outliner and a detailed controller. The detailed\noutliner creates a more detailed, hierarchically structured outline, shifting\ncreative burden from the main drafting procedure to the planning stage. The\ndetailed controller ensures the more detailed outline is still respected during\ngeneration by controlling story passages to align with outline details. In\nhuman evaluations of automatically generated stories, DOC substantially\noutperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5%\nabsolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans\nalso judged DOC to be much more controllable in an interactive generation\nsetting.\n","authors":["Kevin Yang","Dan Klein","Nanyun Peng","Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2212.10077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10071v1","updated":"2022-12-20T08:24:45Z","published":"2022-12-20T08:24:45Z","title":"Large Language Models Are Reasoning Teachers","summary":"  Language models (LMs) have demonstrated remarkable performance on downstream\ntasks, using in-context exemplars or human instructions. Recent works have\nshown that chain-of-thought (CoT) prompting can elicit models to solve complex\nreasoning tasks, step-by-step. However, the efficacy of prompt-based CoT\nmethods is restricted to very large LMs such as GPT-3 (175B), thus limiting\ndeployability. In this paper, we revisit the fine-tuning approach to enable\ncomplex reasoning in smaller LMs, optimized to efficiently perform a specific\ntask. We propose Fine-tune-CoT, a method that leverages the capabilities of\nvery large LMs to generate reasoning samples and teach smaller models via\nfine-tuning. We evaluate our method on publicly available LMs across a wide\nrange of complex tasks and model sizes. We find that Fine-tune-CoT enables\nsubstantial reasoning capability in small models, whereas previous prompt-based\nbaselines exhibit near-random performance. Student models can even outperform\nthe teacher in some tasks while reducing model size requirements by several\norders of magnitude. We conduct extensive ablations and sample studies to\nunderstand the reasoning capabilities of student models. We also identify\nseveral important nuances that have been overlooked in concurrent fine-tuning\nworks on CoT and address them in our analysis.\n","authors":["Namgyu Ho","Laura Schmid","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2212.10071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10060v1","updated":"2022-12-20T08:06:55Z","published":"2022-12-20T08:06:55Z","title":"An AI Dungeon Master's Guide: Learning to Converse and Guide with\n  Intents and Theory-of-Mind in Dungeons and Dragons","summary":"  We propose a novel task, G4C (Goal-driven Guidance Generation in Grounded\nCommunication), for studying goal-driven and grounded natural language\ninteractions. Specifically, we choose Dungeons and Dragons (D&D) -- a\nrole-playing game consisting of multiple player characters and a Dungeon Master\n(DM) who collaborate to achieve a set of goals that are beneficial to the\nplayers -- as a testbed for this task. Here, each of the player characters is a\nstudent, with their own personas and abilities, and the DM is the teacher, an\narbitrator of the rules of the world and responsible for assisting and guiding\nthe students towards a global goal. We propose a theory-of-mind-inspired\nmethodology for training such a DM with reinforcement learning (RL), where a\nDM: (1) learns to predict how the players will react to its utterances using a\ndataset of D&D dialogue transcripts; and (2) uses this prediction as a reward\nfunction providing feedback on how effective these utterances are at guiding\nthe players towards a goal. Human and automated evaluations show that a DM\ntrained with RL to generate guidance by incorporating a theory-of-mind of the\nplayers significantly improves the players' ability to achieve goals grounded\nin their shared world.\n","authors":["Pei Zhou","Andrew Zhu","Jennifer Hu","Jay Pujara","Xiang Ren","Chris Callison-Burch","Yejin Choi","Prithviraj Ammanabrolu"],"pdf_url":"https://arxiv.org/pdf/2212.10060v1.pdf","comment":"17 pages, 9 figures. Preprint, work in progress"},{"id":"http://arxiv.org/abs/2212.10057v1","updated":"2022-12-20T08:04:36Z","published":"2022-12-20T08:04:36Z","title":"WeCheck: Strong Factual Consistency Checker via Weakly Supervised\n  Learning","summary":"  A crucial issue of current text generation models is that they often\nuncontrollably generate factually inconsistent text with respective of their\ninputs. Limited by the lack of annotated data, existing works in evaluating\nfactual consistency directly transfer the reasoning ability of models trained\non other data-rich upstream tasks like question answering (QA) and natural\nlanguage inference (NLI) without any further adaptation. As a result, they\nperform poorly on the real generated text and are biased heavily by their\nsingle-source upstream tasks. To alleviate this problem, we propose a weakly\nsupervised framework that aggregates multiple resources to train a precise and\nefficient factual metric, namely WeCheck. WeCheck first utilizes a generative\nmodel to accurately label a real generated sample by aggregating its weak\nlabels, which are inferred from multiple resources. Then, we train the target\nmetric model with the weak supervision while taking noises into consideration.\nComprehensive experiments on a variety of tasks demonstrate the strong\nperformance of WeCheck, which achieves a 3.4\\% absolute improvement over\nprevious state-of-the-art methods on TRUE benchmark on average.\n","authors":["Wenhao Wu","Wei Li","Xinyan Xiao","Jiachen Liu","Sujian Li","Yajuan Lv"],"pdf_url":"https://arxiv.org/pdf/2212.10057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10051v1","updated":"2022-12-20T07:54:58Z","published":"2022-12-20T07:54:58Z","title":"A Framework of Customer Review Analysis Using the Aspect-Based Opinion\n  Mining Approach","summary":"  Opinion mining is the branch of computation that deals with opinions,\nappraisals, attitudes, and emotions of people and their different aspects. This\nfield has attracted substantial research interest in recent years. Aspect-level\n(called aspect-based opinion mining) is often desired in practical applications\nas it provides detailed opinions or sentiments about different aspects of\nentities and entities themselves, which are usually required for action. Aspect\nextraction and entity extraction are thus two core tasks of aspect-based\nopinion mining. his paper has presented a framework of aspect-based opinion\nmining based on the concept of transfer learning. on real-world customer\nreviews available on the Amazon website. The model has yielded quite\nsatisfactory results in its task of aspect-based opinion mining.\n","authors":["Subhasis Dasgupta","Jaydip Sen"],"pdf_url":"https://arxiv.org/pdf/2212.10051v1.pdf","comment":"This is the accepted version of the paper that has been presented and\n  published in the 20th IEEE Conference, OCIT'22. The final published version\n  is copyright-protected by the IEEE. The paper consists of 5 pages, and it\n  includes 5 figures and 1 table"},{"id":"http://arxiv.org/abs/2212.10047v1","updated":"2022-12-20T07:44:25Z","published":"2022-12-20T07:44:25Z","title":"An Augmentation Strategy for Visually Rich Documents","summary":"  Many business workflows require extracting important fields from form-like\ndocuments (e.g. bank statements, bills of lading, purchase orders, etc.).\nRecent techniques for automating this task work well only when trained with\nlarge datasets. In this work we propose a novel data augmentation technique to\nimprove performance when training data is scarce, e.g. 10-250 documents. Our\ntechnique, which we call FieldSwap, works by swapping out the key phrases of a\nsource field with the key phrases of a target field to generate new synthetic\nexamples of the target field for use in training. We demonstrate that this\napproach can yield 1-7 F1 point improvements in extraction performance.\n","authors":["Jing Xie","James B. Wendt","Yichao Zhou","Seth Ebner","Sandeep Tata"],"pdf_url":"https://arxiv.org/pdf/2212.10047v1.pdf","comment":"9 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2212.06369v3","updated":"2022-12-20T07:40:37Z","published":"2022-12-13T04:57:04Z","title":"Technical Report -- Competition Solution for Prompt Tuning using\n  Pretrained Language Model","summary":"  Prompt tuning recently becomes a hot-spot in the applications of large\npretrained language models on specific downstream tasks. Regarding the Language\nModel as a Service (LMaaS), black-box tuning using derivative-free optimization\n(DFO) provides a novel approach to expand the practical scenarios of pretrained\nmodels and enrich the researches of few-shot learning. In this report, we\npresent our solution in this competition that is based on the LMaaS scenario.\nOur solution consists of several modifications to BBTv2, including multiple\nlabel words, selection of P0, rolling update strategy, multi-task loss from MLP\nclassifier, and finally using the ensemble method to further improve\ngeneralization ability. We also shared some strategies that we tried but didn't\nuse in the final submission for further discussion. In the end we raised a\nquestion about the SNLI dataset and the impact on the results, as well as our\nconcerns about the competition.\n","authors":["Jiang-Long Song","Wu-He Zou","Feng Li","Xiao-Lei Qin","Wei-Dong Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.06369v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.10041v2","updated":"2022-12-20T07:37:38Z","published":"2022-09-20T23:26:02Z","title":"Exploring Optimal Granularity for Extractive Summarization of\n  Unstructured Health Records: Analysis of the Largest Multi-Institutional\n  Archive of Health Records in Japan","summary":"  Automated summarization of clinical texts can reduce the burden of medical\nprofessionals. \"Discharge summaries\" are one promising application of the\nsummarization, because they can be generated from daily inpatient records. Our\npreliminary experiment suggests that 20-31% of the descriptions in discharge\nsummaries overlap with the content of the inpatient records. However, it\nremains unclear how the summaries should be generated from the unstructured\nsource. To decompose the physician's summarization process, this study aimed to\nidentify the optimal granularity in summarization. We first defined three types\nof summarization units with different granularities to compare the performance\nof the discharge summary generation: whole sentences, clinical segments, and\nclauses. We defined clinical segments in this study, aiming to express the\nsmallest medically meaningful concepts. To obtain the clinical segments, it was\nnecessary to automatically split the texts in the first stage of the pipeline.\nAccordingly, we compared rule-based methods and a machine learning method, and\nthe latter outperformed the formers with an F1 score of 0.846 in the splitting\ntask. Next, we experimentally measured the accuracy of extractive summarization\nusing the three types of units, based on the ROUGE-1 metric, on a\nmulti-institutional national archive of health records in Japan. The measured\naccuracies of extractive summarization using whole sentences, clinical\nsegments, and clauses were 31.91, 36.15, and 25.18, respectively. We found that\nthe clinical segments yielded higher accuracy than sentences and clauses. This\nresult indicates that summarization of inpatient records demands finer\ngranularity than sentence-oriented processing. Although we used only Japanese\nhealth records, it can be interpreted as follows: physicians extract \"concepts\nof medical significance\" from patient records and recombine them ...\n","authors":["Kenichiro Ando","Takashi Okumura","Mamoru Komachi","Hiromasa Horiguchi","Yuji Matsumoto"],"pdf_url":"https://arxiv.org/pdf/2209.10041v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10039v1","updated":"2022-12-20T07:22:45Z","published":"2022-12-20T07:22:45Z","title":"A Twitter BERT Approach for Offensive Language Detection in Marathi","summary":"  Automated offensive language detection is essential in combating the spread\nof hate speech, particularly in social media. This paper describes our work on\nOffensive Language Identification in low resource Indic language Marathi. The\nproblem is formulated as a text classification task to identify a tweet as\noffensive or non-offensive. We evaluate different mono-lingual and\nmulti-lingual BERT models on this classification task, focusing on BERT models\npre-trained with social media datasets. We compare the performance of MuRIL,\nMahaTweetBERT, MahaTweetBERT-Hateful, and MahaBERT on the HASOC 2022 test set.\nWe also explore external data augmentation from other existing Marathi hate\nspeech corpus HASOC 2021 and L3Cube-MahaHate. The MahaTweetBERT, a BERT model,\npre-trained on Marathi tweets when fine-tuned on the combined dataset (HASOC\n2021 + HASOC 2022 + MahaHate), outperforms all models with an F1 score of 98.43\non the HASOC 2022 test set. With this, we also provide a new state-of-the-art\nresult on HASOC 2022 / MOLD v2 test set.\n","authors":["Tanmay Chavan","Shantanu Patankar","Aditya Kane","Omkar Gokhale","Raviraj Joshi"],"pdf_url":"https://arxiv.org/pdf/2212.10039v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10029v1","updated":"2022-12-20T06:54:04Z","published":"2022-12-20T06:54:04Z","title":"Do language models have coherent mental models of everyday things?","summary":"  When people think of everyday things like an \"egg,\" they typically have a\nmental image associated with it. This commonsense knowledge helps us understand\nhow these everyday things work and how to interact with them. For example, when\nsomeone tries to make a fried egg, they know that it has a shell and that it\ncan be cracked open to reveal the egg white and yolk inside. However, if a\nsystem does not have a coherent picture of such everyday things, thinking that\nthe egg yolk surrounds the shell, then it might have to resort to ridiculous\napproaches such as trying to scrape the egg yolk off the shell into the pan. Do\nlanguage models have a coherent picture of such everyday things? To investigate\nthis, we propose a benchmark dataset consisting of 100 everyday things, their\nparts, and the relationships between these parts. We observe that\nstate-of-the-art pre-trained language models (LMs) like GPT-3 and Macaw have\nfragments of knowledge about these entities, but they fail to produce\nconsistent parts mental models. We propose a simple extension to these LMs\nwhere we apply a constraint satisfaction layer on top of raw predictions from\nLMs to produce more consistent and accurate parts mental models of everyday\nthings.\n","authors":["Yuling Gu","Bhavana Dalvi Mishra","Peter Clark"],"pdf_url":"https://arxiv.org/pdf/2212.10029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10025v1","updated":"2022-12-20T06:44:32Z","published":"2022-12-20T06:44:32Z","title":"When Federated Learning Meets Pre-trained Language Models'\n  Parameter-Efficient Tuning Methods","summary":"  With increasing privacy concerns on data, recent studies have made\nsignificant progress using federated learning (FL) on privacy-sensitive natural\nlanguage processing (NLP) tasks. Much literature suggests fully fine-tuning\npre-trained language models (PLMs) in the FL paradigm can mitigate the data\nheterogeneity problem and close the performance gap with centralized training.\nHowever, large PLMs bring the curse of prohibitive communication overhead and\nlocal model adaptation costs for the FL system. To this end, we introduce\nvarious parameter-efficient tuning (PETuning) methods into federated learning.\nSpecifically, we provide a holistic empirical study of representative PLMs\ntuning methods in FL. The experimental results cover the analysis of data\nheterogeneity levels, data scales, and different FL scenarios. Overall\ncommunication overhead can be significantly reduced by locally tuning and\nglobally aggregating lightweight model parameters while maintaining acceptable\nperformance in various FL settings. To facilitate the research of PETuning in\nFL, we also develop a federated tuning framework FedPETuning, which allows\npractitioners to exploit different PETuning methods under the FL training\nparadigm conveniently. The source code is available at\n\\url{https://github.com/iezhuozhuo/FedETuning/tree/deltaTuning}.\n","authors":["Zhuo Zhang","Yuanhang Yang","Yong Dai","Lizhen Qu","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2212.10025v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10020v1","updated":"2022-12-20T06:24:25Z","published":"2022-12-20T06:24:25Z","title":"On the Blind Spots of Model-Based Evaluation Metrics for Text Generation","summary":"  In this work, we explore a useful but often neglected methodology for\nrobustness analysis of text generation evaluation metrics: stress tests with\nsynthetic data. Basically, we design and synthesize a wide range of potential\nerrors and check whether they result in a commensurate drop in the metric\nscores. We examine a range of recently proposed evaluation metrics based on\npretrained language models, for the tasks of open-ended generation,\ntranslation, and summarization. Our experiments reveal interesting\ninsensitivities, biases, or even loopholes in existing metrics. For example, we\nfind that BERTScore ignores truncation errors in summarization, and MAUVE\n(built on top of GPT-2) is insensitive to errors at the beginning of\ngenerations. Further, we investigate the reasons behind these blind spots and\nsuggest practical workarounds for a more reliable evaluation of text\ngeneration.\n","authors":["Tianxing He","Jingyu Zhang","Tianle Wang","Sachin Kumar","Kyunghyun Cho","James Glass","Yulia Tsvetkov"],"pdf_url":"https://arxiv.org/pdf/2212.10020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10019v1","updated":"2022-12-20T06:23:02Z","published":"2022-12-20T06:23:02Z","title":"When Do Decompositions Help for Machine Reading?","summary":"  Answering complex questions often requires multi-step reasoning in order to\nobtain the final answer. Most research into decompositions of complex questions\ninvolves open-domain systems, which have shown success in using these\ndecompositions for improved retrieval. In the machine reading setting, however,\nwork to understand when decompositions are helpful is understudied. We conduct\nexperiments on decompositions in machine reading to unify recent work in this\nspace, using a range of models and datasets. We find that decompositions can be\nhelpful in the few-shot case, giving several points of improvement in exact\nmatch scores. However, we also show that when models are given access to\ndatasets with around a few hundred or more examples, decompositions are not\nhelpful (and can actually be detrimental). Thus, our analysis implies that\nmodels can learn decompositions implicitly even with limited data.\n","authors":["Kangda Wei","Dawn Lawrie","Benjamin Van Durme","Yunmo Chen","Orion Weller"],"pdf_url":"https://arxiv.org/pdf/2212.10019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10018v1","updated":"2022-12-20T06:21:21Z","published":"2022-12-20T06:21:21Z","title":"DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization","summary":"  Dialogue summarization has recently garnered significant attention due to its\nwide range of applications. However, existing methods for summarizing dialogues\nare suboptimal because they do not take into account the inherent structure of\ndialogue and rely heavily on labeled data, which can lead to poor performance\nin new domains. In this work, we propose DIONYSUS (dynamic input optimization\nin pre-training for dialogue summarization), a pre-trained encoder-decoder\nmodel for summarizing dialogues in any new domain. To pre-train DIONYSUS, we\ncreate two pseudo summaries for each dialogue example: one is produced by a\nfine-tuned summarization model, and the other is a collection of dialogue turns\nthat convey important information. We then choose one of these pseudo summaries\nbased on the difference in information distribution across different types of\ndialogues. This selected pseudo summary serves as the objective for\npre-training DIONYSUS using a self-supervised approach on a large dialogue\ncorpus. Our experiments show that DIONYSUS outperforms existing methods on six\ndatasets, as demonstrated by its ROUGE scores in zero-shot and few-shot\nsettings.\n","authors":["Yu Li","Baolin Peng","Pengcheng He","Michel Galley","Zhou Yu","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2212.10018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10015v1","updated":"2022-12-20T06:03:51Z","published":"2022-12-20T06:03:51Z","title":"Benchmarking Spatial Relationships in Text-to-Image Generation","summary":"  Spatial understanding is a fundamental aspect of computer vision and integral\nfor human-level reasoning about images, making it an important component for\ngrounded language understanding. While recent large-scale text-to-image\nsynthesis (T2I) models have shown unprecedented improvements in photorealism,\nit is unclear whether they have reliable spatial understanding capabilities. We\ninvestigate the ability of T2I models to generate correct spatial relationships\namong objects and present VISOR, an evaluation metric that captures how\naccurately the spatial relationship described in text is generated in the\nimage. To benchmark existing models, we introduce a large-scale challenge\ndataset SR2D that contains sentences describing two objects and the spatial\nrelationship between them. We construct and harness an automated evaluation\npipeline that employs computer vision to recognize objects and their spatial\nrelationships, and we employ it in a large-scale evaluation of T2I models. Our\nexperiments reveal a surprising finding that, although recent state-of-the-art\nT2I models exhibit high image quality, they are severely limited in their\nability to generate multiple objects or the specified spatial relations such as\nleft/right/above/below. Our analyses demonstrate several biases and artifacts\nof T2I models such as the difficulty with generating multiple objects, a bias\ntowards generating the first object mentioned, spatially inconsistent outputs\nfor equivalent relationships, and a correlation between object co-occurrence\nand spatial understanding capabilities. We conduct a human study that shows the\nalignment between VISOR and human judgment about spatial understanding. We\noffer the SR2D dataset and the VISOR metric to the community in support of T2I\nspatial reasoning research.\n","authors":["Tejas Gokhale","Hamid Palangi","Besmira Nushi","Vibhav Vineet","Eric Horvitz","Ece Kamar","Chitta Baral","Yezhou Yang"],"pdf_url":"https://arxiv.org/pdf/2212.10015v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2212.10013v1","updated":"2022-12-20T06:01:13Z","published":"2022-12-20T06:01:13Z","title":"DocAsRef: A Pilot Empirical Study on Repurposing Reference-Based Summary\n  Quality Metrics Reference-Freely","summary":"  Summary quality assessment metrics have two categories: reference-based and\nreference-free. Reference-based metrics are theoretically more accurate but are\nlimited by the availability and quality of the human-written references, which\nare both difficulty to ensure. This inspires the development of reference-free\nmetrics, which are independent from human-written references, in the past few\nyears. However, existing reference-free metrics cannot be both zero-shot and\naccurate. In this paper, we propose a zero-shot but accurate reference-free\napproach in a sneaky way: feeding documents, based upon which summaries\ngenerated, as references into reference-based metrics. Experimental results\nshow that this zero-shot approach can give us the best-performing\nreference-free metrics on nearly all aspects on several recently-released\ndatasets, even beating reference-free metrics specifically trained for this\ntask sometimes. We further investigate what reference-based metrics can benefit\nfrom such repurposing and whether our additional tweaks help.\n","authors":["Forrest Sheng Bao","Ruixuan Tu","Ge Luo"],"pdf_url":"https://arxiv.org/pdf/2212.10013v1.pdf","comment":"a pilot study"},{"id":"http://arxiv.org/abs/2212.10012v1","updated":"2022-12-20T05:59:42Z","published":"2022-12-20T05:59:42Z","title":"Language Modeling with Latent Situations","summary":"  Language models (LMs) often generate incoherent outputs: they refer to events\nand entity states that are incompatible with the state of the world described\nin their inputs. We introduce SituationSupervision, a family of approaches for\nimproving coherence in LMs by training them to construct and condition on\nexplicit representations of entities and their states. SituationSupervision has\ntwo components: an auxiliary situation modeling task that trains models to\npredict state representations in context, and a latent state inference\nprocedure that imputes these states from partially annotated training data.\nSituationSupervision can be applied to both fine-tuning (by supervising LMs to\nencode state variables in their hidden representations) and prompting (by\ninducing LMs to interleave textual descriptions of entity states with output\ntext). In both cases, SituationSupervision requires only a small number of\nstate annotations to produce major coherence improvements (between 4-11%),\nshowing that standard LMs can be sample-efficiently trained to model not just\nlanguage but the situations it describes.\n","authors":["Belinda Z. Li","Maxwell Nye","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2212.10012v1.pdf","comment":"13 pages, 3 figures, 7 tables"},{"id":"http://arxiv.org/abs/2212.10011v1","updated":"2022-12-20T05:58:32Z","published":"2022-12-20T05:58:32Z","title":"PLUE: Language Understanding Evaluation Benchmark for Privacy Policies\n  in English","summary":"  Privacy policies provide individuals with information about their rights and\nhow their personal information is handled. Natural language understanding (NLU)\ntechnologies can support individuals and practitioners to understand better\nprivacy practices described in lengthy and complex documents. However, existing\nefforts that use NLU technologies are limited by processing the language in a\nway exclusive to a single task focusing on certain privacy practices. To this\nend, we introduce the Privacy Policy Language Understanding Evaluation (PLUE)\nbenchmark, a multi-task benchmark for evaluating the privacy policy language\nunderstanding across various tasks. We also collect a large corpus of privacy\npolicies to enable privacy policy domain-specific language model pre-training.\nWe demonstrate that domain-specific pre-training offers performance\nimprovements across all tasks. We release the benchmark to encourage future\nresearch in this domain.\n","authors":["Jianfeng Chi","Wasi Uddin Ahmad","Yuan Tian","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10008v1","updated":"2022-12-20T05:51:47Z","published":"2022-12-20T05:51:47Z","title":"Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog","summary":"  Many efforts have been made to construct dialog systems for different types\nof conversations, such as task-oriented dialog (TOD) and open-domain dialog\n(ODD). To better mimic human-level conversations that usually fuse various\ndialog modes, it is essential to build a system that can effectively handle\nboth TOD and ODD and access different knowledge sources. To address the lack of\navailable data for the fused task, we propose a framework for automatically\ngenerating dialogues that combine knowledge-grounded ODDs and TODs in various\nsettings. Additionally, we introduce a unified model PivotBot that is capable\nof appropriately adopting TOD and ODD modes and accessing different knowledge\nsources in order to effectively tackle the fused task. Evaluation results\ndemonstrate the superior ability of the proposed model to switch seamlessly\nbetween TOD and ODD tasks.\n","authors":["Miaoran Li","Baolin Peng","Michel Galley","Jianfeng Gao","Zhu Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.10008v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10007v1","updated":"2022-12-20T05:48:09Z","published":"2022-12-20T05:48:09Z","title":"CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file\n  Context","summary":"  While pre-trained language models (LM) for code have achieved great success\nin code completion, they generate code conditioned only on the contents within\nthe file, i.e., in-file context, but ignore the rich semantics in other files\nwithin the same project, i.e., cross-file context, a critical source of\ninformation that is especially useful in modern modular software development.\nSuch overlooking constrains code language models' capacity in code completion,\nleading to unexpected behaviors such as generating hallucinated class member\nfunctions or function calls with unexpected arguments. In this work, we develop\na cross-file context finder tool, CCFINDER, that effectively locates and\nretrieves the most relevant cross-file context. We propose CoCoMIC, a framework\nthat incorporates cross-file context to learn the in-file and cross-file\ncontext jointly on top of pretrained code LMs. CoCoMIC successfully improves\nthe existing code LM with a 19.30% relative increase in exact match and a\n15.41% relative increase in identifier matching for code completion when the\ncross-file context is provided.\n","authors":["Yangruibo Ding","Zijian Wang","Wasi Uddin Ahmad","Murali Krishna Ramanathan","Ramesh Nallapati","Parminder Bhatia","Dan Roth","Bing Xiang"],"pdf_url":"https://arxiv.org/pdf/2212.10007v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16773v3","updated":"2022-12-20T05:31:07Z","published":"2022-11-30T06:27:46Z","title":"KRLS: Improving End-to-End Response Generation in Task Oriented Dialog\n  with Reinforced Keywords Learning","summary":"  In task-oriented dialogs, an informative and successful system response needs\nto include key information such as the phone number of a hotel. Therefore, we\nhypothesize that a model can achieve better overall performance by focusing on\ncorrectly generating key quantities. In this paper, we propose a new training\nalgorithm, Keywords Reinforcement Learning with Next-word Sampling (KRLS), that\nutilizes Reinforcement Learning but avoids the time-consuming auto-regressive\ngeneration, and a fine-grained per-token reward function to help the model\nlearn keywords generation more robustly. Empirical results show that the KRLS\nalgorithm can achieve state-of-the-art performance on the inform, success, and\ncombined score on the MultiWoZ benchmark dataset.\n","authors":["Xiao Yu","Qingyang Wu","Kun Qian","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2211.16773v3.pdf","comment":"added more explaination on the algorithm itself. result tables remain\n  the same"},{"id":"http://arxiv.org/abs/2212.10003v1","updated":"2022-12-20T05:25:12Z","published":"2022-12-20T05:25:12Z","title":"(QA)$^2$: Question Answering with Questionable Assumptions","summary":"  Naturally-occurring information-seeking questions often contain questionable\nassumptions -- assumptions that are false or unverifiable. Questions containing\nquestionable assumptions are challenging because they require a distinct answer\nstrategy that deviates from typical answers to information-seeking questions.\nFor instance, the question \"When did Marie Curie discover Uranium?\" cannot be\nanswered as a typical when question without addressing the false assumption\n\"Marie Curie discovered Uranium\". In this work, we propose (QA)$^2$ (Question\nAnswering with Questionable Assumptions), an open-domain evaluation dataset\nconsisting of naturally-occurring search engine queries that may or may not\ncontain questionable assumptions. To be successful on (QA)$^2$, systems must be\nable to detect questionable assumptions and also be able to produce adequate\nresponses for both typical information-seeking questions and ones with\nquestionable assumptions. We find that current models do struggle with handling\nquestionable assumptions -- the best performing model achieves 59% human rater\nacceptability on abstractive QA with (QA)$^2$ questions, leaving substantial\nheadroom for progress.\n","authors":["Najoung Kim","Phu Mon Htut","Samuel R. Bowman","Jackson Petty"],"pdf_url":"https://arxiv.org/pdf/2212.10003v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.10002v1","updated":"2022-12-20T05:25:01Z","published":"2022-12-20T05:25:01Z","title":"Defending Against Poisoning Attacks in Open-Domain Question Answering","summary":"  Recent work in open-domain question answering (ODQA) has shown that\nadversarial poisoning of the input contexts can cause large drops in accuracy\nfor production systems. However, little to no work has proposed methods to\ndefend against these attacks. To do so, we introduce a new method that uses\nquery augmentation to search for a diverse set of retrieved passages that could\nanswer the original question. We integrate these new passages into the model\nthrough the design of a novel confidence method, comparing the predicted answer\nto its appearance in the retrieved contexts (what we call Confidence from\nAnswer Redundancy, e.g. CAR). Together these methods allow for a simple but\neffective way to defend against poisoning attacks and provide gains of 5-20%\nexact match across varying levels of data poisoning.\n","authors":["Orion Weller","Aleem Khan","Nathaniel Weir","Dawn Lawrie","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2212.10002v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.06539v3","updated":"2022-12-20T05:21:40Z","published":"2022-02-14T08:20:15Z","title":"Deduplicating Training Data Mitigates Privacy Risks in Language Models","summary":"  Past work has shown that large language models are susceptible to privacy\nattacks, where adversaries generate sequences from a trained model and detect\nwhich sequences are memorized from the training set. In this work, we show that\nthe success of these attacks is largely due to duplication in commonly used\nweb-scraped training sets. We first show that the rate at which language models\nregenerate training sequences is superlinearly related to a sequence's count in\nthe training set. For instance, a sequence that is present 10 times in the\ntraining data is on average generated ~1000 times more often than a sequence\nthat is present only once. We next show that existing methods for detecting\nmemorized sequences have near-chance accuracy on non-duplicated training\nsequences. Finally, we find that after applying methods to deduplicate training\ndata, language models are considerably more secure against these types of\nprivacy attacks. Taken together, our results motivate an increased focus on\ndeduplication in privacy-sensitive applications and a reevaluation of the\npracticality of existing privacy attacks.\n","authors":["Nikhil Kandpal","Eric Wallace","Colin Raffel"],"pdf_url":"https://arxiv.org/pdf/2202.06539v3.pdf","comment":"ICML 2022 Camera Ready Version"},{"id":"http://arxiv.org/abs/2212.10001v1","updated":"2022-12-20T05:20:54Z","published":"2022-12-20T05:20:54Z","title":"Towards Understanding Chain-of-Thought Prompting: An Empirical Study of\n  What Matters","summary":"  Chain-of-Thought (CoT) prompting can dramatically improve the multi-step\nreasoning abilities of large language models (LLMs). CoT explicitly encourages\nthe LLM to generate intermediate rationales for solving a problem, by providing\na series of reasoning steps in the demonstrations. Despite its success, there\nis still little understanding of what makes CoT prompting effective and which\naspects of the demonstrated reasoning steps contribute to its performance. In\nthis paper, we show that CoT reasoning is possible even with invalid\ndemonstrations - prompting with invalid reasoning steps can achieve over 80-90%\nof the performance obtained using CoT under various metrics, while still\ngenerating coherent lines of reasoning during inference. Further experiments\nshow that other aspects of the rationales, such as being relevant to the query\nand correctly ordering the reasoning steps, are much more important for\neffective CoT reasoning. Overall, these findings both deepen our understanding\nof CoT prompting, and open up new questions regarding LLMs' capability to learn\nto reason in context.\n","authors":["Boshi Wang","Sewon Min","Xiang Deng","Jiaming Shen","You Wu","Luke Zettlemoyer","Huan Sun"],"pdf_url":"https://arxiv.org/pdf/2212.10001v1.pdf","comment":"Our code and model input/output will be available at\n  https://github.com/sunlab-osu/Understanding-CoT"},{"id":"http://arxiv.org/abs/2212.09741v2","updated":"2022-12-20T05:11:06Z","published":"2022-12-19T18:57:05Z","title":"One Embedder, Any Task: Instruction-Finetuned Text Embeddings","summary":"  We introduce INSTRUCTOR, a new method for computing text embeddings given\ntask instructions: every text input is embedded together with instructions\nexplaining the use case (e.g., task and domain descriptions). Unlike encoders\nfrom prior work that are more specialized, INSTRUCTOR is a single embedder that\ncan generate text embeddings tailored to different downstream tasks and\ndomains, without any further training. We first annotate instructions for 330\ndiverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive\nloss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are\nunseen during training), ranging from classification and information retrieval\nto semantic textual similarity and text generation evaluation. INSTRUCTOR,\nwhile having an order of magnitude fewer parameters than the previous best\nmodel, achieves state-of-the-art performance, with an average improvement of\n3.4% compared to the previous best results on the 70 diverse datasets. Our\nanalysis suggests that INSTRUCTOR is robust to changes in instructions, and\nthat instruction finetuning mitigates the challenge of training a single model\non diverse datasets. Our model, code, and data are available at\nhttps://instructor-embedding.github.io.\n","authors":["Hongjin Su","Weijia Shi","Jungo Kasai","Yizhong Wang","Yushi Hu","Mari Ostendorf","Wen-tau Yih","Noah A. Smith","Luke Zettlemoyer","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2212.09741v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09994v1","updated":"2022-12-20T04:38:23Z","published":"2022-12-20T04:38:23Z","title":"Towards Robustness of Text-to-SQL Models Against Natural and Realistic\n  Adversarial Table Perturbation","summary":"  The robustness of Text-to-SQL parsers against adversarial perturbations plays\na crucial role in delivering highly reliable applications. Previous studies\nalong this line primarily focused on perturbations in the natural language\nquestion side, neglecting the variability of tables. Motivated by this, we\npropose the Adversarial Table Perturbation (ATP) as a new attacking paradigm to\nmeasure the robustness of Text-to-SQL models. Following this proposition, we\ncurate ADVETA, the first robustness evaluation benchmark featuring natural and\nrealistic ATPs. All tested state-of-the-art models experience dramatic\nperformance drops on ADVETA, revealing models' vulnerability in real-world\npractices. To defend against ATP, we build a systematic adversarial training\nexample generation framework tailored for better contextualization of tabular\ndata. Experiments show that our approach not only brings the best robustness\nimprovement against table-side perturbations but also substantially empowers\nmodels against NL-side perturbations. We release our benchmark and code at:\nhttps://github.com/microsoft/ContextualSP.\n","authors":["Xinyu Pi","Bing Wang","Yan Gao","Jiaqi Guo","Zhoujun Li","Jian-Guang Lou"],"pdf_url":"https://arxiv.org/pdf/2212.09994v1.pdf","comment":"Accepted by ACL 2022 (Oral)"},{"id":"http://arxiv.org/abs/2212.09982v1","updated":"2022-12-20T03:54:44Z","published":"2022-12-20T03:54:44Z","title":"Joint Speech Transcription and Translation: Pseudo-Labeling with\n  Out-of-Distribution Data","summary":"  Self-training has been shown to be helpful in addressing data scarcity for\nmany domains, including vision, speech, and language. Specifically,\nself-training, or pseudo-labeling, labels unsupervised data and adds that to\nthe training pool. In this work, we investigate and use pseudo-labeling for a\nrecently proposed novel setup: joint transcription and translation of speech,\nwhich suffers from an absence of sufficient data resources. We show that under\nsuch data-deficient circumstances, the unlabeled data can significantly vary in\ndomain from the supervised data, which results in pseudo-label quality\ndegradation. We investigate two categories of remedies that require no\nadditional supervision and target the domain mismatch: pseudo-label filtering\nand data augmentation. We show that pseudo-label analysis and processing as\nsuch results in additional gains on top of the vanilla pseudo-labeling setup\nresulting in total improvements of up to 0.6% absolute WER and 2.2 BLEU points.\n","authors":["Mozhdeh Gheini","Tatiana Likhomanenko","Matthias Sperber","Hendra Setiawan"],"pdf_url":"https://arxiv.org/pdf/2212.09982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.01986v2","updated":"2022-12-20T02:56:59Z","published":"2022-06-04T13:07:30Z","title":"Delving into the Openness of CLIP","summary":"  Contrastive Language-Image Pre-training (CLIP) has demonstrated great\npotential in realizing open-vocabulary visual recognition in a matching style,\ndue to its holistic use of natural language supervision that covers\nunconstrained real-world visual concepts. However, it is, in turn, also\ndifficult to evaluate and analyze the openness of CLIP-like models, since they\nare in theory open to any vocabulary but the actual accuracy varies. To address\nthe insufficiency of conventional studies on openness, we resort to an\nincremental perspective and define the extensibility, which essentially\napproximates the model's ability to deal with new visual concepts, by\nevaluating openness through vocabulary expansions. Our evaluation based on\nextensibility shows that CLIP-like models are hardly truly open and their\nperformance degrades as the vocabulary expands to different degrees. Further\nanalysis reveals that the over-estimation of openness is not because CLIP-like\nmodels fail to capture the general similarity of image and text features of\nnovel visual concepts, but because of the confusion among competing text\nfeatures, that is, they are not stable with respect to the vocabulary. In light\nof this, we propose to improve the openness of CLIP in the feature space by\nenforcing the distinguishability of text features. Our method retrieves\nrelevant texts from the pre-training corpus to enhance prompts for inference,\nwhich boosts the extensibility and stability of CLIP even without fine-tuning.\n","authors":["Shuhuai Ren","Lei Li","Xuancheng Ren","Guangxiang Zhao","Xu Sun"],"pdf_url":"https://arxiv.org/pdf/2206.01986v2.pdf","comment":"22 pages, 12 figures. Code is available at\n  https://github.com/lancopku/clip-openness"},{"id":"http://arxiv.org/abs/2212.09968v1","updated":"2022-12-20T02:47:37Z","published":"2022-12-20T02:47:37Z","title":"On Improving Summarization Factual Consistency from Natural Language\n  Feedback","summary":"  Despite the recent progress in language generation models, their outputs may\nnot always meet user expectations. In this work, we study whether informational\nfeedback in natural language can be leveraged to improve generation quality and\nuser preference alignment. To this end, we consider factual consistency in\nsummarization, the quality that the summary should only contain information\nsupported by the input documents, for user preference alignment. We collect a\nhigh-quality dataset, DeFacto, containing human demonstrations and\ninformational feedback in natural language consisting of corrective\ninstructions, edited summaries, and explanations with respect to the factual\nconsistency of the summary. Using our dataset, we study two natural language\ngeneration tasks: 1) editing a summary using the human feedback, and 2)\ngenerating human feedback from the original summary. Using the two tasks, we\nfurther evaluate if models can automatically correct factual inconsistencies in\ngenerated summaries. We show that the human-edited summaries we collected are\nmore factually consistent, and pre-trained language models can leverage our\ndataset to improve the factual consistency of original system-generated\nsummaries in our proposed generation tasks. We make the DeFacto dataset\npublicly available at https://github.com/microsoft/DeFacto.\n","authors":["Yixin Liu","Budhaditya Deb","Milagro Teruel","Aaron Halfaker","Dragomir Radev","Ahmed H. Awadallah"],"pdf_url":"https://arxiv.org/pdf/2212.09968v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09955v1","updated":"2022-12-20T02:17:30Z","published":"2022-12-20T02:17:30Z","title":"BUMP: A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of\n  Faithfulness Metrics","summary":"  The proliferation of automatic faithfulness metrics for summarization has\nproduced a need for benchmarks to evaluate them. While existing benchmarks\nmeasure the correlation with human judgements of faithfulness on\nmodel-generated summaries, they are insufficient for diagnosing whether metrics\nare: 1) consistent, i.e., decrease as errors are introduced into a summary, 2)\neffective on human-written texts, and 3) sensitive to different error types (as\nsummaries can contain multiple errors). To address these needs, we present a\nbenchmark of unfaithful minimal pairs (BUMP), a dataset of 889 human-written,\nminimally different summary pairs, where a single error (from an ontology of 7\ntypes) is introduced to a summary from the CNN/DailyMail dataset to produce an\nunfaithful summary. We find BUMP complements existing benchmarks in a number of\nways: 1) the summaries in BUMP are harder to discriminate and less probable\nunder SOTA summarization models, 2) BUMP enables measuring the consistency of\nmetrics, and reveals that the most discriminative metrics tend not to be the\nmost consistent, 3) BUMP enables the measurement of metrics' performance on\nindividual error types and highlights areas of weakness for future work.\n","authors":["Liang Ma","Shuyang Cao","Robert L. Logan IV","Di Lu","Shihao Ran","Ke Zhang","Joel Tetreault","Aoife Cahill","Alejandro Jaimes"],"pdf_url":"https://arxiv.org/pdf/2212.09955v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09648v2","updated":"2022-12-20T02:04:13Z","published":"2022-12-19T17:28:22Z","title":"NusaCrowd: Open Source Initiative for Indonesian NLP Resources","summary":"  We present NusaCrowd, a collaborative initiative to collect and unite\nexisting resources for Indonesian languages, including opening access to\npreviously non-public resources. Through this initiative, we have has brought\ntogether 137 datasets and 117 standardized data loaders. The quality of the\ndatasets has been assessed manually and automatically, and their effectiveness\nhas been demonstrated in multiple experiments. NusaCrowd's data collection\nenables the creation of the first zero-shot benchmarks for natural language\nunderstanding and generation in Indonesian and its local languages.\nFurthermore, NusaCrowd brings the creation of the first multilingual automatic\nspeech recognition benchmark in Indonesian and its local languages. Our work is\nintended to help advance natural language processing research in\nunder-represented languages.\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Alham Fikri Aji","Genta Indra Winata","Bryan Wilie","Rahmad Mahendra","Christian Wibisono","Ade Romadhony","Karissa Vincentio","Fajri Koto","Jennifer Santoso","David Moeljadi","Cahya Wirawan","Frederikus Hudi","Ivan Halim Parmonangan","Ika Alfina","Muhammad Satrio Wicaksono","Ilham Firdausi Putra","Samsul Rahmadani","Yulianti Oenang","Ali Akbar Septiandri","James Jaya","Kaustubh D. Dhole","Arie Ardiyanti Suryani","Rifki Afina Putri","Dan Su","Keith Stevens","Made Nindyatama Nityasya","Muhammad Farid Adilazuarda","Ryan Ignatius","Ryandito Diandaru","Tiezheng Yu","Vito Ghifari","Wenliang Dai","Yan Xu","Dyah Damapuspita","Cuk Tho","Ichwanul Muslim Karo Karo","Tirana Noor Fatyanosa","Ziwei Ji","Pascale Fung","Graham Neubig","Timothy Baldwin","Sebastian Ruder","Herry Sujaini","Sakriani Sakti","Ayu Purwarianti"],"pdf_url":"https://arxiv.org/pdf/2212.09648v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09947v1","updated":"2022-12-20T01:53:26Z","published":"2022-12-20T01:53:26Z","title":"Future Sight: Dynamic Story Generation with Large Pretrained Language\n  Models","summary":"  Recent advances in deep learning research, such as transformers, have\nbolstered the ability for automated agents to generate creative texts similar\nto those that a human would write. By default, transformer decoders can only\ngenerate new text with respect to previously generated text. The output\ndistribution of candidate tokens at any position is conditioned on previously\nselected tokens using a self-attention mechanism to emulate the property of\nautoregression. This is inherently limiting for tasks such as controllable\nstory generation where it may be necessary to condition on future plot events\nwhen writing a story. In this work, we propose Future Sight, a method for\nfinetuning a pretrained generative transformer on the task of future\nconditioning. Transformer decoders are typically pretrained on the task of\ncompleting a context, one token at a time, by means of self-attention. Future\nSight additionally enables a decoder to attend to an encoded future plot event.\nThis motivates the decoder to expand on the context in a way that logically\nconcludes with the provided future. During inference, the future plot event can\nbe written by a human author to steer the narrative being generated in a\ncertain direction. We evaluate the efficacy of our approach on a story\ngeneration task with human evaluators.\n","authors":["Brian D. Zimmerman","Gaurav Sahu","Olga Vechtomova"],"pdf_url":"https://arxiv.org/pdf/2212.09947v1.pdf","comment":"9 pages, 1 figure, 4 tables"},{"id":"http://arxiv.org/abs/2212.09946v1","updated":"2022-12-20T01:52:46Z","published":"2022-12-20T01:52:46Z","title":"Dialog2API: Task-Oriented Dialogue with API Description and Example\n  Programs","summary":"  Functionality and dialogue experience are two important factors of\ntask-oriented dialogue systems. Conventional approaches with closed schema\n(e.g., conversational semantic parsing) often fail as both the functionality\nand dialogue experience are strongly constrained by the underlying schema. We\nintroduce a new paradigm for task-oriented dialogue - Dialog2API - to greatly\nexpand the functionality and provide seamless dialogue experience. The\nconversational model interacts with the environment by generating and executing\nprograms triggering a set of pre-defined APIs. The model also manages the\ndialogue policy and interact with the user through generating appropriate\nnatural language responses. By allowing generating free-form programs,\nDialog2API supports composite goals by combining different APIs, whereas\nunrestricted program revision provides natural and robust dialogue experience.\nTo facilitate Dialog2API, the core model is provided with API documents, an\nexecution environment and optionally some example dialogues annotated with\nprograms. We propose an approach tailored for the Dialog2API, where the\ndialogue states are represented by a stack of programs, with most recently\nmentioned program on the top of the stack. Dialog2API can work with many\napplication scenarios such as software automation and customer service. In this\npaper, we construct a dataset for AWS S3 APIs and present evaluation results of\nin-context learning baselines.\n","authors":["Raphael Shu","Elman Mansimov","Tamer Alkhouli","Nikolaos Pappas","Salvatore Romeo","Arshit Gupta","Saab Mansour","Yi Zhang","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2212.09946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09939v1","updated":"2022-12-20T01:23:01Z","published":"2022-12-20T01:23:01Z","title":"AnyTOD: A Programmable Task-Oriented Dialog System","summary":"  We propose AnyTOD, an end-to-end task-oriented dialog (TOD) system with\nzero-shot capability for unseen tasks. We view TOD as a program executed by a\nlanguage model (LM), where program logic and ontology is provided by a designer\nin the form of a schema. To enable generalization onto unseen schemas and\nprograms without prior training, AnyTOD adopts a neuro-symbolic approach. A\nneural LM keeps track of events that occur during a conversation, and a\nsymbolic program implementing the dialog policy is executed to recommend next\nactions AnyTOD should take. This approach drastically reduces data annotation\nand model training requirements, addressing a long-standing challenge in TOD\nresearch: rapidly adapting a TOD system to unseen tasks and domains. We\ndemonstrate state-of-the-art results on the STAR and ABCD benchmarks, as well\nas AnyTOD's strong zero-shot transfer capability in low-resource settings. In\naddition, we release STARv2, an updated version of the STAR dataset with richer\ndata annotations, for benchmarking zero-shot end-to-end TOD models.\n","authors":["Jeffrey Zhao","Yuan Cao","Raghav Gupta","Harrison Lee","Abhinav Rastogi","Mingqiu Wang","Hagen Soltau","Izhak Shafran","Yonghui Wu"],"pdf_url":"https://arxiv.org/pdf/2212.09939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02623v2","updated":"2022-12-20T00:39:48Z","published":"2022-12-05T22:14:49Z","title":"Unifying Vision, Text, and Layout for Universal Document Processing","summary":"  We propose Universal Document Processing (UDOP), a foundation Document AI\nmodel which unifies text, image, and layout modalities together with varied\ntask formats, including document understanding and generation. UDOP leverages\nthe spatial correlation between textual content and document image to model\nimage, text, and layout modalities with one uniform representation. With a\nnovel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain\ndownstream tasks into a prompt-based sequence generation scheme. UDOP is\npretrained on both large-scale unlabeled document corpora using innovative\nself-supervised objectives and diverse labeled data. UDOP also learns to\ngenerate document images from text and layout modalities via masked image\nreconstruction. To the best of our knowledge, this is the first time in the\nfield of document AI that one model simultaneously achieves high-quality neural\ndocument editing and content customization. Our method sets the\nstate-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,\nacross diverse data domains like finance reports, academic papers, and\nwebsites. UDOP ranks first on the leaderboard of the Document Understanding\nBenchmark (DUE).\n","authors":["Zineng Tang","Ziyi Yang","Guoxin Wang","Yuwei Fang","Yang Liu","Chenguang Zhu","Michael Zeng","Cha Zhang","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2212.02623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09928v1","updated":"2022-12-20T00:33:11Z","published":"2022-12-20T00:33:11Z","title":"Improving the Robustness of Summarization Models by Detecting and\n  Removing Input Noise","summary":"  The evaluation of abstractive summarization models typically uses test data\nthat is identically distributed as training data. In real-world practice,\ndocuments to be summarized may contain input noise caused by text extraction\nartifacts or data pipeline bugs. The robustness of model performance under\ndistribution shift caused by such noise is relatively under-studied. We present\na large empirical study quantifying the sometimes severe loss in performance\n(up to 12 ROUGE-1 points) from different types of input noise for a range of\ndatasets and model sizes. We then propose a light-weight method for detecting\nand removing such noise in the input during model inference without requiring\nany extra training, auxiliary models, or even prior knowledge of the type of\nnoise. Our proposed approach effectively mitigates the loss in performance,\nrecovering a large fraction of the performance drop, sometimes as large as 11\nROUGE-1 points.\n","authors":["Kundan Krishna","Yao Zhao","Jie Ren","Balaji Lakshminarayanan","Jiaming Luo","Mohammad Saleh","Peter J. Liu"],"pdf_url":"https://arxiv.org/pdf/2212.09928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.12265v6","updated":"2022-12-20T23:52:22Z","published":"2021-04-25T21:34:51Z","title":"Contextual-Lexicon Approach for Abusive Language Detection","summary":"  Since a lexicon-based approach is more elegant scientifically, explaining the\nsolution components and being easier to generalize to other applications, this\npaper provides a new approach for offensive language and hate speech detection\non social media. Our approach embodies a lexicon of implicit and explicit\noffensive and swearing expressions annotated with contextual information. Due\nto the severity of the social media abusive comments in Brazil, and the lack of\nresearch in Portuguese, Brazilian Portuguese is the language used to validate\nthe models. Nevertheless, our method may be applied to any other language. The\nconducted experiments show the effectiveness of the proposed approach,\noutperforming the current baseline methods for the Portuguese language.\n","authors":["Francielle Vargas","Fabiana Rodrigues de Góes","Isabelle Carvalho","Fabrício Benevenuto","Thiago Alexandre Salgueiro Pardo"],"pdf_url":"https://arxiv.org/pdf/2104.12265v6.pdf","comment":"Please cite: https://aclanthology.org/2021.ranlp-1.161/"},{"id":"http://arxiv.org/abs/2212.10692v1","updated":"2022-12-20T23:49:37Z","published":"2022-12-20T23:49:37Z","title":"Generation-Augmented Query Expansion For Code Retrieval","summary":"  Pre-trained language models have achieved promising success in code retrieval\ntasks, where a natural language documentation query is given to find the most\nrelevant existing code snippet. However, existing models focus only on\noptimizing the documentation code pairs by embedding them into latent space,\nwithout the association of external knowledge. In this paper, we propose a\ngeneration-augmented query expansion framework. Inspired by the human retrieval\nprocess - sketching an answer before searching, in this work, we utilize the\npowerful code generation model to benefit the code retrieval task.\nSpecifically, we demonstrate that rather than merely retrieving the target code\nsnippet according to the documentation query, it would be helpful to augment\nthe documentation query with its generation counterpart - generated code\nsnippets from the code generation model. To the best of our knowledge, this is\nthe first attempt that leverages the code generation model to enhance the code\nretrieval task. We achieve new state-of-the-art results on the CodeSearchNet\nbenchmark and surpass the baselines significantly.\n","authors":["Dong Li","Yelong Shen","Ruoming Jin","Yi Mao","Kuan Wang","Weizhu Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10690v1","updated":"2022-12-20T23:30:47Z","published":"2022-12-20T23:30:47Z","title":"METEOR Guided Divergence for Video Captioning","summary":"  Automatic video captioning aims for a holistic visual scene understanding. It\nrequires a mechanism for capturing temporal context in video frames and the\nability to comprehend the actions and associations of objects in a given\ntimeframe. Such a system should additionally learn to abstract video sequences\ninto sensible representations as well as to generate natural written language.\nWhile the majority of captioning models focus solely on the visual inputs,\nlittle attention has been paid to the audiovisual modality. To tackle this\nissue, we propose a novel two-fold approach. First, we implement a\nreward-guided KL Divergence to train a video captioning model which is\nresilient towards token permutations. Second, we utilise a Bi-Modal\nHierarchical Reinforcement Learning (BMHRL) Transformer architecture to capture\nlong-term temporal dependencies of the input data as a foundation for our\nhierarchical captioning module. Using our BMHRL, we show the suitability of the\nHRL agent in the generation of content-complete and grammatically sound\nsentences by achieving $4.91$, $2.23$, and $10.80$ in BLEU3, BLEU4, and METEOR\nscores, respectively on the ActivityNet Captions dataset. Finally, we make our\nBMHRL framework and trained models publicly available for users and developers\nat https://github.com/d-rothen/bmhrl.\n","authors":["Daniel Lukas Rothenpieler","Shahin Amiriparian"],"pdf_url":"https://arxiv.org/pdf/2212.10690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10678v1","updated":"2022-12-20T22:41:24Z","published":"2022-12-20T22:41:24Z","title":"Understanding Stereotypes in Language Models: Towards Robust Measurement\n  and Zero-Shot Debiasing","summary":"  Generated texts from large pretrained language models have been shown to\nexhibit a variety of harmful, human-like biases about various demographics.\nThese findings prompted large efforts aiming to understand and measure such\neffects, with the goal of providing benchmarks that can guide the development\nof techniques mitigating these stereotypical associations. However, as recent\nresearch has pointed out, the current benchmarks lack a robust experimental\nsetup, consequently hindering the inference of meaningful conclusions from\ntheir evaluation metrics. In this paper, we extend these arguments and\ndemonstrate that existing techniques and benchmarks aiming to measure\nstereotypes tend to be inaccurate and consist of a high degree of experimental\nnoise that severely limits the knowledge we can gain from benchmarking language\nmodels based on them. Accordingly, we propose a new framework for robustly\nmeasuring and quantifying biases exhibited by generative language models.\nFinally, we use this framework to investigate GPT-3's occupational gender bias\nand propose prompting techniques for mitigating these biases without the need\nfor fine-tuning.\n","authors":["Justus Mattern","Zhijing Jin","Mrinmaya Sachan","Rada Mihalcea","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2212.10678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10670v1","updated":"2022-12-20T22:11:35Z","published":"2022-12-20T22:11:35Z","title":"In-context Learning Distillation: Transferring Few-shot Learning Ability\n  of Pre-trained Language Models","summary":"  Given the success with in-context learning of large pre-trained language\nmodels, we introduce in-context learning distillation to transfer in-context\nfew-shot learning ability from large models to smaller models. We propose to\ncombine in-context learning objectives with language modeling objectives to\ndistill both the ability to read in-context examples and task knowledge to the\nsmaller models. We perform in-context learning distillation under two different\nfew-shot learning paradigms: Meta In-context Tuning (Meta-ICT) and Multitask\nIn-context Tuning (Multitask-ICT). Multitask-ICT performs better on multitask\nfew-shot learning but also requires more computation than Meta-ICT. Our method\nshows consistent improvements for both Meta-ICT and Multitask-ICT on two\nbenchmarks: LAMA and CrossFit. Our extensive experiments and analysis reveal\nthat in-context learning objectives and language modeling objectives are\ncomplementary under the Multitask-ICT paradigm. In-context learning objectives\nachieve the best performance when combined with language modeling objectives.\n","authors":["Yukun Huang","Yanda Chen","Zhou Yu","Kathleen McKeown"],"pdf_url":"https://arxiv.org/pdf/2212.10670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10650v1","updated":"2022-12-20T20:56:52Z","published":"2022-12-20T20:56:52Z","title":"KronA: Parameter Efficient Tuning with Kronecker Adapter","summary":"  Fine-tuning a Pre-trained Language Model (PLM) on a specific downstream task\nhas been a well-known paradigm in Natural Language Processing. However, with\nthe ever-growing size of PLMs, training the entire model on several downstream\ntasks becomes very expensive and resource-hungry. Recently, different Parameter\nEfficient Tuning (PET) techniques are proposed to improve the efficiency of\nfine-tuning PLMs. One popular category of PET methods is the low-rank\nadaptation methods which insert learnable truncated SVD modules into the\noriginal model either sequentially or in parallel. However, low-rank\ndecomposition suffers from limited representation power. In this work, we\naddress this problem using the Kronecker product instead of the low-rank\nrepresentation. We introduce KronA, a Kronecker product-based adapter module\nfor efficient fine-tuning of Transformer-based PLMs. We apply the proposed\nmethods for fine-tuning T5 on the GLUE benchmark to show that incorporating the\nKronecker-based modules can outperform state-of-the-art PET methods.\n","authors":["Ali Edalati","Marzieh Tahaei","Ivan Kobyzev","Vahid Partovi Nia","James J. Clark","Mehdi Rezagholizadeh"],"pdf_url":"https://arxiv.org/pdf/2212.10650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08756v2","updated":"2022-12-20T20:42:24Z","published":"2022-12-16T23:37:44Z","title":"Multi-Scales Data Augmentation Approach In Natural Language Inference\n  For Artifacts Mitigation And Pre-Trained Model Optimization","summary":"  Machine learning models can reach high performance on benchmark natural\nlanguage processing (NLP) datasets but fail in more challenging settings. We\nstudy this issue when a pre-trained model learns dataset artifacts in natural\nlanguage inference (NLI), the topic of studying the logical relationship\nbetween a pair of text sequences. We provide a variety of techniques for\nanalyzing and locating dataset artifacts inside the crowdsourced Stanford\nNatural Language Inference (SNLI) corpus. We study the stylistic pattern of\ndataset artifacts in the SNLI. To mitigate dataset artifacts, we employ a\nunique multi-scale data augmentation technique with two distinct frameworks: a\nbehavioral testing checklist at the sentence level and lexical synonym criteria\nat the word level. Specifically, our combination method enhances our model's\nresistance to perturbation testing, enabling it to continuously outperform the\npre-trained baseline.\n","authors":["Zhenyuan Lu"],"pdf_url":"https://arxiv.org/pdf/2212.08756v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10622v1","updated":"2022-12-20T19:52:41Z","published":"2022-12-20T19:52:41Z","title":"mFACE: Multilingual Summarization with Factual Consistency Evaluation","summary":"  Abstractive summarization has enjoyed renewed interest in recent years,\nthanks to pre-trained language models and the availability of large-scale\ndatasets. Despite promising results, current models still suffer from\ngenerating factually inconsistent summaries, reducing their utility for\nreal-world application. Several recent efforts attempt to address this by\ndevising models that automatically detect factual inconsistencies in machine\ngenerated summaries. However, they focus exclusively on English, a language\nwith abundant resources. In this work, we leverage factual consistency\nevaluation models to improve multilingual summarization. We explore two\nintuitive approaches to mitigate hallucinations based on the signal provided by\na multilingual NLI model, namely data filtering and controlled generation.\nExperimental results in the 45 languages from the XLSum dataset show gains over\nstrong baselines in both automatic and human evaluation.\n","authors":["Roee Aharoni","Shashi Narayan","Joshua Maynez","Jonathan Herzig","Elizabeth Clark","Mirella Lapata"],"pdf_url":"https://arxiv.org/pdf/2212.10622v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2212.10618v1","updated":"2022-12-20T19:48:10Z","published":"2022-12-20T19:48:10Z","title":"Ontologically Faithful Generation of Non-Player Character Dialogues","summary":"  We introduce a language generation task grounded in a popular video game\nenvironment. KNUDGE (KNowledge Constrained User-NPC Dialogue GEneration)\ninvolves generating dialogue trees conditioned on an ontology captured in\nnatural language passages providing quest and entity specifications. KNUDGE is\nconstructed from side quest dialogues drawn directly from game data of Obsidian\nEntertainment's The Outer Worlds, leading to real-world complexities in\ngeneration: (1) dialogues are branching trees as opposed to linear chains of\nutterances; (2) utterances must remain faithful to the game lore--character\npersonas, backstories, and entity relationships; and (3) a dialogue must\naccurately reveal new quest-related details to the human player. We report\nresults for supervised and in-context learning techniques, finding there is\nsignificant room for future work on creating realistic game-quality dialogues.\n","authors":["Nathaniel Weir","Ryan Thomas","Randolph D'Amore","Kellie Hill","Benjamin Van Durme","Harsh Jhamtani"],"pdf_url":"https://arxiv.org/pdf/2212.10618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08143v2","updated":"2022-12-20T19:16:10Z","published":"2022-07-17T11:24:44Z","title":"Can large language models reason about medical questions?","summary":"  Although large language models (LLMs) often produce impressive outputs, it\nremains unclear how they perform in real-world scenarios requiring strong\nreasoning skills and expert domain knowledge. We set out to investigate whether\nGPT-3.5 (Codex and InstructGPT) can be applied to answer and reason about\ndifficult real-world-based questions. We utilize two multiple-choice medical\nexam questions (USMLE and MedMCQA) and a medical reading comprehension dataset\n(PubMedQA). We investigate multiple prompting scenarios: Chain-of-Thought (CoT,\nthink step-by-step), zero- and few-shot (prepending the question with\nquestion-answer exemplars) and retrieval augmentation (injecting Wikipedia\npassages into the prompt). For a subset of the USMLE questions, a medical\nexpert reviewed and annotated the model's CoT. We found that InstructGPT can\noften read, reason and recall expert knowledge. Failure are primarily due to\nlack of knowledge and reasoning errors and trivial guessing heuristics are\nobserved, e.g.\\ too often predicting labels A and D on USMLE. Sampling and\ncombining many completions overcome some of these limitations. Using 100\nsamples, Codex 5-shot CoT not only gives close to well-calibrated predictive\nprobability but also achieves human-level performances on the three datasets.\nUSMLE: 60.2%, MedMCQA: 57.5% and PubMedQA: 78.2%.\n","authors":["Valentin Liévin","Christoffer Egeberg Hother","Ole Winther"],"pdf_url":"https://arxiv.org/pdf/2207.08143v2.pdf","comment":"33 pages, 6 figures, to be submitted"},{"id":"http://arxiv.org/abs/2212.10711v1","updated":"2022-12-20T18:35:33Z","published":"2022-12-20T18:35:33Z","title":"Task Ambiguity in Humans and Language Models","summary":"  Language models have recently achieved strong performance across a wide range\nof NLP benchmarks. However, unlike benchmarks, real world tasks are often\npoorly specified, and agents must deduce the user's intended behavior from a\ncombination of context, instructions, and examples. We investigate how both\nhumans and models behave in the face of such task ambiguity by proposing\nAmbiBench, a new benchmark of six ambiguously-specified classification tasks.\nWe evaluate humans and models on AmbiBench by seeing how well they identify the\nintended task using 1) instructions with varying degrees of ambiguity, and 2)\ndifferent numbers of labeled examples. We find that the combination of model\nscaling (to 175B parameters) and training with human feedback data enables\nmodels to approach or exceed the accuracy of human participants across tasks,\nbut that either one alone is not sufficient. In addition, we show how to\ndramatically improve the accuracy of language models trained without\nlarge-scale human feedback training by finetuning on a small number of\nambiguous in-context examples, providing a promising direction for teaching\nmodels to generalize well in the face of ambiguity.\n","authors":["Alex Tamkin","Kunal Handa","Avash Shrestha","Noah Goodman"],"pdf_url":"https://arxiv.org/pdf/2212.10711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11119v1","updated":"2022-12-20T17:54:08Z","published":"2022-12-20T17:54:08Z","title":"A survey on text generation using generative adversarial networks","summary":"  This work presents a thorough review concerning recent studies and text\ngeneration advancements using Generative Adversarial Networks. The usage of\nadversarial learning for text generation is promising as it provides\nalternatives to generate the so-called \"natural\" language. Nevertheless,\nadversarial text generation is not a simple task as its foremost architecture,\nthe Generative Adversarial Networks, were designed to cope with continuous\ninformation (image) instead of discrete data (text). Thus, most works are based\non three possible options, i.e., Gumbel-Softmax differentiation, Reinforcement\nLearning, and modified training objectives. All alternatives are reviewed in\nthis survey as they present the most recent approaches for generating text\nusing adversarial-based techniques. The selected works were taken from renowned\ndatabases, such as Science Direct, IEEEXplore, Springer, Association for\nComputing Machinery, and arXiv, whereas each selected work has been critically\nanalyzed and assessed to present its objective, methodology, and experimental\nresults.\n","authors":["Gustavo Henrique de Rosa","João Paulo Papa"],"pdf_url":"https://arxiv.org/pdf/2212.11119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11680v1","updated":"2022-12-20T19:37:20Z","published":"2022-12-20T19:37:20Z","title":"Smooth Sailing: Improving Active Learning for Pre-trained Language\n  Models with Representation Smoothness Analysis","summary":"  Developed as a solution to a practical need, active learning (AL) methods aim\nto reduce label complexity and the annotations costs in supervised learning.\nWhile recent work has demonstrated the benefit of using AL in combination with\nlarge pre-trained language models (PLMs), it has often overlooked the practical\nchallenges that hinder the feasibility of AL in realistic settings. We address\nthese challenges by leveraging representation smoothness analysis to improve\nthe effectiveness of AL. We develop an early stopping technique that does not\nrequire a validation set -- often unavailable in realistic AL settings -- and\nobserve significant improvements across multiple datasets and AL methods.\nAdditionally, we find that task adaptation improves AL, whereas standard short\nfine-tuning in AL does not provide improvements over random sampling. Our work\nestablishes the usefulness of representation smoothness analysis in AL and\npresents an AL stopping criterion that reduces label complexity.\n","authors":["Josip Jukić","Jan Šnajder"],"pdf_url":"https://arxiv.org/pdf/2212.11680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11672v1","updated":"2022-12-20T18:45:12Z","published":"2022-12-20T18:45:12Z","title":"Trustworthy Social Bias Measurement","summary":"  How do we design measures of social bias that we trust? While prior work has\nintroduced several measures, no measure has gained widespread trust: instead,\nmounting evidence argues we should distrust these measures. In this work, we\ndesign bias measures that warrant trust based on the cross-disciplinary theory\nof measurement modeling. To combat the frequently fuzzy treatment of social\nbias in NLP, we explicitly define social bias, grounded in principles drawn\nfrom social science research. We operationalize our definition by proposing a\ngeneral bias measurement framework DivDist, which we use to instantiate 5\nconcrete bias measures. To validate our measures, we propose a rigorous testing\nprotocol with 8 testing criteria (e.g. predictive validity: do measures predict\nbiases in US employment?). Through our testing, we demonstrate considerable\nevidence to trust our measures, showing they overcome conceptual, technical,\nand empirical deficiencies present in prior measures.\n","authors":["Rishi Bommasani","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2212.11672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11670v1","updated":"2022-12-20T17:49:27Z","published":"2022-12-20T17:49:27Z","title":"Evaluation for Change","summary":"  Evaluation is the central means for assessing, understanding, and\ncommunicating about NLP models. In this position paper, we argue evaluation\nshould be more than that: it is a force for driving change, carrying a\nsociological and political character beyond its technical dimensions. As a\nforce, evaluation's power arises from its adoption: under our view, evaluation\nsucceeds when it achieves the desired change in the field. Further, by framing\nevaluation as a force, we consider how it competes with other forces. Under our\nanalysis, we conjecture that the current trajectory of NLP suggests\nevaluation's power is waning, in spite of its potential for realizing more\npluralistic ambitions in the field. We conclude by discussing the legitimacy of\nthis power, who acquires this power and how it distributes. Ultimately, we hope\nthe research community will more aggressively harness evaluation for change.\n","authors":["Rishi Bommasani"],"pdf_url":"https://arxiv.org/pdf/2212.11670v1.pdf","comment":"Exploratory position paper"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2212.10562v1","updated":"2022-12-20T18:59:23Z","published":"2022-12-20T18:59:23Z","title":"Character-Aware Models Improve Visual Text Rendering","summary":"  Current image generation models struggle to reliably produce well-formed\nvisual text. In this paper, we investigate a key contributing factor: popular\ntext-to-image models lack character-level input features, making it much harder\nto predict a word's visual makeup as a series of glyphs. To quantify the extent\nof this effect, we conduct a series of controlled experiments comparing\ncharacter-aware vs. character-blind text encoders. In the text-only domain, we\nfind that character-aware models provide large gains on a novel spelling task\n(WikiSpell). Transferring these learnings onto the visual domain, we train a\nsuite of image generation models, and show that character-aware variants\noutperform their character-blind counterparts across a range of novel text\nrendering tasks (our DrawText benchmark). Our models set a much higher\nstate-of-the-art on visual spelling, with 30+ point accuracy gains over\ncompetitors on rare words, despite training on far fewer examples.\n","authors":["Rosanne Liu","Dan Garrette","Chitwan Saharia","William Chan","Adam Roberts","Sharan Narang","Irina Blok","RJ Mical","Mohammad Norouzi","Noah Constant"],"pdf_url":"https://arxiv.org/pdf/2212.10562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10556v1","updated":"2022-12-20T18:57:06Z","published":"2022-12-20T18:57:06Z","title":"Unleashing the Power of Visual Prompting At the Pixel Level","summary":"  This paper presents a simple and effective visual prompting method for\nadapting pre-trained models to downstream recognition tasks. Our method\nincludes two key designs. First, rather than directly adding together the\nprompt and the image, we treat the prompt as an extra and independent learnable\ncomponent. We show that the strategy of reconciling the prompt and the image\nmatters, and find that warping the prompt around a properly shrinked image\nempirically works the best. Second, we re-introduce two \"old tricks\" commonly\nused in building transferable adversarial examples, i.e., input diversity and\ngradient normalization, into visual prompting. These techniques improve\noptimization and enable the prompt to generalize better. We provide extensive\nexperimental results to demonstrate the effectiveness of our method. Using a\nCLIP model, our prompting method sets a new record of 82.8% average accuracy\nacross 12 popular classification datasets, substantially surpassing the prior\nart by +5.6%. It is worth noting that this prompting performance already\noutperforms linear probing by +2.1% and can even match fully fine-tuning in\ncertain datasets. In addition, our prompting method shows competitive\nperformance across different data scales and against distribution shifts. The\ncode is publicly available at https://github.com/UCSC-VLAA/EVP.\n","authors":["Junyang Wu","Xianhang Li","Chen Wei","Huiyu Wang","Alan Yuille","Yuyin Zhou","Cihang Xie"],"pdf_url":"https://arxiv.org/pdf/2212.10556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10553v1","updated":"2022-12-20T18:55:54Z","published":"2022-12-20T18:55:54Z","title":"RangeAugment: Efficient Online Augmentation with Range Learning","summary":"  State-of-the-art automatic augmentation methods (e.g., AutoAugment and\nRandAugment) for visual recognition tasks diversify training data using a large\nset of augmentation operations. The range of magnitudes of many augmentation\noperations (e.g., brightness and contrast) is continuous. Therefore, to make\nsearch computationally tractable, these methods use fixed and manually-defined\nmagnitude ranges for each operation, which may lead to sub-optimal policies. To\nanswer the open question on the importance of magnitude ranges for each\naugmentation operation, we introduce RangeAugment that allows us to efficiently\nlearn the range of magnitudes for individual as well as composite augmentation\noperations. RangeAugment uses an auxiliary loss based on image similarity as a\nmeasure to control the range of magnitudes of augmentation operations. As a\nresult, RangeAugment has a single scalar parameter for search, image\nsimilarity, which we simply optimize via linear search. RangeAugment integrates\nseamlessly with any model and learns model- and task-specific augmentation\npolicies. With extensive experiments on the ImageNet dataset across different\nnetworks, we show that RangeAugment achieves competitive performance to\nstate-of-the-art automatic augmentation methods with 4-5 times fewer\naugmentation operations. Experimental results on semantic segmentation, object\ndetection, foundation models, and knowledge distillation further shows\nRangeAugment's effectiveness.\n","authors":["Sachin Mehta","Saeid Naderiparizi","Fartash Faghri","Maxwell Horton","Lailin Chen","Ali Farhadi","Oncel Tuzel","Mohammad Rastegari"],"pdf_url":"https://arxiv.org/pdf/2212.10553v1.pdf","comment":"Technical report (22 pages including references and appendix)"},{"id":"http://arxiv.org/abs/2212.10550v1","updated":"2022-12-20T18:53:58Z","published":"2022-12-20T18:53:58Z","title":"InstantAvatar: Learning Avatars from Monocular Video in 60 Seconds","summary":"  In this paper, we take a significant step towards real-world applicability of\nmonocular neural avatar reconstruction by contributing InstantAvatar, a system\nthat can reconstruct human avatars from a monocular video within seconds, and\nthese avatars can be animated and rendered at an interactive rate. To achieve\nthis efficiency we propose a carefully designed and engineered system, that\nleverages emerging acceleration structures for neural fields, in combination\nwith an efficient empty space-skipping strategy for dynamic scenes. We also\ncontribute an efficient implementation that we will make available for research\npurposes. Compared to existing methods, InstantAvatar converges 130x faster and\ncan be trained in minutes instead of hours. It achieves comparable or even\nbetter reconstruction quality and novel pose synthesis results. When given the\nsame time budget, our method significantly outperforms SoTA methods.\nInstantAvatar can yield acceptable visual quality in as little as 10 seconds\ntraining time.\n","authors":["Tianjian Jiang","Xu Chen","Jie Song","Otmar Hilliges"],"pdf_url":"https://arxiv.org/pdf/2212.10550v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2212.10549v1","updated":"2022-12-20T18:53:14Z","published":"2022-12-20T18:53:14Z","title":"Cross-modal Attention Congruence Regularization for Vision-Language\n  Relation Alignment","summary":"  Despite recent progress towards scaling up multimodal vision-language models,\nthese models are still known to struggle on compositional generalization\nbenchmarks such as Winoground. We find that a critical component lacking from\ncurrent vision-language models is relation-level alignment: the ability to\nmatch directional semantic relations in text (e.g., \"mug in grass\") with\nspatial relationships in the image (e.g., the position of the mug relative to\nthe grass). To tackle this problem, we show that relation alignment can be\nenforced by encouraging the directed language attention from 'mug' to 'grass'\n(capturing the semantic relation 'in') to match the directed visual attention\nfrom the mug to the grass. Tokens and their corresponding objects are softly\nidentified using the cross-modal attention. We prove that this notion of soft\nrelation alignment is equivalent to enforcing congruence between vision and\nlanguage attention matrices under a 'change of basis' provided by the\ncross-modal attention matrix. Intuitively, our approach projects visual\nattention into the language attention space to calculate its divergence from\nthe actual language attention, and vice versa. We apply our Cross-modal\nAttention Congruence Regularization (CACR) loss to UNITER and improve on the\nstate-of-the-art approach to Winoground.\n","authors":["Rohan Pandey","Rulin Shao","Paul Pu Liang","Ruslan Salakhutdinov","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2212.10549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10541v1","updated":"2022-12-20T18:48:04Z","published":"2022-12-20T18:48:04Z","title":"UNO-QA: An Unsupervised Anomaly-Aware Framework with Test-Time\n  Clustering for OCTA Image Quality Assessment","summary":"  Medical image quality assessment (MIQA) is a vital prerequisite in various\nmedical image analysis applications. Most existing MIQA algorithms are fully\nsupervised that request a large amount of annotated data. However, annotating\nmedical images is time-consuming and labor-intensive. In this paper, we propose\nan unsupervised anomaly-aware framework with test-time clustering for optical\ncoherence tomography angiography (OCTA) image quality assessment in a setting\nwherein only a set of high-quality samples are accessible in the training\nphase. Specifically, a feature-embedding-based low-quality representation\nmodule is proposed to quantify the quality of OCTA images and then to\ndiscriminate between outstanding quality and non-outstanding quality. Within\nthe non-outstanding quality class, to further distinguish gradable images from\nungradable ones, we perform dimension reduction and clustering of multi-scale\nimage features extracted by the trained OCTA quality representation network.\nExtensive experiments are conducted on one publicly accessible dataset\nsOCTA-3*3-10k, with superiority of our proposed framework being successfully\nestablished.\n","authors":["Juntao Chen","Li Lin","Pujin Cheng","Yijin Huang","Xiaoying Tang"],"pdf_url":"https://arxiv.org/pdf/2212.10541v1.pdf","comment":"submitted to ISBI2023"},{"id":"http://arxiv.org/abs/2212.10537v1","updated":"2022-12-20T18:46:28Z","published":"2022-12-20T18:46:28Z","title":"Does CLIP Bind Concepts? Probing Compositionality in Large Image Models","summary":"  Large-scale models combining text and images have made incredible progress in\nrecent years. However, they can still fail at tasks requiring compositional\nknowledge, such as correctly picking out a red cube from a picture of multiple\nshapes. We examine the ability of CLIP (Radford et al., 2021), to caption\nimages requiring compositional knowledge. We implement five compositional\nlanguage models to probe the kinds of structure that CLIP may be using, and\ndevelop a novel training algorithm, Compositional Skipgram for Images (CoSI),\nto train these models. We look at performance in attribute-based tasks,\nrequiring the identification of a particular combination of attribute and\nobject (such as \"red cube\"), and in relational settings, where the spatial\nrelation between two shapes (such as \"cube behind sphere\") must be identified.\nWe find that in some conditions, CLIP is able to learn attribute-object\nlabellings, and to generalize to unseen attribute-object combinations. However,\nwe also see evidence that CLIP is not able to bind features together reliably.\nMoreover, CLIP is not able to reliably learn relations between objects, whereas\nsome compositional models are able to learn these perfectly. Of the five models\nwe developed, none were able to generalize to unseen relations.\n","authors":["Martha Lewis","Qinan Yu","Jack Merullo","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2212.10537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10535v1","updated":"2022-12-20T18:46:16Z","published":"2022-12-20T18:46:16Z","title":"A Survey of Deep Learning for Mathematical Reasoning","summary":"  Mathematical reasoning is a fundamental aspect of human intelligence and is\napplicable in various fields, including science, engineering, finance, and\neveryday life. The development of artificial intelligence (AI) systems capable\nof solving math problems and proving theorems has garnered significant interest\nin the fields of machine learning and natural language processing. For example,\nmathematics serves as a testbed for aspects of reasoning that are challenging\nfor powerful deep learning models, driving new algorithmic and modeling\nadvances. On the other hand, recent advances in large-scale neural language\nmodels have opened up new benchmarks and opportunities to use deep learning for\nmathematical reasoning. In this survey paper, we review the key tasks,\ndatasets, and methods at the intersection of mathematical reasoning and deep\nlearning over the past decade. We also evaluate existing benchmarks and\nmethods, and discuss future research directions in this domain.\n","authors":["Pan Lu","Liang Qiu","Wenhao Yu","Sean Welleck","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10535v1.pdf","comment":"24 pages, 2 figures, 8 tables. The repository is available at\n  https://github.com/lupantech/dl4math"},{"id":"http://arxiv.org/abs/2212.10505v1","updated":"2022-12-20T18:20:50Z","published":"2022-12-20T18:20:50Z","title":"DePlot: One-shot visual language reasoning by plot-to-table translation","summary":"  Visual language such as charts and plots is ubiquitous in the human world.\nComprehending plots and charts requires strong reasoning skills. Prior\nstate-of-the-art (SOTA) models require at least tens of thousands of training\nexamples and their reasoning capabilities are still much limited, especially on\ncomplex human-written queries. This paper presents the first one-shot solution\nto visual language reasoning. We decompose the challenge of visual language\nreasoning into two steps: (1) plot-to-text translation, and (2) reasoning over\nthe translated text. The key in this method is a modality conversion module,\nnamed as DePlot, which translates the image of a plot or chart to a linearized\ntable. The output of DePlot can then be directly used to prompt a pretrained\nlarge language model (LLM), exploiting the few-shot reasoning capabilities of\nLLMs. To obtain DePlot, we standardize the plot-to-table task by establishing\nunified task formats and metrics, and train DePlot end-to-end on this task.\nDePlot can then be used off-the-shelf together with LLMs in a plug-and-play\nfashion. Compared with a SOTA model finetuned on more than >28k data points,\nDePlot+LLM with just one-shot prompting achieves a 24.0% improvement over\nfinetuned SOTA on human-written queries from the task of chart QA.\n","authors":["Fangyu Liu","Julian Martin Eisenschlos","Francesco Piccinno","Syrine Krichene","Chenxi Pang","Kenton Lee","Mandar Joshi","Wenhu Chen","Nigel Collier","Yasemin Altun"],"pdf_url":"https://arxiv.org/pdf/2212.10505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.07885v3","updated":"2022-12-20T17:35:13Z","published":"2022-07-16T09:38:52Z","title":"Clover: Towards A Unified Video-Language Alignment and Fusion Model","summary":"  Building a universal Video-Language model for solving various video\nunderstanding tasks (\\emph{e.g.}, text-video retrieval, video question\nanswering) is an open challenge to the machine learning field. Towards this\ngoal, most recent works build the model by stacking uni-modal and cross-modal\nfeature encoders and train it with pair-wise contrastive pre-text tasks. Though\noffering attractive generality, the resulted models have to compromise between\nefficiency and performance. They mostly adopt different architectures to deal\nwith different downstream tasks. We find this is because the pair-wise training\ncannot well \\emph{align} and \\emph{fuse} features from different modalities. We\nthen introduce \\textbf{Clover}\\textemdash a Correlated Video-Language\npre-training method\\textemdash towards a universal Video-Language model for\nsolving multiple video understanding tasks with neither performance nor\nefficiency compromise. It improves cross-modal feature alignment and fusion via\na novel tri-modal alignment pre-training task. Additionally, we propose to\nenhance the tri-modal alignment via incorporating learning from semantic masked\nsamples and a new pair-wise ranking loss. Clover establishes new\nstate-of-the-arts on multiple downstream tasks, including three retrieval tasks\nfor both zero-shot and fine-tuning settings, and eight video question answering\ntasks. Codes and pre-trained models will be released at\n\\url{https://github.com/LeeYN-43/Clover}.\n","authors":["Jingjia Huang","Yinan Li","Jiashi Feng","Xinglong Wu","Xiaoshuai Sun","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2207.07885v3.pdf","comment":"Update Tri-modal Alignment task"},{"id":"http://arxiv.org/abs/2206.09592v2","updated":"2022-12-20T17:31:38Z","published":"2022-06-20T06:43:17Z","title":"DALL-E for Detection: Language-driven Compositional Image Synthesis for\n  Object Detection","summary":"  We propose a new paradigm to automatically generate training data with\naccurate labels at scale using the text-toimage synthesis frameworks (e.g.,\nDALL-E, Stable Diffusion, etc.). The proposed approach decouples training data\ngeneration into foreground object mask generation and background (context)\nimage generation. For foreground object mask generation, we use a simple\ntextual template with object class name as input to DALL-E to generate a\ndiverse set of foreground images. A foreground-background segmentation\nalgorithm is then used to generate foreground object masks. Next, in order to\ngenerate context images, first a language description of the context is\ngenerated by applying an image captioning method on a small set of images\nrepresenting the context. These language descriptions are then used to generate\ndiverse sets of context images using the DALL-E framework. These are then\ncomposited with object masks generated in the first step to provide an\naugmented training set for a classifier. We demonstrate the advantages of our\napproach on four object detection datasets including on Pascal VOC and COCO\nobject detection tasks. Furthermore, we also highlight the compositional nature\nof our data generation approach on out-of-distribution and zero-shot data\ngeneration scenarios.\n","authors":["Yunhao Ge","Jiashu Xu","Brian Nlong Zhao","Neel Joshi","Laurent Itti","Vibhav Vineet"],"pdf_url":"https://arxiv.org/pdf/2206.09592v2.pdf","comment":"v2 version, update structure (add foreground generation, stable\n  diffusion), add more experiments"},{"id":"http://arxiv.org/abs/2212.10445v1","updated":"2022-12-20T17:21:46Z","published":"2022-12-20T17:21:46Z","title":"Recycling diverse models for out-of-distribution generalization","summary":"  Foundation models are redefining how AI systems are built. Practitioners now\nfollow a standard procedure to build their machine learning solutions: download\na copy of a foundation model, and fine-tune it using some in-house data about\nthe target task of interest. Consequently, the Internet is swarmed by a handful\nof foundation models fine-tuned on many diverse tasks. Yet, these individual\nfine-tunings often lack strong generalization and exist in isolation without\nbenefiting from each other. In our opinion, this is a missed opportunity, as\nthese specialized models contain diverse features. Based on this insight, we\npropose model recycling, a simple strategy that leverages multiple fine-tunings\nof the same foundation model on diverse auxiliary tasks, and repurposes them as\nrich and diverse initializations for the target task. Specifically, model\nrecycling fine-tunes in parallel each specialized model on the target task, and\nthen averages the weights of all target fine-tunings into a final model.\nEmpirically, we show that model recycling maximizes model diversity by\nbenefiting from diverse auxiliary tasks, and achieves a new state of the art on\nthe reference DomainBed benchmark for out-of-distribution generalization.\nLooking forward, model recycling is a contribution to the emerging paradigm of\nupdatable machine learning where, akin to open-source software development, the\ncommunity collaborates to incrementally and reliably update machine learning\nmodels.\n","authors":["Alexandre Ramé","Kartik Ahuja","Jianyu Zhang","Matthieu Cord","Léon Bottou","David Lopez-Paz"],"pdf_url":"https://arxiv.org/pdf/2212.10445v1.pdf","comment":"24 pages, 7 tables, 13 figures"},{"id":"http://arxiv.org/abs/2212.10431v1","updated":"2022-12-20T17:09:53Z","published":"2022-12-20T17:09:53Z","title":"QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity","summary":"  The mechanism of existing style transfer algorithms is by minimizing a hybrid\nloss function to push the generated image toward high similarities in both\ncontent and style. However, this type of approach cannot guarantee visual\nfidelity, i.e., the generated artworks should be indistinguishable from real\nones. In this paper, we devise a new style transfer framework called QuantArt\nfor high visual-fidelity stylization. QuantArt pushes the latent representation\nof the generated artwork toward the centroids of the real artwork distribution\nwith vector quantization. By fusing the quantized and continuous latent\nrepresentations, QuantArt allows flexible control over the generated artworks\nin terms of content preservation, style similarity, and visual fidelity.\nExperiments on various style transfer settings show that our QuantArt framework\nachieves significantly higher visual fidelity compared with the existing style\ntransfer methods.\n","authors":["Siyu Huang","Jie An","Donglai Wei","Jiebo Luo","Hanspeter Pfister"],"pdf_url":"https://arxiv.org/pdf/2212.10431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10428v1","updated":"2022-12-20T17:06:32Z","published":"2022-12-20T17:06:32Z","title":"HouseCat6D -- A Large-Scale Multi-Modal Category Level 6D Object Pose\n  Dataset with Household Objects in Realistic Scenarios","summary":"  Estimating the 6D pose of objects is one of the major fields in 3D computer\nvision. Since the promising outcomes from instance-level pose estimation, the\nresearch trends are heading towards category-level pose estimation for more\npractical application scenarios. However, unlike well-established\ninstance-level pose datasets, available category-level datasets lack annotation\nquality and provided pose quantity. We propose the new category level 6D pose\ndataset HouseCat6D featuring 1) Multi-modality of Polarimetric RGB+P and Depth,\n2) Highly diverse 194 objects of 10 household object categories including 2\nphotometrically challenging categories, 3) High-quality pose annotation with an\nerror range of only 1.35 mm to 1.74 mm, 4) 41 large scale scenes with extensive\nviewpoint coverage, 5) Checkerboard-free environment throughout the entire\nscene. We also provide benchmark results of state-of-the-art category-level\npose estimation networks.\n","authors":["HyunJun Jung","Shun-Cheng Wu","Patrick Ruhkamp","Hannah Schieber","Pengyuan Wang","Giulia Rizzoli","Hongcheng Zhao","Sven Damian Meier","Daniel Roth","Nassir Navab","Benjamin Busam"],"pdf_url":"https://arxiv.org/pdf/2212.10428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10417v1","updated":"2022-12-20T16:48:51Z","published":"2022-12-20T16:48:51Z","title":"Scene Change Detection Using Multiscale Cascade Residual Convolutional\n  Neural Networks","summary":"  Scene change detection is an image processing problem related to partitioning\npixels of a digital image into foreground and background regions. Mostly,\nvisual knowledge-based computer intelligent systems, like traffic monitoring,\nvideo surveillance, and anomaly detection, need to use change detection\ntechniques. Amongst the most prominent detection methods, there are the\nlearning-based ones, which besides sharing similar training and testing\nprotocols, differ from each other in terms of their architecture design\nstrategies. Such architecture design directly impacts on the quality of the\ndetection results, and also in the device resources capacity, like memory. In\nthis work, we propose a novel Multiscale Cascade Residual Convolutional Neural\nNetwork that integrates multiscale processing strategy through a Residual\nProcessing Module, with a Segmentation Convolutional Neural Network.\nExperiments conducted on two different datasets support the effectiveness of\nthe proposed approach, achieving average overall\n$\\boldsymbol{F\\text{-}measure}$ results of $\\boldsymbol{0.9622}$ and\n$\\boldsymbol{0.9664}$ over Change Detection 2014 and PetrobrasROUTES datasets\nrespectively, besides comprising approximately eight times fewer parameters.\nSuch obtained results place the proposed technique amongst the top four\nstate-of-the-art scene change detection methods.\n","authors":["Daniel F. S. Santos","Rafael G. Pires","Danilo Colombo","João P. Papa"],"pdf_url":"https://arxiv.org/pdf/2212.10417v1.pdf","comment":"Published in: 2020 33rd SIBGRAPI Conference on Graphics, Patterns and\n  Images (SIBGRAPI)"},{"id":"http://arxiv.org/abs/2212.10411v1","updated":"2022-12-20T16:39:04Z","published":"2022-12-20T16:39:04Z","title":"DDIPNet and DDIPNet+: Discriminant Deep Image Prior Networks for Remote\n  Sensing Image Classification","summary":"  Research on remote sensing image classification significantly impacts\nessential human routine tasks such as urban planning and agriculture. Nowadays,\nthe rapid advance in technology and the availability of many high-quality\nremote sensing images create a demand for reliable automation methods. The\ncurrent paper proposes two novel deep learning-based architectures for image\nclassification purposes, i.e., the Discriminant Deep Image Prior Network and\nthe Discriminant Deep Image Prior Network+, which combine Deep Image Prior and\nTriplet Networks learning strategies. Experiments conducted over three\nwell-known public remote sensing image datasets achieved state-of-the-art\nresults, evidencing the effectiveness of using deep image priors for remote\nsensing image classification.\n","authors":["Daniel F. S. Santos","Rafael G. Pires","Leandro A. Passos","João P. Papa"],"pdf_url":"https://arxiv.org/pdf/2212.10411v1.pdf","comment":"Published in: 2021 IEEE International Geoscience and Remote Sensing\n  Symposium IGARSS"},{"id":"http://arxiv.org/abs/2204.07713v2","updated":"2022-12-20T16:35:44Z","published":"2022-04-16T04:23:47Z","title":"GAUSS: Guided Encoder-Decoder Architecture for Hyperspectral Unmixing\n  with Spatial Smoothness","summary":"  In recent hyperspectral unmixing (HU) literature, the application of deep\nlearning (DL) has become more prominent, especially with the autoencoder (AE)\narchitecture. We propose a split architecture and use a pseudo-ground truth for\nabundances to guide the `unmixing network' (UN) optimization. Preceding the UN,\nan `approximation network' (AN) is proposed, which will improve the association\nbetween the centre pixel and its neighbourhood. Hence, it will accentuate\nspatial correlation in the abundances as its output is the input to the UN and\nthe reference for the `mixing network' (MN). In the Guided Encoder-Decoder\nArchitecture for Hyperspectral Unmixing with Spatial Smoothness (GAUSS), we\nproposed using one-hot encoded abundances as the pseudo-ground truth to guide\nthe UN; computed using the k-means algorithm to exclude the use of prior HU\nmethods. Furthermore, we release the single-layer constraint on MN by\nintroducing the UN generated abundances in contrast to the standard AE for HU.\nSecondly, we experimented with two modifications on the pre-trained network\nusing the GAUSS method. In GAUSS$_\\textit{blind}$, we have concatenated the UN\nand the MN to back-propagate the reconstruction error gradients to the encoder.\nThen, in the GAUSS$_\\textit{prime}$, abundance results of a signal processing\n(SP) method with reliable abundance results were used as the pseudo-ground\ntruth with the GAUSS architecture. According to quantitative and graphical\nresults for four experimental datasets, the three architectures either\ntranscended or equated the performance of existing HU algorithms from both DL\nand SP domains.\n","authors":["Yasiru Ranasinghe","Kavinga Weerasooriya","Roshan Godaliyadda","Vijitha Herath","Parakrama Ekanayake","Dhananjaya Jayasundara","Lakshitha Ramanayake","Neranjan Senarath","Dulantha Wickramasinghe"],"pdf_url":"https://arxiv.org/pdf/2204.07713v2.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2212.10390v1","updated":"2022-12-20T16:17:40Z","published":"2022-12-20T16:17:40Z","title":"ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic\n  Segmentation","summary":"  State-of-the-art 3D semantic segmentation models are trained on the\noff-the-shelf public benchmarks, but they often face the major challenge when\nthese well-trained models are deployed to a new domain. In this paper, we\npropose an Active-and-Adaptive Segmentation (ADAS) baseline to enhance the weak\ncross-domain generalization ability of a well-trained 3D segmentation model,\nand bridge the point distribution gap between domains. Specifically, before the\ncross-domain adaptation stage begins, ADAS performs an active sampling\noperation to select a maximally-informative subset from both source and target\ndomains for effective adaptation, reducing the adaptation difficulty under 3D\nscenarios. Benefiting from the rise of multi-modal 2D-3D datasets, ADAS\nutilizes a cross-modal attention-based feature fusion module that can extract a\nrepresentative pair of image features and point features to achieve a\nbi-directional image-point feature interaction for better safe adaptation.\nExperimentally, ADAS is verified to be effective in many cross-domain settings\nincluding: 1) Unsupervised Domain Adaptation (UDA), which means that all\nsamples from target domain are unlabeled; 2) Unsupervised Few-shot Domain\nAdaptation (UFDA) which means that only a few unlabeled samples are available\nin the unlabeled target domain; 3) Active Domain Adaptation (ADA) which means\nthat the selected target samples by ADAS are manually annotated. Their results\ndemonstrate that ADAS achieves a significant accuracy gain by easily coupling\nADAS with self-training methods or off-the-shelf UDA works.\n","authors":["Ben Fei","Siyuan Huang","Jiakang Yuan","Botian Shi","Bo Zhang","Tao Chen","Min Dou","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2212.10390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10368v1","updated":"2022-12-20T15:49:56Z","published":"2022-12-20T15:49:56Z","title":"Masked Event Modeling: Self-Supervised Pretraining for Event Cameras","summary":"  Event cameras offer the capacity to asynchronously capture brightness changes\nwith low latency, high temporal resolution, and high dynamic range. Deploying\ndeep learning methods for classification or other tasks to these sensors\ntypically requires large labeled datasets. Since the amount of labeled event\ndata is tiny compared to the bulk of labeled RGB imagery, the progress of\nevent-based vision has remained limited. To reduce the dependency on labeled\nevent data, we introduce Masked Event Modeling (MEM), a self-supervised\npretraining framework for events. Our method pretrains a neural network on\nunlabeled events, which can originate from any event camera recording.\nSubsequently, the pretrained model is finetuned on a downstream task leading to\nan overall better performance while requiring fewer labels. Our method\noutperforms the state-of-the-art on N-ImageNet, N-Cars, and N-Caltech101,\nincreasing the object classification accuracy on N-ImageNet by 7.96%. We\ndemonstrate that Masked Event Modeling is superior to RGB-based pretraining on\na real world dataset.\n","authors":["Simon Klenk","David Bonello","Lukas Koestler","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2212.10368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10367v1","updated":"2022-12-20T15:48:48Z","published":"2022-12-20T15:48:48Z","title":"Modeling Human Eye Movements with Neural Networks in a Maze-Solving Task","summary":"  From smoothly pursuing moving objects to rapidly shifting gazes during visual\nsearch, humans employ a wide variety of eye movement strategies in different\ncontexts. While eye movements provide a rich window into mental processes,\nbuilding generative models of eye movements is notoriously difficult, and to\ndate the computational objectives guiding eye movements remain largely a\nmystery. In this work, we tackled these problems in the context of a canonical\nspatial planning task, maze-solving. We collected eye movement data from human\nsubjects and built deep generative models of eye movements using a novel\ndifferentiable architecture for gaze fixations and gaze shifts. We found that\nhuman eye movements are best predicted by a model that is optimized not to\nperform the task as efficiently as possible but instead to run an internal\nsimulation of an object traversing the maze. This not only provides a\ngenerative model of eye movements in this task but also suggests a\ncomputational theory for how humans solve the task, namely that humans use\nmental simulation.\n","authors":["Jason Li","Nicholas Watters"," Yingting"," Wang","Hansem Sohn","Mehrdad Jazayeri"],"pdf_url":"https://arxiv.org/pdf/2212.10367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10340v1","updated":"2022-12-20T15:25:38Z","published":"2022-12-20T15:25:38Z","title":"Weakly supervised training of universal visual concepts for multi-domain\n  semantic segmentation","summary":"  Deep supervised models have an unprecedented capacity to absorb large\nquantities of training data. Hence, training on multiple datasets becomes a\nmethod of choice towards strong generalization in usual scenes and graceful\nperformance degradation in edge cases. Unfortunately, different datasets often\nhave incompatible labels. For instance, the Cityscapes road class subsumes all\ndriving surfaces, while Vistas defines separate classes for road markings,\nmanholes etc. Furthermore, many datasets have overlapping labels. For instance,\npickups are labeled as trucks in VIPER, cars in Vistas, and vans in ADE20k. We\naddress this challenge by considering labels as unions of universal visual\nconcepts. This allows seamless and principled learning on multi-domain dataset\ncollections without requiring any relabeling effort. Our method achieves\ncompetitive within-dataset and cross-dataset generalization, as well as ability\nto learn visual concepts which are not separately labeled in any of the\ntraining datasets. Experiments reveal competitive or state-of-the-art\nperformance on two multi-domain dataset collections and on the WildDash 2\nbenchmark.\n","authors":["Petra Bevandić","Marin Oršić","Ivan Grubišić","Josip Šarić","Siniša Šegvić"],"pdf_url":"https://arxiv.org/pdf/2212.10340v1.pdf","comment":"23 pages, 10 figures, 9 tables"},{"id":"http://arxiv.org/abs/2212.10319v1","updated":"2022-12-20T15:11:57Z","published":"2022-12-20T15:11:57Z","title":"Image quality prediction using synthetic and natural codebooks:\n  comparative results","summary":"  We investigate a model for image/video quality assessment based on building a\nset of codevectors representing in a sense some basic properties of images,\nsimilar to well-known CORNIA model. We analyze the codebook building method and\npropose some modifications for it. Also the algorithm is investigated from the\npoint of inference time reduction. Both natural and synthetic images are used\nfor building codebooks and some analysis of synthetic images used for codebooks\nis provided. It is demonstrated the results on quality assessment may be\nimproves with the use if synthetic images for codebook construction. We also\ndemonstrate regimes of the algorithm in which real time execution on CPU is\npossible for sufficiently high correlations with mean opinion score (MOS).\nVarious pooling strategies are considered as well as the problem of metric\nsensitivity to bitrate.\n","authors":["Maxim Koroteev","Kirill Aistov","Valeriy Berezovskiy","Pavel Frolov"],"pdf_url":"https://arxiv.org/pdf/2212.10319v1.pdf","comment":"18 pages, 8 figures"},{"id":"http://arxiv.org/abs/2112.11088v4","updated":"2022-12-20T15:02:09Z","published":"2021-12-21T10:48:34Z","title":"EPNet++: Cascade Bi-directional Fusion for Multi-Modal 3D Object\n  Detection","summary":"  Recently, fusing the LiDAR point cloud and camera image to improve the\nperformance and robustness of 3D object detection has received more and more\nattention, as these two modalities naturally possess strong complementarity. In\nthis paper, we propose EPNet++ for multi-modal 3D object detection by\nintroducing a novel Cascade Bi-directional Fusion~(CB-Fusion) module and a\nMulti-Modal Consistency~(MC) loss. More concretely, the proposed CB-Fusion\nmodule enhances point features with plentiful semantic information absorbed\nfrom the image features in a cascade bi-directional interaction fusion manner,\nleading to more powerful and discriminative feature representations. The MC\nloss explicitly guarantees the consistency between predicted scores from two\nmodalities to obtain more comprehensive and reliable confidence scores. The\nexperimental results on the KITTI, JRDB and SUN-RGBD datasets demonstrate the\nsuperiority of EPNet++ over the state-of-the-art methods. Besides, we emphasize\na critical but easily overlooked problem, which is to explore the performance\nand robustness of a 3D detector in a sparser scene. Extensive experiments\npresent that EPNet++ outperforms the existing SOTA methods with remarkable\nmargins in highly sparse point cloud cases, which might be an available\ndirection to reduce the expensive cost of LiDAR sensors. Code is available at:\nhttps://github.com/happinesslz/EPNetV2.\n","authors":["Zhe Liu","Tengteng Huang","Bingling Li","Xiwu Chen","Xi Wang","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2112.11088v4.pdf","comment":"Accepted by TPAMI-2022"},{"id":"http://arxiv.org/abs/2212.10305v1","updated":"2022-12-20T14:53:26Z","published":"2022-12-20T14:53:26Z","title":"Which Pixel to Annotate: a Label-Efficient Nuclei Segmentation Framework","summary":"  Recently deep neural networks, which require a large amount of annotated\nsamples, have been widely applied in nuclei instance segmentation of H\\&E\nstained pathology images. However, it is inefficient and unnecessary to label\nall pixels for a dataset of nuclei images which usually contain similar and\nredundant patterns. Although unsupervised and semi-supervised learning methods\nhave been studied for nuclei segmentation, very few works have delved into the\nselective labeling of samples to reduce the workload of annotation. Thus, in\nthis paper, we propose a novel full nuclei segmentation framework that chooses\nonly a few image patches to be annotated, augments the training set from the\nselected samples, and achieves nuclei segmentation in a semi-supervised manner.\nIn the proposed framework, we first develop a novel consistency-based patch\nselection method to determine which image patches are the most beneficial to\nthe training. Then we introduce a conditional single-image GAN with a\ncomponent-wise discriminator, to synthesize more training samples. Lastly, our\nproposed framework trains an existing segmentation model with the above\naugmented samples. The experimental results show that our proposed method could\nobtain the same-level performance as a fully-supervised baseline by annotating\nless than 5% pixels on some benchmarks.\n","authors":["Wei Lou","Haofeng Li","Guanbin Li","Xiaoguang Han","Xiang Wan"],"pdf_url":"https://arxiv.org/pdf/2212.10305v1.pdf","comment":"IEEE TMI 2022, Released code: https://github.com/lhaof/NuSeg"},{"id":"http://arxiv.org/abs/2212.10292v1","updated":"2022-12-20T14:36:45Z","published":"2022-12-20T14:36:45Z","title":"Towards Unsupervised Visual Reasoning: Do Off-The-Shelf Features Know\n  How to Reason?","summary":"  Recent advances in visual representation learning allowed to build an\nabundance of powerful off-the-shelf features that are ready-to-use for numerous\ndownstream tasks. This work aims to assess how well these features preserve\ninformation about the objects, such as their spatial location, their visual\nproperties and their relative relationships. We propose to do so by evaluating\nthem in the context of visual reasoning, where multiple objects with complex\nrelationships and different attributes are at play. More specifically, we\nintroduce a protocol to evaluate visual representations for the task of Visual\nQuestion Answering. In order to decouple visual feature extraction from\nreasoning, we design a specific attention-based reasoning module which is\ntrained on the frozen visual representations to be evaluated, in a spirit\nsimilar to standard feature evaluations relying on shallow networks. We compare\ntwo types of visual representations, densely extracted local features and\nobject-centric ones, against the performances of a perfect image representation\nusing ground truth. Our main findings are two-fold. First, despite excellent\nperformances on classical proxy tasks, such representations fall short for\nsolving complex reasoning problem. Second, object-centric features better\npreserve the critical information necessary to perform visual reasoning. In our\nproposed framework we show how to methodologically approach this evaluation.\n","authors":["Monika Wysoczańska","Tom Monnier","Tomasz Trzciński","David Picard"],"pdf_url":"https://arxiv.org/pdf/2212.10292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10291v1","updated":"2022-12-20T14:35:33Z","published":"2022-12-20T14:35:33Z","title":"Quantifying and Visualizing Vascular Branching Geometry with Micro-CT:\n  Normalization of Intra- and Inter-Specimen Variations","summary":"  Micro-CT images of the renal arteries of intact rat kidneys, which had their\nvasculature injected with the contrast agent polymer Microfil, were\ncharacterized. Measurement of inter-branch segment properties and the\nhierarchical structure of the vessel trees were computed by an automated\nalgorithmic approach. The perfusion territories of the different kidneys, as\nwell as the local diameters of the segmented vasculature were mapped onto the\nrepresentative structures and visually explored. Various parameters were\ncompared in order to outline key geometrical properties, properties which were\nshown to not have a wide range of inter-specimen variation. It is shown that\nthe fractal scaling in non-symmetric branching reveals itself differently, than\nin symmetric branching (e.g., in the lung the mean bronchial diameters at each\ngeneration are closely related). Also, perfused tissue is shown to have very\nlittle inter-specimen variation and therefore could be used in future studies\nrelated to characterizing various disease states of tissues and organs based on\nvascular branching geometry.\n","authors":["Timothy L. Kline"],"pdf_url":"https://arxiv.org/pdf/2212.10291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11201v2","updated":"2022-12-20T14:22:27Z","published":"2022-11-21T06:24:41Z","title":"Self-Supervised 3D Traversability Estimation with Proxy Bank Guidance","summary":"  Traversability estimation for mobile robots in off-road environments requires\nmore than conventional semantic segmentation used in constrained environments\nlike on-road conditions. Recently, approaches to learning a traversability\nestimation from past driving experiences in a self-supervised manner are\narising as they can significantly reduce human labeling costs and labeling\nerrors. However, the self-supervised data only provide supervision for the\nactually traversed regions, inducing epistemic uncertainty according to the\nscarcity of negative information. Negative data are rarely harvested as the\nsystem can be severely damaged while logging the data. To mitigate the\nuncertainty, we introduce a deep metric learning-based method to incorporate\nunlabeled data with a few positive and negative prototypes in order to leverage\nthe uncertainty, which jointly learns using semantic segmentation and\ntraversability regression. To firmly evaluate the proposed framework, we\nintroduce a new evaluation metric that comprehensively evaluates the\nsegmentation and regression. Additionally, we construct a driving dataset\n`Dtrail' in off-road environments with a mobile robot platform, which is\ncomposed of a wide variety of negative data. We examine our method on Dtrail as\nwell as the publicly available SemanticKITTI dataset.\n","authors":["Jihwan Bae","Junwon Seo","Taekyung Kim","Hae-gon Jeon","Kiho Kwak","Inwook Shim"],"pdf_url":"https://arxiv.org/pdf/2211.11201v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10265v1","updated":"2022-12-20T14:14:37Z","published":"2022-12-20T14:14:37Z","title":"High-resolution canopy height map in the Landes forest (France) based on\n  GEDI, Sentinel-1, and Sentinel-2 data with a deep learning approach","summary":"  In intensively managed forests in Europe, where forests are divided into\nstands of small size and may show heterogeneity within stands, a high spatial\nresolution (10 - 20 meters) is arguably needed to capture the differences in\ncanopy height. In this work, we developed a deep learning model based on\nmulti-stream remote sensing measurements to create a high-resolution canopy\nheight map over the \"Landes de Gascogne\" forest in France, a large maritime\npine plantation of 13,000 km$^2$ with flat terrain and intensive management.\nThis area is characterized by even-aged and mono-specific stands, of a typical\nlength of a few hundred meters, harvested every 35 to 50 years. Our deep\nlearning U-Net model uses multi-band images from Sentinel-1 and Sentinel-2 with\ncomposite time averages as input to predict tree height derived from GEDI\nwaveforms. The evaluation is performed with external validation data from\nforest inventory plots and a stereo 3D reconstruction model based on Skysat\nimagery available at specific locations. We trained seven different U-net\nmodels based on a combination of Sentinel-1 and Sentinel-2 bands to evaluate\nthe importance of each instrument in the dominant height retrieval. The model\noutputs allow us to generate a 10 m resolution canopy height map of the whole\n\"Landes de Gascogne\" forest area for 2020 with a mean absolute error of 2.02 m\non the Test dataset. The best predictions were obtained using all available\nsatellite layers from Sentinel-1 and Sentinel-2 but using only one satellite\nsource also provided good predictions. For all validation datasets in\nconiferous forests, our model showed better metrics than previous canopy height\nmodels available in the same region.\n","authors":["Martin Schwartz","Philippe Ciais","Catherine Ottlé","Aurelien De Truchis","Cedric Vega","Ibrahim Fayad","Martin Brandt","Rasmus Fensholt","Nicolas Baghdadi","François Morneau","David Morin","Dominique Guyon","Sylvia Dayau","Jean-Pierre Wigneron"],"pdf_url":"https://arxiv.org/pdf/2212.10265v1.pdf","comment":"39 pages, 16 figures + supplementary contents"},{"id":"http://arxiv.org/abs/2212.10263v1","updated":"2022-12-20T14:09:37Z","published":"2022-12-20T14:09:37Z","title":"Eff-3DPSeg: 3D organ-level plant shoot segmentation using\n  annotation-efficient point clouds","summary":"  Reliable and automated 3D plant shoot segmentation is a core prerequisite for\nthe extraction of plant phenotypic traits at the organ level. Combining deep\nlearning and point clouds can provide effective ways to address the challenge.\nHowever, fully supervised deep learning methods require datasets to be\npoint-wise annotated, which is extremely expensive and time-consuming. In our\nwork, we proposed a novel weakly supervised framework, Eff-3DPSeg, for 3D plant\nshoot segmentation. First, high-resolution point clouds of soybean were\nreconstructed using a low-cost photogrammetry system, and the Meshlab-based\nPlant Annotator was developed for plant point cloud annotation. Second, a\nweakly-supervised deep learning method was proposed for plant organ\nsegmentation. The method contained: (1) Pretraining a self-supervised network\nusing Viewpoint Bottleneck loss to learn meaningful intrinsic structure\nrepresentation from the raw point clouds; (2) Fine-tuning the pre-trained model\nwith about only 0.5% points being annotated to implement plant organ\nsegmentation. After, three phenotypic traits (stem diameter, leaf width, and\nleaf length) were extracted. To test the generality of the proposed method, the\npublic dataset Pheno4D was included in this study. Experimental results showed\nthat the weakly-supervised network obtained similar segmentation performance\ncompared with the fully-supervised setting. Our method achieved 95.1%, 96.6%,\n95.8% and 92.2% in the Precision, Recall, F1-score, and mIoU for stem leaf\nsegmentation and 53%, 62.8% and 70.3% in the AP, AP@25, and AP@50 for leaf\ninstance segmentation. This study provides an effective way for characterizing\n3D plant architecture, which will become useful for plant breeders to enhance\nselection processes.\n","authors":["Liyi Luo","Xintong Jiang","Yu Yang","Eugene Roy Antony Samy","Mark Lefsrud","Valerio Hoyos-Villegas","Shangpeng Sun"],"pdf_url":"https://arxiv.org/pdf/2212.10263v1.pdf","comment":"This paper has been submitted to Plant Phenomics"},{"id":"http://arxiv.org/abs/2207.06635v5","updated":"2022-12-20T13:59:51Z","published":"2022-07-14T03:08:33Z","title":"EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic\n  Differential Equations","summary":"  Score-based diffusion models (SBDMs) have achieved the SOTA FID results in\nunpaired image-to-image translation (I2I). However, we notice that existing\nmethods totally ignore the training data in the source domain, leading to\nsub-optimal solutions for unpaired I2I. To this end, we propose energy-guided\nstochastic differential equations (EGSDE) that employs an energy function\npretrained on both the source and target domains to guide the inference process\nof a pretrained SDE for realistic and faithful unpaired I2I. Building upon two\nfeature extractors, we carefully design the energy function such that it\nencourages the transferred image to preserve the domain-independent features\nand discard domain-specific ones. Further, we provide an alternative\nexplanation of the EGSDE as a product of experts, where each of the three\nexperts (corresponding to the SDE and two feature extractors) solely\ncontributes to faithfulness or realism. Empirically, we compare EGSDE to a\nlarge family of baselines on three widely-adopted unpaired I2I tasks under four\nmetrics. EGSDE not only consistently outperforms existing SBDMs-based methods\nin almost all settings but also achieves the SOTA realism results without\nharming the faithful performance. Furthermore, EGSDE allows for flexible\ntrade-offs between realism and faithfulness and we improve the realism results\nfurther (e.g., FID of 51.04 in Cat to Dog and FID of 50.43 in Wild to Dog on\nAFHQ) by tuning hyper-parameters. The code is available at\nhttps://github.com/ML-GSAI/EGSDE.\n","authors":["Min Zhao","Fan Bao","Chongxuan Li","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2207.06635v5.pdf","comment":"NIPS 2022"},{"id":"http://arxiv.org/abs/2212.10236v1","updated":"2022-12-20T13:26:42Z","published":"2022-12-20T13:26:42Z","title":"Self-Pair: Synthesizing Changes from Single Source for Object Change\n  Detection in Remote Sensing Imagery","summary":"  For change detection in remote sensing, constructing a training dataset for\ndeep learning models is difficult due to the requirements of bi-temporal\nsupervision. To overcome this issue, single-temporal supervision which treats\nchange labels as the difference of two semantic masks has been proposed. This\nnovel method trains a change detector using two spatially unrelated images with\ncorresponding semantic labels such as building. However, training on unpaired\ndatasets could confuse the change detector in the case of pixels that are\nlabeled unchanged but are visually significantly different. In order to\nmaintain the visual similarity in unchanged area, in this paper, we emphasize\nthat the change originates from the source image and show that manipulating the\nsource image as an after-image is crucial to the performance of change\ndetection. Extensive experiments demonstrate the importance of maintaining\nvisual information between pre- and post-event images, and our method\noutperforms existing methods based on single-temporal supervision. code is\navailable at https://github.com/seominseok0429/Self-Pair-for-Change-Detection.\n","authors":["Minseok Seo","Hakjin Lee","Yongjin Jeon","Junghoon Seo"],"pdf_url":"https://arxiv.org/pdf/2212.10236v1.pdf","comment":"This paper has been accepted by WACV2023"},{"id":"http://arxiv.org/abs/2212.10230v1","updated":"2022-12-20T13:09:58Z","published":"2022-12-20T13:09:58Z","title":"A Comprehensive Study and Comparison of the Robustness of 3D Object\n  Detectors Against Adversarial Attacks","summary":"  Deep learning-based 3D object detectors have made significant progress in\nrecent years and have been deployed in a wide range of applications. It is\ncrucial to understand the robustness of detectors against adversarial attacks\nwhen employing detectors in security-critical applications. In this paper, we\nmake the first attempt to conduct a thorough evaluation and analysis of the\nrobustness of 3D detectors under adversarial attacks. Specifically, we first\nextend three kinds of adversarial attacks to the 3D object detection task to\nbenchmark the robustness of state-of-the-art 3D object detectors against\nattacks on KITTI and Waymo datasets, subsequently followed by the analysis of\nthe relationship between robustness and properties of detectors. Then, we\nexplore the transferability of cross-model, cross-task, and cross-data attacks.\nWe finally conduct comprehensive experiments of defense for 3D detectors,\ndemonstrating that simple transformations like flipping are of little help in\nimproving robustness when the strategy of transformation imposed on input point\ncloud data is exposed to attackers. Our findings will facilitate investigations\nin understanding and defending the adversarial attacks against 3D object\ndetectors to advance this field.\n","authors":["Yifan Zhang","Junhui Hou","Yixuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2212.10230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10229v1","updated":"2022-12-20T13:07:20Z","published":"2022-12-20T13:07:20Z","title":"StyleDomain: Analysis of StyleSpace for Domain Adaptation of StyleGAN","summary":"  Domain adaptation of GANs is a problem of fine-tuning the state-of-the-art\nGAN models (e.g. StyleGAN) pretrained on a large dataset to a specific domain\nwith few samples (e.g. painting faces, sketches, etc.). While there are a great\nnumber of methods that tackle this problem in different ways there are still\nmany important questions that remain unanswered. In this paper, we provide a\nsystematic and in-depth analysis of the domain adaptation problem of GANs,\nfocusing on the StyleGAN model. First, we perform a detailed exploration of the\nmost important parts of StyleGAN that are responsible for adapting the\ngenerator to a new domain depending on the similarity between the source and\ntarget domains. In particular, we show that affine layers of StyleGAN can be\nsufficient for fine-tuning to similar domains. Second, inspired by these\nfindings, we investigate StyleSpace to utilize it for domain adaptation. We\nshow that there exist directions in the StyleSpace that can adapt StyleGAN to\nnew domains. Further, we examine these directions and discover their many\nsurprising properties. Finally, we leverage our analysis and findings to\ndeliver practical improvements and applications in such standard tasks as\nimage-to-image translation and cross-domain morphing.\n","authors":["Aibek Alanov","Vadim Titov","Maksim Nakhodnov","Dmitry Vetrov"],"pdf_url":"https://arxiv.org/pdf/2212.10229v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.10220v1","updated":"2022-12-20T12:52:19Z","published":"2022-12-20T12:52:19Z","title":"CSMPQ:Class Separability Based Mixed-Precision Quantization","summary":"  Mixed-precision quantization has received increasing attention for its\ncapability of reducing the computational burden and speeding up the inference\ntime. Existing methods usually focus on the sensitivity of different network\nlayers, which requires a time-consuming search or training process. To this\nend, a novel mixed-precision quantization method, termed CSMPQ, is proposed.\nSpecifically, the TF-IDF metric that is widely used in natural language\nprocessing (NLP) is introduced to measure the class separability of layer-wise\nfeature maps. Furthermore, a linear programming problem is designed to derive\nthe optimal bit configuration for each layer. Without any iterative process,\nthe proposed CSMPQ achieves better compression trade-offs than the\nstate-of-the-art quantization methods. Specifically, CSMPQ achieves 73.03$\\%$\nTop-1 acc on ResNet-18 with only 59G BOPs for QAT, and 71.30$\\%$ top-1 acc with\nonly 1.5Mb on MobileNetV2 for PTQ.\n","authors":["Mingkai Wang","Taisong Jin","Miaohui Zhang","Zhengtao Yu"],"pdf_url":"https://arxiv.org/pdf/2212.10220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10203v1","updated":"2022-12-20T12:30:51Z","published":"2022-12-20T12:30:51Z","title":"ParallelNet: Multi-mode Trajectory Prediction by Multi-mode Trajectory\n  Fusion","summary":"  Level 5 Autonomous Driving, a technology that a fully automated vehicle (AV)\nrequires no human intervention, has raised serious concerns on safety and\nstability before widespread use. The capability of understanding and predicting\nfuture motion trajectory of road objects can help AV plan a path that is safe\nand easy to control. In this paper, we propose a network architecture that\nparallelizes multiple convolutional neural network backbones and fuses features\nto make multi-mode trajectory prediction. In the 2020 ICRA Nuscene Prediction\nchallenge, our model ranks 15th on the leaderboard across all teams.\n","authors":["Fei Wu","Luoyu Chen","Hao Lu"],"pdf_url":"https://arxiv.org/pdf/2212.10203v1.pdf","comment":"8 pages,8 figures"},{"id":"http://arxiv.org/abs/2212.10200v1","updated":"2022-12-20T12:24:48Z","published":"2022-12-20T12:24:48Z","title":"Redistribution of Weights and Activations for AdderNet Quantization","summary":"  Adder Neural Network (AdderNet) provides a new way for developing\nenergy-efficient neural networks by replacing the expensive multiplications in\nconvolution with cheaper additions (i.e.l1-norm). To achieve higher hardware\nefficiency, it is necessary to further study the low-bit quantization of\nAdderNet. Due to the limitation that the commutative law in multiplication does\nnot hold in l1-norm, the well-established quantization methods on convolutional\nnetworks cannot be applied on AdderNets. Thus, the existing AdderNet\nquantization techniques propose to use only one shared scale to quantize both\nthe weights and activations simultaneously. Admittedly, such an approach can\nkeep the commutative law in the l1-norm quantization process, while the\naccuracy drop after low-bit quantization cannot be ignored. To this end, we\nfirst thoroughly analyze the difference on distributions of weights and\nactivations in AdderNet and then propose a new quantization algorithm by\nredistributing the weights and the activations. Specifically, the pre-trained\nfull-precision weights in different kernels are clustered into different\ngroups, then the intra-group sharing and inter-group independent scales can be\nadopted. To further compensate the accuracy drop caused by the distribution\ndifference, we then develop a lossless range clamp scheme for weights and a\nsimple yet effective outliers clamp strategy for activations. Thus, the\nfunctionality of full-precision weights and the representation ability of\nfull-precision activations can be fully preserved. The effectiveness of the\nproposed quantization method for AdderNet is well verified on several\nbenchmarks, e.g., our 4-bit post-training quantized adder ResNet-18 achieves an\n66.5% top-1 accuracy on the ImageNet with comparable energy efficiency, which\nis about 8.5% higher than that of the previous AdderNet quantization methods.\n","authors":["Ying Nie","Kai Han","Haikang Diao","Chuanjian Liu","Enhua Wu","Yunhe Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13762v2","updated":"2022-12-20T11:24:55Z","published":"2022-11-24T19:00:02Z","title":"ScanNeRF: a Scalable Benchmark for Neural Radiance Fields","summary":"  In this paper, we propose the first-ever real benchmark thought for\nevaluating Neural Radiance Fields (NeRFs) and, in general, Neural Rendering\n(NR) frameworks. We design and implement an effective pipeline for scanning\nreal objects in quantity and effortlessly. Our scan station is built with less\nthan 500$ hardware budget and can collect roughly 4000 images of a scanned\nobject in just 5 minutes. Such a platform is used to build ScanNeRF, a dataset\ncharacterized by several train/val/test splits aimed at benchmarking the\nperformance of modern NeRF methods under different conditions. Accordingly, we\nevaluate three cutting-edge NeRF variants on it to highlight their strengths\nand weaknesses. The dataset is available on our project page, together with an\nonline benchmark to foster the development of better and better NeRFs.\n","authors":["Luca De Luigi","Damiano Bolognini","Federico Domeniconi","Daniele De Gregorio","Matteo Poggi","Luigi Di Stefano"],"pdf_url":"https://arxiv.org/pdf/2211.13762v2.pdf","comment":"WACV 2023. The first three authors contributed equally. Project page:\n  https://eyecan-ai.github.io/scannerf/"},{"id":"http://arxiv.org/abs/2212.10174v1","updated":"2022-12-20T11:24:35Z","published":"2022-12-20T11:24:35Z","title":"CGCV:Context Guided Correlation Volume for Optical Flow Neural Networks","summary":"  Optical flow, which computes the apparent motion from a pair of video frames,\nis a critical tool for scene motion estimation. Correlation volume is the\ncentral component of optical flow computational neural models. It estimates the\npairwise matching costs between cross-frame features, and is then used to\ndecode optical flow. However, traditional correlation volume is frequently\nnoisy, outlier-prone, and sensitive to motion blur. We observe that, although\nthe recent RAFT algorithm also adopts the traditional correlation volume, its\nadditional context encoder provides semantically representative features to the\nflow decoder, implicitly compensating for the deficiency of the correlation\nvolume. However, the benefits of this context encoder has been barely discussed\nor exploited. In this paper, we first investigate the functionality of RAFT's\ncontext encoder, then propose a new Context Guided Correlation Volume (CGCV)\nvia gating and lifting schemes. CGCV can be universally integrated with\nRAFT-based flow computation methods for enhanced performance, especially\neffective in the presence of motion blur, de-focus blur and atmospheric\neffects. By incorporating the proposed CGCV with previous Global Motion\nAggregation (GMA) method, at a minor cost of 0.5% extra parameters, the rank of\nGMA is lifted by 23 places on KITTI 2015 Leader Board, and 3 places on Sintel\nLeader Board. Moreover, at a similar model size, our correlation volume\nachieves competitive or superior performance to state of the art peer\nsupervised models that employ Transformers or Graph Reasoning, as verified by\nextensive experiments.\n","authors":["Jiangpeng Li","Yan Niu"],"pdf_url":"https://arxiv.org/pdf/2212.10174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10170v1","updated":"2022-12-20T11:16:06Z","published":"2022-12-20T11:16:06Z","title":"Hoyer regularizer is all you need for ultra low-latency spiking neural\n  networks","summary":"  Spiking Neural networks (SNN) have emerged as an attractive spatio-temporal\ncomputing paradigm for a wide range of low-power vision tasks. However,\nstate-of-the-art (SOTA) SNN models either incur multiple time steps which\nhinder their deployment in real-time use cases or increase the training\ncomplexity significantly. To mitigate this concern, we present a training\nframework (from scratch) for one-time-step SNNs that uses a novel variant of\nthe recently proposed Hoyer regularizer. We estimate the threshold of each SNN\nlayer as the Hoyer extremum of a clipped version of its activation map, where\nthe clipping threshold is trained using gradient descent with our Hoyer\nregularizer. This approach not only downscales the value of the trainable\nthreshold, thereby emitting a large number of spikes for weight update with a\nlimited number of iterations (due to only one time step) but also shifts the\nmembrane potential values away from the threshold, thereby mitigating the\neffect of noise that can degrade the SNN accuracy. Our approach outperforms\nexisting spiking, binary, and adder neural networks in terms of the\naccuracy-FLOPs trade-off for complex image recognition tasks. Downstream\nexperiments on object detection also demonstrate the efficacy of our approach.\n","authors":["Gourav Datta","Zeyu Liu","Peter A. Beerel"],"pdf_url":"https://arxiv.org/pdf/2212.10170v1.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2212.10167v1","updated":"2022-12-20T11:11:02Z","published":"2022-12-20T11:11:02Z","title":"Seafloor-Invariant Caustics Removal from Underwater Imagery","summary":"  Mapping the seafloor with underwater imaging cameras is of significant\nimportance for various applications including marine engineering, geology,\ngeomorphology, archaeology and biology. For shallow waters, among the\nunderwater imaging challenges, caustics i.e., the complex physical phenomena\nresulting from the projection of light rays being refracted by the wavy\nsurface, is likely the most crucial one. Caustics is the main factor during\nunderwater imaging campaigns that massively degrade image quality and affect\nseverely any 2D mosaicking or 3D reconstruction of the seabed. In this work, we\npropose a novel method for correcting the radiometric effects of caustics on\nshallow underwater imagery. Contrary to the state-of-the-art, the developed\nmethod can handle seabed and riverbed of any anaglyph, correcting the images\nusing real pixel information, thus, improving image matching and 3D\nreconstruction processes. In particular, the developed method employs deep\nlearning architectures in order to classify image pixels to \"non-caustics\" and\n\"caustics\". Then, exploits the 3D geometry of the scene to achieve a pixel-wise\ncorrection, by transferring appropriate color values between the overlapping\nunderwater images. Moreover, to fill the current gap, we have collected,\nannotated and structured a real-world caustic dataset, namely R-CAUSTIC, which\nis openly available. Overall, based on the experimental results and validation\nthe developed methodology is quite promising in both detecting caustics and\nreconstructing their intensity.\n","authors":["Panagiotis Agrafiotis","Konstantinos Karantzalos","Andreas Georgopoulos"],"pdf_url":"https://arxiv.org/pdf/2212.10167v1.pdf","comment":"Submitted to the IEEE Journal of Oceanic Engineering (IEEE-JOE),\n  under review as of December 2022"},{"id":"http://arxiv.org/abs/2206.00515v3","updated":"2022-12-20T11:10:48Z","published":"2022-06-01T14:18:23Z","title":"Landslide4Sense: Reference Benchmark Data and Deep Learning Models for\n  Landslide Detection","summary":"  This study introduces \\textit{Landslide4Sense}, a reference benchmark for\nlandslide detection from remote sensing. The repository features 3,799 image\npatches fusing optical layers from Sentinel-2 sensors with the digital\nelevation model and slope layer derived from ALOS PALSAR. The added\ntopographical information facilitates the accurate detection of landslide\nborders, which recent researches have shown to be challenging using optical\ndata alone. The extensive data set supports deep learning (DL) studies in\nlandslide detection and the development and validation of methods for the\nsystematic update of landslide inventories. The benchmark data set has been\ncollected at four different times and geographical locations: Iburi (September\n2018), Kodagu (August 2018), Gorkha (April 2015), and Taiwan (August 2009).\nEach image pixel is labelled as belonging to a landslide or not, incorporating\nvarious sources and thorough manual annotation. We then evaluate the landslide\ndetection performance of 11 state-of-the-art DL segmentation models: U-Net,\nResU-Net, PSPNet, ContextNet, DeepLab-v2, DeepLab-v3+, FCN-8s, LinkNet, FRRN-A,\nFRRN-B, and SQNet. All models were trained from scratch on patches from one\nquarter of each study area and tested on independent patches from the other\nthree quarters. Our experiments demonstrate that ResU-Net outperformed the\nother models for the landslide detection task. We make the multi-source\nlandslide benchmark data (Landslide4Sense) and the tested DL models publicly\navailable at \\url{https://www.iarai.ac.at/landslide4sense}, establishing an\nimportant resource for remote sensing, computer vision, and machine learning\ncommunities in studies of image classification in general and applications to\nlandslide detection in particular.\n","authors":["Omid Ghorbanzadeh","Yonghao Xu","Pedram Ghamisi","Michael Kopp","David Kreil"],"pdf_url":"https://arxiv.org/pdf/2206.00515v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10156v1","updated":"2022-12-20T10:47:53Z","published":"2022-12-20T10:47:53Z","title":"Goal-oriented Autonomous Driving","summary":"  Modern autonomous driving system is characterized as modular tasks in\nsequential order, i.e., perception, prediction and planning. As sensors and\nhardware get improved, there is trending popularity to devise a system that can\nperform a wide diversity of tasks to fulfill higher-level intelligence.\nContemporary approaches resort to either deploying standalone models for\nindividual tasks, or designing a multi-task paradigm with separate heads. These\nmight suffer from accumulative error or negative transfer effect. Instead, we\nargue that a favorable algorithm framework should be devised and optimized in\npursuit of the ultimate goal, i.e. planning of the self-driving-car. Oriented\nat this goal, we revisit the key components within perception and prediction.\nWe analyze each module and prioritize the tasks hierarchically, such that all\nthese tasks contribute to planning (the goal). To this end, we introduce\nUnified Autonomous Driving (UniAD), the first comprehensive framework\nup-to-date that incorporates full-stack driving tasks in one network. It is\nexquisitely devised to leverage advantages of each module, and provide\ncomplementary feature abstractions for agent interaction from a global\nperspective. Tasks are communicated with unified query design to facilitate\neach other toward planning. We instantiate UniAD on the challenging nuScenes\nbenchmark. With extensive ablations, the effectiveness of using such a\nphilosophy is proven to surpass previous state-of-the-arts by a large margin in\nall aspects. The full suite of codebase and models would be available to\nfacilitate future research in the community.\n","authors":["Yihan Hu","Jiazhi Yang","Li Chen","Keyu Li","Chonghao Sima","Xizhou Zhu","Siqi Chai","Senyao Du","Tianwei Lin","Wenhai Wang","Lewei Lu","Xiaosong Jia","Qiang Liu","Jifeng Dai","Yu Qiao","Hongyang Li"],"pdf_url":"https://arxiv.org/pdf/2212.10156v1.pdf","comment":"Project page: https://opendrivelab.github.io/UniAD/"},{"id":"http://arxiv.org/abs/2212.10149v1","updated":"2022-12-20T10:33:17Z","published":"2022-12-20T10:33:17Z","title":"Tracking by Associating Clips","summary":"  The tracking-by-detection paradigm today has become the dominant method for\nmulti-object tracking and works by detecting objects in each frame and then\nperforming data association across frames. However, its sequential frame-wise\nmatching property fundamentally suffers from the intermediate interruptions in\na video, such as object occlusions, fast camera movements, and abrupt light\nchanges. Moreover, it typically overlooks temporal information beyond the two\nframes for matching. In this paper, we investigate an alternative by treating\nobject association as clip-wise matching. Our new perspective views a single\nlong video sequence as multiple short clips, and then the tracking is performed\nboth within and between the clips. The benefits of this new approach are two\nfolds. First, our method is robust to tracking error accumulation or\npropagation, as the video chunking allows bypassing the interrupted frames, and\nthe short clip tracking avoids the conventional error-prone long-term track\nmemory management. Second, the multiple frame information is aggregated during\nthe clip-wise matching, resulting in a more accurate long-range track\nassociation than the current frame-wise matching. Given the state-of-the-art\ntracking-by-detection tracker, QDTrack, we showcase how the tracking\nperformance improves with our new tracking formulation. We evaluate our\nproposals on two tracking benchmarks, TAO and MOT17 that have complementary\ncharacteristics and challenges each other.\n","authors":["Sanghyun Woo","Kwanyong Park","Seoung Wug Oh","In So Kweon","Joon-Young Lee"],"pdf_url":"https://arxiv.org/pdf/2212.10149v1.pdf","comment":"ECCV 2022"},{"id":"http://arxiv.org/abs/2212.10147v1","updated":"2022-12-20T10:33:03Z","published":"2022-12-20T10:33:03Z","title":"Bridging Images and Videos: A Simple Learning Framework for Large\n  Vocabulary Video Object Detection","summary":"  Scaling object taxonomies is one of the important steps toward a robust\nreal-world deployment of recognition systems. We have faced remarkable progress\nin images since the introduction of the LVIS benchmark. To continue this\nsuccess in videos, a new video benchmark, TAO, was recently presented. Given\nthe recent encouraging results from both detection and tracking communities, we\nare interested in marrying those two advances and building a strong large\nvocabulary video tracker. However, supervisions in LVIS and TAO are inherently\nsparse or even missing, posing two new challenges for training the large\nvocabulary trackers. First, no tracking supervisions are in LVIS, which leads\nto inconsistent learning of detection (with LVIS and TAO) and tracking (only\nwith TAO). Second, the detection supervisions in TAO are partial, which results\nin catastrophic forgetting of absent LVIS categories during video fine-tuning.\nTo resolve these challenges, we present a simple but effective learning\nframework that takes full advantage of all available training data to learn\ndetection and tracking while not losing any LVIS categories to recognize. With\nthis new learning scheme, we show that consistent improvements of various large\nvocabulary trackers are capable, setting strong baseline results on the\nchallenging TAO benchmarks.\n","authors":["Sanghyun Woo","Kwanyong Park","Seoung Wug Oh","In So Kweon","Joon-Young Lee"],"pdf_url":"https://arxiv.org/pdf/2212.10147v1.pdf","comment":"ECCV 2022"},{"id":"http://arxiv.org/abs/2208.00281v2","updated":"2022-12-20T10:22:29Z","published":"2022-07-30T17:41:55Z","title":"Point Primitive Transformer for Long-Term 4D Point Cloud Video\n  Understanding","summary":"  This paper proposes a 4D backbone for long-term point cloud video\nunderstanding. A typical way to capture spatial-temporal context is using\n4Dconv or transformer without hierarchy. However, those methods are neither\neffective nor efficient enough due to camera motion, scene changes, sampling\npatterns, and the complexity of 4D data. To address those issues, we leverage\nthe primitive plane as a mid-level representation to capture the long-term\nspatial-temporal context in 4D point cloud videos and propose a novel\nhierarchical backbone named Point Primitive Transformer(PPTr), which is mainly\ncomposed of intra-primitive point transformers and primitive transformers.\nExtensive experiments show that PPTr outperforms the previous state of the arts\non different tasks.\n","authors":["Hao Wen","Yunze Liu","Jingwei Huang","Bo Duan","Li Yi"],"pdf_url":"https://arxiv.org/pdf/2208.00281v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10140v1","updated":"2022-12-20T10:18:18Z","published":"2022-12-20T10:18:18Z","title":"Tackling Ambiguity with Images: Improved Multimodal Machine Translation\n  and Contrastive Evaluation","summary":"  One of the major challenges of machine translation (MT) is ambiguity, which\ncan in some cases be resolved by accompanying context such as an image.\nHowever, recent work in multimodal MT (MMT) has shown that obtaining\nimprovements from images is challenging, limited not only by the difficulty of\nbuilding effective cross-modal representations but also by the lack of specific\nevaluation and training data. We present a new MMT approach based on a strong\ntext-only MT model, which uses neural adapters and a novel guided\nself-attention mechanism and which is jointly trained on both visual masking\nand MMT. We also release CoMMuTE, a Contrastive Multilingual Multimodal\nTranslation Evaluation dataset, composed of ambiguous sentences and their\npossible translations, accompanied by disambiguating images corresponding to\neach translation. Our approach obtains competitive results over strong\ntext-only models on standard English-to-French benchmarks and outperforms these\nbaselines and state-of-the-art MMT systems with a large margin on our\ncontrastive test set.\n","authors":["Matthieu Futeral","Cordelia Schmid","Ivan Laptev","Benoît Sagot","Rachel Bawden"],"pdf_url":"https://arxiv.org/pdf/2212.10140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12142v2","updated":"2022-12-20T10:11:30Z","published":"2022-10-21T17:53:56Z","title":"Target Aware Poisson-Gaussian Noise Parameters Estimation from Noisy\n  Images","summary":"  Digital sensors can lead to noisy results under many circumstances. To be\nable to remove the undesired noise from images, proper noise modeling and an\naccurate noise parameter estimation is crucial. In this project, we use a\nPoisson-Gaussian noise model for the raw-images captured by the sensor, as it\nfits the physical characteristics of the sensor closely. Moreover, we limit\nourselves to the case where observed (noisy), and ground-truth (noise-free)\nimage pairs are available. Using such pairs is beneficial for the noise\nestimation and is not widely studied in literature. Based on this model, we\nderive the theoretical maximum likelihood solution, discuss its practical\nimplementation and optimization. Further, we propose two algorithms based on\nvariance and cumulant statistics. Finally, we compare the results of our\nmethods with two different approaches, a CNN we trained ourselves, and another\none taken from literature. The comparison between all these methods shows that\nour algorithms outperform the others in terms of MSE and have good additional\nproperties.\n","authors":["Étienne Objois","Kaan Okumuş","Nicolas Bähler"],"pdf_url":"https://arxiv.org/pdf/2210.12142v2.pdf","comment":"11 pages, 14 figures and 4 tables"},{"id":"http://arxiv.org/abs/2212.10132v1","updated":"2022-12-20T10:01:23Z","published":"2022-12-20T10:01:23Z","title":"Content Adaptive Latents and Decoder for Neural Image Compression","summary":"  In recent years, neural image compression (NIC) algorithms have shown\npowerful coding performance. However, most of them are not adaptive to the\nimage content. Although several content adaptive methods have been proposed by\nupdating the encoder-side components, the adaptability of both latents and the\ndecoder is not well exploited. In this work, we propose a new NIC framework\nthat improves the content adaptability on both latents and the decoder.\nSpecifically, to remove redundancy in the latents, our content adaptive channel\ndropping (CACD) method automatically selects the optimal quality levels for the\nlatents spatially and drops the redundant channels. Additionally, we propose\nthe content adaptive feature transformation (CAFT) method to improve\ndecoder-side content adaptability by extracting the characteristic information\nof the image content, which is then used to transform the features in the\ndecoder side. Experimental results demonstrate that our proposed methods with\nthe encoder-side updating algorithm achieve the state-of-the-art performance.\n","authors":["Guanbo Pan","Guo Lu","Zhihao Hu","Dong Xu"],"pdf_url":"https://arxiv.org/pdf/2212.10132v1.pdf","comment":"V1 is accepted to ECCV 2022"},{"id":"http://arxiv.org/abs/2209.06585v2","updated":"2022-12-20T10:00:24Z","published":"2022-09-14T12:06:47Z","title":"Combining Metric Learning and Attention Heads For Accurate and Efficient\n  Multilabel Image Classification","summary":"  Multi-label image classification allows predicting a set of labels from a\ngiven image. Unlike multiclass classification, where only one label per image\nis assigned, such a setup is applicable for a broader range of applications. In\nthis work we revisit two popular approaches to multilabel classification:\ntransformer-based heads and labels relations information graph processing\nbranches. Although transformer-based heads are considered to achieve better\nresults than graph-based branches, we argue that with the proper training\nstrategy, graph-based methods can demonstrate just a small accuracy drop, while\nspending less computational resources on inference. In our training strategy,\ninstead of Asymmetric Loss (ASL), which is the de-facto standard for multilabel\nclassification, we introduce its metric learning modification. In each binary\nclassification sub-problem it operates with $L_2$ normalized feature vectors\ncoming from a backbone and enforces angles between the normalized\nrepresentations of positive and negative samples to be as large as possible.\nThis results in providing a better discrimination ability, than binary cross\nentropy loss does on unnormalized features. With the proposed loss and training\nstrategy, we obtain SOTA results among single modality methods on widespread\nmultilabel classification benchmarks such as MS-COCO, PASCAL-VOC, NUS-Wide and\nVisual Genome 500. Source code of our method is available as a part of the\nOpenVINO Training Extensions\nhttps://github.com/openvinotoolkit/deep-object-reid/tree/multilabel\n","authors":["Kirill Prokofiev","Vladislav Sovrasov"],"pdf_url":"https://arxiv.org/pdf/2209.06585v2.pdf","comment":"Accepted at VISAPP 2023"},{"id":"http://arxiv.org/abs/2209.04747v3","updated":"2022-12-20T09:49:30Z","published":"2022-09-10T22:00:30Z","title":"Diffusion Models in Vision: A Survey","summary":"  Denoising diffusion models represent a recent emerging topic in computer\nvision, demonstrating remarkable results in the area of generative modeling. A\ndiffusion model is a deep generative model that is based on two stages, a\nforward diffusion stage and a reverse diffusion stage. In the forward diffusion\nstage, the input data is gradually perturbed over several steps by adding\nGaussian noise. In the reverse stage, a model is tasked at recovering the\noriginal input data by learning to gradually reverse the diffusion process,\nstep by step. Diffusion models are widely appreciated for the quality and\ndiversity of the generated samples, despite their known computational burdens,\ni.e. low speeds due to the high number of steps involved during sampling. In\nthis survey, we provide a comprehensive review of articles on denoising\ndiffusion models applied in vision, comprising both theoretical and practical\ncontributions in the field. First, we identify and present three generic\ndiffusion modeling frameworks, which are based on denoising diffusion\nprobabilistic models, noise conditioned score networks, and stochastic\ndifferential equations. We further discuss the relations between diffusion\nmodels and other deep generative models, including variational auto-encoders,\ngenerative adversarial networks, energy-based models, autoregressive models and\nnormalizing flows. Then, we introduce a multi-perspective categorization of\ndiffusion models applied in computer vision. Finally, we illustrate the current\nlimitations of diffusion models and envision some interesting directions for\nfuture research.\n","authors":["Florinel-Alin Croitoru","Vlad Hondru","Radu Tudor Ionescu","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2209.04747v3.pdf","comment":"24 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.10124v1","updated":"2022-12-20T09:48:24Z","published":"2022-12-20T09:48:24Z","title":"Image Segmentation-based Unsupervised Multiple Objects Discovery","summary":"  Unsupervised object discovery aims to localize objects in images, while\nremoving the dependence on annotations required by most deep learning-based\nmethods. To address this problem, we propose a fully unsupervised, bottom-up\napproach, for multiple objects discovery. The proposed approach is a two-stage\nframework. First, instances of object parts are segmented by using the\nintra-image similarity between self-supervised local features. The second step\nmerges and filters the object parts to form complete object instances. The\nlatter is performed by two CNN models that capture semantic information on\nobjects from the entire dataset. We demonstrate that the pseudo-labels\ngenerated by our method provide a better precision-recall trade-off than\nexisting single and multiple objects discovery methods. In particular, we\nprovide state-of-the-art results for both unsupervised class-agnostic object\ndetection and unsupervised image segmentation.\n","authors":["Sandra Kara","Hejer Ammar","Florian Chabot","Quoc-Cuong Pham"],"pdf_url":"https://arxiv.org/pdf/2212.10124v1.pdf","comment":"WACV 2023"},{"id":"http://arxiv.org/abs/2206.08368v2","updated":"2022-12-20T09:45:48Z","published":"2022-06-16T17:59:54Z","title":"Unbiased 4D: Monocular 4D Reconstruction with a Neural Deformation Model","summary":"  Capturing general deforming scenes from monocular RGB video is crucial for\nmany computer graphics and vision applications. However, current approaches\nsuffer from drawbacks such as struggling with large scene deformations,\ninaccurate shape completion or requiring 2D point tracks. In contrast, our\nmethod, Ub4D, handles large deformations, performs shape completion in occluded\nregions, and can operate on monocular RGB videos directly by using\ndifferentiable volume rendering. This technique includes three new in the\ncontext of non-rigid 3D reconstruction components, i.e., 1) A coordinate-based\nand implicit neural representation for non-rigid scenes, which in conjunction\nwith differentiable volume rendering enables an unbiased reconstruction of\ndynamic scenes, 2) a proof that extends the unbiased formulation of volume\nrendering to dynamic scenes, and 3) a novel dynamic scene flow loss, which\nenables the reconstruction of larger deformations by leveraging the coarse\nestimates of other methods. Results on our new dataset, which will be made\npublicly available, demonstrate a clear improvement over the state of the art\nin terms of surface reconstruction accuracy and robustness to large\ndeformations.\n","authors":["Erik C. M. Johnson","Marc Habermann","Soshi Shimada","Vladislav Golyanik","Christian Theobalt"],"pdf_url":"https://arxiv.org/pdf/2206.08368v2.pdf","comment":"26 pages, 17 figures, 8 tables"},{"id":"http://arxiv.org/abs/2212.10108v1","updated":"2022-12-20T09:28:25Z","published":"2022-12-20T09:28:25Z","title":"Efficient aggregation of face embeddings for decentralized face\n  recognition deployments (extended version)","summary":"  Biometrics are one of the most privacy-sensitive data. Ubiquitous\nauthentication systems with a focus on privacy favor decentralized approaches\nas they reduce potential attack vectors, both on a technical and organizational\nlevel. The gold standard is to let the user be in control of where their own\ndata is stored, which consequently leads to a high variety of devices used.\nMoreover, in comparison with a centralized system, designs with higher end-user\nfreedom often incur additional network overhead. Therefore, when using face\nrecognition for biometric authentication, an efficient way to compare faces is\nimportant in practical deployments, because it reduces both network and\nhardware requirements that are essential to encourage device diversity. This\npaper proposes an efficient way to aggregate embeddings used for face\nrecognition based on an extensive analysis on different datasets and the use of\ndifferent aggregation strategies. As part of this analysis, a new dataset has\nbeen collected, which is available for research purposes. Our proposed method\nsupports the construction of massively scalable, decentralized face recognition\nsystems with a focus on both privacy and long-term usability.\n","authors":["Philipp Hofer","Michael Roland","Philipp Schwarz","Renè Mayrhofer"],"pdf_url":"https://arxiv.org/pdf/2212.10108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10105v1","updated":"2022-12-20T09:27:48Z","published":"2022-12-20T09:27:48Z","title":"On the Applicability of Synthetic Data for Re-Identification","summary":"  This contribution demonstrates the feasibility of applying Generative\nAdversarial Networks (GANs) on images of EPAL pallet blocks for dataset\nenhancement in the context of re-identification. For many industrial\napplications of re-identification methods, datasets of sufficient volume would\notherwise be unattainable in non-laboratory settings. Using a state-of-the-art\nGAN architecture, namely CycleGAN, images of pallet blocks rotated to their\nleft-hand side were generated from images of visually centered pallet blocks,\nbased on images of rotated pallet blocks that were recorded as part of a\npreviously recorded and published dataset. In this process, the unique chipwood\npattern of the pallet block surface structure was retained, only changing the\norientation of the pallet block itself. By doing so, synthetic data for\nre-identification testing and training purposes was generated, in a manner that\nis distinct from ordinary data augmentation. In total, 1,004 new images of\npallet blocks were generated. The quality of the generated images was gauged\nusing a perspective classifier that was trained on the original images and then\napplied to the synthetic ones, comparing the accuracy between the two sets of\nimages. The classification accuracy was 98% for the original images and 92% for\nthe synthetic images. In addition, the generated images were also used in a\nre-identification task, in order to re-identify original images based on\nsynthetic ones. The accuracy in this scenario was up to 88% for synthetic\nimages, compared to 96% for original images. Through this evaluation, it is\nestablished, whether or not a generated pallet block image closely resembles\nits original counterpart.\n","authors":["Jérôme Rutinowski","Bhargav Vankayalapati","Nils Schwenzfeier","Maribel Acosta","Christopher Reining"],"pdf_url":"https://arxiv.org/pdf/2212.10105v1.pdf","comment":"Accepted as a non-archival paper in AAAI23 workshop AI2SE"},{"id":"http://arxiv.org/abs/2212.05330v3","updated":"2022-12-20T09:11:12Z","published":"2022-12-10T16:26:19Z","title":"Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud\n  Sequence Representation Learning","summary":"  Recent work on 4D point cloud sequences has attracted a lot of attention.\nHowever, obtaining exhaustively labeled 4D datasets is often very expensive and\nlaborious, so it is especially important to investigate how to utilize raw\nunlabeled data. However, most existing self-supervised point cloud\nrepresentation learning methods only consider geometry from a static snapshot\nomitting the fact that sequential observations of dynamic scenes could reveal\nmore comprehensive geometric details. And the video representation learning\nframeworks mostly model motion as image space flows, let alone being\n3D-geometric-aware. To overcome such issues, this paper proposes a new 4D\nself-supervised pre-training method called Complete-to-Partial 4D Distillation.\nOur key idea is to formulate 4D self-supervised representation learning as a\nteacher-student knowledge distillation framework and let the student learn\nuseful 4D representations with the guidance of the teacher. Experiments show\nthat this approach significantly outperforms previous pre-training approaches\non a wide range of 4D point cloud sequence understanding tasks including indoor\nand outdoor scenarios.\n","authors":["Zhuoyang Zhang","Yuhao Dong","Yunze Liu","Li Yi"],"pdf_url":"https://arxiv.org/pdf/2212.05330v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10093v1","updated":"2022-12-20T09:10:25Z","published":"2022-12-20T09:10:25Z","title":"Visual Transformers for Primates Classification and Covid Detection","summary":"  We apply the vision transformer, a deep machine learning model build around\nthe attention mechanism, on mel-spectrogram representations of raw audio\nrecordings. When adding mel-based data augmentation techniques and\nsample-weighting, we achieve comparable performance on both (PRS and CCS\nchallenge) tasks of ComParE21, outperforming most single model baselines. We\nfurther introduce overlapping vertical patching and evaluate the influence of\nparameter configurations. Index Terms: audio classification, attention,\nmel-spectrogram, unbalanced data-sets, computational paralinguistics\n","authors":["Steffen Illium","Robert Müller","Andreas Sedlmeier","Claudia-Linnhoff Popien"],"pdf_url":"https://arxiv.org/pdf/2212.10093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10091v1","updated":"2022-12-20T09:08:00Z","published":"2022-12-20T09:08:00Z","title":"Computer Vision Methods for Automating Turbot Fish Cutting","summary":"  This paper is about the design of an automated machine to cut turbot fish\nspecimens. Machine vision is a key part of this project as it is used to\ncompute a cutting curve for the specimen head. This task is impossible to be\ncarried out by mechanical means. Machine vision is used to detect head boundary\nand a robot is used to cut the head. Binarization and mathematical morphology\nare used to detect fish boundary and this boundary is subsequently analyzed\n(using Hough transform and convex hull) to detect key points and thus defining\nthe cutting curve. Afterwards, mechanical systems are used to slice fish to get\nan easy presentation for end consumer (as fish fillets than can be easily\nmarketed and consumed).\n","authors":["Fernando Martin-Rodriguez","Fernando Isasi-de-Vicente","Monica Fernandez-Barciela"],"pdf_url":"https://arxiv.org/pdf/2212.10091v1.pdf","comment":"5 pages, 11 figurs. Derived from conference publication:\n  https://upcommons.upc.edu/handle/2117/77428"},{"id":"http://arxiv.org/abs/2212.10086v1","updated":"2022-12-20T08:54:11Z","published":"2022-12-20T08:54:11Z","title":"End to End Generative Meta Curriculum Learning For Medical Data\n  Augmentation","summary":"  Current medical image synthetic augmentation techniques rely on intensive use\nof generative adversarial networks (GANs). However, the nature of GAN\narchitecture leads to heavy computational resources to produce synthetic images\nand the augmentation process requires multiple stages to complete. To address\nthese challenges, we introduce a novel generative meta curriculum learning\nmethod that trains the task-specific model (student) end-to-end with only one\nadditional teacher model. The teacher learns to generate curriculum to feed\ninto the student model for data augmentation and guides the student to improve\nperformance in a meta-learning style. In contrast to the generator and\ndiscriminator in GAN, which compete with each other, the teacher and student\ncollaborate to improve the student's performance on the target tasks. Extensive\nexperiments on the histopathology datasets show that leveraging our framework\nresults in significant and consistent improvements in classification\nperformance.\n","authors":["Meng Li","Brian Lovell"],"pdf_url":"https://arxiv.org/pdf/2212.10086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10082v1","updated":"2022-12-20T08:47:17Z","published":"2022-12-20T08:47:17Z","title":"An Information-Theoretic Approach to Transferability in Task Transfer\n  Learning","summary":"  Task transfer learning is a popular technique in image processing\napplications that uses pre-trained models to reduce the supervision cost of\nrelated tasks. An important question is to determine task transferability, i.e.\ngiven a common input domain, estimating to what extent representations learned\nfrom a source task can help in learning a target task. Typically,\ntransferability is either measured experimentally or inferred through task\nrelatedness, which is often defined without a clear operational meaning. In\nthis paper, we present a novel metric, H-score, an easily-computable evaluation\nfunction that estimates the performance of transferred representations from one\ntask to another in classification problems using statistical and information\ntheoretic principles. Experiments on real image data show that our metric is\nnot only consistent with the empirical transferability measurement, but also\nuseful to practitioners in applications such as source model selection and task\ntransfer curriculum learning.\n","authors":["Yajie Bao","Yang Li","Shao-Lun Huang","Lin Zhang","Lizhong Zheng","Amir Zamir","Leonidas Guibas"],"pdf_url":"https://arxiv.org/pdf/2212.10082v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.10201v3","updated":"2022-12-20T08:36:49Z","published":"2022-02-21T13:23:15Z","title":"OG-SGG: Ontology-Guided Scene Graph Generation. A Case Study in Transfer\n  Learning for Telepresence Robotics","summary":"  Scene graph generation from images is a task of great interest to\napplications such as robotics, because graphs are the main way to represent\nknowledge about the world and regulate human-robot interactions in tasks such\nas Visual Question Answering (VQA). Unfortunately, its corresponding area of\nmachine learning is still relatively in its infancy, and the solutions\ncurrently offered do not specialize well in concrete usage scenarios.\nSpecifically, they do not take existing \"expert\" knowledge about the domain\nworld into account; and that might indeed be necessary in order to provide the\nlevel of reliability demanded by the use case scenarios. In this paper, we\npropose an initial approximation to a framework called Ontology-Guided Scene\nGraph Generation (OG-SGG), that can improve the performance of an existing\nmachine learning based scene graph generator using prior knowledge supplied in\nthe form of an ontology (specifically, using the axioms defined within); and we\npresent results evaluated on a specific scenario founded in telepresence\nrobotics. These results show quantitative and qualitative improvements in the\ngenerated scene graphs.\n","authors":["Fernando Amodeo","Fernando Caballero","Natalia Díaz-Rodríguez","Luis Merino"],"pdf_url":"https://arxiv.org/pdf/2202.10201v3.pdf","comment":"20 pages; version accepted and published in IEEE Access"},{"id":"http://arxiv.org/abs/2212.10066v1","updated":"2022-12-20T08:17:08Z","published":"2022-12-20T08:17:08Z","title":"RepMode: Learning to Re-parameterize Diverse Experts for Subcellular\n  Structure Prediction","summary":"  In subcellular biological research, fluorescence staining is a key technique\nto reveal the locations and morphology of subcellular structures. However,\nfluorescence staining is slow, expensive, and harmful to cells. In this paper,\nwe treat it as a deep learning task termed subcellular structure prediction\n(SSP), aiming to predict the 3D fluorescent images of multiple subcellular\nstructures from a 3D transmitted-light image. Unfortunately, due to the\nlimitations of current biotechnology, each image is partially labeled in SSP.\nBesides, naturally, the subcellular structures vary considerably in size, which\ncauses the multi-scale issue in SSP. However, traditional solutions can not\naddress SSP well since they organize network parameters inefficiently and\ninflexibly. To overcome these challenges, we propose Re-parameterizing\nMixture-of-Diverse-Experts (RepMode), a network that dynamically organizes its\nparameters with task-aware priors to handle specified single-label prediction\ntasks of SSP. In RepMode, the Mixture-of-Diverse-Experts (MoDE) block is\ndesigned to learn the generalized parameters for all tasks, and gating\nre-parameterization (GatRep) is performed to generate the specialized\nparameters for each task, by which RepMode can maintain a compact practical\ntopology exactly like a plain network, and meanwhile achieves a powerful\ntheoretical topology. Comprehensive experiments show that RepMode outperforms\nexisting methods on ten of twelve prediction tasks of SSP and achieves\nstate-of-the-art overall performance.\n","authors":["Donghao Zhou","Chunbin Gu","Junde Xu","Furui Liu","Qiong Wang","Guangyong Chen","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2212.10066v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.10054v1","updated":"2022-12-20T08:01:03Z","published":"2022-12-20T08:01:03Z","title":"VoronoiPatches: Evaluating A New Data Augmentation Method","summary":"  Overfitting is a problem in Convolutional Neural Networks (CNN) that causes\npoor generalization of models on unseen data. To remediate this problem, many\nnew and diverse data augmentation methods (DA) have been proposed to supplement\nor generate more training data, and thereby increase its quality. In this work,\nwe propose a new data augmentation algorithm: VoronoiPatches (VP). We primarily\nutilize non-linear recombination of information within an image, fragmenting\nand occluding small information patches. Unlike other DA methods, VP uses small\nconvex polygon-shaped patches in a random layout to transport information\naround within an image. Sudden transitions created between patches and the\noriginal image can, optionally, be smoothed. In our experiments, VP\noutperformed current DA methods regarding model variance and overfitting\ntendencies. We demonstrate data augmentation utilizing non-linear\nre-combination of information within images, and non-orthogonal shapes and\nstructures improves CNN model robustness on unseen data.\n","authors":["Steffen Illium","Gretchen Griffin","Michael Kölle","Maximilian Zorn","Jonas Nüßlein","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2212.10054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08846v2","updated":"2022-12-20T07:51:12Z","published":"2022-12-17T11:00:34Z","title":"Painterly Image Harmonization in Dual Domains","summary":"  Image harmonization aims to produce visually harmonious composite images by\nadjusting the foreground appearance to be compatible with the background. When\nthe composite image has photographic foreground and painterly background, the\ntask is called painterly image harmonization. There are only few works on this\ntask, which are either time-consuming or weak in generating well-harmonized\nresults. In this work, we propose a novel painterly harmonization network\nconsisting of a dual-domain generator and a dual-domain discriminator, which\nharmonizes the composite image in both spatial domain and frequency domain. The\ndual-domain generator performs harmonization by using AdaIn modules in the\nspatial domain and our proposed ResFFT modules in the frequency domain. The\ndual-domain discriminator attempts to distinguish the inharmonious patches\nbased on the spatial feature and frequency feature of each patch, which can\nenhance the ability of generator in an adversarial manner. Extensive\nexperiments on the benchmark dataset show the effectiveness of our method. Our\ncode and model are available at\nhttps://github.com/bcmi/PHDNet-Painterly-Image-Harmonization.\n","authors":["Junyan Cao","Yan Hong","Li Niu"],"pdf_url":"https://arxiv.org/pdf/2212.08846v2.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2212.10049v1","updated":"2022-12-20T07:46:49Z","published":"2022-12-20T07:46:49Z","title":"OBMO: One Bounding Box Multiple Objects for Monocular 3D Object\n  Detection","summary":"  Compared to typical multi-sensor systems, monocular 3D object detection has\nattracted much attention due to its simple configuration. However, there is\nstill a significant gap between LiDAR-based and monocular-based methods. In\nthis paper, we find that the ill-posed nature of monocular imagery can lead to\ndepth ambiguity. Specifically, objects with different depths can appear with\nthe same bounding boxes and similar visual features in the 2D image.\nUnfortunately, the network cannot accurately distinguish different depths from\nsuch non-discriminative visual features, resulting in unstable depth training.\nTo facilitate depth learning, we propose a simple yet effective plug-and-play\nmodule, One Bounding Box Multiple Objects (OBMO). Concretely, we add a set of\nsuitable pseudo labels by shifting the 3D bounding box along the viewing\nfrustum. To constrain the pseudo-3D labels to be reasonable, we carefully\ndesign two label scoring strategies to represent their quality. In contrast to\nthe original hard depth labels, such soft pseudo labels with quality scores\nallow the network to learn a reasonable depth range, boosting training\nstability and thus improving final performance. Extensive experiments on KITTI\nand Waymo benchmarks show that our method significantly improves\nstate-of-the-art monocular 3D detectors by a significant margin (The\nimprovements under the moderate setting on KITTI validation set are\n$\\mathbf{1.82\\sim 10.91\\%}$ mAP in BEV and $\\mathbf{1.18\\sim 9.36\\%}$ mAP in\n3D}. Codes have been released at https://github.com/mrsempress/OBMO.\n","authors":["Chenxi Huang","Tong He","Haidong Ren","Wenxiao Wang","Binbin Lin","Deng Cai"],"pdf_url":"https://arxiv.org/pdf/2212.10049v1.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2106.03323v5","updated":"2022-12-20T07:23:37Z","published":"2021-06-07T03:51:25Z","title":"A Comprehensive Survey and Taxonomy on Single Image Dehazing Based on\n  Deep Learning","summary":"  With the development of convolutional neural networks, hundreds of deep\nlearning based dehazing methods have been proposed. In this paper, we provide a\ncomprehensive survey on supervised, semi-supervised, and unsupervised single\nimage dehazing. We first discuss the physical model, datasets, network modules,\nloss functions, and evaluation metrics that are commonly used. Then, the main\ncontributions of various dehazing algorithms are categorized and summarized.\nFurther, quantitative and qualitative experiments of various baseline methods\nare carried out. Finally, the unsolved issues and challenges that can inspire\nthe future research are pointed out. A collection of useful dehazing materials\nis available at \\url{https://github.com/Xiaofeng-life/AwesomeDehazing}.\n","authors":["Jie Gui","Xiaofeng Cong","Yuan Cao","Wenqi Ren","Jun Zhang","Jing Zhang","Jiuxin Cao","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2106.03323v5.pdf","comment":"This paper is accepted by ACM Computing Surveys"},{"id":"http://arxiv.org/abs/1712.01785v4","updated":"2022-12-20T07:14:37Z","published":"2017-12-05T17:49:18Z","title":"Towards Practical Verification of Machine Learning: The Case of Computer\n  Vision Systems","summary":"  Due to the increasing usage of machine learning (ML) techniques in security-\nand safety-critical domains, such as autonomous systems and medical diagnosis,\nensuring correct behavior of ML systems, especially for different corner cases,\nis of growing importance. In this paper, we propose a generic framework for\nevaluating security and robustness of ML systems using different real-world\nsafety properties. We further design, implement and evaluate VeriVis, a\nscalable methodology that can verify a diverse set of safety properties for\nstate-of-the-art computer vision systems with only blackbox access. VeriVis\nleverage different input space reduction techniques for efficient verification\nof different safety properties. VeriVis is able to find thousands of safety\nviolations in fifteen state-of-the-art computer vision systems including ten\nDeep Neural Networks (DNNs) such as Inception-v3 and Nvidia's Dave self-driving\nsystem with thousands of neurons as well as five commercial third-party vision\nAPIs including Google vision and Clarifai for twelve different safety\nproperties. Furthermore, VeriVis can successfully verify local safety\nproperties, on average, for around 31.7% of the test images. VeriVis finds up\nto 64.8x more violations than existing gradient-based methods that, unlike\nVeriVis, cannot ensure non-existence of any violations. Finally, we show that\nretraining using the safety violations detected by VeriVis can reduce the\naverage number of violations up to 60.2%.\n","authors":["Kexin Pei","Linjie Zhu","Yinzhi Cao","Junfeng Yang","Carl Vondrick","Suman Jana"],"pdf_url":"https://arxiv.org/pdf/1712.01785v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.08493v3","updated":"2022-12-20T07:11:16Z","published":"2021-10-16T06:51:35Z","title":"Improvised Aerial Object Detection approach for YOLOv3 Using Weighted\n  Luminance","summary":"  Aerial imaging plays a crucial role in navigation and data acquisition for\nunmanned aerial vehicles and satellite imaging systems. In recent days, the\nemployment of drones has been escalated in several applications that are not\nlimited to surveillance, delivery systems, aerial warfare, and agricultural\nactivities. Aerial imaging of ground targets is highly challenging because of\nvarious factors that affect light propagation through different mediums.\nSeveral convolutional neural network-based object detection algorithms that are\ndeveloped require more robustness when applied in the field of aerial imaging\nand remote sensing. In order to handle the adverse effects of light propagation\nwith respect to time and solar radiance, adaptive RGB filters for grayscale\nimaging based on weighted luminance are introduced that extensively solve the\nproblem of rayleigh scattering effect. Images of objects that are easily\ndiminished by rayleigh scattering are acquired in various timezones. The\nacquired images are labelled precisely and subjected to training and\nvalidation. The results show that the proposed method detects the object more\naccurately and efficiently than the traditional YOLOv3 approach.\n","authors":["Sai Ganesh CS","Aouthithiye Barathwaj SR Y","R. Swethaa S","R. Azhagumurugan"],"pdf_url":"https://arxiv.org/pdf/2110.08493v3.pdf","comment":"17 pages, 4 figures, Journal Expert Systems with Applications"},{"id":"http://arxiv.org/abs/2212.09321v2","updated":"2022-12-20T06:37:00Z","published":"2022-12-19T09:39:30Z","title":"Learning from Training Dynamics: Identifying Mislabeled Data Beyond\n  Manually Designed Features","summary":"  While mislabeled or ambiguously-labeled samples in the training set could\nnegatively affect the performance of deep models, diagnosing the dataset and\nidentifying mislabeled samples helps to improve the generalization power.\nTraining dynamics, i.e., the traces left by iterations of optimization\nalgorithms, have recently been proved to be effective to localize mislabeled\nsamples with hand-crafted features. In this paper, beyond manually designed\nfeatures, we introduce a novel learning-based solution, leveraging a noise\ndetector, instanced by an LSTM network, which learns to predict whether a\nsample was mislabeled using the raw training dynamics as input. Specifically,\nthe proposed method trains the noise detector in a supervised manner using the\ndataset with synthesized label noises and can adapt to various datasets (either\nnaturally or synthesized label-noised) without retraining. We conduct extensive\nexperiments to evaluate the proposed method. We train the noise detector based\non the synthesized label-noised CIFAR dataset and test such noise detector on\nTiny ImageNet, CUB-200, Caltech-256, WebVision and Clothing1M. Results show\nthat the proposed method precisely detects mislabeled samples on various\ndatasets without further adaptation, and outperforms state-of-the-art methods.\nBesides, more experiments demonstrate that the mislabel identification can\nguide a label correction, namely data debugging, providing orthogonal\nimprovements of algorithm-centric state-of-the-art techniques from the data\naspect.\n","authors":["Qingrui Jia","Xuhong Li","Lei Yu","Jiang Bian","Penghao Zhao","Shupeng Li","Haoyi Xiong","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2212.09321v2.pdf","comment":"AAAI23 accepted Conference Paper"},{"id":"http://arxiv.org/abs/2203.11991v4","updated":"2022-12-20T06:35:30Z","published":"2022-03-22T18:37:11Z","title":"Joint Feature Learning and Relation Modeling for Tracking: A One-Stream\n  Framework","summary":"  The current popular two-stream, two-stage tracking framework extracts the\ntemplate and the search region features separately and then performs relation\nmodeling, thus the extracted features lack the awareness of the target and have\nlimited target-background discriminability. To tackle the above issue, we\npropose a novel one-stream tracking (OSTrack) framework that unifies feature\nlearning and relation modeling by bridging the template-search image pairs with\nbidirectional information flows. In this way, discriminative target-oriented\nfeatures can be dynamically extracted by mutual guidance. Since no extra heavy\nrelation modeling module is needed and the implementation is highly\nparallelized, the proposed tracker runs at a fast speed. To further improve the\ninference efficiency, an in-network candidate early elimination module is\nproposed based on the strong similarity prior calculated in the one-stream\nframework. As a unified framework, OSTrack achieves state-of-the-art\nperformance on multiple benchmarks, in particular, it shows impressive results\non the one-shot tracking benchmark GOT-10k, i.e., achieving 73.7% AO, improving\nthe existing best result (SwinTrack) by 4.3\\%. Besides, our method maintains a\ngood performance-speed trade-off and shows faster convergence. The code and\nmodels are available at https://github.com/botaoye/OSTrack.\n","authors":["Botao Ye","Hong Chang","Bingpeng Ma","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2203.11991v4.pdf","comment":"Accepted by ECCV 2022"},{"id":"http://arxiv.org/abs/2212.10015v1","updated":"2022-12-20T06:03:51Z","published":"2022-12-20T06:03:51Z","title":"Benchmarking Spatial Relationships in Text-to-Image Generation","summary":"  Spatial understanding is a fundamental aspect of computer vision and integral\nfor human-level reasoning about images, making it an important component for\ngrounded language understanding. While recent large-scale text-to-image\nsynthesis (T2I) models have shown unprecedented improvements in photorealism,\nit is unclear whether they have reliable spatial understanding capabilities. We\ninvestigate the ability of T2I models to generate correct spatial relationships\namong objects and present VISOR, an evaluation metric that captures how\naccurately the spatial relationship described in text is generated in the\nimage. To benchmark existing models, we introduce a large-scale challenge\ndataset SR2D that contains sentences describing two objects and the spatial\nrelationship between them. We construct and harness an automated evaluation\npipeline that employs computer vision to recognize objects and their spatial\nrelationships, and we employ it in a large-scale evaluation of T2I models. Our\nexperiments reveal a surprising finding that, although recent state-of-the-art\nT2I models exhibit high image quality, they are severely limited in their\nability to generate multiple objects or the specified spatial relations such as\nleft/right/above/below. Our analyses demonstrate several biases and artifacts\nof T2I models such as the difficulty with generating multiple objects, a bias\ntowards generating the first object mentioned, spatially inconsistent outputs\nfor equivalent relationships, and a correlation between object co-occurrence\nand spatial understanding capabilities. We conduct a human study that shows the\nalignment between VISOR and human judgment about spatial understanding. We\noffer the SR2D dataset and the VISOR metric to the community in support of T2I\nspatial reasoning research.\n","authors":["Tejas Gokhale","Hamid Palangi","Besmira Nushi","Vibhav Vineet","Eric Horvitz","Ece Kamar","Chitta Baral","Yezhou Yang"],"pdf_url":"https://arxiv.org/pdf/2212.10015v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2211.12739v2","updated":"2022-12-20T05:45:27Z","published":"2022-11-23T07:00:11Z","title":"Texts as Images in Prompt Tuning for Multi-Label Image Recognition","summary":"  Prompt tuning has been employed as an efficient way to adapt large\nvision-language pre-trained models (e.g. CLIP) to various downstream tasks in\ndata-limited or label-limited settings. Nonetheless, visual data (e.g., images)\nis by default prerequisite for learning prompts in existing methods. In this\nwork, we advocate that the effectiveness of image-text contrastive learning in\naligning the two modalities (for training CLIP) further makes it feasible to\ntreat texts as images for prompt tuning and introduce TaI prompting. In\ncontrast to the visual data, text descriptions are easy to collect, and their\nclass labels can be directly derived. Particularly, we apply TaI prompting to\nmulti-label image recognition, where sentences in the wild serve as\nalternatives to images for prompt tuning. Moreover, with TaI, double-grained\nprompt tuning (TaI-DPT) is further presented to extract both coarse-grained and\nfine-grained embeddings for enhancing the multi-label recognition performance.\nExperimental results show that our proposed TaI-DPT outperforms zero-shot CLIP\nby a large margin on multiple benchmarks, e.g., MS-COCO, VOC2007, and NUS-WIDE,\nwhile it can be combined with existing methods of prompting from images to\nimprove recognition performance further. Code is released at\nhttps://github.com/guozix/TaI-DPT.\n","authors":["Zixian Guo","Bowen Dong","Zhilong Ji","Jinfeng Bai","Yiwen Guo","Wangmeng Zuo"],"pdf_url":"https://arxiv.org/pdf/2211.12739v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10005v1","updated":"2022-12-20T05:34:58Z","published":"2022-12-20T05:34:58Z","title":"Calibrating Deep Neural Networks using Explicit Regularisation and\n  Dynamic Data Pruning","summary":"  Deep neural networks (DNN) are prone to miscalibrated predictions, often\nexhibiting a mismatch between the predicted output and the associated\nconfidence scores. Contemporary model calibration techniques mitigate the\nproblem of overconfident predictions by pushing down the confidence of the\nwinning class while increasing the confidence of the remaining classes across\nall test samples. However, from a deployment perspective, an ideal model is\ndesired to (i) generate well-calibrated predictions for high-confidence samples\nwith predicted probability say >0.95, and (ii) generate a higher proportion of\nlegitimate high-confidence samples. To this end, we propose a novel\nregularization technique that can be used with classification losses, leading\nto state-of-the-art calibrated predictions at test time; From a deployment\nstandpoint in safety-critical applications, only high-confidence samples from a\nwell-calibrated model are of interest, as the remaining samples have to undergo\nmanual inspection. Predictive confidence reduction of these potentially\n``high-confidence samples'' is a downside of existing calibration approaches.\nWe mitigate this by proposing a dynamic train-time data pruning strategy that\nprunes low-confidence samples every few epochs, providing an increase in\n\"confident yet calibrated samples\". We demonstrate state-of-the-art calibration\nperformance across image classification benchmarks, reducing training time\nwithout much compromise in accuracy. We provide insights into why our dynamic\npruning strategy that prunes low-confidence training samples leads to an\nincrease in high-confidence samples at test time.\n","authors":["Ramya Hebbalaguppe","Rishabh Patra","Tirtharaj Dash","Gautam Shroff","Lovekesh Vig"],"pdf_url":"https://arxiv.org/pdf/2212.10005v1.pdf","comment":"The paper is accepted at Winter Conference on applications of\n  Computer Vision (IEEE WACV) in algorithms tracks. 8 pages Main paper; 3 pages\n  supplementary material"},{"id":"http://arxiv.org/abs/2008.09418v2","updated":"2022-12-20T05:10:47Z","published":"2020-08-21T10:58:33Z","title":"Method to Classify Skin Lesions using Dermoscopic images","summary":"  Skin cancer is the most common cancer in the existing world constituting\none-third of the cancer cases. Benign skin cancers are not fatal, can be cured\nwith proper medication. But it is not the same as the malignant skin cancers.\nIn the case of malignant melanoma, in its peak stage, the maximum life\nexpectancy is less than or equal to 5 years. But, it can be cured if detected\nin early stages. Though there are numerous clinical procedures, the accuracy of\ndiagnosis falls between 49% to 81% and is time-consuming. So, dermoscopy has\nbeen brought into the picture. It helped in increasing the accuracy of\ndiagnosis but could not demolish the error-prone behaviour. A quick and less\nerror-prone solution is needed to diagnose this majorly growing skin cancer.\nThis project deals with the usage of deep learning in skin lesion\nclassification. In this project, an automated model for skin lesion\nclassification using dermoscopic images has been developed with CNN(Convolution\nNeural Networks) as a training model. Convolution neural networks are known for\ncapturing features of an image. So, they are preferred in analyzing medical\nimages to find the characteristics that drive the model towards success.\nTechniques like data augmentation for tackling class imbalance, segmentation\nfor focusing on the region of interest and 10-fold cross-validation to make the\nmodel robust have been brought into the picture. This project also includes\nusage of certain preprocessing techniques like brightening the images using\npiece-wise linear transformation function, grayscale conversion of the image,\nresize the image. This project throws a set of valuable insights on how the\naccuracy of the model hikes with the bringing of new input strategies,\npreprocessing techniques. The best accuracy this model could achieve is 0.886.\n","authors":["Dusa Sai Charan","Hemanth Nadipineni","Subin Sahayam","Umarani Jayaraman"],"pdf_url":"https://arxiv.org/pdf/2008.09418v2.pdf","comment":"16 pages, 14 figures"},{"id":"http://arxiv.org/abs/2212.09993v1","updated":"2022-12-20T04:33:32Z","published":"2022-12-20T04:33:32Z","title":"Are Deep Neural Networks SMARTer than Second Graders?","summary":"  Recent times have witnessed an increasing number of applications of deep\nneural networks towards solving tasks that require superior cognitive\nabilities, e.g., playing Go, generating art, question answering (such as\nChatGPT), etc. Such a dramatic progress raises the question: how generalizable\nare neural networks in solving problems that demand broad skills? To answer\nthis question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task\nand the associated SMART-101 dataset, for evaluating the abstraction,\ndeduction, and generalization abilities of neural networks in solving\nvisuo-linguistic puzzles designed specifically for children in the 6-8 age\ngroup. Our dataset consists of 101 unique puzzles; each puzzle comprises a\npicture and a question, and their solution needs a mix of several elementary\nskills, including arithmetic, algebra, and spatial reasoning, among others. To\nscale our dataset towards training deep neural networks, we programmatically\ngenerate entirely new instances for each puzzle while retaining their solution\nalgorithm. To benchmark the performance on the SMART-101 dataset, we propose a\nvision and language meta-learning model using varied state-of-the-art backbone\nneural networks. Our experiments reveal that while powerful deep models offer\nreasonable performances on puzzles that they are trained on, they are not\nbetter than random accuracy when analyzed for generalization. We also evaluate\nthe recent ChatGPT large language model on a subset of our dataset and find\nthat while ChatGPT produces convincing reasoning abilities, the answers are\noften incorrect.\n","authors":["Anoop Cherian","Kuan-Chuan Peng","Suhas Lohit","Kevin Smith","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2212.09993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09988v1","updated":"2022-12-20T04:15:03Z","published":"2022-12-20T04:15:03Z","title":"Multi-Reference Image Super-Resolution: A Posterior Fusion Approach","summary":"  Reference-based Super-resolution (RefSR) approaches have recently been\nproposed to overcome the ill-posed problem of image super-resolution by\nproviding additional information from a high-resolution image. Multi-reference\nsuper-resolution extends this approach by allowing more information to be\nincorporated. This paper proposes a 2-step-weighting posterior fusion approach\nto combine the outputs of RefSR models with multiple references. Extensive\nexperiments on the CUFED5 dataset demonstrate that the proposed methods can be\napplied to various state-of-the-art RefSR models to get a consistent\nimprovement in image quality.\n","authors":["Ke Zhao","Haining Tan","Tsz Fung Yau"],"pdf_url":"https://arxiv.org/pdf/2212.09988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09983v1","updated":"2022-12-20T03:57:11Z","published":"2022-12-20T03:57:11Z","title":"Texture Representation via Analysis and Synthesis with Generative\n  Adversarial Networks","summary":"  We investigate data-driven texture modeling via analysis and synthesis with\ngenerative adversarial networks. For network training and testing, we have\ncompiled a diverse set of spatially homogeneous textures, ranging from\nstochastic to regular. We adopt StyleGAN3 for synthesis and demonstrate that it\nproduces diverse textures beyond those represented in the training data. For\ntexture analysis, we propose GAN inversion using a novel latent domain\nreconstruction consistency criterion for synthesized textures, and iterative\nrefinement with Gramian loss for real textures. We propose perceptual\nprocedures for evaluating network capabilities, exploring the global and local\nbehavior of latent space trajectories, and comparing with existing texture\nanalysis-synthesis techniques.\n","authors":["Jue Lin","Gaurav Sharma","Thrasyvoulos N. Pappas"],"pdf_url":"https://arxiv.org/pdf/2212.09983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09735v2","updated":"2022-12-20T03:47:40Z","published":"2022-12-19T18:54:59Z","title":"Correspondence Distillation from NeRF-based GAN","summary":"  The neural radiance field (NeRF) has shown promising results in preserving\nthe fine details of objects and scenes. However, unlike mesh-based\nrepresentations, it remains an open problem to build dense correspondences\nacross different NeRFs of the same category, which is essential in many\ndownstream tasks. The main difficulties of this problem lie in the implicit\nnature of NeRF and the lack of ground-truth correspondence annotations. In this\npaper, we show it is possible to bypass these challenges by leveraging the rich\nsemantics and structural priors encapsulated in a pre-trained NeRF-based GAN.\nSpecifically, we exploit such priors from three aspects, namely 1) a dual\ndeformation field that takes latent codes as global structural indicators, 2) a\nlearning objective that regards generator features as geometric-aware local\ndescriptors, and 3) a source of infinite object-specific NeRF samples. Our\nexperiments demonstrate that such priors lead to 3D dense correspondence that\nis accurate, smooth, and robust. We also show that established dense\ncorrespondence across NeRFs can effectively enable many NeRF-based downstream\napplications such as texture transfer.\n","authors":["Yushi Lan","Chen Change Loy","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2212.09735v2.pdf","comment":"Project page: https://nirvanalan.github.io/projects/DDF/index.html"},{"id":"http://arxiv.org/abs/2212.09981v1","updated":"2022-12-20T03:45:38Z","published":"2022-12-20T03:45:38Z","title":"Benchmarking person re-identification datasets and approaches for\n  practical real-world implementations","summary":"  Recently, Person Re-Identification (Re-ID) has received a lot of attention.\nLarge datasets containing labeled images of various individuals have been\nreleased, allowing researchers to develop and test many successful approaches.\nHowever, when such Re-ID models are deployed in new cities or environments, the\ntask of searching for people within a network of security cameras is likely to\nface an important domain shift, thus resulting in decreased performance.\nIndeed, while most public datasets were collected in a limited geographic area,\nimages from a new city present different features (e.g., people's ethnicity and\nclothing style, weather, architecture, etc.). In addition, the whole frames of\nthe video streams must be converted into cropped images of people using\npedestrian detection models, which behave differently from the human annotators\nwho created the dataset used for training. To better understand the extent of\nthis issue, this paper introduces a complete methodology to evaluate Re-ID\napproaches and training datasets with respect to their suitability for\nunsupervised deployment for live operations. This method is used to benchmark\nfour Re-ID approaches on three datasets, providing insight and guidelines that\ncan help to design better Re-ID pipelines in the future.\n","authors":["Jose Huaman","Felix O. Sumari","Luigy Machaca","Esteban Clua","Joris Guerin"],"pdf_url":"https://arxiv.org/pdf/2212.09981v1.pdf","comment":"This paper is the extended version of our short paper accepted in\n  VISAPP - 2023"},{"id":"http://arxiv.org/abs/2212.09979v1","updated":"2022-12-20T03:43:54Z","published":"2022-12-20T03:43:54Z","title":"Flareon: Stealthy any2any Backdoor Injection via Poisoned Augmentation","summary":"  Open software supply chain attacks, once successful, can exact heavy costs in\nmission-critical applications. As open-source ecosystems for deep learning\nflourish and become increasingly universal, they present attackers previously\nunexplored avenues to code-inject malicious backdoors in deep neural network\nmodels. This paper proposes Flareon, a small, stealthy, seemingly harmless code\nmodification that specifically targets the data augmentation pipeline with\nmotion-based triggers. Flareon neither alters ground-truth labels, nor modifies\nthe training loss objective, nor does it assume prior knowledge of the victim\nmodel architecture, training data, and training hyperparameters. Yet, it has a\nsurprisingly large ramification on training -- models trained under Flareon\nlearn powerful target-conditional (or \"any2any\") backdoors. The resulting\nmodels can exhibit high attack success rates for any target choices and better\nclean accuracies than backdoor attacks that not only seize greater control, but\nalso assume more restrictive attack capabilities. We also demonstrate the\neffectiveness of Flareon against recent defenses. Flareon is fully open-source\nand available online to the deep learning community:\nhttps://github.com/lafeat/flareon.\n","authors":["Tianrui Qin","Xianghuan He","Xitong Gao","Yiren Zhao","Kejiang Ye","Cheng-Zhong Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09977v1","updated":"2022-12-20T03:40:44Z","published":"2022-12-20T03:40:44Z","title":"Conditioned Generative Transformers for Histopathology Image Synthetic\n  Augmentation","summary":"  Deep learning networks have demonstrated state-of-the-art performance on\nmedical image analysis tasks. However, the majority of the works rely heavily\non abundantly labeled data, which necessitates extensive involvement of domain\nexperts. Vision transformer (ViT) based generative adversarial networks (GANs)\nrecently demonstrated superior potential in general image synthesis, yet are\nless explored for histopathology images. In this paper, we address these\nchallenges by proposing a pure ViT-based conditional GAN model for\nhistopathology image synthetic augmentation. To alleviate training instability\nand improve generation robustness, we first introduce a conditioned class\nprojection method to facilitate class separation. We then implement a\nmulti-loss weighing function to dynamically balance the losses between\nclassification tasks. We further propose a selective augmentation mechanism to\nactively choose the appropriate generated images and bring additional\nperformance improvements. Extensive experiments on the histopathology datasets\nshow that leveraging our synthetic augmentation framework results in\nsignificant and consistent improvements in classification performance.\n","authors":["Meng Li","Chaoyi Li","Can Peng","Brian Lovell"],"pdf_url":"https://arxiv.org/pdf/2212.09977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.01986v2","updated":"2022-12-20T02:56:59Z","published":"2022-06-04T13:07:30Z","title":"Delving into the Openness of CLIP","summary":"  Contrastive Language-Image Pre-training (CLIP) has demonstrated great\npotential in realizing open-vocabulary visual recognition in a matching style,\ndue to its holistic use of natural language supervision that covers\nunconstrained real-world visual concepts. However, it is, in turn, also\ndifficult to evaluate and analyze the openness of CLIP-like models, since they\nare in theory open to any vocabulary but the actual accuracy varies. To address\nthe insufficiency of conventional studies on openness, we resort to an\nincremental perspective and define the extensibility, which essentially\napproximates the model's ability to deal with new visual concepts, by\nevaluating openness through vocabulary expansions. Our evaluation based on\nextensibility shows that CLIP-like models are hardly truly open and their\nperformance degrades as the vocabulary expands to different degrees. Further\nanalysis reveals that the over-estimation of openness is not because CLIP-like\nmodels fail to capture the general similarity of image and text features of\nnovel visual concepts, but because of the confusion among competing text\nfeatures, that is, they are not stable with respect to the vocabulary. In light\nof this, we propose to improve the openness of CLIP in the feature space by\nenforcing the distinguishability of text features. Our method retrieves\nrelevant texts from the pre-training corpus to enhance prompts for inference,\nwhich boosts the extensibility and stability of CLIP even without fine-tuning.\n","authors":["Shuhuai Ren","Lei Li","Xuancheng Ren","Guangxiang Zhao","Xu Sun"],"pdf_url":"https://arxiv.org/pdf/2206.01986v2.pdf","comment":"22 pages, 12 figures. Code is available at\n  https://github.com/lancopku/clip-openness"},{"id":"http://arxiv.org/abs/2211.10104v2","updated":"2022-12-20T02:30:13Z","published":"2022-11-18T09:07:01Z","title":"Stereo Image Rain Removal via Dual-View Mutual Attention","summary":"  Stereo images, containing left and right view images with disparity, are\nutilized in solving low-vision tasks recently, e.g., rain removal and\nsuper-resolution. Stereo image restoration methods usually obtain better\nperformance than monocular methods by learning the disparity between dual views\neither implicitly or explicitly. However, existing stereo rain removal methods\nstill cannot make full use of the complementary information between two views,\nand we find it is because: 1) the rain streaks have more complex distributions\nin directions and densities, which severely damage the complementary\ninformation and pose greater challenges; 2) the disparity estimation is not\naccurate enough due to the imperfect fusion mechanism for the features between\ntwo views. To overcome such limitations, we propose a new \\underline{Stereo}\n\\underline{I}mage \\underline{R}ain \\underline{R}emoval method (StereoIRR) via\nsufficient interaction between two views, which incorporates: 1) a new\nDual-view Mutual Attention (DMA) mechanism which generates mutual attention\nmaps by taking left and right views as key information for each other to\nfacilitate cross-view feature fusion; 2) a long-range and cross-view\ninteraction, which is constructed with basic blocks and dual-view mutual\nattention, can alleviate the adverse effect of rain on complementary\ninformation to help the features of stereo images to get long-range and\ncross-view interaction and fusion. Notably, StereoIRR outperforms other related\nmonocular and stereo image rain removal methods on several datasets. Our codes\nand datasets will be released.\n","authors":["Yanyan Wei","Zhao Zhang","Zhongqiu Zhao","Yang Zhao","Richang Hong","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2211.10104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.05227v3","updated":"2022-12-20T02:21:11Z","published":"2022-09-12T13:26:26Z","title":"DUET: A Tuning-Free Device-Cloud Collaborative Parameters Generation\n  Framework for Efficient Device Model Generalization","summary":"  Device Model Generalization (DMG) is a practical yet under-investigated\nresearch topic for on-device machine learning applications. It aims to improve\nthe generalization ability of pre-trained models when deployed on\nresource-constrained devices, such as improving the performance of pre-trained\ncloud models on smart mobiles. While quite a lot of works have investigated the\ndata distribution shift across clouds and devices, most of them focus on model\nfine-tuning on personalized data for individual devices to facilitate DMG.\nDespite their promising, these approaches require on-device re-training, which\nis practically infeasible due to the overfitting problem and high time delay\nwhen performing gradient calculation on real-time data. In this paper, we argue\nthat the computational cost brought by fine-tuning can be rather unnecessary.\nWe consequently present a novel perspective to improving DMG without increasing\ncomputational cost, i.e., device-specific parameter generation which directly\nmaps data distribution to parameters. Specifically, we propose an efficient\nDevice-cloUd collaborative parametErs generaTion framework DUET. DUET is\ndeployed on a powerful cloud server that only requires the low cost of\nforwarding propagation and low time delay of data transmission between the\ndevice and the cloud. By doing so, DUET can rehearse the device-specific model\nweight realizations conditioned on the personalized real-time data for an\nindividual device. Importantly, our DUET elegantly connects the cloud and\ndevice as a 'duet' collaboration, frees the DMG from fine-tuning, and enables a\nfaster and more accurate DMG paradigm. We conduct an extensive experimental\nstudy of DUET on three public datasets, and the experimental results confirm\nour framework's effectiveness and generalisability for different DMG tasks.\n","authors":["Zheqi Lv","Wenqiao Zhang","Shengyu Zhang","Kun Kuang","Feng Wang","Yongwei Wang","Zhengyu Chen","Tao Shen","Hongxia Yang","Beng chin Ooi","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2209.05227v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09950v1","updated":"2022-12-20T01:59:27Z","published":"2022-12-20T01:59:27Z","title":"Domain Generalization with Correlated Style Uncertainty","summary":"  Though impressive success has been witnessed in computer vision, deep\nlearning still suffers from the domain shift challenge when the target domain\nfor testing and the source domain for training do not share an identical\ndistribution. To address this, domain generalization approaches intend to\nextract domain invariant features that can lead to a more robust model. Hence,\nincreasing the source domain diversity is a key component of domain\ngeneralization. Style augmentation takes advantage of instance-specific feature\nstatistics containing informative style characteristics to synthetic novel\ndomains. However, all previous works ignored the correlation between different\nfeature channels or only limited the style augmentation through linear\ninterpolation. In this work, we propose a novel augmentation method, called\n\\textit{Correlated Style Uncertainty (CSU)}, to go beyond the linear\ninterpolation of style statistic space while preserving the essential\ncorrelation information. We validate our method's effectiveness by extensive\nexperiments on multiple cross-domain classification tasks, including widely\nused PACS, Office-Home, Camelyon17 datasets and the Duke-Market1501 instance\nretrieval task and obtained significant margin improvements over the\nstate-of-the-art methods. The source code is available for public use.\n","authors":["Zheyuan Zhang","Bin Wang","Debesh Jha","Ugur Demir","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2212.09950v1.pdf","comment":"Code is available after peer review"},{"id":"http://arxiv.org/abs/2212.09948v1","updated":"2022-12-20T01:53:40Z","published":"2022-12-20T01:53:40Z","title":"MM-3DScene: 3D Scene Understanding by Customizing Masked Modeling with\n  Informative-Preserved Reconstruction and Self-Distilled Consistency","summary":"  Masked Modeling (MM) has demonstrated widespread success in various vision\nchallenges, by reconstructing masked visual patches. Yet, applying MM for\nlarge-scale 3D scenes remains an open problem due to the data sparsity and\nscene complexity. The conventional random masking paradigm used in 2D images\noften causes a high risk of ambiguity when recovering the masked region of 3D\nscenes. To this end, we propose a novel informative-preserved reconstruction,\nwhich explores local statistics to discover and preserve the representative\nstructured points, effectively enhancing the pretext masking task for 3D scene\nunderstanding. Integrated with a progressive reconstruction manner, our method\ncan concentrate on modeling regional geometry and enjoy less ambiguity for\nmasked reconstruction. Besides, such scenes with progressive masking ratios can\nalso serve to self-distill their intrinsic spatial consistency, requiring to\nlearn the consistent representations from unmasked areas. By elegantly\ncombining informative-preserved reconstruction on masked areas and consistency\nself-distillation from unmasked areas, a unified framework called MM-3DScene is\nyielded. We conduct comprehensive experiments on a host of downstream tasks.\nThe consistent improvement (e.g., +6.1 mAP@0.5 on object detection and +2.2%\nmIoU on semantic segmentation) demonstrates the superiority of our approach.\n","authors":["Mingye Xu","Mutian Xu","Tong He","Wanli Ouyang","Yali Wang","Xiaoguang Han","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2212.09948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09945v1","updated":"2022-12-20T01:46:18Z","published":"2022-12-20T01:46:18Z","title":"Robust and Resource-efficient Machine Learning Aided Viewport Prediction\n  in Virtual Reality","summary":"  360-degree panoramic videos have gained considerable attention in recent\nyears due to the rapid development of head-mounted displays (HMDs) and\npanoramic cameras. One major problem in streaming panoramic videos is that\npanoramic videos are much larger in size compared to traditional ones.\nMoreover, the user devices are often in a wireless environment, with limited\nbattery, computation power, and bandwidth. To reduce resource consumption,\nresearchers have proposed ways to predict the users' viewports so that only\npart of the entire video needs to be transmitted from the server. However, the\nrobustness of such prediction approaches has been overlooked in the literature:\nit is usually assumed that only a few models, pre-trained on past users'\nexperiences, are applied for prediction to all users. We observe that those\npre-trained models can perform poorly for some users because they might have\ndrastically different behaviors from the majority, and the pre-trained models\ncannot capture the features in unseen videos. In this work, we propose a novel\nmeta learning based viewport prediction paradigm to alleviate the worst\nprediction performance and ensure the robustness of viewport prediction. This\nparadigm uses two machine learning models, where the first model predicts the\nviewing direction, and the second model predicts the minimum video prefetch\nsize that can include the actual viewport. We first train two meta models so\nthat they are sensitive to new training data, and then quickly adapt them to\nusers while they are watching the videos. Evaluation results reveal that the\nmeta models can adapt quickly to each user, and can significantly increase the\nprediction accuracy, especially for the worst-performing predictions.\n","authors":["Yuang Jiang","Konstantinos Poularakis","Diego Kiedanski","Sastry Kompella","Leandros Tassiulas"],"pdf_url":"https://arxiv.org/pdf/2212.09945v1.pdf","comment":"Accepted for publication in 2022 IEEE International Conference on Big\n  Data (IEEE BigData 2022)"},{"id":"http://arxiv.org/abs/2212.02623v2","updated":"2022-12-20T00:39:48Z","published":"2022-12-05T22:14:49Z","title":"Unifying Vision, Text, and Layout for Universal Document Processing","summary":"  We propose Universal Document Processing (UDOP), a foundation Document AI\nmodel which unifies text, image, and layout modalities together with varied\ntask formats, including document understanding and generation. UDOP leverages\nthe spatial correlation between textual content and document image to model\nimage, text, and layout modalities with one uniform representation. With a\nnovel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain\ndownstream tasks into a prompt-based sequence generation scheme. UDOP is\npretrained on both large-scale unlabeled document corpora using innovative\nself-supervised objectives and diverse labeled data. UDOP also learns to\ngenerate document images from text and layout modalities via masked image\nreconstruction. To the best of our knowledge, this is the first time in the\nfield of document AI that one model simultaneously achieves high-quality neural\ndocument editing and content customization. Our method sets the\nstate-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,\nacross diverse data domains like finance reports, academic papers, and\nwebsites. UDOP ranks first on the leaderboard of the Document Understanding\nBenchmark (DUE).\n","authors":["Zineng Tang","Ziyi Yang","Guoxin Wang","Yuwei Fang","Yang Liu","Chenguang Zhu","Michael Zeng","Cha Zhang","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2212.02623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04074v2","updated":"2022-12-20T00:32:07Z","published":"2022-12-08T04:54:01Z","title":"Cross-view Geo-localization via Learning Disentangled Geometric Layout\n  Correspondence","summary":"  Cross-view geo-localization aims to estimate the location of a query ground\nimage by matching it to a reference geo-tagged aerial images database. As an\nextremely challenging task, its difficulties root in the drastic view changes\nand different capturing time between two views. Despite these difficulties,\nrecent works achieve outstanding progress on cross-view geo-localization\nbenchmarks. However, existing methods still suffer from poor performance on the\ncross-area benchmarks, in which the training and testing data are captured from\ntwo different regions. We attribute this deficiency to the lack of ability to\nextract the spatial configuration of visual feature layouts and models'\noverfitting on low-level details from the training set. In this paper, we\npropose GeoDTR which explicitly disentangles geometric information from raw\nfeatures and learns the spatial correlations among visual features from aerial\nand ground pairs with a novel geometric layout extractor module. This module\ngenerates a set of geometric layout descriptors, modulating the raw features\nand producing high-quality latent representations. In addition, we elaborate on\ntwo categories of data augmentations, (i) Layout simulation, which varies the\nspatial configuration while keeping the low-level details intact. (ii) Semantic\naugmentation, which alters the low-level details and encourages the model to\ncapture spatial configurations. These augmentations help to improve the\nperformance of the cross-view geo-localization models, especially on the\ncross-area benchmarks. Moreover, we propose a counterfactual-based learning\nprocess to benefit the geometric layout extractor in exploring spatial\ninformation. Extensive experiments show that GeoDTR not only achieves\nstate-of-the-art results but also significantly boosts the performance on\nsame-area and cross-area benchmarks.\n","authors":["Xiaohan Zhang","Xingyu Li","Waqas Sultani","Yi Zhou","Safwan Wshah"],"pdf_url":"https://arxiv.org/pdf/2212.04074v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.11821v2","updated":"2022-12-20T23:36:52Z","published":"2022-08-25T01:44:28Z","title":"Refine and Represent: Region-to-Object Representation Learning","summary":"  Recent works in self-supervised learning have demonstrated strong performance\non scene-level dense prediction tasks by pretraining with object-centric or\nregion-based correspondence objectives. In this paper, we present\nRegion-to-Object Representation Learning (R2O) which unifies region-based and\nobject-centric pretraining. R2O operates by training an encoder to dynamically\nrefine region-based segments into object-centric masks and then jointly learns\nrepresentations of the contents within the mask. R2O uses a \"region refinement\nmodule\" to group small image regions, generated using a region-level prior,\ninto larger regions which tend to correspond to objects by clustering\nregion-level features. As pretraining progresses, R2O follows a\nregion-to-object curriculum which encourages learning region-level features\nearly on and gradually progresses to train object-centric representations.\nRepresentations learned using R2O lead to state-of-the art performance in\nsemantic segmentation for PASCAL VOC (+0.7 mIOU) and Cityscapes (+0.4 mIOU) and\ninstance segmentation on MS COCO (+0.3 mask AP). Further, after pretraining on\nImageNet, R2O pretrained models are able to surpass existing state-of-the-art\nin unsupervised object segmentation on the Caltech-UCSD Birds 200-2011 dataset\n(+2.9 mIoU) without any further training. We provide the code/models from this\nwork at https://github.com/KKallidromitis/r2o.\n","authors":["Akash Gokul","Konstantinos Kallidromitis","Shufan Li","Yusuke Kato","Kazuki Kozuka","Trevor Darrell","Colorado J Reed"],"pdf_url":"https://arxiv.org/pdf/2208.11821v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10690v1","updated":"2022-12-20T23:30:47Z","published":"2022-12-20T23:30:47Z","title":"METEOR Guided Divergence for Video Captioning","summary":"  Automatic video captioning aims for a holistic visual scene understanding. It\nrequires a mechanism for capturing temporal context in video frames and the\nability to comprehend the actions and associations of objects in a given\ntimeframe. Such a system should additionally learn to abstract video sequences\ninto sensible representations as well as to generate natural written language.\nWhile the majority of captioning models focus solely on the visual inputs,\nlittle attention has been paid to the audiovisual modality. To tackle this\nissue, we propose a novel two-fold approach. First, we implement a\nreward-guided KL Divergence to train a video captioning model which is\nresilient towards token permutations. Second, we utilise a Bi-Modal\nHierarchical Reinforcement Learning (BMHRL) Transformer architecture to capture\nlong-term temporal dependencies of the input data as a foundation for our\nhierarchical captioning module. Using our BMHRL, we show the suitability of the\nHRL agent in the generation of content-complete and grammatically sound\nsentences by achieving $4.91$, $2.23$, and $10.80$ in BLEU3, BLEU4, and METEOR\nscores, respectively on the ActivityNet Captions dataset. Finally, we make our\nBMHRL framework and trained models publicly available for users and developers\nat https://github.com/d-rothen/bmhrl.\n","authors":["Daniel Lukas Rothenpieler","Shahin Amiriparian"],"pdf_url":"https://arxiv.org/pdf/2212.10690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10688v1","updated":"2022-12-20T23:08:55Z","published":"2022-12-20T23:08:55Z","title":"Local Differential Privacy Image Generation Using Flow-based Deep\n  Generative Models","summary":"  Diagnostic radiologists need artificial intelligence (AI) for medical\nimaging, but access to medical images required for training in AI has become\nincreasingly restrictive. To release and use medical images, we need an\nalgorithm that can simultaneously protect privacy and preserve pathologies in\nmedical images. To develop such an algorithm, here, we propose DP-GLOW, a\nhybrid of a local differential privacy (LDP) algorithm and one of the\nflow-based deep generative models (GLOW). By applying a GLOW model, we\ndisentangle the pixelwise correlation of images, which makes it difficult to\nprotect privacy with straightforward LDP algorithms for images. Specifically,\nwe map images onto the latent vector of the GLOW model, each element of which\nfollows an independent normal distribution, and we apply the Laplace mechanism\nto the latent vector. Moreover, we applied DP-GLOW to chest X-ray images to\ngenerate LDP images while preserving pathologies.\n","authors":["Hisaichi Shibata","Shouhei Hanaoka","Yang Cao","Masatoshi Yoshikawa","Tomomi Takenaga","Yukihiro Nomura","Naoto Hayashi","Osamu Abe"],"pdf_url":"https://arxiv.org/pdf/2212.10688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10682v1","updated":"2022-12-20T22:55:46Z","published":"2022-12-20T22:55:46Z","title":"Privacy-Protecting Behaviours of Risk Detection in People with Dementia\n  using Videos","summary":"  People living with dementia often exhibit behavioural and psychological\nsymptoms of dementia that can put their and others' safety at risk. Existing\nvideo surveillance systems in long-term care facilities can be used to monitor\nsuch behaviours of risk to alert the staff to prevent potential injuries or\ndeath in some cases. However, these behaviours of risk events are heterogeneous\nand infrequent in comparison to normal events. Moreover, analyzing raw videos\ncan also raise privacy concerns. In this paper, we present two novel\nprivacy-protecting video-based anomaly detection approaches to detect\nbehaviours of risks in people with dementia. We either extracted body pose\ninformation as skeletons and use semantic segmentation masks to replace\nmultiple humans in the scene with their semantic boundaries. Our work differs\nfrom most existing approaches for video anomaly detection that focus on\nappearance-based features, which can put the privacy of a person at risk and is\nalso susceptible to pixel-based noise, including illumination and viewing\ndirection. We used anonymized videos of normal activities to train customized\nspatio-temporal convolutional autoencoders and identify behaviours of risk as\nanomalies. We show our results on a real-world study conducted in a dementia\ncare unit with patients with dementia, containing approximately 21 hours of\nnormal activities data for training and 9 hours of data containing normal and\nbehaviours of risk events for testing. We compared our approaches with the\noriginal RGB videos and obtained an equivalent area under the receiver\noperating characteristic curve performance of 0.807 for the skeleton-based\napproach and 0.823 for the segmentation mask-based approach. This is one of the\nfirst studies to incorporate privacy for the detection of behaviours of risks\nin people with dementia.\n","authors":["Pratik K. Mishra","Andrea Iaboni","Bing Ye","Kristine Newman","Alex Mihailidis","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2212.10682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10632v1","updated":"2022-12-20T20:11:11Z","published":"2022-12-20T20:11:11Z","title":"High-Throughput, High-Performance Deep Learning-Driven Light Guide Plate\n  Surface Visual Quality Inspection Tailored for Real-World Manufacturing\n  Environments","summary":"  Light guide plates are essential optical components widely used in a diverse\nrange of applications ranging from medical lighting fixtures to back-lit TV\ndisplays. In this work, we introduce a fully-integrated, high-throughput,\nhigh-performance deep learning-driven workflow for light guide plate surface\nvisual quality inspection (VQI) tailored for real-world manufacturing\nenvironments. To enable automated VQI on the edge computing within the\nfully-integrated VQI system, a highly compact deep anti-aliased attention\ncondenser neural network (which we name LightDefectNet) tailored specifically\nfor light guide plate surface defect detection in resource-constrained\nscenarios was created via machine-driven design exploration with computational\nand \"best-practices\" constraints as well as L_1 paired classification\ndiscrepancy loss. Experiments show that LightDetectNet achieves a detection\naccuracy of ~98.2% on the LGPSDD benchmark while having just 770K parameters\n(~33X and ~6.9X lower than ResNet-50 and EfficientNet-B0, respectively) and\n~93M FLOPs (~88X and ~8.4X lower than ResNet-50 and EfficientNet-B0,\nrespectively) and ~8.8X faster inference speed than EfficientNet-B0 on an\nembedded ARM processor. As such, the proposed deep learning-driven workflow,\nintegrated with the aforementioned LightDefectNet neural network, is highly\nsuited for high-throughput, high-performance light plate surface VQI within\nreal-world manufacturing environments.\n","authors":["Carol Xu","Mahmoud Famouri","Gautam Bathla","Mohammad Javad Shafiee","Alexander Wong"],"pdf_url":"https://arxiv.org/pdf/2212.10632v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2204.11765"},{"id":"http://arxiv.org/abs/2206.05575v3","updated":"2022-12-20T19:54:26Z","published":"2022-06-11T17:38:09Z","title":"MammoDL: Mammographic Breast Density Estimation using Federated Learning","summary":"  Assessing breast cancer risk from imaging remains a subjective process, in\nwhich radiologists employ simple computer aided detection (CAD) systems or\nqualitative visual assessment to estimate breast percent density (PD). Machine\nlearning (ML) models have become the most promising way to quantify breast\ncancer risk for early, accurate, and equitable diagnoses, but training such\nmodels in medical research is often restricted to small, single-institution\ndata. Since patient demographics and imaging characteristics may vary\nconsiderably across imaging sites, models trained on single-institution data\ntend not to generalize well. In response to this problem, MammoDL is proposed,\nan open-source software tool that leverages a U-Net architecture to accurately\nestimate breast PD and complexity from mammography. With the Open Federated\nLearning (OpenFL) library, this solution enables secure training on datasets\nacross multiple institutions. MammoDL is a leaner, more flexible model than its\npredecessors, boasting improved generalization due to federation-enabled\ntraining on larger, more representative datasets.\n","authors":["Ramya Muthukrishnan","Angelina Heyler","Keshava Katti","Sarthak Pati","Walter Mankowski","Aprupa Alahari","Michael Sanborn","Emily F. Conant","Christopher Scott","Stacey Winham","Celine Vachon","Pratik Chaudhari","Despina Kontos","Spyridon Bakas"],"pdf_url":"https://arxiv.org/pdf/2206.05575v3.pdf","comment":"Breast Cancer Risk, Digital Mammography, Breast Density, Deep\n  Learning, Machine Learning, Federated Learning, OpenFL"},{"id":"http://arxiv.org/abs/2212.10621v1","updated":"2022-12-20T19:50:54Z","published":"2022-12-20T19:50:54Z","title":"CHAIRS: Towards Full-Body Articulated Human-Object Interaction","summary":"  Fine-grained capturing of 3D HOI boosts human activity understanding and\nfacilitates downstream visual tasks, including action recognition, holistic\nscene reconstruction, and human motion synthesis. Despite its significance,\nexisting works mostly assume that humans interact with rigid objects using only\na few body parts, limiting their scope. In this paper, we address the\nchallenging problem of f-AHOI, wherein the whole human bodies interact with\narticulated objects, whose parts are connected by movable joints. We present\nCHAIRS, a large-scale motion-captured f-AHOI dataset, consisting of 16.2 hours\nof versatile interactions between 46 participants and 81 articulated and rigid\nsittable objects. CHAIRS provides 3D meshes of both humans and articulated\nobjects during the entire interactive process, as well as realistic and\nphysically plausible full-body interactions. We show the value of CHAIRS with\nobject pose estimation. By learning the geometrical relationships in HOI, we\ndevise the very first model that leverage human pose estimation to tackle the\nestimation of articulated object poses and shapes during whole-body\ninteractions. Given an image and an estimated human pose, our model first\nreconstructs the pose and shape of the object, then optimizes the\nreconstruction according to a learned interaction prior. Under both evaluation\nsettings (e.g., with or without the knowledge of objects'\ngeometries/structures), our model significantly outperforms baselines. We hope\nCHAIRS will promote the community towards finer-grained interaction\nunderstanding. We will make the data/code publicly available.\n","authors":["Nan Jiang","Tengyu Liu","Zhexuan Cao","Jieming Cui","Yixin Chen","He Wang","Yixin Zhu","Siyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2212.10621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10613v1","updated":"2022-12-20T19:29:37Z","published":"2022-12-20T19:29:37Z","title":"Temporal Output Discrepancy for Loss Estimation-based Active Learning","summary":"  While deep learning succeeds in a wide range of tasks, it highly depends on\nthe massive collection of annotated data which is expensive and time-consuming.\nTo lower the cost of data annotation, active learning has been proposed to\ninteractively query an oracle to annotate a small proportion of informative\nsamples in an unlabeled dataset. Inspired by the fact that the samples with\nhigher loss are usually more informative to the model than the samples with\nlower loss, in this paper we present a novel deep active learning approach that\nqueries the oracle for data annotation when the unlabeled sample is believed to\nincorporate high loss. The core of our approach is a measurement Temporal\nOutput Discrepancy (TOD) that estimates the sample loss by evaluating the\ndiscrepancy of outputs given by models at different optimization steps. Our\ntheoretical investigation shows that TOD lower-bounds the accumulated sample\nloss thus it can be used to select informative unlabeled samples. On basis of\nTOD, we further develop an effective unlabeled data sampling strategy as well\nas an unsupervised learning criterion for active learning. Due to the\nsimplicity of TOD, our methods are efficient, flexible, and task-agnostic.\nExtensive experimental results demonstrate that our approach achieves superior\nperformances than the state-of-the-art active learning methods on image\nclassification and semantic segmentation tasks. In addition, we show that TOD\ncan be utilized to select the best model of potentially the highest testing\naccuracy from a pool of candidate models.\n","authors":["Siyu Huang","Tianyang Wang","Haoyi Xiong","Bihan Wen","Jun Huan","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2212.10613v1.pdf","comment":"Accepted for IEEE Transactions on Neural Networks and Learning\n  Systems, 2022. Journal extension of ICCV 2021 [arXiv:2107.14153]"},{"id":"http://arxiv.org/abs/2212.10596v1","updated":"2022-12-20T19:12:58Z","published":"2022-12-20T19:12:58Z","title":"Open-Vocabulary Temporal Action Detection with Off-the-Shelf Image-Text\n  Features","summary":"  Detecting actions in untrimmed videos should not be limited to a small,\nclosed set of classes. We present a simple, yet effective strategy for\nopen-vocabulary temporal action detection utilizing pretrained image-text\nco-embeddings. Despite being trained on static images rather than videos, we\nshow that image-text co-embeddings enable openvocabulary performance\ncompetitive with fully-supervised models. We show that the performance can be\nfurther improved by ensembling the image-text features with features encoding\nlocal motion, like optical flow based features, or other modalities, like\naudio. In addition, we propose a more reasonable open-vocabulary evaluation\nsetting for the ActivityNet data set, where the category splits are based on\nsimilarity rather than random assignment.\n","authors":["Vivek Rathod","Bryan Seybold","Sudheendra Vijayanarasimhan","Austin Myers","Xiuye Gu","Vighnesh Birodkar","David A. Ross"],"pdf_url":"https://arxiv.org/pdf/2212.10596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10570v1","updated":"2022-12-20T16:56:54Z","published":"2022-12-20T16:56:54Z","title":"Video Segmentation Learning Using Cascade Residual Convolutional Neural\n  Network","summary":"  Video segmentation consists of a frame-by-frame selection process of\nmeaningful areas related to foreground moving objects. Some applications\ninclude traffic monitoring, human tracking, action recognition, efficient video\nsurveillance, and anomaly detection. In these applications, it is not rare to\nface challenges such as abrupt changes in weather conditions, illumination\nissues, shadows, subtle dynamic background motions, and also camouflage\neffects. In this work, we address such shortcomings by proposing a novel deep\nlearning video segmentation approach that incorporates residual information\ninto the foreground detection learning process. The main goal is to provide a\nmethod capable of generating an accurate foreground detection given a grayscale\nvideo. Experiments conducted on the Change Detection 2014 and on the private\ndataset PetrobrasROUTES from Petrobras support the effectiveness of the\nproposed approach concerning some state-of-the-art video segmentation\ntechniques, with overall F-measures of $\\mathbf{0.9535}$ and $\\mathbf{0.9636}$\nin the Change Detection 2014 and PetrobrasROUTES datasets, respectively. Such a\nresult places the proposed technique amongst the top 3 state-of-the-art video\nsegmentation methods, besides comprising approximately seven times less\nparameters than its top one counterpart.\n","authors":["Daniel F. S. Santos","Rafael G. Pires","Danilo Colombo","João P. Papa"],"pdf_url":"https://arxiv.org/pdf/2212.10570v1.pdf","comment":"Published in: 2019 32nd SIBGRAPI Conference on Graphics, Patterns and\n  Images (SIBGRAPI). arXiv admin note: text overlap with arXiv:2212.10417"},{"id":"http://arxiv.org/abs/2212.11078v1","updated":"2022-12-20T14:53:46Z","published":"2022-12-20T14:53:46Z","title":"C2F-TCN: A Framework for Semi and Fully Supervised Temporal Action\n  Segmentation","summary":"  Temporal action segmentation tags action labels for every frame in an input\nuntrimmed video containing multiple actions in a sequence. For the task of\ntemporal action segmentation, we propose an encoder-decoder-style architecture\nnamed C2F-TCN featuring a \"coarse-to-fine\" ensemble of decoder outputs. The\nC2F-TCN framework is enhanced with a novel model agnostic temporal feature\naugmentation strategy formed by the computationally inexpensive strategy of the\nstochastic max-pooling of segments. It produces more accurate and\nwell-calibrated supervised results on three benchmark action segmentation\ndatasets. We show that the architecture is flexible for both supervised and\nrepresentation learning. In line with this, we present a novel unsupervised way\nto learn frame-wise representation from C2F-TCN. Our unsupervised learning\napproach hinges on the clustering capabilities of the input features and the\nformation of multi-resolution features from the decoder's implicit structure.\nFurther, we provide the first semi-supervised temporal action segmentation\nresults by merging representation learning with conventional supervised\nlearning. Our semi-supervised learning scheme, called\n``Iterative-Contrastive-Classify (ICC)'', progressively improves in performance\nwith more labeled data. The ICC semi-supervised learning in C2F-TCN, with 40%\nlabeled videos, performs similar to fully supervised counterparts.\n","authors":["Dipika Singhania","Rahul Rahaman","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2212.11078v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2112.01402"},{"id":"http://arxiv.org/abs/2212.09506v2","updated":"2022-12-20T09:32:38Z","published":"2022-12-16T06:23:59Z","title":"CLIP is Also an Efficient Segmenter: A Text-Driven Approach for Weakly\n  Supervised Semantic Segmentation","summary":"  Weakly supervised semantic segmentation (WSSS) with image-level labels is a\nchallenging task in computer vision. Mainstream approaches follow a multi-stage\nframework and suffer from high training costs. In this paper, we explore the\npotential of Contrastive Language-Image Pre-training models (CLIP) to localize\ndifferent categories with only image-level labels and without any further\ntraining. To efficiently generate high-quality segmentation masks from CLIP, we\npropose a novel framework called CLIP-ES for WSSS. Our framework improves all\nthree stages of WSSS with special designs for CLIP: 1) We introduce the softmax\nfunction into GradCAM and exploit the zero-shot ability of CLIP to suppress the\nconfusion caused by non-target classes and backgrounds. Meanwhile, to take full\nadvantage of CLIP, we re-explore text inputs under the WSSS setting and\ncustomize two text-driven strategies: sharpness-based prompt selection and\nsynonym fusion. 2) To simplify the stage of CAM refinement, we propose a\nreal-time class-aware attention-based affinity (CAA) module based on the\ninherent multi-head self-attention (MHSA) in CLIP-ViTs. 3) When training the\nfinal segmentation model with the masks generated by CLIP, we introduced a\nconfidence-guided loss (CGL) to mitigate noise and focus on confident regions.\nOur proposed framework dramatically reduces the cost of training for WSSS and\nshows the capability of localizing objects in CLIP. Our CLIP-ES achieves SOTA\nperformance on Pascal VOC 2012 and MS COCO 2014 while only taking 10% time of\nprevious methods for the pseudo mask generation. Code is available at\nhttps://github.com/linyq2117/CLIP-ES.\n","authors":["Yuqi Lin","Minghao Chen","Wenxiao Wang","Boxi Wu","Ke Li","Binbin Lin","Haifeng Liu","Xiaofei He"],"pdf_url":"https://arxiv.org/pdf/2212.09506v2.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.11085v1","updated":"2022-12-20T08:20:48Z","published":"2022-12-20T08:20:48Z","title":"Empirical Analysis of Limits for Memory Distance in Recurrent Neural\n  Networks","summary":"  Common to all different kinds of recurrent neural networks (RNNs) is the\nintention to model relations between data points through time. When there is no\nimmediate relationship between subsequent data points (like when the data\npoints are generated at random, e.g.), we show that RNNs are still able to\nremember a few data points back into the sequence by memorizing them by heart\nusing standard backpropagation. However, we also show that for classical RNNs,\nLSTM and GRU networks the distance of data points between recurrent calls that\ncan be reproduced this way is highly limited (compared to even a loose\nconnection between data points) and subject to various constraints imposed by\nthe type and size of the RNN in question. This implies the existence of a hard\nlimit (way below the information-theoretic one) for the distance between\nrelated data points within which RNNs are still able to recognize said\nrelation.\n","authors":["Steffen Illium","Thore Schillman","Robert Müller","Thomas Gabor","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2212.11085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11684v1","updated":"2022-12-20T21:35:39Z","published":"2022-12-20T21:35:39Z","title":"Scene-aware Egocentric 3D Human Pose Estimation","summary":"  Egocentric 3D human pose estimation with a single head-mounted fisheye camera\nhas recently attracted attention due to its numerous applications in virtual\nand augmented reality. Existing methods still struggle in challenging poses\nwhere the human body is highly occluded or is closely interacting with the\nscene. To address this issue, we propose a scene-aware egocentric pose\nestimation method that guides the prediction of the egocentric pose with scene\nconstraints. To this end, we propose an egocentric depth estimation network to\npredict the scene depth map from a wide-view egocentric fisheye camera while\nmitigating the occlusion of the human body with a depth-inpainting network.\nNext, we propose a scene-aware pose estimation network that projects the 2D\nimage features and estimated depth map of the scene into a voxel space and\nregresses the 3D pose with a V2V network. The voxel-based feature\nrepresentation provides the direct geometric connection between 2D image\nfeatures and scene geometry, and further facilitates the V2V network to\nconstrain the predicted pose based on the estimated scene geometry. To enable\nthe training of the aforementioned networks, we also generated a synthetic\ndataset, called EgoGTA, and an in-the-wild dataset based on EgoPW, called\nEgoPW-Scene. The experimental results of our new evaluation sequences show that\nthe predicted 3D egocentric poses are accurate and physically plausible in\nterms of human-scene interaction, demonstrating that our method outperforms the\nstate-of-the-art methods both quantitatively and qualitatively.\n","authors":["Jian Wang","Lingjie Liu","Weipeng Xu","Kripasindhu Sarkar","Diogo Luvizon","Christian Theobalt"],"pdf_url":"https://arxiv.org/pdf/2212.11684v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.10528v1","updated":"2022-12-20T18:44:21Z","published":"2022-12-20T18:44:21Z","title":"HYRR: Hybrid Infused Reranking for Passage Retrieval","summary":"  We present Hybrid Infused Reranking for Passages Retrieval (HYRR), a\nframework for training rerankers based on a hybrid of BM25 and neural retrieval\nmodels. Retrievers based on hybrid models have been shown to outperform both\nBM25 and neural models alone. Our approach exploits this improved performance\nwhen training a reranker, leading to a robust reranking model. The reranker, a\ncross-attention neural model, is shown to be robust to different first-stage\nretrieval systems, achieving better performance than rerankers simply trained\nupon the first-stage retrievers in the multi-stage systems. We present\nevaluations on a supervised passage retrieval task using MS MARCO and zero-shot\nretrieval tasks using BEIR. The empirical results show strong performance on\nboth evaluations.\n","authors":["Jing Lu","Keith Hall","Ji Ma","Jianmo Ni"],"pdf_url":"https://arxiv.org/pdf/2212.10528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10496v1","updated":"2022-12-20T18:09:52Z","published":"2022-12-20T18:09:52Z","title":"Precise Zero-Shot Dense Retrieval without Relevance Labels","summary":"  While dense retrieval has been shown effective and efficient across tasks and\nlanguages, it remains difficult to create effective fully zero-shot dense\nretrieval systems when no relevance label is available. In this paper, we\nrecognize the difficulty of zero-shot learning and encoding relevance. Instead,\nwe propose to pivot through Hypothetical Document Embeddings~(HyDE). Given a\nquery, HyDE first zero-shot instructs an instruction-following language model\n(e.g. InstructGPT) to generate a hypothetical document. The document captures\nrelevance patterns but is unreal and may contain false details. Then, an\nunsupervised contrastively learned encoder~(e.g. Contriever) encodes the\ndocument into an embedding vector. This vector identifies a neighborhood in the\ncorpus embedding space, where similar real documents are retrieved based on\nvector similarity. This second step ground the generated document to the actual\ncorpus, with the encoder's dense bottleneck filtering out the incorrect\ndetails. Our experiments show that HyDE significantly outperforms the\nstate-of-the-art unsupervised dense retriever Contriever and shows strong\nperformance comparable to fine-tuned retrievers, across various tasks (e.g. web\nsearch, QA, fact verification) and languages~(e.g. sw, ko, ja).\n","authors":["Luyu Gao","Xueguang Ma","Jimmy Lin","Jamie Callan"],"pdf_url":"https://arxiv.org/pdf/2212.10496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10448v1","updated":"2022-12-20T17:25:04Z","published":"2022-12-20T17:25:04Z","title":"Parameter-efficient Zero-shot Transfer for Cross-Language Dense\n  Retrieval with Adapters","summary":"  A popular approach to creating a zero-shot cross-language retrieval model is\nto substitute a monolingual pretrained language model in the retrieval model\nwith a multilingual pretrained language model such as Multilingual BERT. This\nmultilingual model is fined-tuned to the retrieval task with monolingual data\nsuch as English MS MARCO using the same training recipe as the monolingual\nretrieval model used. However, such transferred models suffer from mismatches\nin the languages of the input text during training and inference. In this work,\nwe propose transferring monolingual retrieval models using adapters, a\nparameter-efficient component for a transformer network. By adding adapters\npretrained on language tasks for a specific language with task-specific\nadapters, prior work has shown that the adapter-enhanced models perform better\nthan fine-tuning the entire model when transferring across languages in various\nNLP tasks. By constructing dense retrieval models with adapters, we show that\nmodels trained with monolingual data are more effective than fine-tuning the\nentire model when transferring to a Cross Language Information Retrieval (CLIR)\nsetting. However, we found that the prior suggestion of replacing the language\nadapters to match the target language at inference time is suboptimal for dense\nretrieval models. We provide an in-depth analysis of this discrepancy between\nother cross-language NLP tasks and CLIR.\n","authors":["Eugene Yang","Suraj Nair","Dawn Lawrie","James Mayfield","Douglas W. Oard"],"pdf_url":"https://arxiv.org/pdf/2212.10448v1.pdf","comment":"15 pages, 1 figure"},{"id":"http://arxiv.org/abs/2212.10423v1","updated":"2022-12-20T17:00:36Z","published":"2022-12-20T17:00:36Z","title":"Fine-Grained Distillation for Long Document Retrieval","summary":"  Long document retrieval aims to fetch query-relevant documents from a\nlarge-scale collection, where knowledge distillation has become de facto to\nimprove a retriever by mimicking a heterogeneous yet powerful cross-encoder.\nHowever, in contrast to passages or sentences, retrieval on long documents\nsuffers from the scope hypothesis that a long document may cover multiple\ntopics. This maximizes their structure heterogeneity and poses a\ngranular-mismatch issue, leading to an inferior distillation efficacy. In this\nwork, we propose a new learning framework, fine-grained distillation (FGD), for\nlong-document retrievers. While preserving the conventional dense retrieval\nparadigm, it first produces global-consistent representations crossing\ndifferent fine granularity and then applies multi-granular aligned distillation\nmerely during training. In experiments, we evaluate our framework on two\nlong-document retrieval benchmarks, which show state-of-the-art performance.\n","authors":["Yucheng Zhou","Tao Shen","Xiubo Geng","Chongyang Tao","Guodong Long","Can Xu","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2212.10423v1.pdf","comment":"13 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2212.10380v1","updated":"2022-12-20T16:03:25Z","published":"2022-12-20T16:03:25Z","title":"What Are You Token About? Dense Retrieval as Distributions Over the\n  Vocabulary","summary":"  Dual encoders are now the dominant architecture for dense retrieval. Yet, we\nhave little understanding of how they represent text, and why this leads to\ngood performance. In this work, we shed light on this question via\ndistributions over the vocabulary. We propose to interpret the vector\nrepresentations produced by dual encoders by projecting them into the model's\nvocabulary space. We show that the resulting distributions over vocabulary\ntokens are intuitive and contain rich semantic information. We find that this\nview can explain some of the failure cases of dense retrievers. For example,\nthe inability of models to handle tail entities can be explained via a tendency\nof the token distributions to forget some of the tokens of those entities. We\nleverage this insight and propose a simple way to enrich query and passage\nrepresentations with lexical information at inference time, and show that this\nsignificantly improves performance compared to the original model in\nout-of-domain settings.\n","authors":["Ori Ram","Liat Bezalel","Adi Zicher","Yonatan Belinkov","Jonathan Berant","Amir Globerson"],"pdf_url":"https://arxiv.org/pdf/2212.10380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10136v1","updated":"2022-12-20T10:05:36Z","published":"2022-12-20T10:05:36Z","title":"A Comparison Between Tsetlin Machines and Deep Neural Networks in the\n  Context of Recommendation Systems","summary":"  Recommendation Systems (RSs) are ubiquitous in modern society and are one of\nthe largest points of interaction between humans and AI. Modern RSs are often\nimplemented using deep learning models, which are infamously difficult to\ninterpret. This problem is particularly exasperated in the context of\nrecommendation scenarios, as it erodes the user's trust in the RS. In contrast,\nthe newly introduced Tsetlin Machines (TM) possess some valuable properties due\nto their inherent interpretability. TMs are still fairly young as a technology.\nAs no RS has been developed for TMs before, it has become necessary to perform\nsome preliminary research regarding the practicality of such a system. In this\npaper, we develop the first RS based on TMs to evaluate its practicality in\nthis application domain. This paper compares the viability of TMs with other\nmachine learning models prevalent in the field of RS. We train and investigate\nthe performance of the TM compared with a vanilla feed-forward deep learning\nmodel. These comparisons are based on model performance,\ninterpretability/explainability, and scalability. Further, we provide some\nbenchmark performance comparisons to similar machine learning solutions\nrelevant to RSs.\n","authors":["Karl Audun Borgersen","Morten Goodwin","Jivitesh Sharma"],"pdf_url":"https://arxiv.org/pdf/2212.10136v1.pdf","comment":"Accepted to NLDL 2023"},{"id":"http://arxiv.org/abs/2212.10046v1","updated":"2022-12-20T07:43:21Z","published":"2022-12-20T07:43:21Z","title":"Causal Inference for Knowledge Graph based Recommendation","summary":"  Knowledge Graph (KG), as a side-information, tends to be utilized to\nsupplement the collaborative filtering (CF) based recommendation model. By\nmapping items with the entities in KGs, prior studies mostly extract the\nknowledge information from the KGs and inject it into the representations of\nusers and items. Despite their remarkable performance, they fail to model the\nuser preference on attributes in the KG, since they ignore that (1) the\nstructure information of KG may hinder the user preference learning, and (2)\nthe user's interacted attributes will result in the bias issue on the\nsimilarity scores.\n  With the help of causality tools, we construct the causal-effect relation\nbetween the variables in KG-based recommendation and identify the reasons\ncausing the mentioned challenges. Accordingly, we develop a new framework,\ntermed Knowledge Graph-based Causal Recommendation (KGCR), which implements the\ndeconfounded user preference learning and adopts counterfactual inference to\neliminate bias in the similarity scoring. Ultimately, we evaluate our proposed\nmodel on three datasets, including Amazon-book, LastFM, and Yelp2018 datasets.\nBy conducting extensive experiments on the datasets, we demonstrate that KGCR\noutperforms several state-of-the-art baselines, such as KGNN-LS, KGAT and KGIN.\n","authors":["Yinwei Wei","Xiang Wang","Liqiang Nie","Shaoyu Li","Dingxian Wang","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2212.10046v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10002v1","updated":"2022-12-20T05:25:01Z","published":"2022-12-20T05:25:01Z","title":"Defending Against Poisoning Attacks in Open-Domain Question Answering","summary":"  Recent work in open-domain question answering (ODQA) has shown that\nadversarial poisoning of the input contexts can cause large drops in accuracy\nfor production systems. However, little to no work has proposed methods to\ndefend against these attacks. To do so, we introduce a new method that uses\nquery augmentation to search for a diverse set of retrieved passages that could\nanswer the original question. We integrate these new passages into the model\nthrough the design of a novel confidence method, comparing the predicted answer\nto its appearance in the retrieved contexts (what we call Confidence from\nAnswer Redundancy, e.g. CAR). Together these methods allow for a simple but\neffective way to defend against poisoning attacks and provide gains of 5-20%\nexact match across varying levels of data poisoning.\n","authors":["Orion Weller","Aleem Khan","Nathaniel Weir","Dawn Lawrie","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2212.10002v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06257v2","updated":"2022-12-20T04:54:11Z","published":"2022-09-13T18:31:23Z","title":"SciMED: A Computational Framework For Physics-Informed Symbolic\n  Regression with Scientist-In-The-Loop","summary":"  Discovering a meaningful symbolic expression that explains experimental data\nis a fundamental challenge in many scientific fields. We present a novel,\nopen-source computational framework called Scientist-Machine Equation Detector\n(SciMed), which integrates scientific discipline wisdom in a\nscientist-in-the-loop approach, with state-of-the-art symbolic regression (SR)\nmethods. SciMed combines a wrapper selection method, that is based on a genetic\nalgorithm, with automatic machine learning and two levels of SR methods. We\ntest SciMed on five configurations of a settling sphere, with and without\naerodynamic non-linear drag force, and with excessive noise in the\nmeasurements. We show that SciMed is sufficiently robust to discover the\ncorrect physically meaningful symbolic expressions from the data, and\ndemonstrate how the integration of domain knowledge enhances its performance.\nOur results indicate better performance on these tasks than the\nstate-of-the-art SR software packages, even in cases where no knowledge is\nintegrated. Moreover, we demonstrate how SciMed can alert the user about\npossible missing features, unlike the majority of current SR systems.\n","authors":["Liron Simon Keren","Alex Liberzon","Teddy Lazebnik"],"pdf_url":"https://arxiv.org/pdf/2209.06257v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.05227v3","updated":"2022-12-20T02:21:11Z","published":"2022-09-12T13:26:26Z","title":"DUET: A Tuning-Free Device-Cloud Collaborative Parameters Generation\n  Framework for Efficient Device Model Generalization","summary":"  Device Model Generalization (DMG) is a practical yet under-investigated\nresearch topic for on-device machine learning applications. It aims to improve\nthe generalization ability of pre-trained models when deployed on\nresource-constrained devices, such as improving the performance of pre-trained\ncloud models on smart mobiles. While quite a lot of works have investigated the\ndata distribution shift across clouds and devices, most of them focus on model\nfine-tuning on personalized data for individual devices to facilitate DMG.\nDespite their promising, these approaches require on-device re-training, which\nis practically infeasible due to the overfitting problem and high time delay\nwhen performing gradient calculation on real-time data. In this paper, we argue\nthat the computational cost brought by fine-tuning can be rather unnecessary.\nWe consequently present a novel perspective to improving DMG without increasing\ncomputational cost, i.e., device-specific parameter generation which directly\nmaps data distribution to parameters. Specifically, we propose an efficient\nDevice-cloUd collaborative parametErs generaTion framework DUET. DUET is\ndeployed on a powerful cloud server that only requires the low cost of\nforwarding propagation and low time delay of data transmission between the\ndevice and the cloud. By doing so, DUET can rehearse the device-specific model\nweight realizations conditioned on the personalized real-time data for an\nindividual device. Importantly, our DUET elegantly connects the cloud and\ndevice as a 'duet' collaboration, frees the DMG from fine-tuning, and enables a\nfaster and more accurate DMG paradigm. We conduct an extensive experimental\nstudy of DUET on three public datasets, and the experimental results confirm\nour framework's effectiveness and generalisability for different DMG tasks.\n","authors":["Zheqi Lv","Wenqiao Zhang","Shengyu Zhang","Kun Kuang","Feng Wang","Yongwei Wang","Zhengyu Chen","Tao Shen","Hongxia Yang","Beng chin Ooi","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2209.05227v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09920v1","updated":"2022-12-20T00:06:28Z","published":"2022-12-20T00:06:28Z","title":"Variational Factorization Machines for Preference Elicitation in\n  Large-Scale Recommender Systems","summary":"  Factorization machines (FMs) are a powerful tool for regression and\nclassification in the context of sparse observations, that has been\nsuccessfully applied to collaborative filtering, especially when side\ninformation over users or items is available. Bayesian formulations of FMs have\nbeen proposed to provide confidence intervals over the predictions made by the\nmodel, however they usually involve Markov-chain Monte Carlo methods that\nrequire many samples to provide accurate predictions, resulting in slow\ntraining in the context of large-scale data. In this paper, we propose a\nvariational formulation of factorization machines that allows us to derive a\nsimple objective that can be easily optimized using standard mini-batch\nstochastic gradient descent, making it amenable to large-scale data. Our\nalgorithm learns an approximate posterior distribution over the user and item\nparameters, which leads to confidence intervals over the predictions. We show,\nusing several datasets, that it has comparable or better performance than\nexisting methods in terms of prediction accuracy, and provide some applications\nin active learning strategies, e.g., preference elicitation techniques.\n","authors":["Jill-Jênn Vie","Tomas Rigaux","Hisashi Kashima"],"pdf_url":"https://arxiv.org/pdf/2212.09920v1.pdf","comment":"8 pages, 4 figures, 4 tables. Proceedings of the IEEE BigData 2022\n  conference"},{"id":"http://arxiv.org/abs/2212.09044v2","updated":"2022-12-20T21:49:18Z","published":"2022-12-18T09:31:36Z","title":"Text2Struct: A Machine Learning Pipeline for Mining Structured Data from\n  Text","summary":"  Many analysis and prediction tasks require the extraction of structured data\nfrom unstructured texts. To solve it, this paper presents an end-to-end machine\nlearning pipeline, Text2Struct, including a text annotation scheme, training\ndata processing, and machine learning implementation. We formulated the mining\nproblem as the extraction of metrics and units associated with numerals in the\ntext. The Text2Struct was evaluated on an annotated text dataset collected from\nabstracts of medical publications regarding thrombectomy. In terms of\nprediction performance, a dice coefficient of 0.82 was achieved on the test\ndataset. By random sampling, most predicted relations between numerals and\nentities were well matched to the ground-truth annotations. These results show\nthat the Text2Struct is viable for the mining of structured data from text\nwithout special templates or patterns. It is anticipated to further improve the\npipeline by expanding the dataset and investigating other machine learning\nmodels. A code demonstration can be found at:\nhttps://github.com/zcc861007/CourseProject\n","authors":["Chaochao Zhou","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2212.09044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.03622v2","updated":"2022-12-20T19:12:50Z","published":"2022-01-10T20:08:40Z","title":"Graph-Based Recommendation System Enhanced with Community Detection","summary":"  Many researchers have used tag information to improve the performance of\nrecommendation techniques in recommender systems. Examining the tags of users\nwill help to get their interests and leads to more accuracy in the\nrecommendations. Since user-defined tags are chosen freely and without any\nrestrictions, problems arise in determining their exact meaning and the\nsimilarity of tags. However, using thesauruses and ontologies to find the\nmeaning of tags is not very efficient due to their free definition by users and\nthe use of different languages in many data sets. Therefore, this article uses\nmathematical and statistical methods to determine lexical similarity and\nco-occurrence tags solution to assign semantic similarity. On the other hand,\ndue to the change of users' interests over time this article has considered the\ntime of tag assignments in co-occurrence tags for determining similarity of\ntags. Then the graph is created based on similarity of tags. For modeling the\ninterests of the users, the communities of tags are determined by using\ncommunity detection methods. So, recommendations based on the communities of\ntags and similarity between resources are done. The performance of the proposed\nmethod has been done using two criteria of precision and recall based on\nevaluations with \"Del.icio.us\" dataset. The evaluation results show that the\nprecision and recall of the proposed method have significantly improved,\ncompared to the other methods.\n","authors":["Zeinab Shokrzadeh","Mohammad-Reza Feizi-Derakhshi","Mohammad-Ali Balafar","Jamshid Bagherzadeh Mohasefi"],"pdf_url":"https://arxiv.org/pdf/2201.03622v2.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2212.10564v1","updated":"2022-12-20T18:59:50Z","published":"2022-12-20T18:59:50Z","title":"Does unsupervised grammar induction need pixels?","summary":"  Are extralinguistic signals such as image pixels crucial for inducing\nconstituency grammars? While past work has shown substantial gains from\nmultimodal cues, we investigate whether such gains persist in the presence of\nrich information from large language models (LLMs). We find that our approach,\nLLM-based C-PCFG (LC-PCFG), outperforms previous multi-modal methods on the\ntask of unsupervised constituency parsing, achieving state-of-the-art\nperformance on a variety of datasets. Moreover, LC-PCFG results in an over 50%\nreduction in parameter count, and speedups in training time of 1.7x for\nimage-aided models and more than 5x for video-aided models, respectively. These\nresults challenge the notion that extralinguistic signals such as image pixels\nare needed for unsupervised grammar induction, and point to the need for better\ntext-only baselines in evaluating the need of multi-modality for the task.\n","authors":["Boyi Li","Rodolfo Corona","Karttikeya Mangalam","Catherine Chen","Daniel Flaherty","Serge Belongie","Kilian Q. Weinberger","Jitendra Malik","Trevor Darrell","Dan Klein"],"pdf_url":"https://arxiv.org/pdf/2212.10564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10561v1","updated":"2022-12-20T18:59:23Z","published":"2022-12-20T18:59:23Z","title":"Parsel: A Unified Natural Language Framework for Algorithmic Reasoning","summary":"  Despite recent success in large language model (LLM) reasoning, LLMs still\nstruggle with hierarchical multi-step reasoning like generating complex\nprograms. In these cases, humans often start with a high-level algorithmic\ndesign and implement each part gradually. We introduce Parsel, a framework\nenabling automatic implementation and validation of complex algorithms with\ncode LLMs, based on hierarchical function descriptions in natural language.\nParsel can be used across domains requiring hierarchical reasoning, e.g. code\nsynthesis, theorem proving, and robotic planning. We demonstrate Parsel's\ncapabilities by using it to generate complex programs that cannot currently be\nautomatically implemented from one description and backtranslating Python\nprograms in the APPS dataset. Beyond modeling capabilities, Parsel allows\nproblem-solving with high-level algorithmic designs, benefiting both students\nand professional programmers.\n","authors":["Eric Zelikman","Qian Huang","Gabriel Poesia","Noah D. Goodman","Nick Haber"],"pdf_url":"https://arxiv.org/pdf/2212.10561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10555v1","updated":"2022-12-20T18:56:57Z","published":"2022-12-20T18:56:57Z","title":"PairReranker: Pairwise Reranking for Natural Language Generation","summary":"  Pre-trained language models have been successful in natural language\ngeneration (NLG) tasks. While various decoding methods have been employed, they\noften produce suboptimal results. We first present an empirical analysis of\nthree NLG tasks: summarization, machine translation, and constrained text\ngeneration. We found that selecting the best output from the results of\nmultiple decoding methods can significantly improve performance. To further\nimprove reranking for NLG tasks, we proposed a novel method,\n\\textsc{PairReranker}, which uses a single encoder and a pairwise loss function\nto jointly encode a source input and a pair of candidates and compare them.\nExperiments on three NLG tasks demonstrated the effectiveness and flexibility\nof \\textsc{PairReranker}, showing strong results, compared with previous\nbaselines. In addition, our \\textsc{PairReranker} can generalize to\nsignificantly improve GPT-3 (text-davinci-003) results (e.g., 24.55\\% on\nCommonGen and 11.35\\% on WMT18 zh-en), even though our rerankers are not\ntrained with any GPT-3 candidates.\n","authors":["Dongfu Jiang","Bill Yuchen Lin","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.10555v1.pdf","comment":"We will release our code and data at\n  https://inklab.usc.edu/PairReranker"},{"id":"http://arxiv.org/abs/2212.10553v1","updated":"2022-12-20T18:55:54Z","published":"2022-12-20T18:55:54Z","title":"RangeAugment: Efficient Online Augmentation with Range Learning","summary":"  State-of-the-art automatic augmentation methods (e.g., AutoAugment and\nRandAugment) for visual recognition tasks diversify training data using a large\nset of augmentation operations. The range of magnitudes of many augmentation\noperations (e.g., brightness and contrast) is continuous. Therefore, to make\nsearch computationally tractable, these methods use fixed and manually-defined\nmagnitude ranges for each operation, which may lead to sub-optimal policies. To\nanswer the open question on the importance of magnitude ranges for each\naugmentation operation, we introduce RangeAugment that allows us to efficiently\nlearn the range of magnitudes for individual as well as composite augmentation\noperations. RangeAugment uses an auxiliary loss based on image similarity as a\nmeasure to control the range of magnitudes of augmentation operations. As a\nresult, RangeAugment has a single scalar parameter for search, image\nsimilarity, which we simply optimize via linear search. RangeAugment integrates\nseamlessly with any model and learns model- and task-specific augmentation\npolicies. With extensive experiments on the ImageNet dataset across different\nnetworks, we show that RangeAugment achieves competitive performance to\nstate-of-the-art automatic augmentation methods with 4-5 times fewer\naugmentation operations. Experimental results on semantic segmentation, object\ndetection, foundation models, and knowledge distillation further shows\nRangeAugment's effectiveness.\n","authors":["Sachin Mehta","Saeid Naderiparizi","Fartash Faghri","Maxwell Horton","Lailin Chen","Ali Farhadi","Oncel Tuzel","Mohammad Rastegari"],"pdf_url":"https://arxiv.org/pdf/2212.10553v1.pdf","comment":"Technical report (22 pages including references and appendix)"},{"id":"http://arxiv.org/abs/2212.10549v1","updated":"2022-12-20T18:53:14Z","published":"2022-12-20T18:53:14Z","title":"Cross-modal Attention Congruence Regularization for Vision-Language\n  Relation Alignment","summary":"  Despite recent progress towards scaling up multimodal vision-language models,\nthese models are still known to struggle on compositional generalization\nbenchmarks such as Winoground. We find that a critical component lacking from\ncurrent vision-language models is relation-level alignment: the ability to\nmatch directional semantic relations in text (e.g., \"mug in grass\") with\nspatial relationships in the image (e.g., the position of the mug relative to\nthe grass). To tackle this problem, we show that relation alignment can be\nenforced by encouraging the directed language attention from 'mug' to 'grass'\n(capturing the semantic relation 'in') to match the directed visual attention\nfrom the mug to the grass. Tokens and their corresponding objects are softly\nidentified using the cross-modal attention. We prove that this notion of soft\nrelation alignment is equivalent to enforcing congruence between vision and\nlanguage attention matrices under a 'change of basis' provided by the\ncross-modal attention matrix. Intuitively, our approach projects visual\nattention into the language attention space to calculate its divergence from\nthe actual language attention, and vice versa. We apply our Cross-modal\nAttention Congruence Regularization (CACR) loss to UNITER and improve on the\nstate-of-the-art approach to Winoground.\n","authors":["Rohan Pandey","Rulin Shao","Paul Pu Liang","Ruslan Salakhutdinov","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2212.10549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10544v1","updated":"2022-12-20T18:50:08Z","published":"2022-12-20T18:50:08Z","title":"Pretraining Without Attention","summary":"  Transformers have been essential to pretraining success in NLP. Other\narchitectures have been used, but require attention layers to match benchmark\naccuracy. This work explores pretraining without attention. We test recently\ndeveloped routing layers based on state-space models (SSM) and model\narchitectures based on multiplicative gating. Used together these modeling\nchoices have a large impact on pretraining accuracy. Empirically the proposed\nBidirectional Gated SSM (BiGS) replicates BERT pretraining results without\nattention and can be extended to long-form pretraining of 4096 tokens without\napproximation.\n","authors":["Junxiong Wang","Jing Nathan Yan","Albert Gu","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2212.10544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10538v1","updated":"2022-12-20T18:47:10Z","published":"2022-12-20T18:47:10Z","title":"HyperBO+: Pre-training a universal prior for Bayesian optimization with\n  hierarchical Gaussian processes","summary":"  Bayesian optimization (BO), while proved highly effective for many black-box\nfunction optimization tasks, requires practitioners to carefully select priors\nthat well model their functions of interest. Rather than specifying by hand,\nresearchers have investigated transfer learning based methods to automatically\nlearn the priors, e.g. multi-task BO (Swersky et al., 2013), few-shot BO\n(Wistuba and Grabocka, 2021) and HyperBO (Wang et al., 2022). However, those\nprior learning methods typically assume that the input domains are the same for\nall tasks, weakening their ability to use observations on functions with\ndifferent domains or generalize the learned priors to BO on different search\nspaces. In this work, we present HyperBO+: a pre-training approach for\nhierarchical Gaussian processes that enables the same prior to work universally\nfor Bayesian optimization on functions with different domains. We propose a\ntwo-step pre-training method and analyze its appealing asymptotic properties\nand benefits to BO both theoretically and empirically. On real-world\nhyperparameter tuning tasks that involve multiple search spaces, we demonstrate\nthat HyperBO+ is able to generalize to unseen search spaces and achieves lower\nregrets than competitive baselines.\n","authors":["Zhou Fan","Xinran Han","Zi Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10535v1","updated":"2022-12-20T18:46:16Z","published":"2022-12-20T18:46:16Z","title":"A Survey of Deep Learning for Mathematical Reasoning","summary":"  Mathematical reasoning is a fundamental aspect of human intelligence and is\napplicable in various fields, including science, engineering, finance, and\neveryday life. The development of artificial intelligence (AI) systems capable\nof solving math problems and proving theorems has garnered significant interest\nin the fields of machine learning and natural language processing. For example,\nmathematics serves as a testbed for aspects of reasoning that are challenging\nfor powerful deep learning models, driving new algorithmic and modeling\nadvances. On the other hand, recent advances in large-scale neural language\nmodels have opened up new benchmarks and opportunities to use deep learning for\nmathematical reasoning. In this survey paper, we review the key tasks,\ndatasets, and methods at the intersection of mathematical reasoning and deep\nlearning over the past decade. We also evaluate existing benchmarks and\nmethods, and discuss future research directions in this domain.\n","authors":["Pan Lu","Liang Qiu","Wenhao Yu","Sean Welleck","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10535v1.pdf","comment":"24 pages, 2 figures, 8 tables. The repository is available at\n  https://github.com/lupantech/dl4math"},{"id":"http://arxiv.org/abs/2205.05587v2","updated":"2022-12-20T18:42:26Z","published":"2022-05-11T16:00:14Z","title":"Choice of training label matters: how to best use deep learning for\n  quantitative MRI parameter estimation","summary":"  Deep learning (DL) is gaining popularity as a parameter estimation method for\nquantitative MRI. A range of competing implementations have been proposed,\nrelying on either supervised or self-supervised learning. Self-supervised\napproaches, sometimes referred to as unsupervised, have been loosely based on\nauto-encoders, whereas supervised methods have, to date, been trained on\ngroundtruth labels. These two learning paradigms have been shown to have\ndistinct strengths. Notably, self-supervised approaches have offered lower-bias\nparameter estimates than their supervised alternatives. This result is\ncounterintuitive - incorporating prior knowledge with supervised labels should,\nin theory, lead to improved accuracy. In this work, we show that this apparent\nlimitation of supervised approaches stems from the naive choice of groundtruth\ntraining labels. By training on labels which are deliberately not groundtruth,\nwe show that the low-bias parameter estimation previously associated with\nself-supervised methods can be replicated - and improved on - within a\nsupervised learning framework. This approach sets the stage for a single,\nunifying, deep learning parameter estimation framework, based on supervised\nlearning, where trade-offs between bias and variance are made by careful\nadjustment of training label.\n","authors":["Sean C. Epstein","Timothy J. P. Bray","Margaret Hall-Craggs","Hui Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.05587v2.pdf","comment":"20 pages, 12 figures"},{"id":"http://arxiv.org/abs/2212.10511v1","updated":"2022-12-20T18:30:15Z","published":"2022-12-20T18:30:15Z","title":"When Not to Trust Language Models: Investigating Effectiveness and\n  Limitations of Parametric and Non-Parametric Memories","summary":"  Despite their impressive performance on diverse tasks, large language models\n(LMs) still struggle with tasks requiring rich world knowledge, implying the\nlimitations of relying solely on their parameters to encode a wealth of world\nknowledge. This paper aims to understand LMs' strengths and limitations in\nmemorizing factual knowledge, by conducting large-scale knowledge probing\nexperiments of 10 models and 4 augmentation methods on PopQA, our new\nopen-domain QA dataset with 14k questions. We find that LMs struggle with less\npopular factual knowledge, and that scaling fails to appreciably improve\nmemorization of factual knowledge in the tail. We then show that\nretrieval-augmented LMs largely outperform orders of magnitude larger LMs,\nwhile unassisted LMs remain competitive in questions about high-popularity\nentities. Based on those findings, we devise a simple, yet effective, method\nfor powerful and efficient retrieval-augmented LMs, which retrieves\nnon-parametric memories only when necessary. Experimental results show that\nthis significantly improves models' performance while reducing the inference\ncosts.\n","authors":["Alex Mallen","Akari Asai","Victor Zhong","Rajarshi Das","Hannaneh Hajishirzi","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2212.10511v1.pdf","comment":"Code and data available at\n  https://github.com/AlexTMallen/adaptive-retrieval; work in progress"},{"id":"http://arxiv.org/abs/2212.10503v1","updated":"2022-12-20T18:17:28Z","published":"2022-12-20T18:17:28Z","title":"Mini-Model Adaptation: Efficiently Extending Pretrained Models to New\n  Languages via Aligned Shallow Training","summary":"  Prior work has shown that it is possible to expand pretrained Masked Language\nModels (MLMs) to new languages by learning a new set of embeddings, while\nkeeping the transformer body frozen. Despite learning a small subset of\nparameters, this approach is not compute-efficient, as training the new\nembeddings requires a full forward and backward pass over the entire model. In\nthis work, we propose mini-model adaptation, a compute-efficient alternative\nthat builds a shallow mini-model from a fraction of a large model's parameters.\nNew language-specific embeddings can then be efficiently trained over the\nmini-model, and plugged into the aligned large model for rapid cross-lingual\ntransfer. We explore two approaches to learn mini-models: MiniJoint, which\njointly pretrains the primary model and the mini-model using a single\ntransformer with a secondary MLM head at a middle layer; and MiniPost, where we\nstart from a regular pretrained model and build a mini-model by extracting and\nfreezing a few layers and learning a small number of parameters on top.\nExperiments on XNLI, MLQA and PAWS-X show that mini-model adaptation matches\nthe performance of the standard approach using up to 2.4x less compute.\n","authors":["Kelly Marchisio","Patrick Lewis","Yihong Chen","Mikel Artetxe"],"pdf_url":"https://arxiv.org/pdf/2212.10503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.10132v4","updated":"2022-12-20T18:08:45Z","published":"2021-10-19T17:43:50Z","title":"FriendlyCore: Practical Differentially Private Aggregation","summary":"  Differentially private algorithms for common metric aggregation tasks, such\nas clustering or averaging, often have limited practicality due to their\ncomplexity or to the large number of data points that is required for accurate\nresults. We propose a simple and practical tool, $\\mathsf{FriendlyCore}$, that\ntakes a set of points ${\\cal D}$ from an unrestricted (pseudo) metric space as\ninput. When ${\\cal D}$ has effective diameter $r$, $\\mathsf{FriendlyCore}$\nreturns a \"stable\" subset ${\\cal C} \\subseteq {\\cal D}$ that includes all\npoints, except possibly few outliers, and is {\\em certified} to have diameter\n$r$. $\\mathsf{FriendlyCore}$ can be used to preprocess the input before\nprivately aggregating it, potentially simplifying the aggregation or boosting\nits accuracy. Surprisingly, $\\mathsf{FriendlyCore}$ is light-weight with no\ndependence on the dimension. We empirically demonstrate its advantages in\nboosting the accuracy of mean estimation and clustering tasks such as $k$-means\nand $k$-GMM, outperforming tailored methods.\n","authors":["Eliad Tsfadia","Edith Cohen","Haim Kaplan","Yishay Mansour","Uri Stemmer"],"pdf_url":"https://arxiv.org/pdf/2110.10132v4.pdf","comment":"Published in ICML 2022"},{"id":"http://arxiv.org/abs/2212.08930v2","updated":"2022-12-20T17:59:28Z","published":"2022-12-17T18:51:00Z","title":"On Noisy Evaluation in Federated Hyperparameter Tuning","summary":"  Hyperparameter tuning is critical to the success of federated learning\napplications. Unfortunately, appropriately selecting hyperparameters is\nchallenging in federated networks. Issues of scale, privacy, and heterogeneity\nintroduce noise in the tuning process and make it difficult to evaluate the\nperformance of various hyperparameters. In this work, we perform the first\nsystematic study on the effect of noisy evaluation in federated hyperparameter\ntuning. We first identify and rigorously explore key sources of noise,\nincluding client subsampling, data and systems heterogeneity, and data privacy.\nSurprisingly, our results indicate that even small amounts of noise can\nsignificantly impact tuning methods-reducing the performance of\nstate-of-the-art approaches to that of naive baselines. To address noisy\nevaluation in such scenarios, we propose a simple and effective approach that\nleverages public proxy data to boost the evaluation signal. Our work\nestablishes general challenges, baselines, and best practices for future work\nin federated hyperparameter tuning.\n","authors":["Kevin Kuo","Pratiksha Thaker","Mikhail Khodak","John Ngyuen","Daniel Jiang","Ameet Talwalkar","Virginia Smith"],"pdf_url":"https://arxiv.org/pdf/2212.08930v2.pdf","comment":"19 pages, 15 figures, submitted to MLSys2023 v2: Fixed citation\n  formatting"},{"id":"http://arxiv.org/abs/2212.09252v2","updated":"2022-12-20T17:52:24Z","published":"2022-12-19T05:17:33Z","title":"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems","summary":"  Many dialogue systems (DSs) lack characteristics humans have, such as emotion\nperception, factuality, and informativeness. Enhancing DSs with knowledge\nalleviates this problem, but, as many ways of doing so exist, keeping track of\nall proposed methods is difficult. Here, we present the first survey of\nknowledge-enhanced DSs. We define three categories of systems - internal,\nexternal, and hybrid - based on the knowledge they use. We survey the\nmotivation for enhancing DSs with knowledge, used datasets, and methods for\nknowledge search, knowledge encoding, and knowledge incorporation. Finally, we\npropose how to improve existing systems based on theories from linguistics and\ncognitive science.\n","authors":["Sagi Shaier","Lawrence Hunter","Katharina Kann"],"pdf_url":"https://arxiv.org/pdf/2212.09252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10477v1","updated":"2022-12-20T17:50:36Z","published":"2022-12-20T17:50:36Z","title":"Generalized Simultaneous Perturbation Stochastic Approximation with\n  Reduced Estimator Bias","summary":"  We present in this paper a family of generalized simultaneous perturbation\nstochastic approximation (G-SPSA) estimators that estimate the gradient of the\nobjective using noisy function measurements, but where the number of function\nmeasurements and the form of the gradient estimator is guided by the desired\nestimator bias. In particular, estimators with more function measurements are\nseen to result in lower bias. We provide an analysis of convergence of the\ngeneralized SPSA algorithm, and point to possible future directions.\n","authors":["Shalabh Bhatnagar","Prashanth L. A"],"pdf_url":"https://arxiv.org/pdf/2212.10477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.03741v2","updated":"2022-12-20T17:43:56Z","published":"2022-11-07T18:13:44Z","title":"AskewSGD : An Annealed interval-constrained Optimisation method to train\n  Quantized Neural Networks","summary":"  In this paper, we develop a new algorithm, Annealed Skewed SGD - AskewSGD -\nfor training deep neural networks (DNNs) with quantized weights. First, we\nformulate the training of quantized neural networks (QNNs) as a smoothed\nsequence of interval-constrained optimization problems. Then, we propose a new\nfirst-order stochastic method, AskewSGD, to solve each constrained optimization\nsubproblem. Unlike algorithms with active sets and feasible directions,\nAskewSGD avoids projections or optimization under the entire feasible set and\nallows iterates that are infeasible. The numerical complexity of AskewSGD is\ncomparable to existing approaches for training QNNs, such as the\nstraight-through gradient estimator used in BinaryConnect, or other state of\nthe art methods (ProxQuant, LUQ). We establish convergence guarantees for\nAskewSGD (under general assumptions for the objective function). Experimental\nresults show that the AskewSGD algorithm performs better than or on par with\nstate of the art methods in classical benchmarks.\n","authors":["Louis Leconte","Sholom Schechtman","Eric Moulines"],"pdf_url":"https://arxiv.org/pdf/2211.03741v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10445v1","updated":"2022-12-20T17:21:46Z","published":"2022-12-20T17:21:46Z","title":"Recycling diverse models for out-of-distribution generalization","summary":"  Foundation models are redefining how AI systems are built. Practitioners now\nfollow a standard procedure to build their machine learning solutions: download\na copy of a foundation model, and fine-tune it using some in-house data about\nthe target task of interest. Consequently, the Internet is swarmed by a handful\nof foundation models fine-tuned on many diverse tasks. Yet, these individual\nfine-tunings often lack strong generalization and exist in isolation without\nbenefiting from each other. In our opinion, this is a missed opportunity, as\nthese specialized models contain diverse features. Based on this insight, we\npropose model recycling, a simple strategy that leverages multiple fine-tunings\nof the same foundation model on diverse auxiliary tasks, and repurposes them as\nrich and diverse initializations for the target task. Specifically, model\nrecycling fine-tunes in parallel each specialized model on the target task, and\nthen averages the weights of all target fine-tunings into a final model.\nEmpirically, we show that model recycling maximizes model diversity by\nbenefiting from diverse auxiliary tasks, and achieves a new state of the art on\nthe reference DomainBed benchmark for out-of-distribution generalization.\nLooking forward, model recycling is a contribution to the emerging paradigm of\nupdatable machine learning where, akin to open-source software development, the\ncommunity collaborates to incrementally and reliably update machine learning\nmodels.\n","authors":["Alexandre Ramé","Kartik Ahuja","Jianyu Zhang","Matthieu Cord","Léon Bottou","David Lopez-Paz"],"pdf_url":"https://arxiv.org/pdf/2212.10445v1.pdf","comment":"24 pages, 7 tables, 13 figures"},{"id":"http://arxiv.org/abs/2110.14961v2","updated":"2022-12-20T17:19:13Z","published":"2021-10-28T09:03:37Z","title":"Roto-translated Local Coordinate Frames For Interacting Dynamical\n  Systems","summary":"  Modelling interactions is critical in learning complex dynamical systems,\nnamely systems of interacting objects with highly non-linear and time-dependent\nbehaviour. A large class of such systems can be formalized as\n$\\textit{geometric graphs}$, $\\textit{i.e.}$, graphs with nodes positioned in\nthe Euclidean space given an $\\textit{arbitrarily}$ chosen global coordinate\nsystem, for instance vehicles in a traffic scene. Notwithstanding the arbitrary\nglobal coordinate system, the governing dynamics of the respective dynamical\nsystems are invariant to rotations and translations, also known as\n$\\textit{Galilean invariance}$. As ignoring these invariances leads to worse\ngeneralization, in this work we propose local coordinate frames per node-object\nto induce roto-translation invariance to the geometric graph of the interacting\ndynamical system. Further, the local coordinate frames allow for a natural\ndefinition of anisotropic filtering in graph neural networks. Experiments in\ntraffic scenes, 3D motion capture, and colliding particles demonstrate that the\nproposed approach comfortably outperforms the recent state-of-the-art.\n","authors":["Miltiadis Kofinas","Naveen Shankar Nagaraja","Efstratios Gavves"],"pdf_url":"https://arxiv.org/pdf/2110.14961v2.pdf","comment":"NeurIPS 2021"},{"id":"http://arxiv.org/abs/2212.10439v1","updated":"2022-12-20T17:14:14Z","published":"2022-12-20T17:14:14Z","title":"On the Convergence of Policy Gradient in Robust MDPs","summary":"  Robust Markov decision processes (RMDPs) are promising models that provide\nreliable policies under ambiguities in model parameters. As opposed to nominal\nMarkov decision processes (MDPs), however, the state-of-the-art solution\nmethods for RMDPs are limited to value-based methods, such as value iteration\nand policy iteration. This paper proposes Double-Loop Robust Policy Gradient\n(DRPG), the first generic policy gradient method for RMDPs with a global\nconvergence guarantee in tabular problems. Unlike value-based methods, DRPG\ndoes not rely on dynamic programming techniques. In particular, the inner-loop\nrobust policy evaluation problem is solved via projected gradient descent.\nFinally, our experimental results demonstrate the performance of our algorithm\nand verify our theoretical guarantees.\n","authors":["Qiuhao Wang","Chin Pang Ho","Marek Petrik"],"pdf_url":"https://arxiv.org/pdf/2212.10439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10438v1","updated":"2022-12-20T17:13:22Z","published":"2022-12-20T17:13:22Z","title":"Is Semantic Communications Secure? A Tale of Multi-Domain Adversarial\n  Attacks","summary":"  Semantic communications seeks to transfer information from a source while\nconveying a desired meaning to its destination. We model the\ntransmitter-receiver functionalities as an autoencoder followed by a task\nclassifier that evaluates the meaning of the information conveyed to the\nreceiver. The autoencoder consists of an encoder at the transmitter to jointly\nmodel source coding, channel coding, and modulation, and a decoder at the\nreceiver to jointly model demodulation, channel decoding and source decoding.\nBy augmenting the reconstruction loss with a semantic loss, the two deep neural\nnetworks (DNNs) of this encoder-decoder pair are interactively trained with the\nDNN of the semantic task classifier. This approach effectively captures the\nlatent feature space and reliably transfers compressed feature vectors with a\nsmall number of channel uses while keeping the semantic loss low. We identify\nthe multi-domain security vulnerabilities of using the DNNs for semantic\ncommunications. Based on adversarial machine learning, we introduce test-time\n(targeted and non-targeted) adversarial attacks on the DNNs by manipulating\ntheir inputs at different stages of semantic communications. As a computer\nvision attack, small perturbations are injected to the images at the input of\nthe transmitter's encoder. As a wireless attack, small perturbations signals\nare transmitted to interfere with the input of the receiver's decoder. By\nlaunching these stealth attacks individually or more effectively in a combined\nform as a multi-domain attack, we show that it is possible to change the\nsemantics of the transferred information even when the reconstruction loss\nremains low. These multi-domain adversarial attacks pose as a serious threat to\nthe semantics of information transfer (with larger impact than conventional\njamming) and raise the need of defense methods for the safe adoption of\nsemantic communications.\n","authors":["Yalin E. Sagduyu","Tugba Erpek","Sennur Ulukus","Aylin Yener"],"pdf_url":"https://arxiv.org/pdf/2212.10438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10433v1","updated":"2022-12-20T17:10:06Z","published":"2022-12-20T17:10:06Z","title":"Scheduling with Predictions","summary":"  There is significant interest in deploying machine learning algorithms for\ndiagnostic radiology, as modern learning techniques have made it possible to\ndetect abnormalities in medical images within minutes. While machine-assisted\ndiagnoses cannot yet reliably replace human reviews of images by a radiologist,\nthey could inform prioritization rules for determining the order by which to\nreview patient cases so that patients with time-sensitive conditions could\nbenefit from early intervention.\n  We study this scenario by formulating it as a learning-augmented online\nscheduling problem. We are given information about each arriving patient's\nurgency level in advance, but these predictions are inevitably error-prone. In\nthis formulation, we face the challenges of decision making under imperfect\ninformation, and of responding dynamically to prediction error as we observe\nbetter data in real-time. We propose a simple online policy and show that this\npolicy is in fact the best possible in certain stylized settings. We also\ndemonstrate that our policy achieves the two desiderata of online algorithms\nwith predictions: consistency (performance improvement with prediction\naccuracy) and robustness (protection against the worst case). We complement our\ntheoretical findings with empirical evaluations of the policy under settings\nthat more accurately reflect clinical scenarios in the real world.\n","authors":["Woo-Hyung Cho","Shane Henderson","David Shmoys"],"pdf_url":"https://arxiv.org/pdf/2212.10433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10431v1","updated":"2022-12-20T17:09:53Z","published":"2022-12-20T17:09:53Z","title":"QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity","summary":"  The mechanism of existing style transfer algorithms is by minimizing a hybrid\nloss function to push the generated image toward high similarities in both\ncontent and style. However, this type of approach cannot guarantee visual\nfidelity, i.e., the generated artworks should be indistinguishable from real\nones. In this paper, we devise a new style transfer framework called QuantArt\nfor high visual-fidelity stylization. QuantArt pushes the latent representation\nof the generated artwork toward the centroids of the real artwork distribution\nwith vector quantization. By fusing the quantized and continuous latent\nrepresentations, QuantArt allows flexible control over the generated artworks\nin terms of content preservation, style similarity, and visual fidelity.\nExperiments on various style transfer settings show that our QuantArt framework\nachieves significantly higher visual fidelity compared with the existing style\ntransfer methods.\n","authors":["Siyu Huang","Jie An","Donglai Wei","Jiebo Luo","Hanspeter Pfister"],"pdf_url":"https://arxiv.org/pdf/2212.10431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10430v1","updated":"2022-12-20T17:09:08Z","published":"2022-12-20T17:09:08Z","title":"Walking Noise: Understanding Implications of Noisy Computations on\n  Classification Tasks","summary":"  Machine learning methods like neural networks are extremely successful and\npopular in a variety of applications, however, they come at substantial\ncomputational costs, accompanied by high energy demands. In contrast, hardware\ncapabilities are limited and there is evidence that technology scaling is\nstuttering, therefore, new approaches to meet the performance demands of\nincreasingly complex model architectures are required. As an unsafe\noptimization, noisy computations are more energy efficient, and given a fixed\npower budget also more time efficient. However, any kind of unsafe optimization\nrequires counter measures to ensure functionally correct results.\n  This work considers noisy computations in an abstract form, and gears to\nunderstand the implications of such noise on the accuracy of\nneural-network-based classifiers as an exemplary workload. We propose a\nmethodology called \"Walking Noise\" that allows to assess the robustness of\ndifferent layers of deep architectures by means of a so-called \"midpoint noise\nlevel\" metric. We then investigate the implications of additive and\nmultiplicative noise for different classification tasks and model\narchitectures, with and without batch normalization. While noisy training\nsignificantly increases robustness for both noise types, we observe a clear\ntrend to increase weights and thus increase the signal-to-noise ratio for\nadditive noise injection. For the multiplicative case, we find that some\nnetworks, with suitably simple tasks, automatically learn an internal binary\nrepresentation, hence becoming extremely robust. Overall this work proposes a\nmethod to measure the layer-specific robustness and shares first insights on\nhow networks learn to compensate injected noise, and thus, contributes to\nunderstand robustness against noisy computations.\n","authors":["Hendrik Borras","Bernhard Klein","Holger Fröning"],"pdf_url":"https://arxiv.org/pdf/2212.10430v1.pdf","comment":"11 pages, 14 figures, To be published at the 5th Workshop on\n  Accelerated Machine Learning (AccML) at HiPEAC 2023 Conference"},{"id":"http://arxiv.org/abs/2212.10426v1","updated":"2022-12-20T17:04:50Z","published":"2022-12-20T17:04:50Z","title":"Deep Riemannian Networks for EEG Decoding","summary":"  State-of-the-art performance in electroencephalography (EEG) decoding tasks\nis currently often achieved with either Deep-Learning or\nRiemannian-Geometry-based decoders. Recently, there is growing interest in Deep\nRiemannian Networks (DRNs) possibly combining the advantages of both previous\nclasses of methods. However, there are still a range of topics where additional\ninsight is needed to pave the way for a more widespread application of DRNs in\nEEG. These include architecture design questions such as network size and\nend-to-end ability as well as model training questions. How these factors\naffect model performance has not been explored. Additionally, it is not clear\nhow the data within these networks is transformed, and whether this would\ncorrelate with traditional EEG decoding. Our study aims to lay the groundwork\nin the area of these topics through the analysis of DRNs for EEG with a wide\nrange of hyperparameters. Networks were tested on two public EEG datasets and\ncompared with state-of-the-art ConvNets. Here we propose end-to-end EEG SPDNet\n(EE(G)-SPDNet), and we show that this wide, end-to-end DRN can outperform the\nConvNets, and in doing so use physiologically plausible frequency regions. We\nalso show that the end-to-end approach learns more complex filters than\ntraditional band-pass filters targeting the classical alpha, beta, and gamma\nfrequency bands of the EEG, and that performance can benefit from channel\nspecific filtering approaches. Additionally, architectural analysis revealed\nareas for further improvement due to the possible loss of Riemannian specific\ninformation throughout the network. Our study thus shows how to design and\ntrain DRNs to infer task-related information from the raw EEG without the need\nof handcrafted filterbanks and highlights the potential of end-to-end DRNs such\nas EE(G)-SPDNet for high-performance EEG decoding.\n","authors":["Daniel Wilson","Lukas Alexander Wilhelm Gemein","Robin Tibor Schirrmeister","Tonio Ball"],"pdf_url":"https://arxiv.org/pdf/2212.10426v1.pdf","comment":"26 pages, 15 Figures"},{"id":"http://arxiv.org/abs/2212.09271v2","updated":"2022-12-20T17:03:30Z","published":"2022-12-19T06:52:13Z","title":"Very Large Language Model as a Unified Methodology of Text Mining","summary":"  Text data mining is the process of deriving essential information from\nlanguage text. Typical text mining tasks include text categorization, text\nclustering, topic modeling, information extraction, and text summarization.\nVarious data sets are collected and various algorithms are designed for the\ndifferent types of tasks. In this paper, I present a blue sky idea that very\nlarge language model (VLLM) will become an effective unified methodology of\ntext mining. I discuss at least three advantages of this new methodology\nagainst conventional methods. Finally I discuss the challenges in the design\nand development of VLLM techniques for text mining.\n","authors":["Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2212.09271v2.pdf","comment":"4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.10422v1","updated":"2022-12-20T16:59:56Z","published":"2022-12-20T16:59:56Z","title":"Localising In-Domain Adaptation of Transformer-Based Biomedical Language\n  Models","summary":"  In the era of digital healthcare, the huge volumes of textual information\ngenerated every day in hospitals constitute an essential but underused asset\nthat could be exploited with task-specific, fine-tuned biomedical language\nrepresentation models, improving patient care and management. For such\nspecialized domains, previous research has shown that fine-tuning models\nstemming from broad-coverage checkpoints can largely benefit additional\ntraining rounds over large-scale in-domain resources. However, these resources\nare often unreachable for less-resourced languages like Italian, preventing\nlocal medical institutions to employ in-domain adaptation. In order to reduce\nthis gap, our work investigates two accessible approaches to derive biomedical\nlanguage models in languages other than English, taking Italian as a concrete\nuse-case: one based on neural machine translation of English resources,\nfavoring quantity over quality; the other based on a high-grade, narrow-scoped\ncorpus natively in Italian, thus preferring quality over quantity. Our study\nshows that data quantity is a harder constraint than data quality for\nbiomedical adaptation, but the concatenation of high-quality data can improve\nmodel performance even when dealing with relatively size-limited corpora. The\nmodels published from our investigations have the potential to unlock important\nresearch opportunities for Italian hospitals and academia. Finally, the set of\nlessons learned from the study constitutes valuable insights towards a solution\nto build biomedical language models that are generalizable to other\nless-resourced languages and different domain settings.\n","authors":["Tommaso Mario Buonocore","Claudio Crema","Enea Parimbelli","Alberto Redolfi","Riccardo Bellazzi"],"pdf_url":"https://arxiv.org/pdf/2212.10422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10420v1","updated":"2022-12-20T16:55:33Z","published":"2022-12-20T16:55:33Z","title":"Settling the Reward Hypothesis","summary":"  The reward hypothesis posits that, \"all of what we mean by goals and purposes\ncan be well thought of as maximization of the expected value of the cumulative\nsum of a received scalar signal (reward).\" We aim to fully settle this\nhypothesis. This will not conclude with a simple affirmation or refutation, but\nrather specify completely the implicit requirements on goals and purposes under\nwhich the hypothesis holds.\n","authors":["Michael Bowling","John D. Martin","David Abel","Will Dabney"],"pdf_url":"https://arxiv.org/pdf/2212.10420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10417v1","updated":"2022-12-20T16:48:51Z","published":"2022-12-20T16:48:51Z","title":"Scene Change Detection Using Multiscale Cascade Residual Convolutional\n  Neural Networks","summary":"  Scene change detection is an image processing problem related to partitioning\npixels of a digital image into foreground and background regions. Mostly,\nvisual knowledge-based computer intelligent systems, like traffic monitoring,\nvideo surveillance, and anomaly detection, need to use change detection\ntechniques. Amongst the most prominent detection methods, there are the\nlearning-based ones, which besides sharing similar training and testing\nprotocols, differ from each other in terms of their architecture design\nstrategies. Such architecture design directly impacts on the quality of the\ndetection results, and also in the device resources capacity, like memory. In\nthis work, we propose a novel Multiscale Cascade Residual Convolutional Neural\nNetwork that integrates multiscale processing strategy through a Residual\nProcessing Module, with a Segmentation Convolutional Neural Network.\nExperiments conducted on two different datasets support the effectiveness of\nthe proposed approach, achieving average overall\n$\\boldsymbol{F\\text{-}measure}$ results of $\\boldsymbol{0.9622}$ and\n$\\boldsymbol{0.9664}$ over Change Detection 2014 and PetrobrasROUTES datasets\nrespectively, besides comprising approximately eight times fewer parameters.\nSuch obtained results place the proposed technique amongst the top four\nstate-of-the-art scene change detection methods.\n","authors":["Daniel F. S. Santos","Rafael G. Pires","Danilo Colombo","João P. Papa"],"pdf_url":"https://arxiv.org/pdf/2212.10417v1.pdf","comment":"Published in: 2020 33rd SIBGRAPI Conference on Graphics, Patterns and\n  Images (SIBGRAPI)"},{"id":"http://arxiv.org/abs/2208.14878v3","updated":"2022-12-20T16:45:26Z","published":"2022-08-31T14:11:23Z","title":"Formalising the Robustness of Counterfactual Explanations for Neural\n  Networks","summary":"  The use of counterfactual explanations (CFXs) is an increasingly popular\nexplanation strategy for machine learning models. However, recent studies have\nshown that these explanations may not be robust to changes in the underlying\nmodel (e.g., following retraining), which raises questions about their\nreliability in real-world applications. Existing attempts towards solving this\nproblem are heuristic, and the robustness to model changes of the resulting\nCFXs is evaluated with only a small number of retrained models, failing to\nprovide exhaustive guarantees. To remedy this, we propose {\\Delta}-robustness,\nthe first notion to formally and deterministically assess the robustness (to\nmodel changes) of CFXs for neural networks. We introduce an abstraction\nframework based on interval neural networks to verify the {\\Delta}-robustness\nof CFXs against a possibly infinite set of changes to the model parameters,\ni.e., weights and biases. We then demonstrate the utility of this approach in\ntwo distinct ways. First, we analyse the {\\Delta}-robustness of a number of CFX\ngeneration methods from the literature and show that they unanimously host\nsignificant deficiencies in this regard. Second, we demonstrate how embedding\n{\\Delta}-robustness within existing methods can provide CFXs which are provably\nrobust.\n","authors":["Junqi Jiang","Francesco Leofante","Antonio Rago","Francesca Toni"],"pdf_url":"https://arxiv.org/pdf/2208.14878v3.pdf","comment":"Accepted at AAAI 2023, camera-ready version"},{"id":"http://arxiv.org/abs/2205.00849v2","updated":"2022-12-20T16:40:52Z","published":"2022-05-02T12:23:55Z","title":"Model-based Deep Learning Receiver Design for Rate-Splitting Multiple\n  Access","summary":"  Effective and adaptive interference management is required in next generation\nwireless communication systems. To address this challenge, Rate-Splitting\nMultiple Access (RSMA), relying on multi-antenna rate-splitting (RS) at the\ntransmitter and successive interference cancellation (SIC) at the receivers,\nhas been intensively studied in recent years, albeit mostly under the\nassumption of perfect Channel State Information at the Receiver (CSIR) and\nideal capacity-achieving modulation and coding schemes. To assess its practical\nperformance, benefits, and limits under more realistic conditions, this work\nproposes a novel design for a practical RSMA receiver based on model-based deep\nlearning (MBDL) methods, which aims to unite the simple structure of the\nconventional SIC receiver and the robustness and model agnosticism of deep\nlearning techniques. The MBDL receiver is evaluated in terms of uncoded Symbol\nError Rate (SER), throughput performance through Link-Level Simulations (LLS),\nand average training overhead. Also, a comparison with the SIC receiver, with\nperfect and imperfect CSIR, is given. Results reveal that the MBDL receiver\noutperforms by a significant margin the SIC receiver with imperfect CSIR, due\nto its ability to generate on demand non-linear symbol detection boundaries in\na pure data-driven manner.\n","authors":["Rafael Cerna Loli","Onur Dizdar","Bruno Clerckx","Cong Ling"],"pdf_url":"https://arxiv.org/pdf/2205.00849v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10411v1","updated":"2022-12-20T16:39:04Z","published":"2022-12-20T16:39:04Z","title":"DDIPNet and DDIPNet+: Discriminant Deep Image Prior Networks for Remote\n  Sensing Image Classification","summary":"  Research on remote sensing image classification significantly impacts\nessential human routine tasks such as urban planning and agriculture. Nowadays,\nthe rapid advance in technology and the availability of many high-quality\nremote sensing images create a demand for reliable automation methods. The\ncurrent paper proposes two novel deep learning-based architectures for image\nclassification purposes, i.e., the Discriminant Deep Image Prior Network and\nthe Discriminant Deep Image Prior Network+, which combine Deep Image Prior and\nTriplet Networks learning strategies. Experiments conducted over three\nwell-known public remote sensing image datasets achieved state-of-the-art\nresults, evidencing the effectiveness of using deep image priors for remote\nsensing image classification.\n","authors":["Daniel F. S. Santos","Rafael G. Pires","Leandro A. Passos","João P. Papa"],"pdf_url":"https://arxiv.org/pdf/2212.10411v1.pdf","comment":"Published in: 2021 IEEE International Geoscience and Remote Sensing\n  Symposium IGARSS"},{"id":"http://arxiv.org/abs/2212.10390v1","updated":"2022-12-20T16:17:40Z","published":"2022-12-20T16:17:40Z","title":"ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic\n  Segmentation","summary":"  State-of-the-art 3D semantic segmentation models are trained on the\noff-the-shelf public benchmarks, but they often face the major challenge when\nthese well-trained models are deployed to a new domain. In this paper, we\npropose an Active-and-Adaptive Segmentation (ADAS) baseline to enhance the weak\ncross-domain generalization ability of a well-trained 3D segmentation model,\nand bridge the point distribution gap between domains. Specifically, before the\ncross-domain adaptation stage begins, ADAS performs an active sampling\noperation to select a maximally-informative subset from both source and target\ndomains for effective adaptation, reducing the adaptation difficulty under 3D\nscenarios. Benefiting from the rise of multi-modal 2D-3D datasets, ADAS\nutilizes a cross-modal attention-based feature fusion module that can extract a\nrepresentative pair of image features and point features to achieve a\nbi-directional image-point feature interaction for better safe adaptation.\nExperimentally, ADAS is verified to be effective in many cross-domain settings\nincluding: 1) Unsupervised Domain Adaptation (UDA), which means that all\nsamples from target domain are unlabeled; 2) Unsupervised Few-shot Domain\nAdaptation (UFDA) which means that only a few unlabeled samples are available\nin the unlabeled target domain; 3) Active Domain Adaptation (ADA) which means\nthat the selected target samples by ADAS are manually annotated. Their results\ndemonstrate that ADAS achieves a significant accuracy gain by easily coupling\nADAS with self-training methods or off-the-shelf UDA works.\n","authors":["Ben Fei","Siyuan Huang","Jiakang Yuan","Botian Shi","Bo Zhang","Tao Chen","Min Dou","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2212.10390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08073v2","updated":"2022-12-20T16:03:56Z","published":"2022-11-15T11:53:55Z","title":"GLUE-X: Evaluating Natural Language Understanding Models from an\n  Out-of-distribution Generalization Perspective","summary":"  Pre-trained language models (PLMs) are known to improve the generalization\nperformance of natural language understanding models by leveraging large\namounts of data during the pre-training phase. However, the out-of-distribution\n(OOD) generalization problem remains a challenge in many NLP tasks, limiting\nthe real-world deployment of these methods. This paper presents the first\nattempt at creating a unified benchmark named GLUE-X for evaluating OOD\nrobustness in NLP models, highlighting the importance of OOD robustness and\nproviding insights on how to measure the robustness of a model and how to\nimprove it. The benchmark includes 13 publicly available datasets for OOD\ntesting, and evaluations are conducted on 8 classic NLP tasks over 19 popularly\nused PLMs. Our findings confirm the need for improved OOD accuracy in NLP\ntasks, as significant performance degradation was observed in all settings\ncompared to in-distribution (ID) accuracy.\n","authors":["Linyi Yang","Shuibai Zhang","Libo Qin","Yafu Li","Yidong Wang","Hanmeng Liu","Jindong Wang","Xing Xie","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.08073v2.pdf","comment":"17 pages, GLUE-X, OOD Generalization"},{"id":"http://arxiv.org/abs/2212.10376v1","updated":"2022-12-20T15:58:01Z","published":"2022-12-20T15:58:01Z","title":"The Third International Verification of Neural Networks Competition\n  (VNN-COMP 2022): Summary and Results","summary":"  This report summarizes the 3rd International Verification of Neural Networks\nCompetition (VNN-COMP 2022), held as a part of the 5th Workshop on Formal\nMethods for ML-Enabled Autonomous Systems (FoMLAS), which was collocated with\nthe 34th International Conference on Computer-Aided Verification (CAV).\nVNN-COMP is held annually to facilitate the fair and objective comparison of\nstate-of-the-art neural network verification tools, encourage the\nstandardization of tool interfaces, and bring together the neural network\nverification community. To this end, standardized formats for networks (ONNX)\nand specification (VNN-LIB) were defined, tools were evaluated on equal-cost\nhardware (using an automatic evaluation pipeline based on AWS instances), and\ntool parameters were chosen by the participants before the final test sets were\nmade public. In the 2022 iteration, 11 teams participated on a diverse set of\n12 scored benchmarks. This report summarizes the rules, benchmarks,\nparticipating tools, results, and lessons learned from this iteration of this\ncompetition.\n","authors":["Mark Niklas Müller","Christopher Brix","Stanley Bak","Changliu Liu","Taylor T. Johnson"],"pdf_url":"https://arxiv.org/pdf/2212.10376v1.pdf","comment":"54 pages, 27 tables, and 16 figures"},{"id":"http://arxiv.org/abs/2212.10367v1","updated":"2022-12-20T15:48:48Z","published":"2022-12-20T15:48:48Z","title":"Modeling Human Eye Movements with Neural Networks in a Maze-Solving Task","summary":"  From smoothly pursuing moving objects to rapidly shifting gazes during visual\nsearch, humans employ a wide variety of eye movement strategies in different\ncontexts. While eye movements provide a rich window into mental processes,\nbuilding generative models of eye movements is notoriously difficult, and to\ndate the computational objectives guiding eye movements remain largely a\nmystery. In this work, we tackled these problems in the context of a canonical\nspatial planning task, maze-solving. We collected eye movement data from human\nsubjects and built deep generative models of eye movements using a novel\ndifferentiable architecture for gaze fixations and gaze shifts. We found that\nhuman eye movements are best predicted by a model that is optimized not to\nperform the task as efficiently as possible but instead to run an internal\nsimulation of an object traversing the maze. This not only provides a\ngenerative model of eye movements in this task but also suggests a\ncomputational theory for how humans solve the task, namely that humans use\nmental simulation.\n","authors":["Jason Li","Nicholas Watters"," Yingting"," Wang","Hansem Sohn","Mehrdad Jazayeri"],"pdf_url":"https://arxiv.org/pdf/2212.10367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10355v1","updated":"2022-12-20T15:40:08Z","published":"2022-12-20T15:40:08Z","title":"Optimizing Serially Concatenated Neural Codes with Classical Decoders","summary":"  For improving short-length codes, we demonstrate that classic decoders can\nalso be used with real-valued, neural encoders, i.e., deep-learning based\ncodeword sequence generators. Here, the classical decoder can be a valuable\ntool to gain insights into these neural codes and shed light on weaknesses.\nSpecifically, the turbo-autoencoder is a recently developed channel coding\nscheme where both encoder and decoder are replaced by neural networks. We first\nshow that the limited receptive field of convolutional neural network\n(CNN)-based codes enables the application of the BCJR algorithm to optimally\ndecode them with feasible computational complexity. These maximum a posteriori\n(MAP) component decoders then are used to form classical (iterative) turbo\ndecoders for parallel or serially concatenated CNN encoders, offering a\nclose-to-maximum likelihood (ML) decoding of the learned codes. To the best of\nour knowledge, this is the first time that a classical decoding algorithm is\napplied to a non-trivial, real-valued neural code. Furthermore, as the BCJR\nalgorithm is fully differentiable, it is possible to train, or fine-tune, the\nneural encoder in an end-to-end fashion.\n","authors":["Jannis Clausius","Marvin Geiselhart","Stephan ten Brink"],"pdf_url":"https://arxiv.org/pdf/2212.10355v1.pdf","comment":"Submitted to IEEE WSA/SCC"},{"id":"http://arxiv.org/abs/2109.00542v3","updated":"2022-12-20T15:38:20Z","published":"2021-09-01T16:59:09Z","title":"Shared Certificates for Neural Network Verification","summary":"  Existing neural network verifiers compute a proof that each input is handled\ncorrectly under a given perturbation by propagating a symbolic abstraction of\nreachable values at each layer. This process is repeated from scratch\nindependently for each input (e.g., image) and perturbation (e.g., rotation),\nleading to an expensive overall proof effort when handling an entire dataset.\nIn this work, we introduce a new method for reducing this verification cost\nwithout losing precision based on a key insight that abstractions obtained at\nintermediate layers for different inputs and perturbations can overlap or\ncontain each other. Leveraging our insight, we introduce the general concept of\nshared certificates, enabling proof effort reuse across multiple inputs to\nreduce overall verification costs. We perform an extensive experimental\nevaluation to demonstrate the effectiveness of shared certificates in reducing\nthe verification cost on a range of datasets and attack specifications on image\nclassifiers including the popular patch and geometric perturbations. We release\nour implementation at https://github.com/eth-sri/proof-sharing.\n","authors":["Marc Fischer","Christian Sprecher","Dimitar I. Dimitrov","Gagandeep Singh","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2109.00542v3.pdf","comment":"Extended version of our CAV'22 paper"},{"id":"http://arxiv.org/abs/2205.15449v3","updated":"2022-12-20T15:36:27Z","published":"2022-05-30T22:16:25Z","title":"Posterior and Computational Uncertainty in Gaussian Processes","summary":"  Gaussian processes scale prohibitively with the size of the dataset. In\nresponse, many approximation methods have been developed, which inevitably\nintroduce approximation error. This additional source of uncertainty, due to\nlimited computation, is entirely ignored when using the approximate posterior.\nTherefore in practice, GP models are often as much about the approximation\nmethod as they are about the data. Here, we develop a new class of methods that\nprovides consistent estimation of the combined uncertainty arising from both\nthe finite number of data observed and the finite amount of computation\nexpended. The most common GP approximations map to an instance in this class,\nsuch as methods based on the Cholesky factorization, conjugate gradients, and\ninducing points. For any method in this class, we prove (i) convergence of its\nposterior mean in the associated RKHS, (ii) decomposability of its combined\nposterior covariance into mathematical and computational covariances, and (iii)\nthat the combined variance is a tight worst-case bound for the squared error\nbetween the method's posterior mean and the latent function. Finally, we\nempirically demonstrate the consequences of ignoring computational uncertainty\nand show how implicitly modeling it improves generalization performance on\nbenchmark datasets.\n","authors":["Jonathan Wenger","Geoff Pleiss","Marvin Pförtner","Philipp Hennig","John P. Cunningham"],"pdf_url":"https://arxiv.org/pdf/2205.15449v3.pdf","comment":"Advances in Neural Information Processing Systems (NeurIPS 2022)"},{"id":"http://arxiv.org/abs/2208.14344v2","updated":"2022-12-20T15:28:31Z","published":"2022-08-30T15:42:36Z","title":"Analysis of Distributed Deep Learning in the Cloud","summary":"  We aim to resolve this problem by introducing a comprehensive distributed\ndeep learning (DDL) profiler, which can determine the various execution\n\"stalls\" that DDL suffers from while running on a public cloud. We have\nimplemented the profiler by extending prior work to additionally estimate two\ntypes of communication stalls - interconnect and network stalls. We train\npopular DNN models using the profiler to characterize various AWS GPU instances\nand list their advantages and shortcomings for users to make an informed\ndecision. We observe that the more expensive GPU instances may not be the most\nperformant for all DNN models and AWS may sub-optimally allocate hardware\ninterconnect resources. Specifically, the intra-machine interconnect can\nintroduce communication overheads up to 90% of DNN training time and\nnetwork-connected instances can suffer from up to 5x slowdown compared to\ntraining on a single instance. Further, we model the impact of DNN macroscopic\nfeatures such as the number of layers and the number of gradients on\ncommunication stalls. Finally, we propose a measurement-based recommendation\nmodel for users to lower their public cloud monetary costs for DDL, given a\ntime budget.\n","authors":["Aakash Sharma","Vivek M. Bhasi","Sonali Singh","Rishabh Jain","Jashwant Raj Gunasekaran","Subrata Mitra","Mahmut Taylan Kandemir","George Kesidis","Chita R. Das"],"pdf_url":"https://arxiv.org/pdf/2208.14344v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10343v1","updated":"2022-12-20T15:26:39Z","published":"2022-12-20T15:26:39Z","title":"Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio\n  Access Technologies","summary":"  The evolution of wireless communications into 6G and beyond is expected to\nrely on new machine learning (ML)-based capabilities. These can enable\nproactive decisions and actions from wireless-network components to sustain\nquality-of-service (QoS) and user experience. Moreover, new use cases in the\narea of vehicular and industrial communications will emerge. Specifically in\nthe area of vehicle communication, vehicle-to-everything (V2X) schemes will\nbenefit strongly from such advances. With this in mind, we have conducted a\ndetailed measurement campaign with the purpose of enabling a plethora of\ndiverse ML-based studies. The resulting datasets offer GPS-located wireless\nmeasurements across diverse urban environments for both cellular (with two\ndifferent operators) and sidelink radio access technologies, thus enabling a\nvariety of different studies towards V2X. The datasets are labeled and sampled\nwith a high time resolution. Furthermore, we make the data publicly available\nwith all the necessary information to support the on-boarding of new\nresearchers. We provide an initial analysis of the data showing some of the\nchallenges that ML needs to overcome and the features that ML can leverage, as\nwell as some hints at potential research studies.\n","authors":["Rodrigo Hernangómez","Philipp Geuer","Alexandros Palaios","Daniel Schäufele","Cara Watermann","Khawla Taleb-Bouhemadi","Mohammad Parvini","Anton Krause","Sanket Partani","Christian Vielhaus","Martin Kasparick","Daniel F. Külzer","Friedrich Burmeister","Sławomir Stańczak","Gerhard Fettweis","Hans D. Schotten","Frank H. P. Fitzek"],"pdf_url":"https://arxiv.org/pdf/2212.10343v1.pdf","comment":"Submitted to a conference"},{"id":"http://arxiv.org/abs/2109.09426v2","updated":"2022-12-20T15:10:10Z","published":"2021-09-20T11:09:10Z","title":"A Meta-Learning Approach for Training Explainable Graph Neural Networks","summary":"  In this paper, we investigate the degree of explainability of graph neural\nnetworks (GNNs). Existing explainers work by finding global/local subgraphs to\nexplain a prediction, but they are applied after a GNN has already been\ntrained. Here, we propose a meta-learning framework for improving the level of\nexplainability of a GNN directly at training time, by steering the optimization\nprocedure towards what we call `interpretable minima'. Our framework (called\nMATE, MetA-Train to Explain) jointly trains a model to solve the original task,\ne.g., node classification, and to provide easily processable outputs for\ndownstream algorithms that explain the model's decisions in a human-friendly\nway. In particular, we meta-train the model's parameters to quickly minimize\nthe error of an instance-level GNNExplainer trained on-the-fly on randomly\nsampled nodes. The final internal representation relies upon a set of features\nthat can be `better' understood by an explanation algorithm, e.g., another\ninstance of GNNExplainer. Our model-agnostic approach can improve the\nexplanations produced for different GNN architectures and use any\ninstance-based explainer to drive this process. Experiments on synthetic and\nreal-world datasets for node and graph classification show that we can produce\nmodels that are consistently easier to explain by different algorithms.\nFurthermore, this increase in explainability comes at no cost for the accuracy\nof the model.\n","authors":["Indro Spinelli","Simone Scardapane","Aurelio Uncini"],"pdf_url":"https://arxiv.org/pdf/2109.09426v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10318v1","updated":"2022-12-20T15:09:30Z","published":"2022-12-20T15:09:30Z","title":"Learned Systems Security","summary":"  A learned system uses machine learning (ML) internally to improve\nperformance. We can expect such systems to be vulnerable to some adversarial-ML\nattacks. Often, the learned component is shared between mutually-distrusting\nusers or processes, much like microarchitectural resources such as caches,\npotentially giving rise to highly-realistic attacker models. However, compared\nto attacks on other ML-based systems, attackers face a level of indirection as\nthey cannot interact directly with the learned model. Additionally, the\ndifference between the attack surface of learned and non-learned versions of\nthe same system is often subtle. These factors obfuscate the de-facto risks\nthat the incorporation of ML carries. We analyze the root causes of\npotentially-increased attack surface in learned systems and develop a framework\nfor identifying vulnerabilities that stem from the use of ML. We apply our\nframework to a broad set of learned systems under active development. To\nempirically validate the many vulnerabilities surfaced by our framework, we\nchoose 3 of them and implement and evaluate exploits against prominent\nlearned-system instances. We show that the use of ML caused leakage of past\nqueries in a database, enabled a poisoning attack that causes exponential\nmemory blowup in an index structure and crashes it in seconds, and enabled\nindex users to snoop on each others' key distributions by timing queries over\ntheir own keys. We find that adversarial ML is a universal threat against\nlearned systems, point to open research gaps in our understanding of\nlearned-systems security, and conclude by discussing mitigations, while noting\nthat data leakage is inherent in systems whose learned component is shared\nbetween multiple parties.\n","authors":["Roei Schuster","Jin Peng Zhou","Paul Grubbs","Thorsten Eisenhofer","Nicolas Papernot"],"pdf_url":"https://arxiv.org/pdf/2212.10318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10307v1","updated":"2022-12-20T14:54:47Z","published":"2022-12-20T14:54:47Z","title":"Efficient and Sound Differentiable Programming in a Functional\n  Array-Processing Language","summary":"  Automatic differentiation (AD) is a technique for computing the derivative of\na function represented by a program. This technique is considered as the\nde-facto standard for computing the differentiation in many machine learning\nand optimisation software tools. Despite the practicality of this technique,\nthe performance of the differentiated programs, especially for functional\nlanguages and in the presence of vectors, is suboptimal. We present an AD\nsystem for a higher-order functional array-processing language. The core\nfunctional language underlying this system simultaneously supports both\nsource-to-source forward-mode AD and global optimisations such as loop\ntransformations. In combination, gradient computation with forward-mode AD can\nbe as efficient as reverse mode, and the Jacobian matrices required for\nnumerical algorithms such as Gauss-Newton and Levenberg-Marquardt can be\nefficiently computed.\n","authors":["Amir Shaikhha","Mathieu Huot","Shabnam Ghasemirad","Andrew Fitzgibbon","Simon Peyton Jones","Dimitrios Vytiniotis"],"pdf_url":"https://arxiv.org/pdf/2212.10307v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:1806.02136"},{"id":"http://arxiv.org/abs/2212.10306v1","updated":"2022-12-20T14:54:04Z","published":"2022-12-20T14:54:04Z","title":"A Pattern Discovery Approach to Multivariate Time Series Forecasting","summary":"  Multivariate time series forecasting constitutes important functionality in\ncyber-physical systems, whose prediction accuracy can be improved significantly\nby capturing temporal and multivariate correlations among multiple time series.\nState-of-the-art deep learning methods fail to construct models for full time\nseries because model complexity grows exponentially with time series length.\nRather, these methods construct local temporal and multivariate correlations\nwithin subsequences, but fail to capture correlations among subsequences, which\nsignificantly affect their forecasting accuracy. To capture the temporal and\nmultivariate correlations among subsequences, we design a pattern discovery\nmodel, that constructs correlations via diverse pattern functions. While the\ntraditional pattern discovery method uses shared and fixed pattern functions\nthat ignore the diversity across time series. We propose a novel pattern\ndiscovery method that can automatically capture diverse and complex time series\npatterns. We also propose a learnable correlation matrix, that enables the\nmodel to capture distinct correlations among multiple time series. Extensive\nexperiments show that our model achieves state-of-the-art prediction accuracy.\n","authors":["Yunyao Cheng","Chenjuan Guo","Kaixuan Chen","Kai Zhao","Bin Yang","Jiandong Xie","Christian S. Jensen","Feiteng Huang","Kai Zheng"],"pdf_url":"https://arxiv.org/pdf/2212.10306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.03150v3","updated":"2022-12-20T14:48:30Z","published":"2022-06-07T09:54:38Z","title":"Group Meritocratic Fairness in Linear Contextual Bandits","summary":"  We study the linear contextual bandit problem where an agent has to select\none candidate from a pool and each candidate belongs to a sensitive group. In\nthis setting, candidates' rewards may not be directly comparable between\ngroups, for example when the agent is an employer hiring candidates from\ndifferent ethnic groups and some groups have a lower reward due to\ndiscriminatory bias and/or social injustice. We propose a notion of fairness\nthat states that the agent's policy is fair when it selects a candidate with\nhighest relative rank, which measures how good the reward is when compared to\ncandidates from the same group. This is a very strong notion of fairness, since\nthe relative rank is not directly observed by the agent and depends on the\nunderlying reward model and on the distribution of rewards. Thus we study the\nproblem of learning a policy which approximates a fair policy under the\ncondition that the contexts are independent between groups and the distribution\nof rewards of each group is absolutely continuous. In particular, we design a\ngreedy policy which at each round constructs a ridge regression estimate from\nthe observed context-reward pairs, and then computes an estimate of the\nrelative rank of each candidate using the empirical cumulative distribution\nfunction. We prove that, despite its simplicity and the lack of an initial\nexploration phase, the greedy policy achieves, up to log factors and with high\nprobability, a fair pseudo-regret of order $\\sqrt{dT}$ after $T$ rounds, where\n$d$ is the dimension of the context vectors. The policy also satisfies\ndemographic parity at each round when averaged over all possible information\navailable before the selection. Finally, we use simulated settings and\nexperiments on the US census data to show that our policy achieves sub-linear\nfair pseudo-regret also in practice.\n","authors":["Riccardo Grazzi","Arya Akhavan","John Isak Texas Falk","Leonardo Cella","Massimiliano Pontil"],"pdf_url":"https://arxiv.org/pdf/2206.03150v3.pdf","comment":"NeurIPS 2022. Code for the experiments at\n  https://github.com/CSML-IIT-UCL/GMFbandits"},{"id":"http://arxiv.org/abs/2212.10299v1","updated":"2022-12-20T14:46:44Z","published":"2022-12-20T14:46:44Z","title":"Cell-Free Data Power Control Via Scalable Multi-Objective Bayesian\n  Optimisation","summary":"  Cell-free multi-user multiple input multiple output networks are a promising\nalternative to classical cellular architectures, since they have the potential\nto provide uniform service quality and high resource utilisation over the\nentire coverage area of the network. To realise this potential, previous works\nhave developed radio resource management mechanisms using various optimisation\nengines. In this work, we consider the problem of overall ergodic spectral\nefficiency maximisation in the context of uplink-downlink data power control in\ncell-free networks. To solve this problem in large networks, and to address\nconvergence-time limitations, we apply scalable multi-objective Bayesian\noptimisation. Furthermore, we discuss how an intersection of multi-fidelity\nemulation and Bayesian optimisation can improve radio resource management in\ncell-free networks.\n","authors":["Sergey S. Tambovskiy","Gábor Fodor","Hugo Tullberg"],"pdf_url":"https://arxiv.org/pdf/2212.10299v1.pdf","comment":"2022 IEEE 33rd Annual International Symposium on Personal, Indoor and\n  Mobile Radio Communications (PIMRC)"},{"id":"http://arxiv.org/abs/2212.10264v1","updated":"2022-12-20T14:11:31Z","published":"2022-12-20T14:11:31Z","title":"ReCode: Robustness Evaluation of Code Generation Models","summary":"  Code generation models have achieved impressive performance. However, they\ntend to be brittle as slight edits to a prompt could lead to very different\ngenerations; these robustness properties, critical for user experience when\ndeployed in real-life applications, are not well understood. Most existing\nworks on robustness in text or code tasks have focused on classification, while\nrobustness in generation tasks is an uncharted area and to date there is no\ncomprehensive benchmark for robustness in code generation. In this paper, we\npropose ReCode, a comprehensive robustness evaluation benchmark for code\ngeneration models. We customize over 30 transformations specifically for code\non docstrings, function and variable names, code syntax, and code format. They\nare carefully designed to be natural in real-life coding practice, preserve the\noriginal semantic meaning, and thus provide multifaceted assessments of a\nmodel's robustness performance. With human annotators, we verified that over\n90% of the perturbed prompts do not alter the semantic meaning of the original\nprompt. In addition, we define robustness metrics for code generation models\nconsidering the worst-case behavior under each type of perturbation, taking\nadvantage of the fact that executing the generated code can serve as objective\nevaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well\nas function completion tasks derived from them. Interesting observations\ninclude: better robustness for CodeGen over InCoder and GPT-J; models are most\nsensitive to syntax perturbations; more challenging robustness evaluation on\nMBPP over HumanEval.\n","authors":["Shiqi Wang","Zheng Li","Haifeng Qian","Chenghao Yang","Zijian Wang","Mingyue Shang","Varun Kumar","Samson Tan","Baishakhi Ray","Parminder Bhatia","Ramesh Nallapati","Murali Krishna Ramanathan","Dan Roth","Bing Xiang"],"pdf_url":"https://arxiv.org/pdf/2212.10264v1.pdf","comment":"Code and data available at https://github.com/amazon-science/recode"},{"id":"http://arxiv.org/abs/2212.10258v1","updated":"2022-12-20T14:06:50Z","published":"2022-12-20T14:06:50Z","title":"In and Out-of-Domain Text Adversarial Robustness via Label Smoothing","summary":"  Recently it has been shown that state-of-the-art NLP models are vulnerable to\nadversarial attacks, where the predictions of a model can be drastically\naltered by slight modifications to the input (such as synonym substitutions).\nWhile several defense techniques have been proposed, and adapted, to the\ndiscrete nature of text adversarial attacks, the benefits of general-purpose\nregularization methods such as label smoothing for language models, have not\nbeen studied. In this paper, we study the adversarial robustness provided by\nvarious label smoothing strategies in foundational models for diverse NLP tasks\nin both in-domain and out-of-domain settings. Our experiments show that label\nsmoothing significantly improves adversarial robustness in pre-trained models\nlike BERT, against various popular attacks. We also analyze the relationship\nbetween prediction confidence and robustness, showing that label smoothing\nreduces over-confident errors on adversarial examples.\n","authors":["Yahan Yang","Soham Dan","Dan Roth","Insup Lee"],"pdf_url":"https://arxiv.org/pdf/2212.10258v1.pdf","comment":"Preprint. Under Submission"},{"id":"http://arxiv.org/abs/2206.04360v2","updated":"2022-12-20T13:58:50Z","published":"2022-06-09T09:01:05Z","title":"A general approximation lower bound in $L^p$ norm, with applications to\n  feed-forward neural networks","summary":"  We study the fundamental limits to the expressive power of neural networks.\nGiven two sets $F$, $G$ of real-valued functions, we first prove a general\nlower bound on how well functions in $F$ can be approximated in $L^p(\\mu)$ norm\nby functions in $G$, for any $p \\geq 1$ and any probability measure $\\mu$. The\nlower bound depends on the packing number of $F$, the range of $F$, and the\nfat-shattering dimension of $G$. We then instantiate this bound to the case\nwhere $G$ corresponds to a piecewise-polynomial feed-forward neural network,\nand describe in details the application to two sets $F$: H{\\\"o}lder balls and\nmultivariate monotonic functions. Beside matching (known or new) upper bounds\nup to log factors, our lower bounds shed some light on the similarities or\ndifferences between approximation in $L^p$ norm or in sup norm, solving an open\nquestion by DeVore et al. (2021). Our proof strategy differs from the sup norm\ncase and uses a key probability result of Mendelson (2002).\n","authors":["El Mehdi Achour","Armand Foucault","Sébastien Gerchinovitz","François Malgouyres"],"pdf_url":"https://arxiv.org/pdf/2206.04360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10249v1","updated":"2022-12-20T13:54:04Z","published":"2022-12-20T13:54:04Z","title":"Learning efficient backprojections across cortical hierarchies in real\n  time","summary":"  Models of sensory processing and learning in the cortex need to efficiently\nassign credit to synapses in all areas. In deep learning, a known solution is\nerror backpropagation, which however requires biologically implausible weight\ntransport from feed-forward to feedback paths.\n  We introduce Phaseless Alignment Learning (PAL), a bio-plausible method to\nlearn efficient feedback weights in layered cortical hierarchies. This is\nachieved by exploiting the noise naturally found in biophysical systems as an\nadditional carrier of information. In our dynamical system, all weights are\nlearned simultaneously with always-on plasticity and using only information\nlocally available to the synapses. Our method is completely phase-free (no\nforward and backward passes or phased learning) and allows for efficient error\npropagation across multi-layer cortical hierarchies, while maintaining\nbiologically plausible signal transport and learning.\n  Our method is applicable to a wide class of models and improves on previously\nknown biologically plausible ways of credit assignment: compared to random\nsynaptic feedback, it can solve complex tasks with less neurons and learn more\nuseful latent representations. We demonstrate this on various classification\ntasks using a cortical microcircuit model with prospective coding.\n","authors":["Kevin Max","Laura Kriener","Garibaldi Pineda García","Thomas Nowotny","Walter Senn","Mihai A. Petrovici"],"pdf_url":"https://arxiv.org/pdf/2212.10249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10229v1","updated":"2022-12-20T13:07:20Z","published":"2022-12-20T13:07:20Z","title":"StyleDomain: Analysis of StyleSpace for Domain Adaptation of StyleGAN","summary":"  Domain adaptation of GANs is a problem of fine-tuning the state-of-the-art\nGAN models (e.g. StyleGAN) pretrained on a large dataset to a specific domain\nwith few samples (e.g. painting faces, sketches, etc.). While there are a great\nnumber of methods that tackle this problem in different ways there are still\nmany important questions that remain unanswered. In this paper, we provide a\nsystematic and in-depth analysis of the domain adaptation problem of GANs,\nfocusing on the StyleGAN model. First, we perform a detailed exploration of the\nmost important parts of StyleGAN that are responsible for adapting the\ngenerator to a new domain depending on the similarity between the source and\ntarget domains. In particular, we show that affine layers of StyleGAN can be\nsufficient for fine-tuning to similar domains. Second, inspired by these\nfindings, we investigate StyleSpace to utilize it for domain adaptation. We\nshow that there exist directions in the StyleSpace that can adapt StyleGAN to\nnew domains. Further, we examine these directions and discover their many\nsurprising properties. Finally, we leverage our analysis and findings to\ndeliver practical improvements and applications in such standard tasks as\nimage-to-image translation and cross-domain morphing.\n","authors":["Aibek Alanov","Vadim Titov","Maksim Nakhodnov","Dmitry Vetrov"],"pdf_url":"https://arxiv.org/pdf/2212.10229v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2110.03894v3","updated":"2022-12-20T12:44:24Z","published":"2021-10-08T05:07:35Z","title":"Neural Model Reprogramming with Similarity Based Mapping for\n  Low-Resource Spoken Command Classification","summary":"  In this study, we propose a novel adversarial reprogramming (AR) approach for\nlow-resource spoken command recognition (SCR), and build an AR-SCR system. The\nAR procedure aims to modify the acoustic signals (from the target domain) to\nrepurpose a pretrained SCR model (from the source domain). To solve the label\nmismatches between source and target domains, and further improve the stability\nof AR, we propose a novel similarity-based label mapping technique to align\nclasses. In addition, the transfer learning (TL) technique is combined with the\noriginal AR process to improve the model adaptation capability. We evaluate the\nproposed AR-SCR system on three low-resource SCR datasets, including Arabic,\nLithuanian, and dysarthric Mandarin speech. Experimental results show that with\na pretrained AM trained on a large-scale English dataset, the proposed AR-SCR\nsystem outperforms the current state-of-the-art results on Arabic and\nLithuanian speech commands datasets, with only a limited amount of training\ndata.\n","authors":["Hao Yen","Pin-Jui Ku","Chao-Han Huck Yang","Hu Hu","Sabato Marco Siniscalchi","Pin-Yu Chen","Yu Tsao"],"pdf_url":"https://arxiv.org/pdf/2110.03894v3.pdf","comment":"Submitted to ICASSP 2023. The draft has been updated on its new\n  reprogramming findings with data augmentation results (8.7% to 10.9%\n  relatively improvements)"},{"id":"http://arxiv.org/abs/2212.10207v1","updated":"2022-12-20T12:40:29Z","published":"2022-12-20T12:40:29Z","title":"Graph Neural Networks in Computer Vision -- Architectures, Datasets and\n  Common Approaches","summary":"  Graph Neural Networks (GNNs) are a family of graph networks inspired by\nmechanisms existing between nodes on a graph. In recent years there has been an\nincreased interest in GNN and their derivatives, i.e., Graph Attention Networks\n(GAT), Graph Convolutional Networks (GCN), and Graph Recurrent Networks (GRN).\nAn increase in their usability in computer vision is also observed. The number\nof GNN applications in this field continues to expand; it includes video\nanalysis and understanding, action and behavior recognition, computational\nphotography, image and video synthesis from zero or few shots, and many more.\nThis contribution aims to collect papers published about GNN-based approaches\ntowards computer vision. They are described and summarized from three\nperspectives. Firstly, we investigate the architectures of Graph Neural\nNetworks and their derivatives used in this area to provide accurate and\nexplainable recommendations for the ensuing investigations. As for the other\naspect, we also present datasets used in these works. Finally, using graph\nanalysis, we also examine relations between GNN-based studies in computer\nvision and potential sources of inspiration identified outside of this field.\n","authors":["Maciej Krzywda","Szymon Łukasik","Amir H. Gandomi"],"pdf_url":"https://arxiv.org/pdf/2212.10207v1.pdf","comment":"2022 International Joint Conference on Neural Networks (IJCNN), 2022"},{"id":"http://arxiv.org/abs/2212.10191v1","updated":"2022-12-20T12:02:40Z","published":"2022-12-20T12:02:40Z","title":"Emotion Selectable End-to-End Text-based Speech Editing","summary":"  Text-based speech editing allows users to edit speech by intuitively cutting,\ncopying, and pasting text to speed up the process of editing speech. In the\nprevious work, CampNet (context-aware mask prediction network) is proposed to\nrealize text-based speech editing, significantly improving the quality of\nedited speech. This paper aims at a new task: adding emotional effect to the\nediting speech during the text-based speech editing to make the generated\nspeech more expressive. To achieve this task, we propose Emo-CampNet (emotion\nCampNet), which can provide the option of emotional attributes for the\ngenerated speech in text-based speech editing and has the one-shot ability to\nedit unseen speakers' speech. Firstly, we propose an end-to-end\nemotion-selectable text-based speech editing model. The key idea of the model\nis to control the emotion of generated speech by introducing additional emotion\nattributes based on the context-aware mask prediction network. Secondly, to\nprevent the emotion of the generated speech from being interfered by the\nemotional components in the original speech, a neutral content generator is\nproposed to remove the emotion from the original speech, which is optimized by\nthe generative adversarial framework. Thirdly, two data augmentation methods\nare proposed to enrich the emotional and pronunciation information in the\ntraining set, which can enable the model to edit the unseen speaker's speech.\nThe experimental results that 1) Emo-CampNet can effectively control the\nemotion of the generated speech in the process of text-based speech editing;\nAnd can edit unseen speakers' speech. 2) Detailed ablation experiments further\nprove the effectiveness of emotional selectivity and data augmentation methods.\nThe demo page is available at https://hairuo55.github.io/Emo-CampNet/\n","authors":["Tao Wang","Jiangyan Yi","Ruibo Fu","Jianhua Tao","Zhengqi Wen","Chu Yuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.10191v1.pdf","comment":"Under review, 12 pages, 11 figures, demo page is available at\n  https://hairuo55.github.io/Emo-CampNet/"},{"id":"http://arxiv.org/abs/2207.09154v2","updated":"2022-12-20T11:17:06Z","published":"2022-07-19T09:50:34Z","title":"Investigating Bayesian optimization for expensive-to-evaluate black box\n  functions: Application in fluid dynamics","summary":"  Bayesian optimization provides an effective method to optimize\nexpensive-to-evaluate black box functions. It has been widely applied to\nproblems in many fields, including notably in computer science, e.g. in machine\nlearning to optimize hyperparameters of neural networks, and in engineering,\ne.g. in fluid dynamics to optimize control strategies that maximize drag\nreduction. This paper empirically studies and compares the performance and the\nrobustness of common Bayesian optimization algorithms on a range of synthetic\ntest functions to provide general guidance on the design of Bayesian\noptimization algorithms for specific problems. It investigates the choice of\nacquisition function, the effect of different numbers of training samples, the\nexact and Monte Carlo based calculation of acquisition functions, and both\nsingle-point and multi-point optimization. The test functions considered cover\na wide selection of challenges and therefore serve as an ideal test bed to\nunderstand the performance of Bayesian optimization to specific challenges, and\nin general. To illustrate how these findings can be used to inform a Bayesian\noptimization setup tailored to a specific problem, two simulations in the area\nof computational fluid dynamics are optimized, giving evidence that suitable\nsolutions can be found in a small number of evaluations of the objective\nfunction for complex, real problems. The results of our investigation can\nsimilarly be applied to other areas, such as machine learning and physical\nexperiments, where objective functions are expensive to evaluate and their\nmathematical expressions are unknown.\n","authors":["Mike Diessner","Joseph O'Connor","Andrew Wynn","Sylvain Laizet","Yu Guan","Kevin Wilson","Richard D. Whalley"],"pdf_url":"https://arxiv.org/pdf/2207.09154v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.11038v2","updated":"2022-12-20T11:09:05Z","published":"2022-06-21T07:25:43Z","title":"Deep Reinforcement Learning for Turbulence Modeling in Large Eddy\n  Simulations","summary":"  Over the last years, supervised learning (SL) has established itself as the\nstate-of-the-art for data-driven turbulence modeling. In the SL paradigm,\nmodels are trained based on a dataset, which is typically computed a priori\nfrom a high-fidelity solution by applying the respective filter function, which\nseparates the resolved and the unresolved flow scales. For implicitly filtered\nlarge eddy simulation (LES), this approach is infeasible, since here, the\nemployed discretization itself acts as an implicit filter function. As a\nconsequence, the exact filter form is generally not known and thus, the\ncorresponding closure terms cannot be computed even if the full solution is\navailable. The reinforcement learning (RL) paradigm can be used to avoid this\ninconsistency by training not on a previously obtained training dataset, but\ninstead by interacting directly with the dynamical LES environment itself. This\nallows to incorporate the potentially complex implicit LES filter into the\ntraining process by design. In this work, we apply a reinforcement learning\nframework to find an optimal eddy-viscosity for implicitly filtered large eddy\nsimulations of forced homogeneous isotropic turbulence. For this, we formulate\nthe task of turbulence modeling as an RL task with a policy network based on\nconvolutional neural networks that adapts the eddy-viscosity in LES dynamically\nin space and time based on the local flow state only. We demonstrate that the\ntrained models can provide long-term stable simulations and that they\noutperform established analytical models in terms of accuracy. In addition, the\nmodels generalize well to other resolutions and discretizations. We thus\ndemonstrate that RL can provide a framework for consistent, accurate and stable\nturbulence modeling especially for implicitly filtered LES.\n","authors":["Marius Kurz","Philipp Offenhäuser","Andrea Beck"],"pdf_url":"https://arxiv.org/pdf/2206.11038v2.pdf","comment":"17 pages, 9 figures. Accepted Manuscript"},{"id":"http://arxiv.org/abs/2212.10154v1","updated":"2022-12-20T10:46:40Z","published":"2022-12-20T10:46:40Z","title":"Human-Guided Fair Classification for Natural Language Processing","summary":"  Text classifiers have promising applications in high-stake tasks such as\nresume screening and content moderation. These classifiers must be fair and\navoid discriminatory decisions by being invariant to perturbations of sensitive\nattributes such as gender or ethnicity. However, there is a gap between human\nintuition about these perturbations and the formal similarity specifications\ncapturing them. While existing research has started to address this gap,\ncurrent methods are based on hardcoded word replacements, resulting in\nspecifications with limited expressivity or ones that fail to fully align with\nhuman intuition (e.g., in cases of asymmetric counterfactuals). This work\nproposes novel methods for bridging this gap by discovering expressive and\nintuitive individual fairness specifications. We show how to leverage\nunsupervised style transfer and GPT-3's zero-shot capabilities to automatically\ngenerate expressive candidate pairs of semantically similar sentences that\ndiffer along sensitive attributes. We then validate the generated pairs via an\nextensive crowdsourcing study, which confirms that a lot of these pairs align\nwith human intuition about fairness in the context of toxicity classification.\nFinally, we show how limited amounts of human feedback can be leveraged to\nlearn a similarity specification that can be used to train downstream\nfairness-aware models.\n","authors":["Florian E. Dorner","Momchil Peychev","Nikola Konstantinov","Naman Goel","Elliott Ash","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2212.10154v1.pdf","comment":"31 pages, 1 figure"},{"id":"http://arxiv.org/abs/2209.02535v2","updated":"2022-12-20T10:17:10Z","published":"2022-09-06T14:36:57Z","title":"Analyzing Transformers in Embedding Space","summary":"  Understanding Transformer-based models has attracted significant attention,\nas they lie at the heart of recent technological advances across machine\nlearning. While most interpretability methods rely on running models over\ninputs, recent work has shown that a zero-pass approach, where parameters are\ninterpreted directly without a forward/backward pass is feasible for some\nTransformer parameters, and for two-layer attention networks. In this work, we\npresent a theoretical analysis where all parameters of a trained Transformer\nare interpreted by projecting them into the embedding space, that is, the space\nof vocabulary items they operate on. We derive a simple theoretical framework\nto support our arguments and provide ample evidence for its validity. First, an\nempirical analysis showing that parameters of both pretrained and fine-tuned\nmodels can be interpreted in embedding space. Second, we present two\napplications of our framework: (a) aligning the parameters of different models\nthat share a vocabulary, and (b) constructing a classifier without training by\n``translating'' the parameters of a fine-tuned classifier to parameters of a\ndifferent model that was only pretrained. Overall, our findings open the door\nto interpretation methods that, at least in part, abstract away from model\nspecifics and operate in the embedding space only.\n","authors":["Guy Dar","Mor Geva","Ankit Gupta","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2209.02535v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08342v7","updated":"2022-12-20T10:15:46Z","published":"2022-10-15T17:32:49Z","title":"Well-definedness of Physical Law Learning: The Uniqueness Problem","summary":"  Physical law learning is the ambiguous attempt at automating the derivation\nof governing equations with the use of machine learning techniques. The current\nliterature focuses however solely on the development of methods to achieve this\ngoal, and a theoretical foundation is at present missing. This paper shall thus\nserve as a first step to build a comprehensive theoretical framework for\nlearning physical laws, aiming to provide reliability to according algorithms.\nOne key problem consists in the fact that the governing equations might not be\nuniquely determined by the given data. We will study this problem in the common\nsituation that a physical law is described by an ordinary or partial\ndifferential equation. For various different classes of differential equations,\nwe provide both necessary and sufficient conditions for a function to uniquely\ndetermine the differential equation which is governing the phenomenon. We then\nuse our results to devise numerical algorithms to determine whether a function\nsolves a differential equation uniquely. Finally, we provide extensive\nnumerical experiments showing that our algorithms in combination with common\napproaches for learning physical laws indeed allow to guarantee that a unique\ngoverning differential equation is learnt, without assuming any knowledge about\nthe function, thereby ensuring reliability.\n","authors":["Philipp Scholl","Aras Bacho","Holger Boche","Gitta Kutyniok"],"pdf_url":"https://arxiv.org/pdf/2210.08342v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09162v2","updated":"2022-12-20T10:06:49Z","published":"2022-12-18T20:43:37Z","title":"Medical Diagnosis with Large Scale Multimodal Transformers: Leveraging\n  Diverse Data for More Accurate Diagnosis","summary":"  Multimodal deep learning has been used to predict clinical endpoints and\ndiagnoses from clinical routine data. However, these models suffer from scaling\nissues: they have to learn pairwise interactions between each piece of\ninformation in each data type, thereby escalating model complexity beyond\nmanageable scales. This has so far precluded a widespread use of multimodal\ndeep learning. Here, we present a new technical approach of \"learnable\nsynergies\", in which the model only selects relevant interactions between data\nmodalities and keeps an \"internal memory\" of relevant data. Our approach is\neasily scalable and naturally adapts to multimodal data inputs from clinical\nroutine. We demonstrate this approach on three large multimodal datasets from\nradiology and ophthalmology and show that it outperforms state-of-the-art\nmodels in clinically relevant diagnosis tasks. Our new approach is transferable\nand will allow the application of multimodal deep learning to a broad set of\nclinically relevant problems.\n","authors":["Firas Khader","Gustav Mueller-Franzes","Tianci Wang","Tianyu Han","Soroosh Tayebi Arasteh","Christoph Haarburger","Johannes Stegmaier","Keno Bressem","Christiane Kuhl","Sven Nebelung","Jakob Nikolas Kather","Daniel Truhn"],"pdf_url":"https://arxiv.org/pdf/2212.09162v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04747v3","updated":"2022-12-20T09:49:30Z","published":"2022-09-10T22:00:30Z","title":"Diffusion Models in Vision: A Survey","summary":"  Denoising diffusion models represent a recent emerging topic in computer\nvision, demonstrating remarkable results in the area of generative modeling. A\ndiffusion model is a deep generative model that is based on two stages, a\nforward diffusion stage and a reverse diffusion stage. In the forward diffusion\nstage, the input data is gradually perturbed over several steps by adding\nGaussian noise. In the reverse stage, a model is tasked at recovering the\noriginal input data by learning to gradually reverse the diffusion process,\nstep by step. Diffusion models are widely appreciated for the quality and\ndiversity of the generated samples, despite their known computational burdens,\ni.e. low speeds due to the high number of steps involved during sampling. In\nthis survey, we provide a comprehensive review of articles on denoising\ndiffusion models applied in vision, comprising both theoretical and practical\ncontributions in the field. First, we identify and present three generic\ndiffusion modeling frameworks, which are based on denoising diffusion\nprobabilistic models, noise conditioned score networks, and stochastic\ndifferential equations. We further discuss the relations between diffusion\nmodels and other deep generative models, including variational auto-encoders,\ngenerative adversarial networks, energy-based models, autoregressive models and\nnormalizing flows. Then, we introduce a multi-perspective categorization of\ndiffusion models applied in computer vision. Finally, we illustrate the current\nlimitations of diffusion models and envision some interesting directions for\nfuture research.\n","authors":["Florinel-Alin Croitoru","Vlad Hondru","Radu Tudor Ionescu","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2209.04747v3.pdf","comment":"24 pages, 3 figures"},{"id":"http://arxiv.org/abs/2204.10607v2","updated":"2022-12-20T09:46:15Z","published":"2022-04-22T09:55:33Z","title":"Federated Learning via Inexact ADMM","summary":"  One of the crucial issues in federated learning is how to develop efficient\noptimization algorithms. Most of the current ones require full device\nparticipation and/or impose strong assumptions for convergence. Different from\nthe widely-used gradient descent-based algorithms, in this paper, we develop an\ninexact alternating direction method of multipliers (ADMM), which is both\ncomputation- and communication-efficient, capable of combating the stragglers'\neffect, and convergent under mild conditions. Furthermore, it has a high\nnumerical performance compared with several state-of-the-art algorithms for\nfederated learning.\n","authors":["Shenglong Zhou","Geoffrey Ye Li"],"pdf_url":"https://arxiv.org/pdf/2204.10607v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.05589v3","updated":"2022-12-20T09:30:54Z","published":"2021-10-11T20:04:07Z","title":"Next Period Recommendation Reality Check","summary":"  Over the past decade, tremendous progress has been made in Recommender\nSystems (RecSys) for well-known tasks such as next-item and next-basket\nprediction. On the other hand, the recently proposed next-period recommendation\n(NPR) task is not covered as much. Current works about NPR are mostly based\naround distinct problem formulations, methods, and proprietary datasets, making\nsolutions difficult to reproduce. In this article, we aim to fill the gap in\nRecSys methods evaluation on the NPR task using publicly available datasets and\n(1) introduce the TTRS, a large-scale financial transactions dataset suitable\nfor RecSys methods evaluation; (2) benchmark popular RecSys approaches on\nseveral datasets for the NPR task. When performing our analysis, we found a\nstrong repetitive consumption pattern in several real-world datasets. With this\nsetup, our results suggest that the repetitive nature of data is still hard to\ngeneralize for the evaluated RecSys methods, and novel item prediction\nperformance is still questionable.\n","authors":["Sergey Kolesnikov","Oleg Lashinin","Michail Pechatov","Alexander Kosov"],"pdf_url":"https://arxiv.org/pdf/2110.05589v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10105v1","updated":"2022-12-20T09:27:48Z","published":"2022-12-20T09:27:48Z","title":"On the Applicability of Synthetic Data for Re-Identification","summary":"  This contribution demonstrates the feasibility of applying Generative\nAdversarial Networks (GANs) on images of EPAL pallet blocks for dataset\nenhancement in the context of re-identification. For many industrial\napplications of re-identification methods, datasets of sufficient volume would\notherwise be unattainable in non-laboratory settings. Using a state-of-the-art\nGAN architecture, namely CycleGAN, images of pallet blocks rotated to their\nleft-hand side were generated from images of visually centered pallet blocks,\nbased on images of rotated pallet blocks that were recorded as part of a\npreviously recorded and published dataset. In this process, the unique chipwood\npattern of the pallet block surface structure was retained, only changing the\norientation of the pallet block itself. By doing so, synthetic data for\nre-identification testing and training purposes was generated, in a manner that\nis distinct from ordinary data augmentation. In total, 1,004 new images of\npallet blocks were generated. The quality of the generated images was gauged\nusing a perspective classifier that was trained on the original images and then\napplied to the synthetic ones, comparing the accuracy between the two sets of\nimages. The classification accuracy was 98% for the original images and 92% for\nthe synthetic images. In addition, the generated images were also used in a\nre-identification task, in order to re-identify original images based on\nsynthetic ones. The accuracy in this scenario was up to 88% for synthetic\nimages, compared to 96% for original images. Through this evaluation, it is\nestablished, whether or not a generated pallet block image closely resembles\nits original counterpart.\n","authors":["Jérôme Rutinowski","Bhargav Vankayalapati","Nils Schwenzfeier","Maribel Acosta","Christopher Reining"],"pdf_url":"https://arxiv.org/pdf/2212.10105v1.pdf","comment":"Accepted as a non-archival paper in AAAI23 workshop AI2SE"},{"id":"http://arxiv.org/abs/2212.10103v1","updated":"2022-12-20T09:24:25Z","published":"2022-12-20T09:24:25Z","title":"VSVC: Backdoor attack against Keyword Spotting based on Voiceprint\n  Selection and Voice Conversion","summary":"  Keyword spotting (KWS) based on deep neural networks (DNNs) has achieved\nmassive success in voice control scenarios. However, training of such DNN-based\nKWS systems often requires significant data and hardware resources.\nManufacturers often entrust this process to a third-party platform. This makes\nthe training process uncontrollable, where attackers can implant backdoors in\nthe model by manipulating third-party training data. An effective backdoor\nattack can force the model to make specified judgments under certain\nconditions, i.e., triggers. In this paper, we design a backdoor attack scheme\nbased on Voiceprint Selection and Voice Conversion, abbreviated as VSVC.\nExperimental results demonstrated that VSVC is feasible to achieve an average\nattack success rate close to 97% in four victim models when poisoning less than\n1% of the training data.\n","authors":["Hanbo Cai","Pengcheng Zhang","Hai Dong","Yan Xiao","Shunhui Ji"],"pdf_url":"https://arxiv.org/pdf/2212.10103v1.pdf","comment":"7 pages,5 figures"},{"id":"http://arxiv.org/abs/2212.10093v1","updated":"2022-12-20T09:10:25Z","published":"2022-12-20T09:10:25Z","title":"Visual Transformers for Primates Classification and Covid Detection","summary":"  We apply the vision transformer, a deep machine learning model build around\nthe attention mechanism, on mel-spectrogram representations of raw audio\nrecordings. When adding mel-based data augmentation techniques and\nsample-weighting, we achieve comparable performance on both (PRS and CCS\nchallenge) tasks of ComParE21, outperforming most single model baselines. We\nfurther introduce overlapping vertical patching and evaluate the influence of\nparameter configurations. Index Terms: audio classification, attention,\nmel-spectrogram, unbalanced data-sets, computational paralinguistics\n","authors":["Steffen Illium","Robert Müller","Andreas Sedlmeier","Claudia-Linnhoff Popien"],"pdf_url":"https://arxiv.org/pdf/2212.10093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.02209v2","updated":"2022-12-20T08:51:48Z","published":"2022-06-14T16:26:15Z","title":"Tackling Data Scarcity with Transfer Learning: A Case Study of Thickness\n  Characterization from Optical Spectra of Perovskite Thin Films","summary":"  Transfer learning increasingly becomes an important tool in handling data\nscarcity often encountered in machine learning. In the application of\nhigh-throughput thickness as a downstream process of the high-throughput\noptimization of optoelectronic thin films with autonomous workflows, data\nscarcity occurs especially for new materials. To achieve high-throughput\nthickness characterization, we propose a machine learning model called\nthicknessML that predicts thickness from UV-Vis spectrophotometry input and an\noverarching transfer learning workflow. We demonstrate the transfer learning\nworkflow from generic source domain of generic band-gapped materials to\nspecific target domain of perovskite materials, where the target domain data\nonly come from limited number (18) of refractive indices from literature. The\ntarget domain can be easily extended to other material classes with a few\nliterature data. Defining thickness prediction accuracy to be within-10%\ndeviation, thicknessML achieves 92.2% (with a deviation of 3.6%) accuracy with\ntransfer learning compared to 81.8% (with a deviation of 3.6%) 11.7% without\n(lower mean and larger standard deviation). Experimental validation on six\ndeposited perovskite films also corroborates the efficacy of the proposed\nworkflow by yielding a 10.5% mean absolute percentage error (MAPE).\n","authors":["Siyu Isaac Parker Tian","Zekun Ren","Selvaraj Venkataraj","Yuanhang Cheng","Daniil Bash","Felipe Oviedo","J. Senthilnath","Vijila Chellappan","Yee-Fun Lim","Armin G. Aberle","Benjamin P MacLeod","Fraser G. L. Parlane","Curtis P. Berlinguette","Qianxiao Li","Tonio Buonassisi","Zhe Liu"],"pdf_url":"https://arxiv.org/pdf/2207.02209v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10082v1","updated":"2022-12-20T08:47:17Z","published":"2022-12-20T08:47:17Z","title":"An Information-Theoretic Approach to Transferability in Task Transfer\n  Learning","summary":"  Task transfer learning is a popular technique in image processing\napplications that uses pre-trained models to reduce the supervision cost of\nrelated tasks. An important question is to determine task transferability, i.e.\ngiven a common input domain, estimating to what extent representations learned\nfrom a source task can help in learning a target task. Typically,\ntransferability is either measured experimentally or inferred through task\nrelatedness, which is often defined without a clear operational meaning. In\nthis paper, we present a novel metric, H-score, an easily-computable evaluation\nfunction that estimates the performance of transferred representations from one\ntask to another in classification problems using statistical and information\ntheoretic principles. Experiments on real image data show that our metric is\nnot only consistent with the empirical transferability measurement, but also\nuseful to practitioners in applications such as source model selection and task\ntransfer curriculum learning.\n","authors":["Yajie Bao","Yang Li","Shao-Lun Huang","Lin Zhang","Lizhong Zheng","Amir Zamir","Leonidas Guibas"],"pdf_url":"https://arxiv.org/pdf/2212.10082v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10081v1","updated":"2022-12-20T08:46:42Z","published":"2022-12-20T08:46:42Z","title":"Galaxy Image Classification using Hierarchical Data Learning with\n  Weighted Sampling and Label Smoothing","summary":"  With the development of a series of Galaxy sky surveys in recent years, the\nobservations increased rapidly, which makes the research of machine learning\nmethods for galaxy image recognition a hot topic. Available automatic galaxy\nimage recognition researches are plagued by the large differences in similarity\nbetween categories, the imbalance of data between different classes, and the\ndiscrepancy between the discrete representation of Galaxy classes and the\nessentially gradual changes from one morphological class to the adjacent class\n(DDRGC). These limitations have motivated several astronomers and machine\nlearning experts to design projects with improved galaxy image recognition\ncapabilities. Therefore, this paper proposes a novel learning method,\n``Hierarchical Imbalanced data learning with Weighted sampling and Label\nsmoothing\" (HIWL). The HIWL consists of three key techniques respectively\ndealing with the above-mentioned three problems: (1) Designed a hierarchical\ngalaxy classification model based on an efficient backbone network; (2)\nUtilized a weighted sampling scheme to deal with the imbalance problem; (3)\nAdopted a label smoothing technique to alleviate the DDRGC problem. We applied\nthis method to galaxy photometric images from the Galaxy Zoo-The Galaxy\nChallenge, exploring the recognition of completely round smooth, in between\nsmooth, cigar-shaped, edge-on and spiral. The overall classification accuracy\nis 96.32\\%, and some superiorities of the HIWL are shown based on recall,\nprecision, and F1-Score in comparing with some related works. In addition, we\nalso explored the visualization of the galaxy image features and model\nattention to understand the foundations of the proposed scheme.\n","authors":["Xiaohua Ma","Xiangru Li","Ali Luo","Jinqu Zhang","Hui Li"],"pdf_url":"https://arxiv.org/pdf/2212.10081v1.pdf","comment":"accepted by MNRAS"},{"id":"http://arxiv.org/abs/2212.10080v1","updated":"2022-12-20T08:43:10Z","published":"2022-12-20T08:43:10Z","title":"Rumour detection using graph neural network and oversampling in\n  benchmark Twitter dataset","summary":"  Recently, online social media has become a primary source for new information\nand misinformation or rumours. In the absence of an automatic rumour detection\nsystem the propagation of rumours has increased manifold leading to serious\nsocietal damages. In this work, we propose a novel method for building\nautomatic rumour detection system by focusing on oversampling to alleviating\nthe fundamental challenges of class imbalance in rumour detection task. Our\noversampling method relies on contextualised data augmentation to generate\nsynthetic samples for underrepresented classes in the dataset. The key idea\nexploits selection of tweets in a thread for augmentation which can be achieved\nby introducing a non-random selection criteria to focus the augmentation\nprocess on relevant tweets. Furthermore, we propose two graph neural\nnetworks(GNN) to model non-linear conversations on a thread. To enhance the\ntweet representations in our method we employed a custom feature selection\ntechnique based on state-of-the-art BERTweet model. Experiments of three\npublicly available datasets confirm that 1) our GNN models outperform the the\ncurrent state-of-the-art classifiers by more than 20%(F1-score); 2) our\noversampling technique increases the model performance by more than\n9%;(F1-score) 3) focusing on relevant tweets for data augmentation via\nnon-random selection criteria can further improve the results; and 4) our\nmethod has superior capabilities to detect rumours at very early stage.\n","authors":["Shaswat Patel","Prince Bansal","Preeti Kaur"],"pdf_url":"https://arxiv.org/pdf/2212.10080v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10079v1","updated":"2022-12-20T08:34:56Z","published":"2022-12-20T08:34:56Z","title":"A Survey on Pretrained Language Models for Neural Code Intelligence","summary":"  As the complexity of modern software continues to escalate, software\nengineering has become an increasingly daunting and error-prone endeavor. In\nrecent years, the field of Neural Code Intelligence (NCI) has emerged as a\npromising solution, leveraging the power of deep learning techniques to tackle\nanalytical tasks on source code with the goal of improving programming\nefficiency and minimizing human errors within the software industry. Pretrained\nlanguage models have become a dominant force in NCI research, consistently\ndelivering state-of-the-art results across a wide range of tasks, including\ncode summarization, generation, and translation. In this paper, we present a\ncomprehensive survey of the NCI domain, including a thorough review of\npretraining techniques, tasks, datasets, and model architectures. We hope this\npaper will serve as a bridge between the natural language and programming\nlanguage communities, offering insights for future research in this rapidly\nevolving field.\n","authors":["Yichen Xu","Yanqiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.10079v1.pdf","comment":"work in progress. 13 pages"},{"id":"http://arxiv.org/abs/2212.10078v1","updated":"2022-12-20T08:33:57Z","published":"2022-12-20T08:33:57Z","title":"Constructing Organism Networks from Collaborative Self-Replicators","summary":"  We introduce organism networks, which function like a single neural network\nbut are composed of several neural particle networks; while each particle\nnetwork fulfils the role of a single weight application within the organism\nnetwork, it is also trained to self-replicate its own weights. As organism\nnetworks feature vastly more parameters than simpler architectures, we perform\nour initial experiments on an arithmetic task as well as on simplified\nMNIST-dataset classification as a collective. We observe that individual\nparticle networks tend to specialise in either of the tasks and that the ones\nfully specialised in the secondary task may be dropped from the network without\nhindering the computational accuracy of the primary task. This leads to the\ndiscovery of a novel pruning-strategy for sparse neural networks\n","authors":["Steffen Illium","Maximilian Zorn","Cristian Lenta","Michael Kölle","Claudia Linnhoff-Popien","Thomas Gabor"],"pdf_url":"https://arxiv.org/pdf/2212.10078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10076v1","updated":"2022-12-20T08:29:18Z","published":"2022-12-20T08:29:18Z","title":"Out-of-sample scoring and automatic selection of causal estimators","summary":"  Recently, many causal estimators for Conditional Average Treatment Effect\n(CATE) and instrumental variable (IV) problems have been published and open\nsourced, allowing to estimate granular impact of both randomized treatments\n(such as A/B tests) and of user choices on the outcomes of interest. However,\nthe practical application of such models has ben hampered by the lack of a\nvalid way to score the performance of such models out of sample, in order to\nselect the best one for a given application. We address that gap by proposing\nnovel scoring approaches for both the CATE case and an important subset of\ninstrumental variable problems, namely those where the instrumental variable is\ncustomer acces to a product feature, and the treatment is the customer's choice\nto use that feature. Being able to score model performance out of sample allows\nus to apply hyperparameter optimization methods to causal model selection and\ntuning. We implement that in an open source package that relies on DoWhy and\nEconML libraries for implementation of causal inference models (and also\nincludes a Transformed Outcome model implementation), and on FLAML for\nhyperparameter optimization and for component models used in the causal models.\nWe demonstrate on synthetic data that optimizing the proposed scores is a\nreliable method for choosing the model and its hyperparameter values, whose\nestimates are close to the true impact, in the randomized CATE and IV cases.\nFurther, we provide examles of applying these methods to real customer data\nfrom Wise.\n","authors":["Egor Kraev","Timo Flesch","Hudson Taylor Lekunze","Mark Harley","Pere Planell Morell"],"pdf_url":"https://arxiv.org/pdf/2212.10076v1.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2212.10071v1","updated":"2022-12-20T08:24:45Z","published":"2022-12-20T08:24:45Z","title":"Large Language Models Are Reasoning Teachers","summary":"  Language models (LMs) have demonstrated remarkable performance on downstream\ntasks, using in-context exemplars or human instructions. Recent works have\nshown that chain-of-thought (CoT) prompting can elicit models to solve complex\nreasoning tasks, step-by-step. However, the efficacy of prompt-based CoT\nmethods is restricted to very large LMs such as GPT-3 (175B), thus limiting\ndeployability. In this paper, we revisit the fine-tuning approach to enable\ncomplex reasoning in smaller LMs, optimized to efficiently perform a specific\ntask. We propose Fine-tune-CoT, a method that leverages the capabilities of\nvery large LMs to generate reasoning samples and teach smaller models via\nfine-tuning. We evaluate our method on publicly available LMs across a wide\nrange of complex tasks and model sizes. We find that Fine-tune-CoT enables\nsubstantial reasoning capability in small models, whereas previous prompt-based\nbaselines exhibit near-random performance. Student models can even outperform\nthe teacher in some tasks while reducing model size requirements by several\norders of magnitude. We conduct extensive ablations and sample studies to\nunderstand the reasoning capabilities of student models. We also identify\nseveral important nuances that have been overlooked in concurrent fine-tuning\nworks on CoT and address them in our analysis.\n","authors":["Namgyu Ho","Laura Schmid","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2212.10071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10064v1","updated":"2022-12-20T08:13:29Z","published":"2022-12-20T08:13:29Z","title":"AdverSAR: Adversarial Search and Rescue via Multi-Agent Reinforcement\n  Learning","summary":"  Search and Rescue (SAR) missions in remote environments often employ\nautonomous multi-robot systems that learn, plan, and execute a combination of\nlocal single-robot control actions, group primitives, and global\nmission-oriented coordination and collaboration. Often, SAR coordination\nstrategies are manually designed by human experts who can remotely control the\nmulti-robot system and enable semi-autonomous operations. However, in remote\nenvironments where connectivity is limited and human intervention is often not\npossible, decentralized collaboration strategies are needed for\nfully-autonomous operations. Nevertheless, decentralized coordination may be\nineffective in adversarial environments due to sensor noise, actuation faults,\nor manipulation of inter-agent communication data. In this paper, we propose an\nalgorithmic approach based on adversarial multi-agent reinforcement learning\n(MARL) that allows robots to efficiently coordinate their strategies in the\npresence of adversarial inter-agent communications. In our setup, the objective\nof the multi-robot team is to discover targets strategically in an\nobstacle-strewn geographical area by minimizing the average time needed to find\nthe targets. It is assumed that the robots have no prior knowledge of the\ntarget locations, and they can interact with only a subset of neighboring\nrobots at any time. Based on the centralized training with decentralized\nexecution (CTDE) paradigm in MARL, we utilize a hierarchical meta-learning\nframework to learn dynamic team-coordination modalities and discover emergent\nteam behavior under complex cooperative-competitive scenarios. The\neffectiveness of our approach is demonstrated on a collection of prototype\ngrid-world environments with different specifications of benign and adversarial\nagents, target locations, and agent rewards.\n","authors":["Aowabin Rahman","Arnab Bhattacharya","Thiagarajan Ramachandran","Sayak Mukherjee","Himanshu Sharma","Ted Fujimoto","Samrat Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2212.10064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10054v1","updated":"2022-12-20T08:01:03Z","published":"2022-12-20T08:01:03Z","title":"VoronoiPatches: Evaluating A New Data Augmentation Method","summary":"  Overfitting is a problem in Convolutional Neural Networks (CNN) that causes\npoor generalization of models on unseen data. To remediate this problem, many\nnew and diverse data augmentation methods (DA) have been proposed to supplement\nor generate more training data, and thereby increase its quality. In this work,\nwe propose a new data augmentation algorithm: VoronoiPatches (VP). We primarily\nutilize non-linear recombination of information within an image, fragmenting\nand occluding small information patches. Unlike other DA methods, VP uses small\nconvex polygon-shaped patches in a random layout to transport information\naround within an image. Sudden transitions created between patches and the\noriginal image can, optionally, be smoothed. In our experiments, VP\noutperformed current DA methods regarding model variance and overfitting\ntendencies. We demonstrate data augmentation utilizing non-linear\nre-combination of information within images, and non-orthogonal shapes and\nstructures improves CNN model robustness on unseen data.\n","authors":["Steffen Illium","Gretchen Griffin","Michael Kölle","Maximilian Zorn","Jonas Nüßlein","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2212.10054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10048v1","updated":"2022-12-20T07:44:48Z","published":"2022-12-20T07:44:48Z","title":"Asynchronous Distributed Bilevel Optimization","summary":"  Bilevel optimization plays an essential role in many machine learning tasks,\nranging from hyperparameter optimization to meta-learning. Existing studies on\nbilevel optimization, however, focus on either centralized or synchronous\ndistributed setting. The centralized bilevel optimization approaches require\ncollecting massive amount of data to a single server, which inevitably incur\nsignificant communication expenses and may give rise to data privacy risks.\nSynchronous distributed bilevel optimization algorithms, on the other hand,\noften face the straggler problem and will immediately stop working if a few\nworkers fail to respond. As a remedy, we propose Asynchronous Distributed\nBilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel\noptimization problems with both nonconvex upper-level and lower-level objective\nfunctions, and its convergence is theoretically guaranteed. Furthermore, it is\nrevealed through theoretic analysis that the iteration complexity of ADBO to\nobtain the $\\epsilon$-stationary point is upper bounded by\n$\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public\ndatasets have been conducted to elucidate the effectiveness and efficiency of\nthe proposed ADBO.\n","authors":["Yang Jiao","Kai Yang","Tiancheng Wu","Dongjin Song","Chengtao Jian"],"pdf_url":"https://arxiv.org/pdf/2212.10048v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.01191v6","updated":"2022-12-20T07:28:58Z","published":"2021-10-04T05:11:23Z","title":"Molformer: Motif-based Transformer on 3D Heterogeneous Molecular Graphs","summary":"  Procuring expressive molecular representations underpins AI-driven molecule\ndesign and scientific discovery. The research mainly focuses on atom-level\nhomogeneous molecular graphs, ignoring the rich information in subgraphs or\nmotifs. However, it has been widely accepted that substructures play a dominant\nrole in identifying and determining molecular properties. To address such\nissues, we formulate heterogeneous molecular graphs (HMGs), and introduce a\nnovel architecture to exploit both molecular motifs and 3D geometry. Precisely,\nwe extract functional groups as motifs for small molecules and employ\nreinforcement learning to adaptively select quaternary amino acids as motif\ncandidates for proteins. Then HMGs are constructed with both atom-level and\nmotif-level nodes. To better accommodate those HMGs, we introduce a variant of\nTransformer named Molformer, which adopts a heterogeneous self-attention layer\nto distinguish the interactions between multi-level nodes. Besides, it is also\ncoupled with a multi-scale mechanism to capture fine-grained local patterns\nwith increasing contextual scales. An attentive farthest point sampling\nalgorithm is also proposed to obtain the molecular representations. We validate\nMolformer across a broad range of domains, including quantum chemistry,\nphysiology, and biophysics. Extensive experiments show that Molformer\noutperforms or achieves the comparable performance of several state-of-the-art\nbaselines. Our work provides a promising way to utilize informative motifs from\nthe perspective of multi-level graph construction.\n","authors":["Fang Wu","Dragomir Radev","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2110.01191v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.03323v5","updated":"2022-12-20T07:23:37Z","published":"2021-06-07T03:51:25Z","title":"A Comprehensive Survey and Taxonomy on Single Image Dehazing Based on\n  Deep Learning","summary":"  With the development of convolutional neural networks, hundreds of deep\nlearning based dehazing methods have been proposed. In this paper, we provide a\ncomprehensive survey on supervised, semi-supervised, and unsupervised single\nimage dehazing. We first discuss the physical model, datasets, network modules,\nloss functions, and evaluation metrics that are commonly used. Then, the main\ncontributions of various dehazing algorithms are categorized and summarized.\nFurther, quantitative and qualitative experiments of various baseline methods\nare carried out. Finally, the unsolved issues and challenges that can inspire\nthe future research are pointed out. A collection of useful dehazing materials\nis available at \\url{https://github.com/Xiaofeng-life/AwesomeDehazing}.\n","authors":["Jie Gui","Xiaofeng Cong","Yuan Cao","Wenqi Ren","Jun Zhang","Jing Zhang","Jiuxin Cao","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2106.03323v5.pdf","comment":"This paper is accepted by ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2212.10032v1","updated":"2022-12-20T07:07:44Z","published":"2022-12-20T07:07:44Z","title":"Real-time Health Monitoring of Heat Exchangers using Hypernetworks and\n  PINNs","summary":"  We demonstrate a Physics-informed Neural Network (PINN) based model for\nreal-time health monitoring of a heat exchanger, that plays a critical role in\nimproving energy efficiency of thermal power plants. A hypernetwork based\napproach is used to enable the domain-decomposed PINN learn the thermal\nbehavior of the heat exchanger in response to dynamic boundary conditions,\neliminating the need to re-train. As a result, we achieve orders of magnitude\nreduction in inference time in comparison to existing PINNs, while maintaining\nthe accuracy on par with the physics-based simulations. This makes the approach\nvery attractive for predictive maintenance of the heat exchanger in digital\ntwin environments.\n","authors":["Ritam Majumdar","Vishal Jadhav","Anirudh Deodhar","Shirish Karande","Lovekesh Vig","Venkataramana Runkana"],"pdf_url":"https://arxiv.org/pdf/2212.10032v1.pdf","comment":"Neural Information Processing Systems 2022: The Machine Learning and\n  the Physical Sciences workshop"},{"id":"http://arxiv.org/abs/2212.09000v2","updated":"2022-12-20T06:52:07Z","published":"2022-12-18T03:57:12Z","title":"Confidence-aware Training of Smoothed Classifiers for Certified\n  Robustness","summary":"  Any classifier can be \"smoothed out\" under Gaussian noise to build a new\nclassifier that is provably robust to $\\ell_2$-adversarial perturbations, viz.,\nby averaging its predictions over the noise via randomized smoothing. Under the\nsmoothed classifiers, the fundamental trade-off between accuracy and\n(adversarial) robustness has been well evidenced in the literature: i.e.,\nincreasing the robustness of a classifier for an input can be at the expense of\ndecreased accuracy for some other inputs. In this paper, we propose a simple\ntraining method leveraging this trade-off to obtain robust smoothed\nclassifiers, in particular, through a sample-wise control of robustness over\nthe training samples. We make this control feasible by using \"accuracy under\nGaussian noise\" as an easy-to-compute proxy of adversarial robustness for an\ninput. Specifically, we differentiate the training objective depending on this\nproxy to filter out samples that are unlikely to benefit from the worst-case\n(adversarial) objective. Our experiments show that the proposed method, despite\nits simplicity, consistently exhibits improved certified robustness upon\nstate-of-the-art training methods. Somewhat surprisingly, we find these\nimprovements persist even for other notions of robustness, e.g., to various\ntypes of common corruptions.\n","authors":["Jongheon Jeong","Seojin Kim","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2212.09000v2.pdf","comment":"21 pages; AAAI 2023; Code is available at\n  https://github.com/alinlab/smoothing-catrs"},{"id":"http://arxiv.org/abs/2207.06240v2","updated":"2022-12-20T06:48:39Z","published":"2022-07-11T16:04:20Z","title":"Physics Informed Symbolic Networks","summary":"  We introduce Physics Informed Symbolic Networks (PISN) which utilize\nphysics-informed loss to obtain a symbolic solution for a system of Partial\nDifferential Equations (PDE). Given a context-free grammar to describe the\nlanguage of symbolic expressions, we propose to use weighted sum as continuous\napproximation for selection of a production rule. We use this approximation to\ndefine multilayer symbolic networks. We consider Kovasznay flow (Navier-Stokes)\nand two-dimensional viscous Burger's equations to illustrate that PISN are able\nto provide a performance comparable to PINNs across various start-of-the-art\nadvances: multiple outputs and governing equations, domain-decomposition,\nhypernetworks. Furthermore, we propose Physics-informed Neurosymbolic Networks\n(PINSN) which employ a multilayer perceptron (MLP) operator to model the\nresidue of symbolic networks. PINSNs are observed to give 2-3 orders of\nperformance gain over standard PINN.\n","authors":["Ritam Majumdar","Vishal Jadhav","Anirudh Deodhar","Shirish Karande","Lovekesh Vig","Venkataramana Runkana"],"pdf_url":"https://arxiv.org/pdf/2207.06240v2.pdf","comment":"Neural Information Processing Systems 2022: The Symbiosis of Deep\n  Learning and Differential Equations Workshop"},{"id":"http://arxiv.org/abs/2212.10025v1","updated":"2022-12-20T06:44:32Z","published":"2022-12-20T06:44:32Z","title":"When Federated Learning Meets Pre-trained Language Models'\n  Parameter-Efficient Tuning Methods","summary":"  With increasing privacy concerns on data, recent studies have made\nsignificant progress using federated learning (FL) on privacy-sensitive natural\nlanguage processing (NLP) tasks. Much literature suggests fully fine-tuning\npre-trained language models (PLMs) in the FL paradigm can mitigate the data\nheterogeneity problem and close the performance gap with centralized training.\nHowever, large PLMs bring the curse of prohibitive communication overhead and\nlocal model adaptation costs for the FL system. To this end, we introduce\nvarious parameter-efficient tuning (PETuning) methods into federated learning.\nSpecifically, we provide a holistic empirical study of representative PLMs\ntuning methods in FL. The experimental results cover the analysis of data\nheterogeneity levels, data scales, and different FL scenarios. Overall\ncommunication overhead can be significantly reduced by locally tuning and\nglobally aggregating lightweight model parameters while maintaining acceptable\nperformance in various FL settings. To facilitate the research of PETuning in\nFL, we also develop a federated tuning framework FedPETuning, which allows\npractitioners to exploit different PETuning methods under the FL training\nparadigm conveniently. The source code is available at\n\\url{https://github.com/iezhuozhuo/FedETuning/tree/deltaTuning}.\n","authors":["Zhuo Zhang","Yuanhang Yang","Yong Dai","Lizhen Qu","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2212.10025v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09321v2","updated":"2022-12-20T06:37:00Z","published":"2022-12-19T09:39:30Z","title":"Learning from Training Dynamics: Identifying Mislabeled Data Beyond\n  Manually Designed Features","summary":"  While mislabeled or ambiguously-labeled samples in the training set could\nnegatively affect the performance of deep models, diagnosing the dataset and\nidentifying mislabeled samples helps to improve the generalization power.\nTraining dynamics, i.e., the traces left by iterations of optimization\nalgorithms, have recently been proved to be effective to localize mislabeled\nsamples with hand-crafted features. In this paper, beyond manually designed\nfeatures, we introduce a novel learning-based solution, leveraging a noise\ndetector, instanced by an LSTM network, which learns to predict whether a\nsample was mislabeled using the raw training dynamics as input. Specifically,\nthe proposed method trains the noise detector in a supervised manner using the\ndataset with synthesized label noises and can adapt to various datasets (either\nnaturally or synthesized label-noised) without retraining. We conduct extensive\nexperiments to evaluate the proposed method. We train the noise detector based\non the synthesized label-noised CIFAR dataset and test such noise detector on\nTiny ImageNet, CUB-200, Caltech-256, WebVision and Clothing1M. Results show\nthat the proposed method precisely detects mislabeled samples on various\ndatasets without further adaptation, and outperforms state-of-the-art methods.\nBesides, more experiments demonstrate that the mislabel identification can\nguide a label correction, namely data debugging, providing orthogonal\nimprovements of algorithm-centric state-of-the-art techniques from the data\naspect.\n","authors":["Qingrui Jia","Xuhong Li","Lei Yu","Jiang Bian","Penghao Zhao","Shupeng Li","Haoyi Xiong","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2212.09321v2.pdf","comment":"AAAI23 accepted Conference Paper"},{"id":"http://arxiv.org/abs/2206.01995v5","updated":"2022-12-20T06:17:13Z","published":"2022-06-04T14:14:58Z","title":"Combinatorial Causal Bandits","summary":"  In combinatorial causal bandits (CCB), the learning agent chooses at most $K$\nvariables in each round to intervene, collects feedback from the observed\nvariables, with the goal of minimizing expected regret on the target variable\n$Y$. We study under the context of binary generalized linear models (BGLMs)\nwith a succinct parametric representation of the causal models. We present the\nalgorithm BGLM-OFU for Markovian BGLMs (i.e. no hidden variables) based on the\nmaximum likelihood estimation method, and show that it achieves $O(\\sqrt{T}\\log\nT)$ regret, where $T$ is the time horizon. For the special case of linear\nmodels with hidden variables, we apply causal inference techniques such as the\ndo-calculus to convert the original model into a Markovian model, and then show\nthat our BGLM-OFU algorithm and another algorithm based on the linear\nregression both solve such linear models with hidden variables. Our novelty\nincludes (a) considering the combinatorial intervention action space and the\ngeneral causal models including ones with hidden variables, (b) integrating and\nadapting techniques from diverse studies such as generalized linear bandits and\nonline influence maximization, and (c) avoiding unrealistic assumptions (such\nas knowing the joint distribution of the parents of $Y$ under all\ninterventions) and regret factors exponential to causal graph size in prior\nstudies.\n","authors":["Shi Feng","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2206.01995v5.pdf","comment":"30 pages, 9 figures"},{"id":"http://arxiv.org/abs/2209.04130v2","updated":"2022-12-20T06:09:57Z","published":"2022-09-09T06:07:17Z","title":"In-situ animal behavior classification using knowledge distillation and\n  fixed-point quantization","summary":"  We explore the use of knowledge distillation (KD) for learning compact and\naccurate models that enable classification of animal behavior from\naccelerometry data on wearable devices. To this end, we take a deep and complex\nconvolutional neural network, known as residual neural network (ResNet), as the\nteacher model. ResNet is specifically designed for multivariate time-series\nclassification. We use ResNet to distill the knowledge of animal behavior\nclassification datasets into soft labels, which consist of the predicted\npseudo-probabilities of every class for each datapoint. We then use the soft\nlabels to train our significantly less complex student models, which are based\non the gated recurrent unit (GRU) and multilayer perceptron (MLP). The\nevaluation results using two real-world animal behavior classification datasets\nshow that the classification accuracy of the student GRU-MLP models improves\nappreciably through KD, approaching that of the teacher ResNet model. To\nfurther reduce the computational and memory requirements of performing\ninference using the student models trained via KD, we utilize dynamic\nfixed-point quantization (DQ) through an appropriate modification of the\ncomputational graph of the considered models. We implement both unquantized and\nquantized versions of the developed KD-based models on the embedded systems of\nour purpose-built collar and ear tag devices to classify animal behavior in\nsitu and in real time. Our evaluations corroborate the effectiveness of KD and\nDQ in improving the accuracy and efficiency of in-situ animal behavior\nclassification.\n","authors":["Reza Arablouei","Liang Wang","Caitlin Phillips","Lachlan Currie","Jordan Yates","Greg Bishop-Hurley"],"pdf_url":"https://arxiv.org/pdf/2209.04130v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10010v1","updated":"2022-12-20T05:57:27Z","published":"2022-12-20T05:57:27Z","title":"Identifying latent distances with Finslerian geometry","summary":"  Riemannian geometry provides powerful tools to explore the latent space of\ngenerative models while preserving the inherent structure of the data manifold.\nLengths, energies and volume measures can be derived from a pullback metric,\ndefined through the immersion that maps the latent space to the data space.\nWith this in mind, most generative models are stochastic, and so is the\npullback metric. Manipulating stochastic objects is strenuous in practice. In\norder to perform operations such as interpolations, or measuring the distance\nbetween data points, we need a deterministic approximation of the pullback\nmetric. In this work, we are defining a new metric as the expected length\nderived from the stochastic pullback metric. We show this metric is Finslerian,\nand we compare it with the expected pullback metric. In high dimensions, we\nshow that the metrics converge to each other at a rate of\n$\\mathcal{O}\\left(\\frac{1}{D}\\right)$.\n","authors":["Alison Pouplin","David Eklund","Carl Henrik Ek","Søren Hauberg"],"pdf_url":"https://arxiv.org/pdf/2212.10010v1.pdf","comment":"32 pages, 12 figures, Poster presentation at NeurIPS 2022 workshop:\n  \"Symmetry and Geometry in Neural Representations\""},{"id":"http://arxiv.org/abs/2202.12416v4","updated":"2022-12-20T05:45:13Z","published":"2022-02-24T23:24:52Z","title":"Microgrid Optimal Energy Scheduling Considering Neural Network based\n  Battery Degradation","summary":"  Battery energy storage system (BESS) can effec-tively mitigate the\nuncertainty of variable renewable generation. Degradation is unpreventable and\nhard to model and predict for batteries such as the most popular Lithium-ion\nbattery (LiB). In this paper, we propose a data driven method to predict the\nbat-tery degradation per a given scheduled battery operational pro-file.\nParticularly, a neural network based battery degradation (NNBD) model is\nproposed to quantify the battery degradation with inputs of major battery\ndegradation factors. When incorpo-rating the proposed NNBD model into microgrid\nday-ahead scheduling (MDS), we can establish a battery degradation based MDS\n(BDMDS) model that can consider the equivalent battery degradation cost\nprecisely with the proposed cycle based battery usage processing (CBUP) method\nfor the NNBD model. Since the proposed NNBD model is highly non-linear and\nnon-convex, BDMDS would be very hard to solve. To address this issue, a neural\nnetwork and optimization decoupled heuristic (NNODH) algorithm is proposed in\nthis paper to effectively solve this neural network embedded optimization\nproblem. Simulation results demonstrate that the proposed NNODH algorithm is\nable to ob-tain the optimal solution with lowest total cost including normal\noperation cost and battery degradation cost.\n","authors":["Cunzhi Zhao","Xingpeng Li"],"pdf_url":"https://arxiv.org/pdf/2202.12416v4.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2212.10006v1","updated":"2022-12-20T05:35:15Z","published":"2022-12-20T05:35:15Z","title":"Multi-head Uncertainty Inference for Adversarial Attack Detection","summary":"  Deep neural networks (DNNs) are sensitive and susceptible to tiny\nperturbation by adversarial attacks which causes erroneous predictions. Various\nmethods, including adversarial defense and uncertainty inference (UI), have\nbeen developed in recent years to overcome the adversarial attacks. In this\npaper, we propose a multi-head uncertainty inference (MH-UI) framework for\ndetecting adversarial attack examples. We adopt a multi-head architecture with\nmultiple prediction heads (i.e., classifiers) to obtain predictions from\ndifferent depths in the DNNs and introduce shallow information for the UI.\nUsing independent heads at different depths, the normalized predictions are\nassumed to follow the same Dirichlet distribution, and we estimate distribution\nparameter of it by moment matching. Cognitive uncertainty brought by the\nadversarial attacks will be reflected and amplified on the distribution.\nExperimental results show that the proposed MH-UI framework can outperform all\nthe referred UI methods in the adversarial attack detection task with different\nsettings.\n","authors":["Yuqi Yang","Songyun Yang","Jiyang Xie. Zhongwei Si","Kai Guo","Ke Zhang","Kongming Liang"],"pdf_url":"https://arxiv.org/pdf/2212.10006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10005v1","updated":"2022-12-20T05:34:58Z","published":"2022-12-20T05:34:58Z","title":"Calibrating Deep Neural Networks using Explicit Regularisation and\n  Dynamic Data Pruning","summary":"  Deep neural networks (DNN) are prone to miscalibrated predictions, often\nexhibiting a mismatch between the predicted output and the associated\nconfidence scores. Contemporary model calibration techniques mitigate the\nproblem of overconfident predictions by pushing down the confidence of the\nwinning class while increasing the confidence of the remaining classes across\nall test samples. However, from a deployment perspective, an ideal model is\ndesired to (i) generate well-calibrated predictions for high-confidence samples\nwith predicted probability say >0.95, and (ii) generate a higher proportion of\nlegitimate high-confidence samples. To this end, we propose a novel\nregularization technique that can be used with classification losses, leading\nto state-of-the-art calibrated predictions at test time; From a deployment\nstandpoint in safety-critical applications, only high-confidence samples from a\nwell-calibrated model are of interest, as the remaining samples have to undergo\nmanual inspection. Predictive confidence reduction of these potentially\n``high-confidence samples'' is a downside of existing calibration approaches.\nWe mitigate this by proposing a dynamic train-time data pruning strategy that\nprunes low-confidence samples every few epochs, providing an increase in\n\"confident yet calibrated samples\". We demonstrate state-of-the-art calibration\nperformance across image classification benchmarks, reducing training time\nwithout much compromise in accuracy. We provide insights into why our dynamic\npruning strategy that prunes low-confidence training samples leads to an\nincrease in high-confidence samples at test time.\n","authors":["Ramya Hebbalaguppe","Rishabh Patra","Tirtharaj Dash","Gautam Shroff","Lovekesh Vig"],"pdf_url":"https://arxiv.org/pdf/2212.10005v1.pdf","comment":"The paper is accepted at Winter Conference on applications of\n  Computer Vision (IEEE WACV) in algorithms tracks. 8 pages Main paper; 3 pages\n  supplementary material"},{"id":"http://arxiv.org/abs/2202.06539v3","updated":"2022-12-20T05:21:40Z","published":"2022-02-14T08:20:15Z","title":"Deduplicating Training Data Mitigates Privacy Risks in Language Models","summary":"  Past work has shown that large language models are susceptible to privacy\nattacks, where adversaries generate sequences from a trained model and detect\nwhich sequences are memorized from the training set. In this work, we show that\nthe success of these attacks is largely due to duplication in commonly used\nweb-scraped training sets. We first show that the rate at which language models\nregenerate training sequences is superlinearly related to a sequence's count in\nthe training set. For instance, a sequence that is present 10 times in the\ntraining data is on average generated ~1000 times more often than a sequence\nthat is present only once. We next show that existing methods for detecting\nmemorized sequences have near-chance accuracy on non-duplicated training\nsequences. Finally, we find that after applying methods to deduplicate training\ndata, language models are considerably more secure against these types of\nprivacy attacks. Taken together, our results motivate an increased focus on\ndeduplication in privacy-sensitive applications and a reevaluation of the\npracticality of existing privacy attacks.\n","authors":["Nikhil Kandpal","Eric Wallace","Colin Raffel"],"pdf_url":"https://arxiv.org/pdf/2202.06539v3.pdf","comment":"ICML 2022 Camera Ready Version"},{"id":"http://arxiv.org/abs/2008.09418v2","updated":"2022-12-20T05:10:47Z","published":"2020-08-21T10:58:33Z","title":"Method to Classify Skin Lesions using Dermoscopic images","summary":"  Skin cancer is the most common cancer in the existing world constituting\none-third of the cancer cases. Benign skin cancers are not fatal, can be cured\nwith proper medication. But it is not the same as the malignant skin cancers.\nIn the case of malignant melanoma, in its peak stage, the maximum life\nexpectancy is less than or equal to 5 years. But, it can be cured if detected\nin early stages. Though there are numerous clinical procedures, the accuracy of\ndiagnosis falls between 49% to 81% and is time-consuming. So, dermoscopy has\nbeen brought into the picture. It helped in increasing the accuracy of\ndiagnosis but could not demolish the error-prone behaviour. A quick and less\nerror-prone solution is needed to diagnose this majorly growing skin cancer.\nThis project deals with the usage of deep learning in skin lesion\nclassification. In this project, an automated model for skin lesion\nclassification using dermoscopic images has been developed with CNN(Convolution\nNeural Networks) as a training model. Convolution neural networks are known for\ncapturing features of an image. So, they are preferred in analyzing medical\nimages to find the characteristics that drive the model towards success.\nTechniques like data augmentation for tackling class imbalance, segmentation\nfor focusing on the region of interest and 10-fold cross-validation to make the\nmodel robust have been brought into the picture. This project also includes\nusage of certain preprocessing techniques like brightening the images using\npiece-wise linear transformation function, grayscale conversion of the image,\nresize the image. This project throws a set of valuable insights on how the\naccuracy of the model hikes with the bringing of new input strategies,\npreprocessing techniques. The best accuracy this model could achieve is 0.886.\n","authors":["Dusa Sai Charan","Hemanth Nadipineni","Subin Sahayam","Umarani Jayaraman"],"pdf_url":"https://arxiv.org/pdf/2008.09418v2.pdf","comment":"16 pages, 14 figures"},{"id":"http://arxiv.org/abs/2209.06257v2","updated":"2022-12-20T04:54:11Z","published":"2022-09-13T18:31:23Z","title":"SciMED: A Computational Framework For Physics-Informed Symbolic\n  Regression with Scientist-In-The-Loop","summary":"  Discovering a meaningful symbolic expression that explains experimental data\nis a fundamental challenge in many scientific fields. We present a novel,\nopen-source computational framework called Scientist-Machine Equation Detector\n(SciMed), which integrates scientific discipline wisdom in a\nscientist-in-the-loop approach, with state-of-the-art symbolic regression (SR)\nmethods. SciMed combines a wrapper selection method, that is based on a genetic\nalgorithm, with automatic machine learning and two levels of SR methods. We\ntest SciMed on five configurations of a settling sphere, with and without\naerodynamic non-linear drag force, and with excessive noise in the\nmeasurements. We show that SciMed is sufficiently robust to discover the\ncorrect physically meaningful symbolic expressions from the data, and\ndemonstrate how the integration of domain knowledge enhances its performance.\nOur results indicate better performance on these tasks than the\nstate-of-the-art SR software packages, even in cases where no knowledge is\nintegrated. Moreover, we demonstrate how SciMed can alert the user about\npossible missing features, unlike the majority of current SR systems.\n","authors":["Liron Simon Keren","Alex Liberzon","Teddy Lazebnik"],"pdf_url":"https://arxiv.org/pdf/2209.06257v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.03337v2","updated":"2022-12-20T04:52:41Z","published":"2021-03-04T21:15:37Z","title":"Revisiting Priority $k$-Center: Fairness and Outliers","summary":"  In the Priority $k$-Center problem, the input consists of a metric space\n$(X,d)$, an integer $k$, and for each point $v \\in X$ a priority radius $r(v)$.\nThe goal is to choose $k$-centers $S \\subseteq X$ to minimize $\\max_{v \\in X}\n\\frac{1}{r(v)} d(v,S)$. If all $r(v)$'s are uniform, one obtains the $k$-Center\nproblem. Plesn\\'ik [Plesn\\'ik, Disc. Appl. Math. 1987] introduced the Priority\n$k$-Center problem and gave a $2$-approximation algorithm matching the best\npossible algorithm for $k$-Center. We show how the problem is related to two\ndifferent notions of fair clustering [Harris et al., NeurIPS 2018; Jung et al.,\nFORC 2020]. Motivated by these developments we revisit the problem and, in our\nmain technical contribution, develop a framework that yields constant factor\napproximation algorithms for Priority $k$-Center with outliers. Our framework\nextends to generalizations of Priority $k$-Center to matroid and knapsack\nconstraints, and as a corollary, also yields algorithms with fairness\nguarantees in the lottery model of Harris et al [Harris et al, JMLR 2019].\n","authors":["Tanvi Bajpai","Deeparnab Chakrabarty","Chandra Chekuri","Maryam Negahbani"],"pdf_url":"https://arxiv.org/pdf/2103.03337v2.pdf","comment":"34 pages, 1 figure"},{"id":"http://arxiv.org/abs/2212.09993v1","updated":"2022-12-20T04:33:32Z","published":"2022-12-20T04:33:32Z","title":"Are Deep Neural Networks SMARTer than Second Graders?","summary":"  Recent times have witnessed an increasing number of applications of deep\nneural networks towards solving tasks that require superior cognitive\nabilities, e.g., playing Go, generating art, question answering (such as\nChatGPT), etc. Such a dramatic progress raises the question: how generalizable\nare neural networks in solving problems that demand broad skills? To answer\nthis question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task\nand the associated SMART-101 dataset, for evaluating the abstraction,\ndeduction, and generalization abilities of neural networks in solving\nvisuo-linguistic puzzles designed specifically for children in the 6-8 age\ngroup. Our dataset consists of 101 unique puzzles; each puzzle comprises a\npicture and a question, and their solution needs a mix of several elementary\nskills, including arithmetic, algebra, and spatial reasoning, among others. To\nscale our dataset towards training deep neural networks, we programmatically\ngenerate entirely new instances for each puzzle while retaining their solution\nalgorithm. To benchmark the performance on the SMART-101 dataset, we propose a\nvision and language meta-learning model using varied state-of-the-art backbone\nneural networks. Our experiments reveal that while powerful deep models offer\nreasonable performances on puzzles that they are trained on, they are not\nbetter than random accuracy when analyzed for generalization. We also evaluate\nthe recent ChatGPT large language model on a subset of our dataset and find\nthat while ChatGPT produces convincing reasoning abilities, the answers are\noften incorrect.\n","authors":["Anoop Cherian","Kuan-Chuan Peng","Suhas Lohit","Kevin Smith","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2212.09993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09991v1","updated":"2022-12-20T04:21:19Z","published":"2022-12-20T04:21:19Z","title":"Dynamic Molecular Graph-based Implementation for Biophysical Properties\n  Prediction","summary":"  Neural Networks (GNNs) have revolutionized the molecular discovery to\nunderstand patterns and identify unknown features that can aid in predicting\nbiophysical properties and protein-ligand interactions. However, current models\ntypically rely on 2-dimensional molecular representations as input, and while\nutilization of 2\\3- dimensional structural data has gained deserved traction in\nrecent years as many of these models are still limited to static graph\nrepresentations. We propose a novel approach based on the transformer model\nutilizing GNNs for characterizing dynamic features of protein-ligand\ninteractions. Our message passing transformer pre-trains on a set of molecular\ndynamic data based off of physics-based simulations to learn coordinate\nconstruction and make binding probability and affinity predictions as a\ndownstream task. Through extensive testing we compare our results with the\nexisting models, our MDA-PLI model was able to outperform the molecular\ninteraction prediction models with an RMSE of 1.2958. The geometric encodings\nenabled by our transformer architecture and the addition of time series data\nadd a new dimensionality to this form of research.\n","authors":["Carter Knutson","Gihan Panapitiya","Rohith Varikoti","Neeraj Kumar"],"pdf_url":"https://arxiv.org/pdf/2212.09991v1.pdf","comment":"4 pages and appendix, 3 figures, Ellis Critical assessment of\n  molecular machine learning workshop [ML4Molecules] 2022 poster session"},{"id":"http://arxiv.org/abs/2208.09215v2","updated":"2022-12-20T04:13:57Z","published":"2022-08-19T08:37:09Z","title":"Almost Cost-Free Communication in Federated Best Arm Identification","summary":"  We study the problem of best arm identification in a federated learning\nmulti-armed bandit setup with a central server and multiple clients. Each\nclient is associated with a multi-armed bandit in which each arm yields {\\em\ni.i.d.}\\ rewards following a Gaussian distribution with an unknown mean and\nknown variance. The set of arms is assumed to be the same at all the clients.\nWe define two notions of best arm -- local and global. The local best arm at a\nclient is the arm with the largest mean among the arms local to the client,\nwhereas the global best arm is the arm with the largest average mean across all\nthe clients. We assume that each client can only observe the rewards from its\nlocal arms and thereby estimate its local best arm. The clients communicate\nwith a central server on uplinks that entail a cost of $C\\ge0$ units per usage\nper uplink. The global best arm is estimated at the server. The goal is to\nidentify the local best arms and the global best arm with minimal total cost,\ndefined as the sum of the total number of arm selections at all the clients and\nthe total communication cost, subject to an upper bound on the error\nprobability. We propose a novel algorithm {\\sc FedElim} that is based on\nsuccessive elimination and communicates only in exponential time steps and\nobtain a high probability instance-dependent upper bound on its total cost. The\nkey takeaway from our paper is that for any $C\\geq 0$ and error probabilities\nsufficiently small, the total number of arm selections (resp.\\ the total cost)\nunder {\\sc FedElim} is at most~$2$ (resp.~$3$) times the maximum total number\nof arm selections under its variant that communicates in every time step.\nAdditionally, we show that the latter is optimal in expectation up to a\nconstant factor, thereby demonstrating that communication is almost cost-free\nin {\\sc FedElim}. We numerically validate the efficacy of {\\sc FedElim}.\n","authors":["Kota Srinivas Reddy","P. N. Karthik","Vincent Y. F. Tan"],"pdf_url":"https://arxiv.org/pdf/2208.09215v2.pdf","comment":"Accepted to AAAI 2023"},{"id":"http://arxiv.org/abs/2212.09984v1","updated":"2022-12-20T04:00:58Z","published":"2022-12-20T04:00:58Z","title":"Using Machine Learning to Determine Morphologies of $z<1$ AGN Host\n  Galaxies in the Hyper Suprime-Cam Wide Survey","summary":"  We present a machine-learning framework to accurately characterize\nmorphologies of Active Galactic Nucleus (AGN) host galaxies within $z<1$. We\nfirst use PSFGAN to decouple host galaxy light from the central point source,\nthen we invoke the Galaxy Morphology Network (GaMorNet) to estimate whether the\nhost galaxy is disk-dominated, bulge-dominated, or indeterminate. Using optical\nimages from five bands of the HSC Wide Survey, we build models independently in\nthree redshift bins: low $(0<z<0.25)$, medium $(0.25<z<0.5)$, and high\n$(0.5<z<1.0)$. By first training on a large number of simulated galaxies, then\nfine-tuning using far fewer classified real galaxies, our framework predicts\nthe actual morphology for $\\sim$ $60\\%-70\\%$ host galaxies from test sets, with\na classification precision of $\\sim$ $80\\%-95\\%$, depending on redshift bin.\nSpecifically, our models achieve disk precision of $96\\%/82\\%/79\\%$ and bulge\nprecision of $90\\%/90\\%/80\\%$ (for the 3 redshift bins), at thresholds\ncorresponding to indeterminate fractions of $30\\%/43\\%/42\\%$. The\nclassification precision of our models has a noticeable dependency on host\ngalaxy radius and magnitude. No strong dependency is observed on contrast\nratio. Comparing classifications of real AGNs, our models agree well with\ntraditional 2D fitting with GALFIT. The PSFGAN+GaMorNet framework does not\ndepend on the choice of fitting functions or galaxy-related input parameters,\nruns orders of magnitude faster than GALFIT, and is easily generalizable via\ntransfer learning, making it an ideal tool for studying AGN host galaxy\nmorphology in forthcoming large imaging survey.\n","authors":["Chuan Tian","C. Megan Urry","Aritra Ghosh","Ryan Ofman","Tonima Tasnim Ananna","Connor Auge","Nico Cappelluti","Meredith C. Powell","David B. Sanders","Kevin Schawinski","Dominic Stark","Grant R. Tremblay"],"pdf_url":"https://arxiv.org/pdf/2212.09984v1.pdf","comment":"Accepted for publication in The Astrophysical Journal. 35 Pages. 25\n  Figures"},{"id":"http://arxiv.org/abs/2212.09981v1","updated":"2022-12-20T03:45:38Z","published":"2022-12-20T03:45:38Z","title":"Benchmarking person re-identification datasets and approaches for\n  practical real-world implementations","summary":"  Recently, Person Re-Identification (Re-ID) has received a lot of attention.\nLarge datasets containing labeled images of various individuals have been\nreleased, allowing researchers to develop and test many successful approaches.\nHowever, when such Re-ID models are deployed in new cities or environments, the\ntask of searching for people within a network of security cameras is likely to\nface an important domain shift, thus resulting in decreased performance.\nIndeed, while most public datasets were collected in a limited geographic area,\nimages from a new city present different features (e.g., people's ethnicity and\nclothing style, weather, architecture, etc.). In addition, the whole frames of\nthe video streams must be converted into cropped images of people using\npedestrian detection models, which behave differently from the human annotators\nwho created the dataset used for training. To better understand the extent of\nthis issue, this paper introduces a complete methodology to evaluate Re-ID\napproaches and training datasets with respect to their suitability for\nunsupervised deployment for live operations. This method is used to benchmark\nfour Re-ID approaches on three datasets, providing insight and guidelines that\ncan help to design better Re-ID pipelines in the future.\n","authors":["Jose Huaman","Felix O. Sumari","Luigy Machaca","Esteban Clua","Joris Guerin"],"pdf_url":"https://arxiv.org/pdf/2212.09981v1.pdf","comment":"This paper is the extended version of our short paper accepted in\n  VISAPP - 2023"},{"id":"http://arxiv.org/abs/2212.09980v1","updated":"2022-12-20T03:44:25Z","published":"2022-12-20T03:44:25Z","title":"Continual Mean Estimation Under User-Level Privacy","summary":"  We consider the problem of continually releasing an estimate of the\npopulation mean of a stream of samples that is user-level differentially\nprivate (DP). At each time instant, a user contributes a sample, and the users\ncan arrive in arbitrary order. Until now these requirements of continual\nrelease and user-level privacy were considered in isolation. But, in practice,\nboth these requirements come together as the users often contribute data\nrepeatedly and multiple queries are made. We provide an algorithm that outputs\na mean estimate at every time instant $t$ such that the overall release is\nuser-level $\\varepsilon$-DP and has the following error guarantee: Denoting by\n$M_t$ the maximum number of samples contributed by a user, as long as\n$\\tilde{\\Omega}(1/\\varepsilon)$ users have $M_t/2$ samples each, the error at\ntime $t$ is $\\tilde{O}(1/\\sqrt{t}+\\sqrt{M}_t/t\\varepsilon)$. This is a\nuniversal error guarantee which is valid for all arrival patterns of the users.\nFurthermore, it (almost) matches the existing lower bounds for the\nsingle-release setting at all time instants when users have contributed equal\nnumber of samples.\n","authors":["Anand Jerry George","Lekshmi Ramesh","Aditya Vikram Singh","Himanshu Tyagi"],"pdf_url":"https://arxiv.org/pdf/2212.09980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.08976v2","updated":"2022-12-20T03:33:42Z","published":"2021-08-20T03:13:34Z","title":"ASAT: Adaptively Scaled Adversarial Training in Time Series","summary":"  Adversarial training is a method for enhancing neural networks to improve the\nrobustness against adversarial examples. Besides the security concerns of\npotential adversarial examples, adversarial training can also improve the\ngeneralization ability of neural networks, train robust neural networks, and\nprovide interpretability for neural networks. In this work, we introduce\nadversarial training in time series analysis to enhance the neural networks for\nbetter generalization ability by taking the finance field as an example.\nRethinking existing research on adversarial training, we propose the adaptively\nscaled adversarial training (ASAT) in time series analysis, by rescaling data\nat different time slots with adaptive scales. Experimental results show that\nthe proposed ASAT can improve both the generalization ability and the\nadversarial robustness of neural networks compared to the baselines. Compared\nto the traditional adversarial training algorithm, ASAT can achieve better\ngeneralization ability and similar adversarial robustness.\n","authors":["Zhiyuan Zhang","Wei Li","Ruihan Bao","Keiko Harimoto","Yunfang Wu","Xu Sun"],"pdf_url":"https://arxiv.org/pdf/2108.08976v2.pdf","comment":"Accepted to Neurocomputing"},{"id":"http://arxiv.org/abs/2106.05492v3","updated":"2022-12-20T03:33:34Z","published":"2021-06-10T04:32:20Z","title":"Learning to Play General-Sum Games Against Multiple Boundedly Rational\n  Agents","summary":"  We study the problem of training a principal in a multi-agent general-sum\ngame using reinforcement learning (RL). Learning a robust principal policy\nrequires anticipating the worst possible strategic responses of other agents,\nwhich is generally NP-hard. However, we show that no-regret dynamics can\nidentify these worst-case responses in poly-time in smooth games. We propose a\nframework that uses this policy evaluation method for efficiently learning a\nrobust principal policy using RL. This framework can be extended to provide\nrobustness to boundedly rational agents too. Our motivating application is\nautomated mechanism design: we empirically demonstrate our framework learns\nrobust mechanisms in both matrix games and complex spatiotemporal games. In\nparticular, we learn a dynamic tax policy that improves the welfare of a\nsimulated trade-and-barter economy by 15%, even when facing previously unseen\nboundedly rational RL taxpayers.\n","authors":["Eric Zhao","Alexander R. Trott","Caiming Xiong","Stephan Zheng"],"pdf_url":"https://arxiv.org/pdf/2106.05492v3.pdf","comment":"15 pages, 6 figures. Appearing at the Thirty-seventh AAAI Conference\n  on Artificial Intelligence (AAAI 2023)"},{"id":"http://arxiv.org/abs/2212.09975v1","updated":"2022-12-20T03:33:26Z","published":"2022-12-20T03:33:26Z","title":"Sophisticated deep learning with on-chip optical diffractive tensor\n  processing","summary":"  The ever-growing deep learning technologies are making revolutionary changes\nfor modern life. However, conventional computing architectures are designed to\nprocess sequential and digital programs, being extremely burdened with\nperforming massive parallel and adaptive deep learning applications. Photonic\nintegrated circuits provide an efficient approach to mitigate bandwidth\nlimitations and power-wall brought by its electronic counterparts, showing\ngreat potential in ultrafast and energy-free high-performance computing. Here,\nwe propose an optical computing architecture enabled by on-chip diffraction to\nimplement convolutional acceleration, termed optical convolution unit (OCU). We\ndemonstrate that any real-valued convolution kernels can be exploited by OCU\nwith a prominent computational throughput boosting via the concept of structral\nre-parameterization. With OCU as the fundamental unit, we build an optical\nconvolutional neural network (oCNN) to implement two popular deep learning\ntasks: classification and regression. For classification, Fashion-MNIST and\nCIFAR-4 datasets are tested with accuracy of 91.63% and 86.25%, respectively.\nFor regression, we build an optical denoising convolutional neural network\n(oDnCNN) to handle Gaussian noise in gray scale images with noise level\n{\\sigma} = 10, 15, 20, resulting clean images with average PSNR of 31.70dB,\n29.39dB and 27.72dB, respectively. The proposed OCU presents remarkable\nperformance of low energy consumption and high information density due to its\nfully passive nature and compact footprint, providing a highly parallel while\nlightweight solution for future computing architecture to handle high\ndimensional tensors in deep learning.\n","authors":["Yuyao Huang","Tingzhao Fu","Honghao Huang","Sigang Yang","Hongwei Chen"],"pdf_url":"https://arxiv.org/pdf/2212.09975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09974v1","updated":"2022-12-20T03:28:41Z","published":"2022-12-20T03:28:41Z","title":"Insights into undergraduate pathways using course load analytics","summary":"  Course load analytics (CLA) inferred from LMS and enrollment features can\noffer a more accurate representation of course workload to students than credit\nhours and potentially aid in their course selection decisions. In this study,\nwe produce and evaluate the first machine-learned predictions of student course\nload ratings and generalize our model to the full 10,000 course catalog of a\nlarge public university. We then retrospectively analyze longitudinal\ndifferences in the semester load of student course selections throughout their\ndegree. CLA by semester shows that a student's first semester at the university\nis among their highest load semesters, as opposed to a credit hour-based\nanalysis, which would indicate it is among their lowest. Investigating what\nrole predicted course load may play in program retention, we find that students\nwho maintain a semester load that is low as measured by credit hours but high\nas measured by CLA are more likely to leave their program of study. This\ndiscrepancy in course load is particularly pertinent in STEM and associated\nwith high prerequisite courses. Our findings have implications for academic\nadvising, institutional handling of the freshman experience, and student-facing\nanalytics to help students better plan, anticipate, and prepare for their\nselected courses.\n","authors":["Conrad Borchers","Zachary A. Pardos"],"pdf_url":"https://arxiv.org/pdf/2212.09974v1.pdf","comment":"Accepted to Learning Analytics and Knowledge (LAK 2023)"},{"id":"http://arxiv.org/abs/2206.01986v2","updated":"2022-12-20T02:56:59Z","published":"2022-06-04T13:07:30Z","title":"Delving into the Openness of CLIP","summary":"  Contrastive Language-Image Pre-training (CLIP) has demonstrated great\npotential in realizing open-vocabulary visual recognition in a matching style,\ndue to its holistic use of natural language supervision that covers\nunconstrained real-world visual concepts. However, it is, in turn, also\ndifficult to evaluate and analyze the openness of CLIP-like models, since they\nare in theory open to any vocabulary but the actual accuracy varies. To address\nthe insufficiency of conventional studies on openness, we resort to an\nincremental perspective and define the extensibility, which essentially\napproximates the model's ability to deal with new visual concepts, by\nevaluating openness through vocabulary expansions. Our evaluation based on\nextensibility shows that CLIP-like models are hardly truly open and their\nperformance degrades as the vocabulary expands to different degrees. Further\nanalysis reveals that the over-estimation of openness is not because CLIP-like\nmodels fail to capture the general similarity of image and text features of\nnovel visual concepts, but because of the confusion among competing text\nfeatures, that is, they are not stable with respect to the vocabulary. In light\nof this, we propose to improve the openness of CLIP in the feature space by\nenforcing the distinguishability of text features. Our method retrieves\nrelevant texts from the pre-training corpus to enhance prompts for inference,\nwhich boosts the extensibility and stability of CLIP even without fine-tuning.\n","authors":["Shuhuai Ren","Lei Li","Xuancheng Ren","Guangxiang Zhao","Xu Sun"],"pdf_url":"https://arxiv.org/pdf/2206.01986v2.pdf","comment":"22 pages, 12 figures. Code is available at\n  https://github.com/lancopku/clip-openness"},{"id":"http://arxiv.org/abs/2212.09970v1","updated":"2022-12-20T02:51:28Z","published":"2022-12-20T02:51:28Z","title":"Data Augmentation on Graphs: A Survey","summary":"  In recent years, graph representation learning has achieved remarkable\nsuccess while suffering from low-quality data problems. As a mature technology\nto improve data quality in computer vision, data augmentation has also\nattracted increasing attention in graph domain. For promoting the development\nof this emerging research direction, in this survey, we comprehensively review\nand summarize the existing graph data augmentation (GDAug) techniques.\nSpecifically, we first summarize a variety of feasible taxonomies, and then\nclassify existing GDAug studies based on fine-grained graph elements.\nFurthermore, for each type of GDAug technique, we formalize the general\ndefinition, discuss the technical details, and give schematic illustration. In\naddition, we also summarize common performance metrics and specific design\nmetrics for constructing a GDAug evaluation system. Finally, we summarize the\napplications of GDAug from both data and model levels, as well as future\ndirections.\n","authors":["Jiajun Zhou","Chenxuan Xie","Zhenyu Wen","Xiangyu Zhao","Qi Xuan"],"pdf_url":"https://arxiv.org/pdf/2212.09970v1.pdf","comment":"31 pages, 11 figures, under review"},{"id":"http://arxiv.org/abs/2212.09967v1","updated":"2022-12-20T02:45:09Z","published":"2022-12-20T02:45:09Z","title":"Learning Subgrid-scale Models with Neural Ordinary Differential\n  Equations","summary":"  We propose a new approach to learning the subgrid-scale model effects when\nsimulating partial differential equations (PDEs) solved by the method of lines\nand their representation in chaotic ordinary differential equations, based on\nneural ordinary differential equations (NODEs). Solving systems with fine\ntemporal and spatial grid scales is an ongoing computational challenge, and\nclosure models are generally difficult to tune. Machine learning approaches\nhave increased the accuracy and efficiency of computational fluid dynamics\nsolvers. In this approach neural networks are used to learn the coarse- to\nfine-grid map, which can be viewed as subgrid scale parameterization. We\npropose a strategy that uses the NODE and partial knowledge to learn the source\ndynamics at a continuous level. Our method inherits the advantages of NODEs and\ncan be used to parameterize subgrid scales, approximate coupling operators, and\nimprove the efficiency of low-order solvers. Numerical results using the\ntwo-scale Lorenz 96 ODE and the convection-diffusion PDE are used to illustrate\nthis approach.\n","authors":["Shinhoo Kang","Emil M. Constantinescu"],"pdf_url":"https://arxiv.org/pdf/2212.09967v1.pdf","comment":"20 pages, 14 figures"},{"id":"http://arxiv.org/abs/2212.09962v1","updated":"2022-12-20T02:30:13Z","published":"2022-12-20T02:30:13Z","title":"Distributional Robustness Bounds Generalization Errors","summary":"  Bayesian methods, distributionally robust optimization methods, and\nregularization methods are three pillars of trustworthy machine learning\nhedging against distributional uncertainty, e.g., the uncertainty of an\nempirical distribution compared to the true underlying distribution. This paper\ninvestigates the connections among the three frameworks and, in particular,\nexplores why these frameworks tend to have smaller generalization errors.\nSpecifically, first, we suggest a quantitative definition for \"distributional\nrobustness\", propose the concept of \"robustness measure\", and formalize several\nphilosophical concepts in distributionally robust optimization. Second, we show\nthat Bayesian methods are distributionally robust in the probably approximately\ncorrect (PAC) sense; In addition, by constructing a Dirichlet-process-like\nprior in Bayesian nonparametrics, it can be proven that any regularized\nempirical risk minimization method is equivalent to a Bayesian method. Third,\nwe show that generalization errors of machine learning models can be\ncharacterized using the distributional uncertainty of the nominal distribution\nand the robustness measures of these machine learning models, which is a new\nperspective to bound generalization errors, and therefore, explain the reason\nwhy distributionally robust machine learning models, Bayesian models, and\nregularization models tend to have smaller generalization errors.\n","authors":["Shixiong Wang","Haowei Wang","Jean Honorio"],"pdf_url":"https://arxiv.org/pdf/2212.09962v1.pdf","comment":"47 Pages, 2 Figures"},{"id":"http://arxiv.org/abs/2212.09961v1","updated":"2022-12-20T02:28:27Z","published":"2022-12-20T02:28:27Z","title":"Uncertainty Quantification of MLE for Entity Ranking with Covariates","summary":"  This paper concerns with statistical estimation and inference for the ranking\nproblems based on pairwise comparisons with additional covariate information\nsuch as the attributes of the compared items. Despite extensive studies, few\nprior literatures investigate this problem under the more realistic setting\nwhere covariate information exists. To tackle this issue, we propose a novel\nmodel, Covariate-Assisted Ranking Estimation (CARE) model, that extends the\nwell-known Bradley-Terry-Luce (BTL) model, by incorporating the covariate\ninformation. Specifically, instead of assuming every compared item has a fixed\nlatent score $\\{\\theta_i^*\\}_{i=1}^n$, we assume the underlying scores are\ngiven by $\\{\\alpha_i^*+{x}_i^\\top\\beta^*\\}_{i=1}^n$, where $\\alpha_i^*$ and\n${x}_i^\\top\\beta^*$ represent latent baseline and covariate score of the $i$-th\nitem, respectively. We impose natural identifiability conditions and derive the\n$\\ell_{\\infty}$- and $\\ell_2$-optimal rates for the maximum likelihood\nestimator of $\\{\\alpha_i^*\\}_{i=1}^{n}$ and $\\beta^*$ under a sparse comparison\ngraph, using a novel `leave-one-out' technique (Chen et al., 2019) . To conduct\nstatistical inferences, we further derive asymptotic distributions for the MLE\nof $\\{\\alpha_i^*\\}_{i=1}^n$ and $\\beta^*$ with minimal sample complexity. This\nallows us to answer the question whether some covariates have any explanation\npower for latent scores and to threshold some sparse parameters to improve the\nranking performance. We improve the approximation method used in (Gao et al.,\n2021) for the BLT model and generalize it to the CARE model. Moreover, we\nvalidate our theoretical results through large-scale numerical studies and an\napplication to the mutual fund stock holding dataset.\n","authors":["Jianqing Fan","Jikai Hou","Mengxin Yu"],"pdf_url":"https://arxiv.org/pdf/2212.09961v1.pdf","comment":"This paper studies uncertainty quantification for ranking with\n  covariates"},{"id":"http://arxiv.org/abs/2212.08323v2","updated":"2022-12-20T02:17:34Z","published":"2022-12-16T07:49:15Z","title":"An ensemble neural network approach to forecast Dengue outbreak based on\n  climatic condition","summary":"  Dengue fever is a virulent disease spreading over 100 tropical and\nsubtropical countries in Africa, the Americas, and Asia. This arboviral disease\naffects around 400 million people globally, severely distressing the healthcare\nsystems. The unavailability of a specific drug and ready-to-use vaccine makes\nthe situation worse. Hence, policymakers must rely on early warning systems to\ncontrol intervention-related decisions. Forecasts routinely provide critical\ninformation for dangerous epidemic events. However, the available forecasting\nmodels (e.g., weather-driven mechanistic, statistical time series, and machine\nlearning models) lack a clear understanding of different components to improve\nprediction accuracy and often provide unstable and unreliable forecasts. This\nstudy proposes an ensemble wavelet neural network with exogenous factor(s)\n(XEWNet) model that can produce reliable estimates for dengue outbreak\nprediction for three geographical regions, namely San Juan, Iquitos, and\nAhmedabad. The proposed XEWNet model is flexible and can easily incorporate\nexogenous climate variable(s) confirmed by statistical causality tests in its\nscalable framework. The proposed model is an integrated approach that uses\nwavelet transformation into an ensemble neural network framework that helps in\ngenerating more reliable long-term forecasts. The proposed XEWNet allows\ncomplex non-linear relationships between the dengue incidence cases and\nrainfall; however, mathematically interpretable, fast in execution, and easily\ncomprehensible. The proposal's competitiveness is measured using computational\nexperiments based on various statistical metrics and several statistical\ncomparison tests. In comparison with statistical, machine learning, and deep\nlearning methods, our proposed XEWNet performs better in 75% of the cases for\nshort-term and long-term forecasting of dengue incidence.\n","authors":["Madhurima Panja","Tanujit Chakraborty","Sk Shahid Nadim","Indrajit Ghosh","Uttam Kumar","Nan Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08323v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09947v1","updated":"2022-12-20T01:53:26Z","published":"2022-12-20T01:53:26Z","title":"Future Sight: Dynamic Story Generation with Large Pretrained Language\n  Models","summary":"  Recent advances in deep learning research, such as transformers, have\nbolstered the ability for automated agents to generate creative texts similar\nto those that a human would write. By default, transformer decoders can only\ngenerate new text with respect to previously generated text. The output\ndistribution of candidate tokens at any position is conditioned on previously\nselected tokens using a self-attention mechanism to emulate the property of\nautoregression. This is inherently limiting for tasks such as controllable\nstory generation where it may be necessary to condition on future plot events\nwhen writing a story. In this work, we propose Future Sight, a method for\nfinetuning a pretrained generative transformer on the task of future\nconditioning. Transformer decoders are typically pretrained on the task of\ncompleting a context, one token at a time, by means of self-attention. Future\nSight additionally enables a decoder to attend to an encoded future plot event.\nThis motivates the decoder to expand on the context in a way that logically\nconcludes with the provided future. During inference, the future plot event can\nbe written by a human author to steer the narrative being generated in a\ncertain direction. We evaluate the efficacy of our approach on a story\ngeneration task with human evaluators.\n","authors":["Brian D. Zimmerman","Gaurav Sahu","Olga Vechtomova"],"pdf_url":"https://arxiv.org/pdf/2212.09947v1.pdf","comment":"9 pages, 1 figure, 4 tables"},{"id":"http://arxiv.org/abs/2212.02623v2","updated":"2022-12-20T00:39:48Z","published":"2022-12-05T22:14:49Z","title":"Unifying Vision, Text, and Layout for Universal Document Processing","summary":"  We propose Universal Document Processing (UDOP), a foundation Document AI\nmodel which unifies text, image, and layout modalities together with varied\ntask formats, including document understanding and generation. UDOP leverages\nthe spatial correlation between textual content and document image to model\nimage, text, and layout modalities with one uniform representation. With a\nnovel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain\ndownstream tasks into a prompt-based sequence generation scheme. UDOP is\npretrained on both large-scale unlabeled document corpora using innovative\nself-supervised objectives and diverse labeled data. UDOP also learns to\ngenerate document images from text and layout modalities via masked image\nreconstruction. To the best of our knowledge, this is the first time in the\nfield of document AI that one model simultaneously achieves high-quality neural\ndocument editing and content customization. Our method sets the\nstate-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,\nacross diverse data domains like finance reports, academic papers, and\nwebsites. UDOP ranks first on the leaderboard of the Document Understanding\nBenchmark (DUE).\n","authors":["Zineng Tang","Ziyi Yang","Guoxin Wang","Yuwei Fang","Yang Liu","Chenguang Zhu","Michael Zeng","Cha Zhang","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2212.02623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09928v1","updated":"2022-12-20T00:33:11Z","published":"2022-12-20T00:33:11Z","title":"Improving the Robustness of Summarization Models by Detecting and\n  Removing Input Noise","summary":"  The evaluation of abstractive summarization models typically uses test data\nthat is identically distributed as training data. In real-world practice,\ndocuments to be summarized may contain input noise caused by text extraction\nartifacts or data pipeline bugs. The robustness of model performance under\ndistribution shift caused by such noise is relatively under-studied. We present\na large empirical study quantifying the sometimes severe loss in performance\n(up to 12 ROUGE-1 points) from different types of input noise for a range of\ndatasets and model sizes. We then propose a light-weight method for detecting\nand removing such noise in the input during model inference without requiring\nany extra training, auxiliary models, or even prior knowledge of the type of\nnoise. Our proposed approach effectively mitigates the loss in performance,\nrecovering a large fraction of the performance drop, sometimes as large as 11\nROUGE-1 points.\n","authors":["Kundan Krishna","Yao Zhao","Jie Ren","Balaji Lakshminarayanan","Jiaming Luo","Mohammad Saleh","Peter J. Liu"],"pdf_url":"https://arxiv.org/pdf/2212.09928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09925v1","updated":"2022-12-20T00:26:23Z","published":"2022-12-20T00:26:23Z","title":"Plug & Play Directed Evolution of Proteins with Gradient-based Discrete\n  MCMC","summary":"  A long-standing goal of machine-learning-based protein engineering is to\naccelerate the discovery of novel mutations that improve the function of a\nknown protein. We introduce a sampling framework for evolving proteins in\nsilico that supports mixing and matching a variety of unsupervised models, such\nas protein language models, and supervised models that predict protein function\nfrom sequence. By composing these models, we aim to improve our ability to\nevaluate unseen mutations and constrain search to regions of sequence space\nlikely to contain functional proteins. Our framework achieves this without any\nmodel fine-tuning or re-training by constructing a product of experts\ndistribution directly in discrete protein space. Instead of resorting to brute\nforce search or random sampling, which is typical of classic directed\nevolution, we introduce a fast MCMC sampler that uses gradients to propose\npromising mutations. We conduct in silico directed evolution experiments on\nwide fitness landscapes and across a range of different pre-trained\nunsupervised models, including a 650M parameter protein language model. Our\nresults demonstrate an ability to efficiently discover variants with high\nevolutionary likelihood as well as estimated activity multiple mutations away\nfrom a wild type protein, suggesting our sampler provides a practical and\neffective new paradigm for machine-learning-based protein engineering.\n","authors":["Patrick Emami","Aidan Perreault","Jeffrey Law","David Biagioni","Peter C. St. John"],"pdf_url":"https://arxiv.org/pdf/2212.09925v1.pdf","comment":"33 pages, 8 figures. Under review. Code is available at\n  https://github.com/pemami4911/ppde. A short version of this work appeared at\n  the NeurIPS 2022 Machine Learning in Structural Biology Workshop"},{"id":"http://arxiv.org/abs/2206.05183v2","updated":"2022-12-20T00:17:33Z","published":"2022-06-10T15:23:23Z","title":"GD-VAEs: Geometric Dynamic Variational Autoencoders for Learning\n  Nonlinear Dynamics and Dimension Reductions","summary":"  We develop data-driven methods incorporating geometric and topological\ninformation to learn parsimonious representations of nonlinear dynamics from\nobservations. We develop approaches for learning nonlinear state space models\nof the dynamics for general manifold latent spaces using training strategies\nrelated to Variational Autoencoders (VAEs). Our methods are referred to as\nGeometric Dynamic (GD) Variational Autoencoders (GD-VAEs). We learn encoders\nand decoders for the system states and evolution based on deep neural network\narchitectures that include general Multilayer Perceptrons (MLPs), Convolutional\nNeural Networks (CNNs), and Transpose CNNs (T-CNNs). Motivated by problems\narising in parameterized PDEs and physics, we investigate the performance of\nour methods on tasks for learning low dimensional representations of the\nnonlinear Burgers equations, constrained mechanical systems, and spatial fields\nof reaction-diffusion systems. GD-VAEs provide methods for obtaining\nrepresentations for use in diverse learning tasks involving dynamics.\n","authors":["Ryan Lopez","Paul J. Atzberger"],"pdf_url":"https://arxiv.org/pdf/2206.05183v2.pdf","comment":"15 figures. arXiv admin note: text overlap with arXiv:2012.03448"},{"id":"http://arxiv.org/abs/2212.09921v1","updated":"2022-12-20T00:08:37Z","published":"2022-12-20T00:08:37Z","title":"Normalized Stochastic Gradient Descent Training of Deep Neural Networks","summary":"  In this paper, we introduce a novel optimization algorithm for machine\nlearning model training called Normalized Stochastic Gradient Descent (NSGD)\ninspired by Normalized Least Mean Squares (NLMS) from adaptive filtering. When\nwe train a high-complexity model on a large dataset, the learning rate is\nsignificantly important as a poor choice of optimizer parameters can lead to\ndivergence. The algorithm updates the new set of network weights using the\nstochastic gradient but with $\\ell_1$ and $\\ell_2$-based normalizations on the\nlearning rate parameter similar to the NLMS algorithm. Our main difference from\nthe existing normalization methods is that we do not include the error term in\nthe normalization process. We normalize the update term using the input vector\nto the neuron. Our experiments present that the model can be trained to a\nbetter accuracy level on different initial settings using our optimization\nalgorithm. In this paper, we demonstrate the efficiency of our training\nalgorithm using ResNet-20 and a toy neural network on different benchmark\ndatasets with different initializations. The NSGD improves the accuracy of the\nResNet-20 from 91.96\\% to 92.20\\% on the CIFAR-10 dataset.\n","authors":["Salih Atici","Hongyi Pan","Ahmet Enis Cetin"],"pdf_url":"https://arxiv.org/pdf/2212.09921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09920v1","updated":"2022-12-20T00:06:28Z","published":"2022-12-20T00:06:28Z","title":"Variational Factorization Machines for Preference Elicitation in\n  Large-Scale Recommender Systems","summary":"  Factorization machines (FMs) are a powerful tool for regression and\nclassification in the context of sparse observations, that has been\nsuccessfully applied to collaborative filtering, especially when side\ninformation over users or items is available. Bayesian formulations of FMs have\nbeen proposed to provide confidence intervals over the predictions made by the\nmodel, however they usually involve Markov-chain Monte Carlo methods that\nrequire many samples to provide accurate predictions, resulting in slow\ntraining in the context of large-scale data. In this paper, we propose a\nvariational formulation of factorization machines that allows us to derive a\nsimple objective that can be easily optimized using standard mini-batch\nstochastic gradient descent, making it amenable to large-scale data. Our\nalgorithm learns an approximate posterior distribution over the user and item\nparameters, which leads to confidence intervals over the predictions. We show,\nusing several datasets, that it has comparable or better performance than\nexisting methods in terms of prediction accuracy, and provide some applications\nin active learning strategies, e.g., preference elicitation techniques.\n","authors":["Jill-Jênn Vie","Tomas Rigaux","Hisashi Kashima"],"pdf_url":"https://arxiv.org/pdf/2212.09920v1.pdf","comment":"8 pages, 4 figures, 4 tables. Proceedings of the IEEE BigData 2022\n  conference"},{"id":"http://arxiv.org/abs/2212.10690v1","updated":"2022-12-20T23:30:47Z","published":"2022-12-20T23:30:47Z","title":"METEOR Guided Divergence for Video Captioning","summary":"  Automatic video captioning aims for a holistic visual scene understanding. It\nrequires a mechanism for capturing temporal context in video frames and the\nability to comprehend the actions and associations of objects in a given\ntimeframe. Such a system should additionally learn to abstract video sequences\ninto sensible representations as well as to generate natural written language.\nWhile the majority of captioning models focus solely on the visual inputs,\nlittle attention has been paid to the audiovisual modality. To tackle this\nissue, we propose a novel two-fold approach. First, we implement a\nreward-guided KL Divergence to train a video captioning model which is\nresilient towards token permutations. Second, we utilise a Bi-Modal\nHierarchical Reinforcement Learning (BMHRL) Transformer architecture to capture\nlong-term temporal dependencies of the input data as a foundation for our\nhierarchical captioning module. Using our BMHRL, we show the suitability of the\nHRL agent in the generation of content-complete and grammatically sound\nsentences by achieving $4.91$, $2.23$, and $10.80$ in BLEU3, BLEU4, and METEOR\nscores, respectively on the ActivityNet Captions dataset. Finally, we make our\nBMHRL framework and trained models publicly available for users and developers\nat https://github.com/d-rothen/bmhrl.\n","authors":["Daniel Lukas Rothenpieler","Shahin Amiriparian"],"pdf_url":"https://arxiv.org/pdf/2212.10690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10681v1","updated":"2022-12-20T22:53:19Z","published":"2022-12-20T22:53:19Z","title":"A Physics-Informed Neural Network to Model Port Channels","summary":"  We describe a Physics-Informed Neural Network (PINN) that simulates the flow\ninduced by the astronomical tide in a synthetic port channel, with dimensions\nbased on the Santos - S\\~ao Vicente - Bertioga Estuarine System. PINN models\naim to combine the knowledge of physical systems and data-driven machine\nlearning models. This is done by training a neural network to minimize the\nresiduals of the governing equations in sample points. In this work, our flow\nis governed by the Navier-Stokes equations with some approximations. There are\ntwo main novelties in this paper. First, we design our model to assume that the\nflow is periodic in time, which is not feasible in conventional simulation\nmethods. Second, we evaluate the benefit of resampling the function evaluation\npoints during training, which has a near zero computational cost and has been\nverified to improve the final model, especially for small batch sizes. Finally,\nwe discuss some limitations of the approximations used in the Navier-Stokes\nequations regarding the modeling of turbulence and how it interacts with PINNs.\n","authors":["Marlon S. Mathias","Marcel R. de Barros","Jefferson F. Coelho","Lucas P. de Freitas","Felipe M. Moreno","Caio F. D. Netto","Fabio G. Cozman","Anna H. R. Costa","Eduardo A. Tannuri","Edson S. Gomi","Marcelo Dottori"],"pdf_url":"https://arxiv.org/pdf/2212.10681v1.pdf","comment":"Published at the Workshop AI: Modeling Oceans and Climate Change\n  (AIMOCC 2022), held in conjunction with the 31st International Joint\n  Conference on Artificial Intelligence and the 25th European Conference on\n  Artificial Intelligence (IJCAI-ECAI 2022)"},{"id":"http://arxiv.org/abs/2212.10678v1","updated":"2022-12-20T22:41:24Z","published":"2022-12-20T22:41:24Z","title":"Understanding Stereotypes in Language Models: Towards Robust Measurement\n  and Zero-Shot Debiasing","summary":"  Generated texts from large pretrained language models have been shown to\nexhibit a variety of harmful, human-like biases about various demographics.\nThese findings prompted large efforts aiming to understand and measure such\neffects, with the goal of providing benchmarks that can guide the development\nof techniques mitigating these stereotypical associations. However, as recent\nresearch has pointed out, the current benchmarks lack a robust experimental\nsetup, consequently hindering the inference of meaningful conclusions from\ntheir evaluation metrics. In this paper, we extend these arguments and\ndemonstrate that existing techniques and benchmarks aiming to measure\nstereotypes tend to be inaccurate and consist of a high degree of experimental\nnoise that severely limits the knowledge we can gain from benchmarking language\nmodels based on them. Accordingly, we propose a new framework for robustly\nmeasuring and quantifying biases exhibited by generative language models.\nFinally, we use this framework to investigate GPT-3's occupational gender bias\nand propose prompting techniques for mitigating these biases without the need\nfor fine-tuning.\n","authors":["Justus Mattern","Zhijing Jin","Mrinmaya Sachan","Rada Mihalcea","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2212.10678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02421v2","updated":"2022-12-20T22:32:59Z","published":"2022-12-05T17:18:17Z","title":"Score-based denoising for atomic structure identification","summary":"  We propose an accurate method for removing thermal vibrations that complicate\nthe task of analyzing complex dynamics in atomistic simulation of condensed\nmatter. Our method iteratively subtracts thermal noises or perturbations in\natomic positions using a denoising score function trained on synthetically\nnoised but otherwise perfect crystal lattices. The resulting denoised\nstructures clearly reveal underlying crystal order while retaining disorder\nassociated with crystal defects. Purely geometric, agnostic to interatomic\npotentials, and trained without inputs from explicit simulations, our denoiser\ncan be applied to simulation data generated from vastly different interatomic\ninteractions. Followed by a simple phase classification tool such as the Common\nNeighbor Analysis, the denoiser outperforms other existing methods and reaches\nperfect classification accuracy on a recently proposed benchmark dataset\nconsisting of perturbed crystal structures (DC3). Demonstrated here in a wide\nvariety of atomistic simulation contexts, the denoiser is general, robust, and\nreadily extendable to delineate order from disorder in structurally and\nchemically complex materials.\n","authors":["Tim Hsu","Babak Sadigh","Nicolas Bertin","Cheol Woo Park","James Chapman","Vasily Bulatov","Fei Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.02421v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10670v1","updated":"2022-12-20T22:11:35Z","published":"2022-12-20T22:11:35Z","title":"In-context Learning Distillation: Transferring Few-shot Learning Ability\n  of Pre-trained Language Models","summary":"  Given the success with in-context learning of large pre-trained language\nmodels, we introduce in-context learning distillation to transfer in-context\nfew-shot learning ability from large models to smaller models. We propose to\ncombine in-context learning objectives with language modeling objectives to\ndistill both the ability to read in-context examples and task knowledge to the\nsmaller models. We perform in-context learning distillation under two different\nfew-shot learning paradigms: Meta In-context Tuning (Meta-ICT) and Multitask\nIn-context Tuning (Multitask-ICT). Multitask-ICT performs better on multitask\nfew-shot learning but also requires more computation than Meta-ICT. Our method\nshows consistent improvements for both Meta-ICT and Multitask-ICT on two\nbenchmarks: LAMA and CrossFit. Our extensive experiments and analysis reveal\nthat in-context learning objectives and language modeling objectives are\ncomplementary under the Multitask-ICT paradigm. In-context learning objectives\nachieve the best performance when combined with language modeling objectives.\n","authors":["Yukun Huang","Yanda Chen","Zhou Yu","Kathleen McKeown"],"pdf_url":"https://arxiv.org/pdf/2212.10670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09044v2","updated":"2022-12-20T21:49:18Z","published":"2022-12-18T09:31:36Z","title":"Text2Struct: A Machine Learning Pipeline for Mining Structured Data from\n  Text","summary":"  Many analysis and prediction tasks require the extraction of structured data\nfrom unstructured texts. To solve it, this paper presents an end-to-end machine\nlearning pipeline, Text2Struct, including a text annotation scheme, training\ndata processing, and machine learning implementation. We formulated the mining\nproblem as the extraction of metrics and units associated with numerals in the\ntext. The Text2Struct was evaluated on an annotated text dataset collected from\nabstracts of medical publications regarding thrombectomy. In terms of\nprediction performance, a dice coefficient of 0.82 was achieved on the test\ndataset. By random sampling, most predicted relations between numerals and\nentities were well matched to the ground-truth annotations. These results show\nthat the Text2Struct is viable for the mining of structured data from text\nwithout special templates or patterns. It is anticipated to further improve the\npipeline by expanding the dataset and investigating other machine learning\nmodels. A code demonstration can be found at:\nhttps://github.com/zcc861007/CourseProject\n","authors":["Chaochao Zhou","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2212.09044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10083v2","updated":"2022-12-20T21:40:58Z","published":"2022-05-20T10:58:41Z","title":"A Unified Experiment Design Approach for Cyclic and Acyclic Causal\n  Models","summary":"  We study experiment design for unique identification of the causal graph of a\nsystem where the graph may contain cycles. The presence of cycles in the\nstructure introduces major challenges for experiment design as, unlike acyclic\ngraphs, learning the skeleton of causal graphs with cycles may not be possible\nfrom merely the observational distribution. Furthermore, intervening on a\nvariable in such graphs does not necessarily lead to orienting all the edges\nincident to it. In this paper, we propose an experiment design approach that\ncan learn both cyclic and acyclic graphs and hence, unifies the task of\nexperiment design for both types of graphs. We provide a lower bound on the\nnumber of experiments required to guarantee the unique identification of the\ncausal graph in the worst case, showing that the proposed approach is\norder-optimal in terms of the number of experiments up to an additive\nlogarithmic term. Moreover, we extend our result to the setting where the size\nof each experiment is bounded by a constant. For this case, we show that our\napproach is optimal in terms of the size of the largest experiment required for\nuniquely identifying the causal graph in the worst case.\n","authors":["Ehsan Mokhtarian","Saber Salehkaleybar","AmirEmad Ghassami","Negar Kiyavash"],"pdf_url":"https://arxiv.org/pdf/2205.10083v2.pdf","comment":"30 pages, 6 figures, 1 table"},{"id":"http://arxiv.org/abs/2111.08626v2","updated":"2022-12-20T21:19:11Z","published":"2021-11-16T17:11:05Z","title":"Adjoint-Matching Neural Network Surrogates for Fast 4D-Var Data\n  Assimilation","summary":"  Data assimilation is the process of fusing information from imperfect\ncomputer simulations with noisy, sparse measurements of reality to obtain\nimproved estimates of the state or parameters of a dynamical system of\ninterest. The data assimilation procedures used in many geoscience\napplications, such as numerical weather forecasting, are variants of the\nour-dimensional variational (4D-Var) algorithm. The cost of solving the\nunderlying 4D-Var optimization problem is dominated by the cost of repeated\nforward and adjoint model runs. This motivates substituting the evaluations of\nthe physical model and its adjoint by fast, approximate surrogate models.\nNeural networks offer a promising approach for the data-driven creation of\nsurrogate models. The accuracy of the surrogate 4D-Var solution depends on the\naccuracy with each the surrogate captures both the forward and the adjoint\nmodel dynamics. We formulate and analyze several approaches to incorporate\nadjoint information into the construction of neural network surrogates. The\nresulting networks are tested on unseen data and in a sequential data\nassimilation problem using the Lorenz-63 system. Surrogates constructed using\nadjoint information demonstrate superior performance on the 4D-Var data\nassimilation problem compared to a standard neural network surrogate that uses\nonly forward dynamics information.\n","authors":["Austin Chennault","Andrey A. Popov","Amit N. Subrahmanya","Rachel Cooper","Ali Haisam Muhammad Rafid","Anuj Karpatne","Adrian Sandu"],"pdf_url":"https://arxiv.org/pdf/2111.08626v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06951v2","updated":"2022-12-20T21:07:36Z","published":"2022-12-14T00:04:56Z","title":"AI Ethics on Blockchain: Topic Analysis on Twitter Data for Blockchain\n  Security","summary":"  Blockchain has empowered computer systems to be more secure using a\ndistributed network. However, the current blockchain design suffers from\nfairness issues in transaction ordering. Miners are able to reorder\ntransactions to generate profits, the so-called miner extractable value (MEV).\nExisting research recognizes MEV as a severe security issue and proposes\npotential solutions, including prominent Flashbots. However, previous studies\nhave mostly analyzed blockchain data, which might not capture the impacts of\nMEV in a much broader AI society. Thus, in this research, we applied natural\nlanguage processing (NLP) methods to comprehensively analyze topics in tweets\non MEV. We collected more than 20000 tweets with \\#MEV and \\#Flashbots hashtags\nand analyzed their topics. Our results show that the tweets discussed profound\ntopics of ethical concern, including security, equity, emotional sentiments,\nand the desire for solutions to MEV. We also identify the co-movements of MEV\nactivities on blockchain and social media platforms. Our study contributes to\nthe literature at the interface of blockchain security, MEV solutions, and AI\nethics.\n","authors":["Yihang Fu","Zesen Zhuang","Luyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.06951v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10649v1","updated":"2022-12-20T20:56:18Z","published":"2022-12-20T20:56:18Z","title":"Inversion of Bayesian Networks","summary":"  Variational autoencoders and Helmholtz machines use a recognition network\n(encoder) to approximate the posterior distribution of a generative model\n(decoder). In this paper we study the necessary and sufficient properties of a\nrecognition network so that it can model the true posterior distribution\nexactly. These results are derived in the general context of probabilistic\ngraphical modelling / Bayesian networks, for which the network represents a set\nof conditional independence statements. We derive both global conditions, in\nterms of d-separation, and local conditions for the recognition network to have\nthe desired qualities. It turns out that for the local conditions the property\nperfectness (for every node, all parents are joined) plays an important role.\n","authors":["Jesse van Oostrum","Peter van Hintum","Nihat Ay"],"pdf_url":"https://arxiv.org/pdf/2212.10649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.14550v5","updated":"2022-12-20T20:52:55Z","published":"2022-05-29T00:59:38Z","title":"Machine Learning for Microcontroller-Class Hardware: A Review","summary":"  The advancements in machine learning opened a new opportunity to bring\nintelligence to the low-end Internet-of-Things nodes such as microcontrollers.\nConventional machine learning deployment has high memory and compute footprint\nhindering their direct deployment on ultra resource-constrained\nmicrocontrollers. This paper highlights the unique requirements of enabling\nonboard machine learning for microcontroller class devices. Researchers use a\nspecialized model development workflow for resource-limited applications to\nensure the compute and latency budget is within the device limits while still\nmaintaining the desired performance. We characterize a closed-loop widely\napplicable workflow of machine learning model development for microcontroller\nclass devices and show that several classes of applications adopt a specific\ninstance of it. We present both qualitative and numerical insights into\ndifferent stages of model development by showcasing several use cases. Finally,\nwe identify the open research challenges and unsolved questions demanding\ncareful considerations moving forward.\n","authors":["Swapnil Sayan Saha","Sandeep Singh Sandha","Mani Srivastava"],"pdf_url":"https://arxiv.org/pdf/2205.14550v5.pdf","comment":"Published in IEEE Sensors Journal. Cite this as: S. S. Saha, S. S.\n  Sandha and M. Srivastava, \"Machine Learning for Microcontroller-Class\n  Hardware: A Review,\" in IEEE Sensors Journal, vol. 22, no. 22, pp.\n  21362-21390, 15 Nov., 2022"},{"id":"http://arxiv.org/abs/2206.05575v3","updated":"2022-12-20T19:54:26Z","published":"2022-06-11T17:38:09Z","title":"MammoDL: Mammographic Breast Density Estimation using Federated Learning","summary":"  Assessing breast cancer risk from imaging remains a subjective process, in\nwhich radiologists employ simple computer aided detection (CAD) systems or\nqualitative visual assessment to estimate breast percent density (PD). Machine\nlearning (ML) models have become the most promising way to quantify breast\ncancer risk for early, accurate, and equitable diagnoses, but training such\nmodels in medical research is often restricted to small, single-institution\ndata. Since patient demographics and imaging characteristics may vary\nconsiderably across imaging sites, models trained on single-institution data\ntend not to generalize well. In response to this problem, MammoDL is proposed,\nan open-source software tool that leverages a U-Net architecture to accurately\nestimate breast PD and complexity from mammography. With the Open Federated\nLearning (OpenFL) library, this solution enables secure training on datasets\nacross multiple institutions. MammoDL is a leaner, more flexible model than its\npredecessors, boasting improved generalization due to federation-enabled\ntraining on larger, more representative datasets.\n","authors":["Ramya Muthukrishnan","Angelina Heyler","Keshava Katti","Sarthak Pati","Walter Mankowski","Aprupa Alahari","Michael Sanborn","Emily F. Conant","Christopher Scott","Stacey Winham","Celine Vachon","Pratik Chaudhari","Despina Kontos","Spyridon Bakas"],"pdf_url":"https://arxiv.org/pdf/2206.05575v3.pdf","comment":"Breast Cancer Risk, Digital Mammography, Breast Density, Deep\n  Learning, Machine Learning, Federated Learning, OpenFL"},{"id":"http://arxiv.org/abs/2202.12823v2","updated":"2022-12-20T19:43:37Z","published":"2022-02-25T17:03:36Z","title":"GenéLive! Generating Rhythm Actions in Love Live!","summary":"  This article presents our generative model for rhythm action games together\nwith applications in business operations. Rhythm action games are video games\nin which the player is challenged to issue commands at the right timings during\na music session. The timings are rendered in the chart, which consists of\nvisual symbols, called notes, flying through the screen. We introduce our deep\ngenerative model, Gen\\'eLive!, which outperforms the state-of-the-art model by\ntaking into account musical structures through beats and temporal scales.\nThanks to its favorable performance, Gen\\'eLive! was put into operation at KLab\nInc., a Japan-based video game developer, and reduced the business cost of\nchart generation by as much as half. The application target included the\nphenomenal \"Love Live!,\" which has more than 10 million users across Asia and\nbeyond, and is one of the few rhythm action franchises that has led the online\nera of the genre. In this article, we evaluate the generative performance of\nGen\\'eLive! using production datasets at KLab as well as open datasets for\nreproducibility, while the model continues to operate in their business. Our\ncode and the model, tuned and trained using a supercomputer, are publicly\navailable.\n","authors":["Atsushi Takada","Daichi Yamazaki","Likun Liu","Yudai Yoshida","Nyamkhuu Ganbat","Takayuki Shimotomai","Taiga Yamamoto","Daisuke Sakurai","Naoki Hamada"],"pdf_url":"https://arxiv.org/pdf/2202.12823v2.pdf","comment":"15 pages, 13 figures, to appear at AAAI-23"},{"id":"http://arxiv.org/abs/2212.10614v1","updated":"2022-12-20T19:32:30Z","published":"2022-12-20T19:32:30Z","title":"MolCPT: Molecule Continuous Prompt Tuning to Generalize Molecular\n  Representation Learning","summary":"  Molecular representation learning is crucial for the problem of molecular\nproperty prediction, where graph neural networks (GNNs) serve as an effective\nsolution due to their structure modeling capabilities. Since labeled data is\noften scarce and expensive to obtain, it is a great challenge for GNNs to\ngeneralize in the extensive molecular space. Recently, the training paradigm of\n\"pre-train, fine-tune\" has been leveraged to improve the generalization\ncapabilities of GNNs. It uses self-supervised information to pre-train the GNN,\nand then performs fine-tuning to optimize the downstream task with just a few\nlabels. However, pre-training does not always yield statistically significant\nimprovement, especially for self-supervised learning with random structural\nmasking. In fact, the molecular structure is characterized by motif subgraphs,\nwhich are frequently occurring and influence molecular properties. To leverage\nthe task-related motifs, we propose a novel paradigm of \"pre-train, prompt,\nfine-tune\" for molecular representation learning, named molecule continuous\nprompt tuning (MolCPT). MolCPT defines a motif prompting function that uses the\npre-trained model to project the standalone input into an expressive prompt.\nThe prompt effectively augments the molecular graph with meaningful motifs in\nthe continuous representation space; this provides more structural patterns to\naid the downstream classifier in identifying molecular properties. Extensive\nexperiments on several benchmark datasets show that MolCPT efficiently\ngeneralizes pre-trained GNNs for molecular property prediction, with or without\na few fine-tuning steps.\n","authors":["Cameron Diao","Kaixiong Zhou","Xiao Huang","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2212.10614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10613v1","updated":"2022-12-20T19:29:37Z","published":"2022-12-20T19:29:37Z","title":"Temporal Output Discrepancy for Loss Estimation-based Active Learning","summary":"  While deep learning succeeds in a wide range of tasks, it highly depends on\nthe massive collection of annotated data which is expensive and time-consuming.\nTo lower the cost of data annotation, active learning has been proposed to\ninteractively query an oracle to annotate a small proportion of informative\nsamples in an unlabeled dataset. Inspired by the fact that the samples with\nhigher loss are usually more informative to the model than the samples with\nlower loss, in this paper we present a novel deep active learning approach that\nqueries the oracle for data annotation when the unlabeled sample is believed to\nincorporate high loss. The core of our approach is a measurement Temporal\nOutput Discrepancy (TOD) that estimates the sample loss by evaluating the\ndiscrepancy of outputs given by models at different optimization steps. Our\ntheoretical investigation shows that TOD lower-bounds the accumulated sample\nloss thus it can be used to select informative unlabeled samples. On basis of\nTOD, we further develop an effective unlabeled data sampling strategy as well\nas an unsupervised learning criterion for active learning. Due to the\nsimplicity of TOD, our methods are efficient, flexible, and task-agnostic.\nExtensive experimental results demonstrate that our approach achieves superior\nperformances than the state-of-the-art active learning methods on image\nclassification and semantic segmentation tasks. In addition, we show that TOD\ncan be utilized to select the best model of potentially the highest testing\naccuracy from a pool of candidate models.\n","authors":["Siyu Huang","Tianyang Wang","Haoyi Xiong","Bihan Wen","Jun Huan","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2212.10613v1.pdf","comment":"Accepted for IEEE Transactions on Neural Networks and Learning\n  Systems, 2022. Journal extension of ICCV 2021 [arXiv:2107.14153]"},{"id":"http://arxiv.org/abs/2209.09400v2","updated":"2022-12-20T19:21:30Z","published":"2022-09-20T01:12:31Z","title":"Polynomial-Time Reachability for LTI Systems with Two-Level Lattice\n  Neural Network Controllers","summary":"  In this paper, we consider the computational complexity of bounding the\nreachable set of a Linear Time-Invariant (LTI) system controlled by a Rectified\nLinear Unit (ReLU) Two-Level Lattice (TLL) Neural Network (NN) controller. In\nparticular, we show that for such a system and controller, it is possible to\ncompute the exact one-step reachable set in polynomial time in the size of the\nTLL NN controller (number of neurons). Additionally, we show that a tight\nbounding box of the reachable set is computable via two polynomial-time\nmethods: one with polynomial complexity in the size of the TLL and the other\nwith polynomial complexity in the Lipschitz constant of the controller and\nother problem parameters. Finally, we propose a pragmatic algorithm that\nadaptively combines the benefits of (semi-)exact reachability and approximate\nreachability, which we call L-TLLBox. We evaluate L-TLLBox with an empirical\ncomparison to a state-of-the-art NN controller reachability tool. In our\nexperiments, L-TLLBox completed reachability analysis as much as 5000x faster\nthan this tool on the same network/system, while producing reach boxes that\nwere from 0.08 to 1.42 times the area.\n","authors":["James Ferlez","Yasser Shoukry"],"pdf_url":"https://arxiv.org/pdf/2209.09400v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08143v2","updated":"2022-12-20T19:16:10Z","published":"2022-07-17T11:24:44Z","title":"Can large language models reason about medical questions?","summary":"  Although large language models (LLMs) often produce impressive outputs, it\nremains unclear how they perform in real-world scenarios requiring strong\nreasoning skills and expert domain knowledge. We set out to investigate whether\nGPT-3.5 (Codex and InstructGPT) can be applied to answer and reason about\ndifficult real-world-based questions. We utilize two multiple-choice medical\nexam questions (USMLE and MedMCQA) and a medical reading comprehension dataset\n(PubMedQA). We investigate multiple prompting scenarios: Chain-of-Thought (CoT,\nthink step-by-step), zero- and few-shot (prepending the question with\nquestion-answer exemplars) and retrieval augmentation (injecting Wikipedia\npassages into the prompt). For a subset of the USMLE questions, a medical\nexpert reviewed and annotated the model's CoT. We found that InstructGPT can\noften read, reason and recall expert knowledge. Failure are primarily due to\nlack of knowledge and reasoning errors and trivial guessing heuristics are\nobserved, e.g.\\ too often predicting labels A and D on USMLE. Sampling and\ncombining many completions overcome some of these limitations. Using 100\nsamples, Codex 5-shot CoT not only gives close to well-calibrated predictive\nprobability but also achieves human-level performances on the three datasets.\nUSMLE: 60.2%, MedMCQA: 57.5% and PubMedQA: 78.2%.\n","authors":["Valentin Liévin","Christoffer Egeberg Hother","Ole Winther"],"pdf_url":"https://arxiv.org/pdf/2207.08143v2.pdf","comment":"33 pages, 6 figures, to be submitted"},{"id":"http://arxiv.org/abs/2212.10579v1","updated":"2022-12-20T19:00:03Z","published":"2022-12-20T19:00:03Z","title":"Resonant Anomaly Detection with Multiple Reference Datasets","summary":"  An important class of techniques for resonant anomaly detection in high\nenergy physics builds models that can distinguish between reference and target\ndatasets, where only the latter has appreciable signal. Such techniques,\nincluding Classification Without Labels (CWoLa) and Simulation Assisted\nLikelihood-free Anomaly Detection (SALAD) rely on a single reference dataset.\nThey cannot take advantage of commonly-available multiple datasets and thus\ncannot fully exploit available information. In this work, we propose\ngeneralizations of CWoLa and SALAD for settings where multiple reference\ndatasets are available, building on weak supervision techniques. We demonstrate\nimproved performance in a number of settings with realistic and synthetic data.\nAs an added benefit, our generalizations enable us to provide finite-sample\nguarantees, improving on existing asymptotic analyses.\n","authors":["Mayee F. Chen","Benjamin Nachman","Frederic Sala"],"pdf_url":"https://arxiv.org/pdf/2212.10579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10711v1","updated":"2022-12-20T18:35:33Z","published":"2022-12-20T18:35:33Z","title":"Task Ambiguity in Humans and Language Models","summary":"  Language models have recently achieved strong performance across a wide range\nof NLP benchmarks. However, unlike benchmarks, real world tasks are often\npoorly specified, and agents must deduce the user's intended behavior from a\ncombination of context, instructions, and examples. We investigate how both\nhumans and models behave in the face of such task ambiguity by proposing\nAmbiBench, a new benchmark of six ambiguously-specified classification tasks.\nWe evaluate humans and models on AmbiBench by seeing how well they identify the\nintended task using 1) instructions with varying degrees of ambiguity, and 2)\ndifferent numbers of labeled examples. We find that the combination of model\nscaling (to 175B parameters) and training with human feedback data enables\nmodels to approach or exceed the accuracy of human participants across tasks,\nbut that either one alone is not sufficient. In addition, we show how to\ndramatically improve the accuracy of language models trained without\nlarge-scale human feedback training by finetuning on a small number of\nambiguous in-context examples, providing a promising direction for teaching\nmodels to generalize well in the face of ambiguity.\n","authors":["Alex Tamkin","Kunal Handa","Avash Shrestha","Noah Goodman"],"pdf_url":"https://arxiv.org/pdf/2212.10711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1909.12098v3","updated":"2022-12-20T18:12:23Z","published":"2019-09-26T13:45:39Z","title":"Sequential Training of Neural Networks with Gradient Boosting","summary":"  This paper presents a novel technique based on gradient boosting to train the\nfinal layers of a neural network (NN). Gradient boosting is an additive\nexpansion algorithm in which a series of models are trained sequentially to\napproximate a given function. A neural network can also be seen as an additive\nexpansion where the scalar product of the responses of the last hidden layer\nand its weights provide the final output of the network. Instead of training\nthe network as a whole, the proposed algorithm trains the network sequentially\nin $T$ steps. First, the bias term of the network is initialized with a\nconstant approximation that minimizes the average loss of the data. Then, at\neach step, a portion of the network, composed of $J$ neurons, is trained to\napproximate the pseudo-residuals on the training data computed from the\nprevious iterations. Finally, the $T$ partial models and bias are integrated as\na single NN with $T \\times J$ neurons in the hidden layer. Extensive\nexperiments in classification and regression tasks, as well as in combination\nwith deep neural networks, are carried out showing a competitive generalization\nperformance with respect to neural networks trained with different standard\nsolvers, such as Adam, L-BFGS, SGD and deep models. Furthermore, we show that\nthe proposed method design permits to switch off a number of hidden units\nduring test (the units that were last trained) without a significant reduction\nof its generalization ability. This permits the adaptation of the model to\ndifferent classification speed requirements on the fly.\n","authors":["Seyedsaman Emami","Gonzalo Martínez-Muñoz"],"pdf_url":"https://arxiv.org/pdf/1909.12098v3.pdf","comment":"This paper is under consideration at Pattern Recognition Letters"},{"id":"http://arxiv.org/abs/2212.11119v1","updated":"2022-12-20T17:54:08Z","published":"2022-12-20T17:54:08Z","title":"A survey on text generation using generative adversarial networks","summary":"  This work presents a thorough review concerning recent studies and text\ngeneration advancements using Generative Adversarial Networks. The usage of\nadversarial learning for text generation is promising as it provides\nalternatives to generate the so-called \"natural\" language. Nevertheless,\nadversarial text generation is not a simple task as its foremost architecture,\nthe Generative Adversarial Networks, were designed to cope with continuous\ninformation (image) instead of discrete data (text). Thus, most works are based\non three possible options, i.e., Gumbel-Softmax differentiation, Reinforcement\nLearning, and modified training objectives. All alternatives are reviewed in\nthis survey as they present the most recent approaches for generating text\nusing adversarial-based techniques. The selected works were taken from renowned\ndatabases, such as Science Direct, IEEEXplore, Springer, Association for\nComputing Machinery, and arXiv, whereas each selected work has been critically\nanalyzed and assessed to present its objective, methodology, and experimental\nresults.\n","authors":["Gustavo Henrique de Rosa","João Paulo Papa"],"pdf_url":"https://arxiv.org/pdf/2212.11119v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2212.10431v1","updated":"2022-12-20T17:09:53Z","published":"2022-12-20T17:09:53Z","title":"QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity","summary":"  The mechanism of existing style transfer algorithms is by minimizing a hybrid\nloss function to push the generated image toward high similarities in both\ncontent and style. However, this type of approach cannot guarantee visual\nfidelity, i.e., the generated artworks should be indistinguishable from real\nones. In this paper, we devise a new style transfer framework called QuantArt\nfor high visual-fidelity stylization. QuantArt pushes the latent representation\nof the generated artwork toward the centroids of the real artwork distribution\nwith vector quantization. By fusing the quantized and continuous latent\nrepresentations, QuantArt allows flexible control over the generated artworks\nin terms of content preservation, style similarity, and visual fidelity.\nExperiments on various style transfer settings show that our QuantArt framework\nachieves significantly higher visual fidelity compared with the existing style\ntransfer methods.\n","authors":["Siyu Huang","Jie An","Donglai Wei","Jiebo Luo","Hanspeter Pfister"],"pdf_url":"https://arxiv.org/pdf/2212.10431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10295v1","updated":"2022-12-20T14:38:33Z","published":"2022-12-20T14:38:33Z","title":"Interacting with New York City Data by HoloLens through Remote Rendering","summary":"  In the digital era, Extended Reality (XR) is considered the next frontier.\nHowever, XR systems are computationally intensive, and they must be implemented\nwithin strict latency constraints. Thus, XR devices with finite computing\nresources are limited in terms of quality of experience (QoE) they can offer,\nparticularly in cases of big 3D data. This problem can be effectively addressed\nby offloading the highly intensive rendering tasks to a remote server.\nTherefore, we proposed a remote rendering enabled XR system that presents the\n3D city model of New York City on the Microsoft HoloLens. Experimental results\nindicate that remote rendering outperforms local rendering for the New York\nCity model with significant improvement in average QoE by at least 21%.\nAdditionally, we clarified the network traffic pattern in the proposed XR\nsystem developed under the OpenXR standard.\n","authors":["Zijian Long","Haiwei Dong","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2212.10295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.12823v2","updated":"2022-12-20T19:43:37Z","published":"2022-02-25T17:03:36Z","title":"GenéLive! Generating Rhythm Actions in Love Live!","summary":"  This article presents our generative model for rhythm action games together\nwith applications in business operations. Rhythm action games are video games\nin which the player is challenged to issue commands at the right timings during\na music session. The timings are rendered in the chart, which consists of\nvisual symbols, called notes, flying through the screen. We introduce our deep\ngenerative model, Gen\\'eLive!, which outperforms the state-of-the-art model by\ntaking into account musical structures through beats and temporal scales.\nThanks to its favorable performance, Gen\\'eLive! was put into operation at KLab\nInc., a Japan-based video game developer, and reduced the business cost of\nchart generation by as much as half. The application target included the\nphenomenal \"Love Live!,\" which has more than 10 million users across Asia and\nbeyond, and is one of the few rhythm action franchises that has led the online\nera of the genre. In this article, we evaluate the generative performance of\nGen\\'eLive! using production datasets at KLab as well as open datasets for\nreproducibility, while the model continues to operate in their business. Our\ncode and the model, tuned and trained using a supercomputer, are publicly\navailable.\n","authors":["Atsushi Takada","Daichi Yamazaki","Likun Liu","Yudai Yoshida","Nyamkhuu Ganbat","Takayuki Shimotomai","Taiga Yamamoto","Daisuke Sakurai","Naoki Hamada"],"pdf_url":"https://arxiv.org/pdf/2202.12823v2.pdf","comment":"15 pages, 13 figures, to appear at AAAI-23"}]},"2022-12-21T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2212.11270v1","updated":"2022-12-21T18:58:41Z","published":"2022-12-21T18:58:41Z","title":"Generalized Decoding for Pixel, Image, and Language","summary":"  We present X-Decoder, a generalized decoding model that can predict\npixel-level segmentation and language tokens seamlessly. X-Decodert takes as\ninput two types of queries: (i) generic non-semantic queries and (ii) semantic\nqueries induced from text inputs, to decode different pixel-level and\ntoken-level outputs in the same semantic space. With such a novel design,\nX-Decoder is the first work that provides a unified way to support all types of\nimage segmentation and a variety of vision-language (VL) tasks. Further, our\ndesign enables seamless interactions across tasks at different granularities\nand brings mutual benefits by learning a common and rich pixel-level\nvisual-semantic understanding space, without any pseudo-labeling. After\npretraining on a mixed set of a limited amount of segmentation data and\nmillions of image-text pairs, X-Decoder exhibits strong transferability to a\nwide range of downstream tasks in both zero-shot and finetuning settings.\nNotably, it achieves (1) state-of-the-art results on open-vocabulary\nsegmentation and referring segmentation on eight datasets; (2) better or\ncompetitive finetuned performance to other generalist and specialist models on\nsegmentation and VL tasks; and (3) flexibility for efficient finetuning and\nnovel task composition (e.g., referring captioning and image editing). Code,\ndemo, video, and visualization are available at https://x-decoder-vl.github.io.\n","authors":["Xueyan Zou","Zi-Yi Dou","Jianwei Yang","Zhe Gan","Linjie Li","Chunyuan Li","Xiyang Dai","Harkirat Behl","Jianfeng Wang","Lu Yuan","Nanyun Peng","Lijuan Wang","Yong Jae Lee","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2212.11270v1.pdf","comment":"https://x-decoder-vl.github.io"},{"id":"http://arxiv.org/abs/2212.11261v1","updated":"2022-12-21T18:54:19Z","published":"2022-12-21T18:54:19Z","title":"Contrastive Language-Vision AI Models Pretrained on Web-Scraped\n  Multimodal Data Exhibit Sexual Objectification Bias","summary":"  Nine language-vision AI models trained on web scrapes with the Contrastive\nLanguage-Image Pretraining (CLIP) objective are evaluated for evidence of a\nbias studied by psychologists: the sexual objectification of girls and women,\nwhich occurs when a person's human characteristics are disregarded and the\nperson is treated as a body or a collection of body parts. A first experiment\nuses standardized images of women from the Sexual OBjectification and EMotion\nDatabase, and finds that, commensurate with prior research in psychology, human\ncharacteristics are disassociated from images of objectified women: the model's\nrecognition of emotional state is mediated by whether the subject is fully or\npartially clothed. Embedding association tests (EATs) return significant effect\nsizes for both anger (d >.8) and sadness (d >.5). A second experiment measures\nthe effect in a representative application: an automatic image captioner\n(Antarctic Captions) includes words denoting emotion less than 50% as often for\nimages of partially clothed women than for images of fully clothed women. A\nthird experiment finds that images of female professionals (scientists,\ndoctors, executives) are likely to be associated with sexual descriptions\nrelative to images of male professionals. A fourth experiment shows that a\nprompt of \"a [age] year old girl\" generates sexualized images (as determined by\nan NSFW classifier) up to 73% of the time for VQGAN-CLIP (age 17), and up to\n40% of the time for Stable Diffusion (ages 14 and 18); the corresponding rate\nfor boys never surpasses 9%. The evidence indicates that language-vision AI\nmodels trained on automatically collected web scrapes learn biases of sexual\nobjectification, which propagate to downstream applications.\n","authors":["Robert Wolfe","Yiwei Yang","Bill Howe","Aylin Caliskan"],"pdf_url":"https://arxiv.org/pdf/2212.11261v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2209.14694v2","updated":"2022-12-21T18:13:35Z","published":"2022-09-29T11:35:47Z","title":"GROOT: Corrective Reward Optimization for Generative Sequential Labeling","summary":"  Sequential labeling is a fundamental NLP task, forming the backbone of many\napplications. Supervised learning of Seq2Seq models has shown great success on\nthese problems. However, the training objectives are still significantly\ndisconnected with the metrics and desiderata we care about in practice. For\nexample, a practical sequence tagging application may want to optimize for a\ncertain precision-recall trade-off (of the top-k predictions) which is quite\ndifferent from the standard objective of maximizing the likelihood of the gold\nlabeled sequence. Thus to bridge this gap, we propose GROOT -- a simple yet\neffective framework for Generative Reward Optimization Of Text sequences. GROOT\nworks by training a generative sequential labeling model to match the decoder\noutput distribution with that of the (black-box) reward function. Using an\niterative training regime, we first generate prediction candidates, then\ncorrect errors in them, and finally contrast those candidates (based on their\nreward values). As demonstrated via extensive experiments on four public\nbenchmarks, GROOT significantly improves all reward metrics. Furthermore, GROOT\nleads to improvements of the overall decoder distribution as evidenced by the\nquality gains of the top-$k$ candidates.\n","authors":["Kazuma Hashimoto","Karthik Raman"],"pdf_url":"https://arxiv.org/pdf/2209.14694v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11234v1","updated":"2022-12-21T17:59:11Z","published":"2022-12-21T17:59:11Z","title":"Improving Narrative Relationship Embeddings by Training with Additional\n  Inverse-Relationship Constraints","summary":"  We consider the problem of embedding character-entity relationships from the\nreduced semantic space of narratives, proposing and evaluating the assumption\nthat these relationships hold under a reflection operation. We analyze this\nassumption and compare the approach to a baseline state-of-the-art model with a\nunique evaluation that simulates efficacy on a downstream clustering task with\nhuman-created labels. Although our model creates clusters that achieve\nSilhouette scores of -.084, outperforming the baseline -.227, our analysis\nreveals that the models approach the task much differently and perform well on\nvery different examples. We conclude that our assumption might be useful for\nspecific types of data and should be evaluated on a wider range of tasks.\n","authors":["Mikolaj Figurski"],"pdf_url":"https://arxiv.org/pdf/2212.11234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11185v1","updated":"2022-12-21T16:56:07Z","published":"2022-12-21T16:56:07Z","title":"Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns\n  Predict Reading Times Over and Above GPT-2 Surprisal","summary":"  Transformer-based large language models are trained to make predictions about\nthe next word by aggregating representations of previous tokens through their\nself-attention mechanism. In the field of cognitive modeling, such attention\npatterns have recently been interpreted as embodying the process of cue-based\nretrieval, in which attention over multiple targets is taken to generate\ninterference and latency during retrieval. Under this framework, this work\nfirst defines an entropy-based predictor that quantifies the diffuseness of\nself-attention, as well as distance-based predictors that capture the\nincremental change in attention patterns across timesteps. Moreover, following\nrecent studies that question the informativeness of attention weights, we also\nexperiment with alternative methods for incorporating vector norms into\nattention weights. Regression experiments using predictors calculated from the\nGPT-2 language model show that these predictors deliver a substantially better\nfit to held-out self-paced reading and eye-tracking data over a rigorous\nbaseline including GPT-2 surprisal. Additionally, the distance-based predictors\ngenerally demonstrated higher predictive power, with effect sizes of up to 6.59\nms per standard deviation on self-paced reading times (compared to 2.82 ms for\nsurprisal) and 1.05 ms per standard deviation on eye-gaze durations (compared\nto 3.81 ms for surprisal).\n","authors":["Byung-Doh Oh","William Schuler"],"pdf_url":"https://arxiv.org/pdf/2212.11185v1.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2203.13352v2","updated":"2022-12-21T16:54:56Z","published":"2022-03-24T21:54:49Z","title":"Does human speech follow Benford's Law?","summary":"  Researchers have observed that the frequencies of leading digits in many\nman-made and naturally occurring datasets follow a logarithmic curve, with\ndigits that start with the number 1 accounting for $\\sim 30\\%$ of all numbers\nin the dataset and digits that start with the number 9 accounting for $\\sim\n5\\%$ of all numbers in the dataset. This phenomenon, known as Benford's Law, is\nhighly repeatable and appears in lists of numbers from electricity bills, stock\nprices, tax returns, house prices, death rates, lengths of rivers, and\nnaturally occurring images. In this paper we demonstrate that human speech\nspectra also follow Benford's Law on average. That is, when averaged over many\nspeakers, the frequencies of leading digits in speech magnitude spectra follow\nthis distribution, although with some variability at the individual sample\nlevel. We use this observation to motivate a new set of features that can be\nefficiently extracted from speech and demonstrate that these features can be\nused to classify between human speech and synthetic speech.\n","authors":["Leo Hsu","Visar Berisha"],"pdf_url":"https://arxiv.org/pdf/2203.13352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11182v1","updated":"2022-12-21T16:52:10Z","published":"2022-12-21T16:52:10Z","title":"Universal versus system-specific features of punctuation usage patterns\n  in~major Western~languages","summary":"  The celebrated proverb that \"speech is silver, silence is golden\" has a long\nmultinational history and multiple specific meanings. In written texts\npunctuation can in fact be considered one of its manifestations. Indeed, the\nvirtue of effectively speaking and writing involves - often decisively - the\ncapacity to apply the properly placed breaks. In the present study, based on a\nlarge corpus of world-famous and representative literary texts in seven major\nWestern languages, it is shown that the distribution of intervals between\nconsecutive punctuation marks in almost all texts can universally be\ncharacterised by only two parameters of the discrete Weibull distribution which\ncan be given an intuitive interpretation in terms of the so-called hazard\nfunction. The values of these two parameters tend to be language-specific,\nhowever, and even appear to navigate translations. The properties of the\ncomputed hazard functions indicate that among the studied languages, English\nturns out to be the least constrained by the necessity to place a consecutive\npunctuation mark to partition a sequence of words. This may suggest that when\ncompared to other studied languages, English is more flexible, in the sense of\nallowing longer uninterrupted sequences of words. Spanish reveals similar\ntendency to only a bit lesser extent.\n","authors":["Tomasz Stanisz","Stanislaw Drozdz","Jaroslaw Kwapien"],"pdf_url":"https://arxiv.org/pdf/2212.11182v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.10196v3","updated":"2022-12-21T13:11:52Z","published":"2022-04-19T11:15:25Z","title":"Multimodal Hate Speech Detection from Bengali Memes and Texts","summary":"  Numerous machine learning (ML) and deep learning (DL)-based approaches have\nbeen proposed to utilize textual data from social media for anti-social\nbehavior analysis like cyberbullying, fake news detection, and identification\nof hate speech mainly for highly-resourced languages such as English. However,\ndespite having a lot of diversity and millions of native speakers, some\nlanguages like Bengali are under-resourced, which is due to a lack of\ncomputational resources for natural language processing (NLP). Similar to other\nlanguages, Bengali social media contents also include images along with texts\n(e.g., multimodal memes are posted by embedding short texts into images on\nFacebook). Therefore, only the textual data is not enough to judge them since\nimages might give extra context to make a proper judgement. This paper is about\nhate speech detection from multimodal Bengali memes and texts. We prepared the\nonly multimodal hate speech dataset for-a-kind of problem for Bengali, which we\nuse to train state-of-the-art neural architectures (e.g., Bi-LSTM/Conv-LSTM\nwith word embeddings, ConvNets + pre-trained language models, e.g., monolingual\nBangla BERT, multilingual BERT-cased/uncased, and XLM-RoBERTa) to jointly\nanalyze textual and visual information for hate speech detection. Conv-LSTM and\nXLM-RoBERTa models performed best for texts, yielding F1 scores of 0.78 and\n0.82, respectively. As of memes, ResNet-152 and DenseNet-161 models yield F1\nscores of 0.78 and 0.79, respectively. As for multimodal fusion, XLM-RoBERTa +\nDenseNet-161 performed the best, yielding an F1 score of 0.83. Our study\nsuggests that text modality is most useful for hate speech detection, while\nmemes are moderately useful.\n","authors":["Md. Rezaul Karim","Sumon Kanti Dey","Tanhim Islam","Md. Shajalal","Bharathi Raja Chakravarthi"],"pdf_url":"https://arxiv.org/pdf/2204.10196v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2107.00648 by other authors"},{"id":"http://arxiv.org/abs/2212.07428v3","updated":"2022-12-21T13:10:10Z","published":"2022-12-14T10:50:13Z","title":"Towards Linguistically Informed Multi-Objective Pre-Training for Natural\n  Language Inference","summary":"  We introduce a linguistically enhanced combination of pre-training methods\nfor transformers. The pre-training objectives include POS-tagging, synset\nprediction based on semantic knowledge graphs, and parent prediction based on\ndependency parse trees. Our approach achieves competitive results on the\nNatural Language Inference task, compared to the state of the art. Specifically\nfor smaller models, the method results in a significant performance boost,\nemphasizing the fact that intelligent pre-training can make up for fewer\nparameters and help building more efficient models. Combining POS-tagging and\nsynset prediction yields the overall best results.\n","authors":["Maren Pielka","Svetlana Schmidt","Lisa Pucknat","Rafet Sifa"],"pdf_url":"https://arxiv.org/pdf/2212.07428v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10983v1","updated":"2022-12-21T12:36:17Z","published":"2022-12-21T12:36:17Z","title":"Computer says \"No\": The Case Against Empathetic Conversational AI","summary":"  Emotions are an integral part of human cognition and they guide not only our\nunderstanding of the world but also our actions within it. As such, whether we\nsoothe or flame an emotion is not inconsequential. Recent work in\nconversational AI has focused on responding empathetically to users, validating\nand soothing their emotions without a real basis. This AI-aided emotional\nregulation can have negative consequences for users and society, tending\ntowards a one-noted happiness defined as only the absence of \"negative\"\nemotions. We argue that we must carefully consider whether and how to respond\nto users' emotions.\n","authors":["Alba Curry","Amanda Cercas Curry"],"pdf_url":"https://arxiv.org/pdf/2212.10983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10947v1","updated":"2022-12-21T11:38:51Z","published":"2022-12-21T11:38:51Z","title":"Parallel Context Windows Improve In-Context Learning of Large Language\n  Models","summary":"  For applications that require processing large amounts of text at inference\ntime, Large Language Models (LLMs) are handicapped by their limited context\nwindows, which are typically 2048 tokens. In-context learning, an emergent\nphenomenon in LLMs in sizes above a certain parameter threshold, constitutes\none significant example because it can only leverage training examples that fit\ninto the context window. Existing efforts to address the context window\nlimitation involve training specialized architectures, which tend to be smaller\nthan the sizes in which in-context learning manifests due to the memory\nfootprint of processing long texts. We present Parallel Context Windows (PCW),\na method that alleviates the context window restriction for any off-the-shelf\nLLM without further training. The key to the approach is to carve a long\ncontext into chunks (``windows'') that fit within the architecture, restrict\nthe attention mechanism to apply only within each window, and re-use the\npositional embeddings among the windows. We test the PCW approach on in-context\nlearning with models that range in size between 750 million and 178 billion\nparameters, and show substantial improvements for tasks with diverse input and\noutput spaces. Our results motivate further investigation of Parallel Context\nWindows as a method for applying off-the-shelf LLMs in other settings that\nrequire long text sequences.\n","authors":["Nir Ratner","Yoav Levine","Yonatan Belinkov","Ori Ram","Omri Abend","Ehud Karpas","Amnon Shashua","Kevin Leyton-Brown","Yoav Shoham"],"pdf_url":"https://arxiv.org/pdf/2212.10947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.06216v3","updated":"2022-12-21T11:37:14Z","published":"2022-08-12T10:57:48Z","title":"Is Your Model Sensitive? SPeDaC: A New Benchmark for Detecting and\n  Classifying Sensitive Personal Data","summary":"  In recent years, there has been an exponential growth of applications,\nincluding dialogue systems, that handle sensitive personal information. This\nhas brought to light the extremely important issue of personal data protection\nin virtual environments. Sensitive Information Detection (SID) approaches\ndifferent domains and languages in literature. However, if we refer to the\npersonal data domain, a shared benchmark or the absence of an available labeled\nresource makes comparison with the state-of-the-art difficult. We introduce and\nrelease SPeDaC , a new annotated resource for the identification of sensitive\npersonal data categories in the English language. SPeDaC enables the evaluation\nof computational models for three different SID subtasks with increasing levels\nof complexity. SPeDaC 1 regards binary classification, a model has to detect if\na sentence contains sensitive information or not; whereas, in SPeDaC 2 we\ncollected labeled sentences using 5 categories that relate to macro-domains of\npersonal information; in SPeDaC 3, the labeling is fine-grained (61 personal\ndata categories). We conduct an extensive evaluation of the resource using\ndifferent state-of-the-art-classifiers. The results show that SPeDaC is\nchallenging, particularly with regard to fine-grained classification. The\ntransformer models achieve the best results (acc. RoBERTa on SPeDaC 1 = 98.20%,\nDeBERTa on SPeDaC 2 = 95.81% and SPeDaC 3 = 77.63%).\n","authors":["Gaia Gambarelli","Aldo Gangemi","Rocco Tripodi"],"pdf_url":"https://arxiv.org/pdf/2208.06216v3.pdf","comment":"25 pages, 4 figures, 12 tables"},{"id":"http://arxiv.org/abs/2212.10938v1","updated":"2022-12-21T11:25:41Z","published":"2022-12-21T11:25:41Z","title":"Critic-Guided Decoding for Controlled Text Generation","summary":"  Steering language generation towards objectives or away from undesired\ncontent has been a long-standing goal in utilizing language models (LM). Recent\nwork has demonstrated reinforcement learning and weighted decoding as effective\napproaches to achieve a higher level of language control and quality with pros\nand cons. In this work, we propose a novel critic decoding method for\ncontrolled language generation (CriticControl) that combines the strengths of\nreinforcement learning and weighted decoding. Specifically, we adopt the\nactor-critic framework to train an LM-steering critic from non-differentiable\nreward models. And similar to weighted decoding, our method freezes the\nlanguage model and manipulates the output token distribution using called\ncritic, improving training efficiency and stability. Evaluation of our method\non three controlled generation tasks, namely topic control, sentiment control,\nand detoxification, shows that our approach generates more coherent and\nwell-controlled texts than previous methods. In addition, CriticControl\ndemonstrates superior generalization ability in zero-shot settings. Human\nevaluation studies also corroborate our findings.\n","authors":["Minbeom Kim","Hwanhee Lee","Kang Min Yoo","Joonsuk Park","Hwaran Lee","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2212.10938v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2212.10935v1","updated":"2022-12-21T11:23:31Z","published":"2022-12-21T11:23:31Z","title":"Esports Data-to-commentary Generation on Large-scale Data-to-text\n  Dataset","summary":"  Esports, a sports competition using video games, has become one of the most\nimportant sporting events in recent years. Although the amount of esports data\nis increasing than ever, only a small fraction of those data accompanies text\ncommentaries for the audience to retrieve and understand the plays. Therefore,\nin this study, we introduce a task of generating game commentaries from\nstructured data records to address the problem. We first build a large-scale\nesports data-to-text dataset using structured data and commentaries from a\npopular esports game, League of Legends. On this dataset, we devise several\ndata preprocessing methods including linearization and data splitting to\naugment its quality. We then introduce several baseline encoder-decoder models\nand propose a hierarchical model to generate game commentaries. Considering the\ncharacteristics of esports commentaries, we design evaluation metrics including\nthree aspects of the output: correctness, fluency, and strategic depth.\nExperimental results on our large-scale esports dataset confirmed the advantage\nof the hierarchical model, and the results revealed several challenges of this\nnovel task.\n","authors":["Zihan Wang","Naoki Yoshinaga"],"pdf_url":"https://arxiv.org/pdf/2212.10935v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10933v1","updated":"2022-12-21T11:22:38Z","published":"2022-12-21T11:22:38Z","title":"Resolving Indirect Referring Expressions for Entity Selection","summary":"  Recent advances in language modeling have enabled new conversational systems.\nIn particular, it is often desirable for people to make choices among specified\noptions when using such systems. We address the problem of reference\nresolution, when people use natural expressions to choose between real world\nentities. For example, given the choice `Should we make a Simnel cake or a\nPandan cake?' a natural response from a non-expert may be indirect: `let's make\nthe green one'. Reference resolution has been little studied with natural\nexpressions, thus robustly understanding such language has large potential for\nimproving naturalness in dialog, recommendation, and search systems. We create\nAltEntities (Alternative Entities), a new public dataset of entity pairs and\nutterances, and develop models for the disambiguation problem. Consisting of\n42K indirect referring expressions across three domains, it enables for the\nfirst time the study of how large language models can be adapted to this task.\nWe find they achieve 82%-87% accuracy in realistic settings, which while\nreasonable also invites further advances.\n","authors":["Mohammad Javad Hosseini","Filip Radlinski","Silvia Pareti","Annie Louis"],"pdf_url":"https://arxiv.org/pdf/2212.10933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10929v1","updated":"2022-12-21T11:18:09Z","published":"2022-12-21T11:18:09Z","title":"SPT: Semi-Parametric Prompt Tuning for Multitask Prompted Learning","summary":"  Pre-trained large language models can efficiently interpolate human-written\nprompts in a natural way. Multitask prompted learning can help generalization\nthrough a diverse set of tasks at once, thus enhancing the potential for more\neffective downstream fine-tuning. To perform efficient multitask-inference in\nthe same batch, parameter-efficient fine-tuning methods such as prompt tuning\nhave been proposed. However, the existing prompt tuning methods may lack\ngeneralization. We propose SPT, a semi-parametric prompt tuning method for\nmultitask prompted learning. The novel component of SPT is a memory bank from\nwhere memory prompts are retrieved based on discrete prompts. Extensive\nexperiments, such as (i) fine-tuning a full language model with SPT on 31\ndifferent tasks from 8 different domains and evaluating zero-shot\ngeneralization on 9 heldout datasets under 5 NLP task categories and (ii)\npretraining SPT on the GLUE datasets and evaluating fine-tuning on the\nSuperGLUE datasets, demonstrate effectiveness of SPT.\n","authors":["M Saiful Bari","Aston Zhang","Shuai Zheng","Xingjian Shi","Yi Zhu","Shafiq Joty","Mu Li"],"pdf_url":"https://arxiv.org/pdf/2212.10929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10923v1","updated":"2022-12-21T11:12:14Z","published":"2022-12-21T11:12:14Z","title":"Language Models as Inductive Reasoners","summary":"  Inductive reasoning is a core component of human intelligence. In the past\nresearch of inductive reasoning within computer science, logic language is used\nas representations of knowledge (facts and rules, more specifically). However,\nlogic language can cause systematic problems for inductive reasoning such as\ndisability of handling raw input such as natural language, sensitiveness to\nmislabeled data, and incapacity to handle ambiguous input. To this end, we\npropose a new task, which is to induce natural language rules from natural\nlanguage facts, and create a dataset termed DEER containing 1.2k rule-fact\npairs for the task, where rules and facts are written in natural language. New\nautomatic metrics are also proposed and analysed for the evaluation of this\ntask. With DEER, we investigate a modern approach for inductive reasoning where\nwe use natural language as representation for knowledge instead of logic\nlanguage and use pretrained language models as ''reasoners''. Moreover, we\nprovide the first and comprehensive analysis of how well pretrained language\nmodels can induce natural language rules from natural language facts. We also\npropose a new framework drawing insights from philosophy literature for this\ntask, which we show in the experiment section that surpasses baselines in both\nautomatic and human evaluations.\n","authors":["Zonglin Yang","Li Dong","Xinya Du","Hao Cheng","Erik Cambria","Xiaodong Liu","Jianfeng Gao","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.10923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10901v1","updated":"2022-12-21T10:20:54Z","published":"2022-12-21T10:20:54Z","title":"RECAP: Retrieval Augmented Music Captioner","summary":"  With the prevalence of stream media platforms serving music search and\nrecommendation, interpreting music by understanding audio and lyrics\ninteractively has become an important and challenging task. However, many\nprevious works focus on refining individual components of encoder-decoder\narchitecture mapping music to caption tokens, ignoring the potential usage of\naudio and lyrics correspondence. In this paper, we propose to explicitly learn\nthe multi-modal alignment with retrieval augmentation by contrastive learning.\nBy learning audio-lyrics correspondence, the model is guided to learn better\ncross-modal attention weights, thus generating high-quality caption words. We\nprovide both theoretical and empirical results that demonstrate the advantage\nof the proposed method.\n","authors":["Zihao He","Weituo Hao","Xuchen Song"],"pdf_url":"https://arxiv.org/pdf/2212.10901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00731v2","updated":"2022-12-21T10:15:52Z","published":"2022-09-01T21:16:47Z","title":"In conversation with Artificial Intelligence: aligning language models\n  with human values","summary":"  Large-scale language technologies are increasingly used in various forms of\ncommunication with humans across different contexts. One particular use case\nfor these technologies is conversational agents, which output natural language\ntext in response to prompts and queries. This mode of engagement raises a\nnumber of social and ethical questions. For example, what does it mean to align\nconversational agents with human norms or values? Which norms or values should\nthey be aligned with? And how can this be accomplished? In this paper, we\npropose a number of steps that help answer these questions. We start by\ndeveloping a philosophical analysis of the building blocks of linguistic\ncommunication between conversational agents and human interlocutors. We then\nuse this analysis to identify and formulate ideal norms of conversation that\ncan govern successful linguistic communication between humans and\nconversational agents. Furthermore, we explore how these norms can be used to\nalign conversational agents with human values across a range of different\ndiscursive domains. We conclude by discussing the practical implications of our\nproposal for the design of conversational agents that are aligned with these\nnorms and values.\n","authors":["Atoosa Kasirzadeh","Iason Gabriel"],"pdf_url":"https://arxiv.org/pdf/2209.00731v2.pdf","comment":"Accepted for publication with minor revisions at Philosophy &\n  Technology"},{"id":"http://arxiv.org/abs/2212.10898v1","updated":"2022-12-21T10:15:19Z","published":"2022-12-21T10:15:19Z","title":"Training language models for deeper understanding improves brain\n  alignment","summary":"  Building systems that achieve a deeper understanding of language is one of\nthe central goals of natural language processing (NLP). Towards this goal,\nrecent works have begun to train language models on narrative datasets which\nrequire extracting the most critical information by integrating across long\ncontexts. However, it is still an open question whether these models are\nlearning a deeper understanding of the text, or if the models are simply\nlearning a heuristic to complete the task. This work investigates this further\nby turning to the one language processing system that truly understands complex\nlanguage: the human brain. We show that training language models for deeper\nnarrative understanding results in richer representations that have improved\nalignment to human brain activity. We further find that the improvements in\nbrain alignment are larger for character names than for other discourse\nfeatures, which indicates that these models are learning important narrative\nelements. Taken together, these results suggest that this type of training can\nindeed lead to deeper language understanding. These findings have consequences\nboth for cognitive neuroscience by revealing some of the significant factors\nbehind brain-NLP alignment, and for NLP by highlighting that understanding of\nlong-range context can be improved beyond language modeling.\n","authors":["Khai Loong Aw","Mariya Toneva"],"pdf_url":"https://arxiv.org/pdf/2212.10898v1.pdf","comment":"37 pages, 42 figures"},{"id":"http://arxiv.org/abs/2212.10888v1","updated":"2022-12-21T09:58:14Z","published":"2022-12-21T09:58:14Z","title":"A Survey of Mix-based Data Augmentation: Taxonomy, Methods,\n  Applications, and Explainability","summary":"  Data augmentation (DA) is indispensable in modern machine learning and deep\nneural networks. The basic idea of DA is to construct new training data to\nimprove the model's generalization by adding slightly disturbed versions of\nexisting data or synthesizing new data. In this work, we review a small but\nessential subset of DA -- Mix-based Data Augmentation (MixDA) that generates\nnovel samples by mixing multiple examples. Unlike conventional DA approaches\nbased on a single-sample operation or requiring domain knowledge, MixDA is more\ngeneral in creating a broad spectrum of new data and has received increasing\nattention in the community. We begin with proposing a new taxonomy classifying\nMixDA into, Mixup-based, Cutmix-based, and hybrid approaches according to a\nhierarchical view of the data mix. Various MixDA techniques are then\ncomprehensively reviewed in a more fine-grained way. Owing to its\ngeneralization, MixDA has penetrated a variety of applications which are also\ncompletely reviewed in this work. We also examine why MixDA works from\ndifferent aspects of improving model performance, generalization, and\ncalibration while explaining the model behavior based on the properties of\nMixDA. Finally, we recapitulate the critical findings and fundamental\nchallenges of current MixDA studies, and outline the potential directions for\nfuture works. Different from previous related works that summarize the DA\napproaches in a specific domain (e.g., images or natural language processing)\nor only review a part of MixDA studies, we are the first to provide a\nsystematical survey of MixDA in terms of its taxonomy, methodology,\napplications, and explainability. This work can serve as a roadmap to MixDA\ntechniques and application reviews while providing promising directions for\nresearchers interested in this exciting area.\n","authors":["Chengtai Cao","Fan Zhou","Yurou Dai","Jianping Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10879v1","updated":"2022-12-21T09:44:08Z","published":"2022-12-21T09:44:08Z","title":"Cross-Linguistic Syntactic Difference in Multilingual BERT: How Good is\n  It and How Does It Affect Transfer?","summary":"  Multilingual BERT (mBERT) has demonstrated considerable cross-lingual\nsyntactic ability, whereby it enables effective zero-shot cross-lingual\ntransfer of syntactic knowledge. The transfer is more successful between some\nlanguages, but it is not well understood what leads to this variation and\nwhether it fairly reflects difference between languages. In this work, we\ninvestigate the distributions of grammatical relations induced from mBERT in\nthe context of 24 typologically different languages. We demonstrate that the\ndistance between the distributions of different languages is highly consistent\nwith the syntactic difference in terms of linguistic formalisms. Such\ndifference learnt via self-supervision plays a crucial role in the zero-shot\ntransfer performance and can be predicted by variation in morphosyntactic\nproperties between languages. These results suggest that mBERT properly encodes\nlanguages in a way consistent with linguistic diversity and provide insights\ninto the mechanism of cross-lingual transfer.\n","authors":["Ningyu Xu","Tao Gui","Ruotian Ma","Qi Zhang","Jingting Ye","Menghan Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2212.10879v1.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2212.10873v1","updated":"2022-12-21T09:37:05Z","published":"2022-12-21T09:37:05Z","title":"Prompt-Augmented Linear Probing: Scaling Beyond The Limit of Few-shot\n  In-Context Learners","summary":"  Through in-context learning (ICL), large-scale language models are effective\nfew-shot learners without additional model fine-tuning. However, the ICL\nperformance does not scale well with the number of available training samples\nas it is limited by the inherent input length constraint of the underlying\nlanguage model. Meanwhile, many studies have revealed that language models are\nalso powerful feature extractors, allowing them to be utilized in a black-box\nmanner and enabling the linear probing paradigm, where lightweight\ndiscriminators are trained on top of the pre-extracted input representations.\nThis paper proposes prompt-augmented linear probing (PALP), a hybrid of linear\nprobing and ICL, which leverages the best of both worlds. PALP inherits the\nscalability of linear probing and the capability of enforcing language models\nto derive more meaningful representations via tailoring input into a more\nconceivable form. Throughout in-depth investigations on various datasets, we\nverified that PALP significantly enhances the input representations closing the\ngap between ICL in the data-hungry scenario and fine-tuning in the\ndata-abundant scenario with little training overhead, potentially making PALP a\nstrong alternative in a black-box scenario.\n","authors":["Hyunsoo Cho","Hyuhng Joon Kim","Junyeob Kim","Sang-Woo Lee","Sang-goo Lee","Kang Min Yoo","Taeuk Kim"],"pdf_url":"https://arxiv.org/pdf/2212.10873v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2212.10559v2","updated":"2022-12-21T08:36:47Z","published":"2022-12-20T18:58:48Z","title":"Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient\n  Descent as Meta-Optimizers","summary":"  Large pretrained language models have shown surprising In-Context Learning\n(ICL) ability. With a few demonstration input-label pairs, they can predict the\nlabel for an unseen input without additional parameter updates. Despite the\ngreat success in performance, the working mechanism of ICL still remains an\nopen problem. In order to better understand how ICL works, this paper explains\nlanguage models as meta-optimizers and understands ICL as a kind of implicit\nfinetuning. Theoretically, we figure out that the Transformer attention has a\ndual form of gradient descent based optimization. On top of it, we understand\nICL as follows: GPT first produces meta-gradients according to the\ndemonstration examples, and then these meta-gradients are applied to the\noriginal GPT to build an ICL model. Experimentally, we comprehensively compare\nthe behavior of ICL and explicit finetuning based on real tasks to provide\nempirical evidence that supports our understanding. The results prove that ICL\nbehaves similarly to explicit finetuning at the prediction level, the\nrepresentation level, and the attention behavior level. Further, inspired by\nour understanding of meta-optimization, we design a momentum-based attention by\nanalogy with the momentum-based gradient descent algorithm. Its consistently\nbetter performance over vanilla attention supports our understanding again from\nanother aspect, and more importantly, it shows the potential to utilize our\nunderstanding for future model designing.\n","authors":["Damai Dai","Yutao Sun","Li Dong","Yaru Hao","Zhifang Sui","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2212.10559v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10843v1","updated":"2022-12-21T08:34:28Z","published":"2022-12-21T08:34:28Z","title":"Generating Multiple-Length Summaries via Reinforcement Learning for\n  Unsupervised Sentence Summarization","summary":"  Sentence summarization shortens given texts while maintaining core contents\nof the texts. Unsupervised approaches have been studied to summarize texts\nwithout human-written summaries. However, recent unsupervised models are\nextractive, which remove words from texts and thus they are less flexible than\nabstractive summarization. In this work, we devise an abstractive model based\non reinforcement learning without ground-truth summaries. We formulate the\nunsupervised summarization based on the Markov decision process with rewards\nrepresenting the summary quality. To further enhance the summary quality, we\ndevelop a multi-summary learning mechanism that generates multiple summaries\nwith varying lengths for a given text, while making the summaries mutually\nenhance each other. Experimental results show that the proposed model\nsubstantially outperforms both abstractive and extractive models, yet\nfrequently generating new words not contained in input texts.\n","authors":["Dongmin Hyun","Xiting Wang","Chanyoung Park","Xing Xie","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2212.10843v1.pdf","comment":"Findings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2211.05719v3","updated":"2022-12-21T08:12:46Z","published":"2022-11-10T17:37:04Z","title":"MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal\n  Open-domain Conversation","summary":"  Responding with multi-modal content has been recognized as an essential\ncapability for an intelligent conversational agent. In this paper, we introduce\nthe MMDialog dataset to better facilitate multi-modal conversation. MMDialog is\ncomposed of a curated set of 1.08 million real-world dialogues with 1.53\nmillion unique images across 4,184 topics. MMDialog has two main and unique\nadvantages. First, it is the largest multi-modal conversation dataset by the\nnumber of dialogues by 88x. Second, it contains massive topics to generalize\nthe open-domain. To build engaging dialogue system with this dataset, we\npropose and normalize two response producing tasks based on retrieval and\ngenerative scenarios. In addition, we build two baselines for above tasks with\nstate-of-the-art techniques and report their experimental performance. We also\npropose a novel evaluation metric MM-Relevance to measure the multi-modal\nresponses. Our dataset and scripts are available in\nhttps://github.com/victorsungo/MMDialog.\n","authors":["Jiazhan Feng","Qingfeng Sun","Can Xu","Pu Zhao","Yaming Yang","Chongyang Tao","Dongyan Zhao","Qingwei Lin"],"pdf_url":"https://arxiv.org/pdf/2211.05719v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07072v2","updated":"2022-12-21T07:36:49Z","published":"2022-12-14T07:48:42Z","title":"SMSMix: Sense-Maintained Sentence Mixup for Word Sense Disambiguation","summary":"  Word Sense Disambiguation (WSD) is an NLP task aimed at determining the\ncorrect sense of a word in a sentence from discrete sense choices. Although\ncurrent systems have attained unprecedented performances for such tasks, the\nnonuniform distribution of word senses during training generally results in\nsystems performing poorly on rare senses. To this end, we consider data\naugmentation to increase the frequency of these least frequent senses (LFS) to\nreduce the distributional bias of senses during training. We propose\nSense-Maintained Sentence Mixup (SMSMix), a novel word-level mixup method that\nmaintains the sense of a target word. SMSMix smoothly blends two sentences\nusing mask prediction while preserving the relevant span determined by saliency\nscores to maintain a specific word's sense. To the best of our knowledge, this\nis the first attempt to apply mixup in NLP while preserving the meaning of a\nspecific word. With extensive experiments, we validate that our augmentation\nmethod can effectively give more information about rare senses during training\nwith maintained target sense label.\n","authors":["Hee Suk Yoon","Eunseop Yoon","John Harvill","Sunjae Yoon","Mark Hasegawa-Johnson","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2212.07072v2.pdf","comment":"EMNLP2022"},{"id":"http://arxiv.org/abs/2212.10826v1","updated":"2022-12-21T07:35:33Z","published":"2022-12-21T07:35:33Z","title":"End-to-End Automatic Speech Recognition model for the Sudanese Dialect","summary":"  Designing a natural voice interface rely mostly on Speech recognition for\ninteraction between human and their modern digital life equipment. In addition,\nspeech recognition narrows the gap between monolingual individuals to better\nexchange communication. However, the field lacks wide support for several\nuniversal languages and their dialects, while most of the daily conversations\nare carried out using them. This paper comes to inspect the viability of\ndesigning an Automatic Speech Recognition model for the Sudanese dialect, which\nis one of the Arabic Language dialects, and its complexity is a product of\nhistorical and social conditions unique to its speakers. This condition is\nreflected in both the form and content of the dialect, so this paper gives an\noverview of the Sudanese dialect and the tasks of collecting represented\nresources and pre-processing performed to construct a modest dataset to\novercome the lack of annotated data. Also proposed end- to-end speech\nrecognition model, the design of the model was formed using Convolution Neural\nNetworks. The Sudanese dialect dataset would be a stepping stone to enable\nfuture Natural Language Processing research targeting the dialect. The designed\nmodel provided some insights into the current recognition task and reached an\naverage Label Error Rate of 73.67%.\n","authors":["Ayman Mansour","Wafaa F. Mukhtar"],"pdf_url":"https://arxiv.org/pdf/2212.10826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10823v1","updated":"2022-12-21T07:30:22Z","published":"2022-12-21T07:30:22Z","title":"Continual Contrastive Finetuning Improves Low-Resource Relation\n  Extraction","summary":"  Relation extraction (RE), which has relied on structurally annotated corpora\nfor model training, has been particularly challenging in low-resource scenarios\nand domains. Recent literature has tackled low-resource RE by self-supervised\nlearning, where the solution involves pretraining the relation embedding by\nRE-based objective and finetuning on labeled data by classification-based\nobjective. However, a critical challenge to this approach is the gap in\nobjectives, which prevents the RE model from fully utilizing the knowledge in\npretrained representations. In this paper, we aim at bridging the gap and\npropose to pretrain and finetune the RE model using consistent objectives of\ncontrastive learning. Since in this kind of representation learning paradigm,\none relation may easily form multiple clusters in the representation space, we\nfurther propose a multi-center contrastive loss that allows one relation to\nform multiple clusters to better align with pretraining. Experiments on two\ndocument-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness\nof our method. Particularly, when using 1% end-task training data, our method\noutperforms PLM-based RE classifier by 10.5% and 5.8% on the two datasets,\nrespectively.\n","authors":["Wenxuan Zhou","Sheng Zhang","Tristan Naumann","Muhao Chen","Hoifung Poon"],"pdf_url":"https://arxiv.org/pdf/2212.10823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10819v1","updated":"2022-12-21T07:17:32Z","published":"2022-12-21T07:17:32Z","title":"Attend to the Right Context: A Plug-and-Play Module for\n  Content-Controllable Summarization","summary":"  Content-Controllable Summarization generates summaries focused on the given\ncontrolling signals. Due to the lack of large-scale training corpora for the\ntask, we propose a plug-and-play module RelAttn to adapt any general\nsummarizers to the content-controllable summarization task. RelAttn first\nidentifies the relevant content in the source documents, and then makes the\nmodel attend to the right context by directly steering the attention weight. We\nfurther apply an unsupervised online adaptive parameter searching algorithm to\ndetermine the degree of control in the zero-shot setting, while such parameters\nare learned in the few-shot setting. By applying the module to three backbone\nsummarization models, experiments show that our method effectively improves all\nthe summarizers, and outperforms the prefix-based method and a widely used\nplug-and-play model in both zero- and few-shot settings. Tellingly, more\nbenefit is observed in the scenarios when more control is needed.\n","authors":["Wen Xiao","Lesly Miculicich","Yang Liu","Pengcheng He","Giuseppe Carenini"],"pdf_url":"https://arxiv.org/pdf/2212.10819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10818v1","updated":"2022-12-21T07:15:59Z","published":"2022-12-21T07:15:59Z","title":"4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict\n  decoders","summary":"  The network architecture of end-to-end (E2E) automatic speech recognition\n(ASR) can be classified into several models, including connectionist temporal\nclassification (CTC), recurrent neural network transducer (RNN-T), attention\nmechanism, and non-autoregressive mask-predict models. Since each of these\nnetwork architectures has pros and cons, a typical use case is to switch these\nseparate models depending on the application requirement, resulting in the\nincreased overhead of maintaining all models. Several methods for integrating\ntwo of these complementary models to mitigate the overhead issue have been\nproposed; however, if we integrate more models, we will further benefit from\nthese complementary models and realize broader applications with a single\nsystem. This paper proposes four-decoder joint modeling (4D) of CTC, attention,\nRNN-T, and mask-predict, which has the following three advantages: 1) The four\ndecoders are jointly trained so that they can be easily switched depending on\nthe application scenarios. 2) Joint training may bring model regularization and\nimprove the model robustness thanks to their complementary properties. 3) Novel\none-pass joint decoding methods using CTC, attention, and RNN-T further\nimproves the performance. The experimental results showed that the proposed\nmodel consistently reduced the WER.\n","authors":["Yui Sudo","Muhammad Shakeel","Brian Yan","Jiatong Shi","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2212.10818v1.pdf","comment":"Submitted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2212.10815v1","updated":"2022-12-21T07:06:55Z","published":"2022-12-21T07:06:55Z","title":"ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language\n  Models","summary":"  We explore the use of large language models (LLMs) for zero-shot semantic\nparsing. Semantic parsing involves mapping natural language utterances to\ntask-specific meaning representations. Language models are generally trained on\nthe publicly available text and code and cannot be expected to directly\ngeneralize to domain-specific parsing tasks in a zero-shot setting. In this\nwork, we propose ZEROTOP, a zero-shot task-oriented parsing method that\ndecomposes a semantic parsing problem into a set of abstractive and extractive\nquestion-answering (QA) problems, enabling us to leverage the ability of LLMs\nto zero-shot answer reading comprehension questions. For each utterance, we\nprompt the LLM with questions corresponding to its top-level intent and a set\nof slots and use the LLM generations to construct the target meaning\nrepresentation. We observe that current LLMs fail to detect unanswerable\nquestions; and as a result, cannot handle questions corresponding to missing\nslots. To address this problem, we fine-tune a language model on public QA\ndatasets using synthetic negative samples. Experimental results show that our\nQA-based decomposition paired with the fine-tuned LLM can correctly parse ~16%\nof utterances in the MTOP dataset without requiring any annotated data.\n","authors":["Dheeraj Mekala","Jason Wolfe","Subhro Roy"],"pdf_url":"https://arxiv.org/pdf/2212.10815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10792v1","updated":"2022-12-21T06:22:03Z","published":"2022-12-21T06:22:03Z","title":"Reconstruction Probing","summary":"  We propose reconstruction probing, a new analysis method for contextualized\nrepresentations based on reconstruction probabilities in masked language models\n(MLMs). This method relies on comparing the reconstruction probabilities of\ntokens in a given sequence when conditioned on the representation of a single\ntoken that has been fully contextualized and when conditioned on only the\ndecontextualized lexical prior of the model. This comparison can be understood\nas quantifying the contribution of contextualization towards reconstruction --\nthe difference in the reconstruction probabilities can only be attributed to\nthe representational change of the single token induced by contextualization.\nWe apply this analysis to three MLMs and find that contextualization boosts\nreconstructability of tokens that are close to the token being reconstructed in\nterms of linear and syntactic distance. Furthermore, we extend our analysis to\nfiner-grained decomposition of contextualized representations, and we find that\nthese boosts are largely attributable to static and positional embeddings at\nthe input layer.\n","authors":["Najoung Kim","Jatin Khilnani","Alex Warstadt","Abed Qaddoumi"],"pdf_url":"https://arxiv.org/pdf/2212.10792v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.10791v1","updated":"2022-12-21T06:20:28Z","published":"2022-12-21T06:20:28Z","title":"OpineSum: Entailment-based self-training for abstractive opinion\n  summarization","summary":"  A typical product or place often has hundreds of reviews, and summarization\nof these texts is an important and challenging problem. Recent progress on\nabstractive summarization in domains such as news has been driven by supervised\nsystems trained on hundreds of thousands of news articles paired with\nhuman-written summaries. However for opinion texts, such large scale datasets\nare rarely available. Unsupervised methods, self-training, and few-shot\nlearning approaches bridge that gap. In this work, we present a novel\nself-training approach, OpineSum, for abstractive opinion summarization. The\nsummaries in this approach are built using a novel application of textual\nentailment and capture the consensus of opinions across the various reviews for\nan item. This method can be used to obtain silver-standard summaries on a large\nscale and train both unsupervised and few-shot abstractive summarization\nsystems. OpineSum achieves state-of-the-art performance in both settings.\n","authors":["Annie Louis","Joshua Maynez"],"pdf_url":"https://arxiv.org/pdf/2212.10791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10789v1","updated":"2022-12-21T06:18:31Z","published":"2022-12-21T06:18:31Z","title":"Multi-modal Molecule Structure-text Model for Text-based Retrieval and\n  Editing","summary":"  There is increasing adoption of artificial intelligence in drug discovery.\nHowever, existing works use machine learning to mainly utilize the chemical\nstructures of molecules yet ignore the vast textual knowledge available in\nchemistry. Incorporating textual knowledge enables us to realize new drug\ndesign objectives, adapt to text-based instructions, and predict complex\nbiological activities. We present a multi-modal molecule structure-text model,\nMoleculeSTM, by jointly learning molecule's chemical structures and textual\ndescriptions via a contrastive learning strategy. To train MoleculeSTM, we\nconstruct the largest multi-modal dataset to date, namely PubChemSTM, with over\n280K chemical structure-text pairs. To demonstrate the effectiveness and\nutility of MoleculeSTM, we design two challenging zero-shot tasks based on text\ninstructions, including structure-text retrieval and molecule editing.\nMoleculeSTM possesses two main properties: open vocabulary and compositionality\nvia natural language. In experiments, MoleculeSTM obtains the state-of-the-art\ngeneralization ability to novel biochemical concepts across various benchmarks.\n","authors":["Shengchao Liu","Weili Nie","Chengpeng Wang","Jiarui Lu","Zhuoran Qiao","Ling Liu","Jian Tang","Chaowei Xiao","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2212.10789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10786v1","updated":"2022-12-21T06:00:22Z","published":"2022-12-21T06:00:22Z","title":"Multi-hop Evidence Retrieval for Cross-document Relation Extraction","summary":"  Relation Extraction (RE) has been extended to cross-document scenarios\nbecause many relations are not simply described in a single document. This\ninevitably brings the challenge of efficient open-space evidence retrieval to\nsupport the inference of cross-document relations, along with the challenge of\nmulti-hop reasoning on top of entities and evidence scattered in an open set of\ndocuments. To combat these challenges, we propose Mr.CoD, a multi-hop evidence\nretrieval method based on evidence path mining and ranking with adapted dense\nretrievers. We explore multiple variants of retrievers to show evidence\nretrieval is an essential part in cross-document RE. Experiments on CodRED show\nthat evidence retrieval with Mr.Cod effectively acquires cross-document\nevidence that essentially supports open-setting cross-document RE.\nAdditionally, we show that Mr.CoD facilitates evidence retrieval and boosts\nend-to-end RE performance with effective multi-hop reasoning in both closed and\nopen settings of RE.\n","authors":["Keming Lu","I-Hung Hsu","Wenxuan Zhou","Mingyu Derek Ma","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10786v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.10785v1","updated":"2022-12-21T05:54:14Z","published":"2022-12-21T05:54:14Z","title":"SERENGETI: Massively Multilingual Language Models for Africa","summary":"  Multilingual language models (MLMs) acquire valuable, generalizable\nlinguistic information during pretraining and have advanced the state of the\nart on task-specific finetuning. So far, only ~ 28 out of ~2,000 African\nlanguages are covered in existing language models. We ameliorate this\nlimitation by developing SERENGETI, a set of massively multilingual language\nmodel that covers 517 African languages and language varieties. We evaluate our\nnovel models on eight natural language understanding tasks across 20 datasets,\ncomparing to four MLMs that each cover any number of African languages.\nSERENGETI outperforms other models on 11 datasets across the eights tasks and\nachieves 82.27 average F-1. We also perform error analysis on our models'\nperformance and show the influence of mutual intelligibility when the models\nare applied under zero-shot settings. We will publicly release our models for\nresearch.\n","authors":["Ife Adebara","AbdelRahim Elmadany","Muhammad Abdul-Mageed","Alcides Alcoba Inciarte"],"pdf_url":"https://arxiv.org/pdf/2212.10785v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2212.10784v1","updated":"2022-12-21T05:49:08Z","published":"2022-12-21T05:49:08Z","title":"Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical\n  Relation Extraction?","summary":"  Two key obstacles in biomedical relation extraction (RE) are the scarcity of\nannotations and the prevalence of instances without explicitly pre-defined\nlabels due to low annotation coverage. Existing approaches, which treat\nbiomedical RE as a multi-class classification task, often result in poor\ngeneralization in low-resource settings and do not have the ability to make\nselective prediction on unknown cases but give a guess from seen relations,\nhindering the applicability of those approaches. We present NBR, which converts\nbiomedical RE as natural language inference formulation through indirect\nsupervision. By converting relations to natural language hypotheses, NBR is\ncapable of exploiting semantic cues to alleviate annotation scarcity. By\nincorporating a ranking-based loss that implicitly calibrates abstinent\ninstances, NBR learns a clearer decision boundary and is instructed to abstain\non uncertain instances. Extensive experiments on three widely-used biomedical\nRE benchmarks, namely ChemProt, DDI and GAD, verify the effectiveness of NBR in\nboth full-set and low-resource regimes. Our analysis demonstrates that indirect\nsupervision benefits biomedical RE even when a domain gap exists, and combining\nNLI knowledge with biomedical knowledge leads to the best performance gains.\n","authors":["Jiashu Xu","Mingyu Derek Ma","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10784v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2212.10773v1","updated":"2022-12-21T05:17:06Z","published":"2022-12-21T05:17:06Z","title":"MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction\n  Tuning","summary":"  Instruction tuning, a new learning paradigm that fine-tunes pre-trained\nlanguage models on tasks specified through instructions, has shown promising\nzero-shot performance on various natural language processing tasks. However,\nit's still not explored for vision and multimodal tasks. In this work, we\nintroduce MultiInstruct, the first multimodal instruction tuning benchmark\ndataset that consists of 47 diverse multimodal tasks covering 11 broad\ncategories. Each task is designed at least with 5,000 instances (input-out\npairs) from existing open-source datasets and 5 expert-written instructions. We\ntake OFA as the base pre-trained model for multimodal instruction tuning, and\nto improve its performance, we explore multiple transfer learning strategies to\nleverage the large-scale Natural Instructions dataset. Experimental results\ndemonstrate its strong zero-shot performance on various unseen multimodal tasks\nand the benefit of transfer learning from text-only instructions. We also\ndesign a new evaluation metric: Sensitivity, to evaluate how sensitive the\nmodel is to the variety of instructions. Our results indicate that the model is\nless sensitive to the varying instructions after finetuning on a diverse set of\ntasks and instructions for each task.\n","authors":["Zhiyang Xu","Ying Shen","Lifu Huang"],"pdf_url":"https://arxiv.org/pdf/2212.10773v1.pdf","comment":"16 pages, 10 tables, 4 figures"},{"id":"http://arxiv.org/abs/2212.10770v1","updated":"2022-12-21T05:02:49Z","published":"2022-12-21T05:02:49Z","title":"ImPaKT: A Dataset for Open-Schema Knowledge Base Construction","summary":"  Large language models have ushered in a golden age of semantic parsing. The\nseq2seq paradigm allows for open-schema and abstractive attribute and relation\nextraction given only small amounts of finetuning data. Language model\npretraining has simultaneously enabled great strides in natural language\ninference, reasoning about entailment and implication in free text. These\nadvances motivate us to construct ImPaKT, a dataset for open-schema information\nextraction, consisting of around 2500 text snippets from the C4 corpus, in the\nshopping domain (product buying guides), professionally annotated with\nextracted attributes, types, attribute summaries (attribute schema discovery\nfrom idiosyncratic text), many-to-one relations between compound and atomic\nattributes, and implication relations. We release this data in hope that it\nwill be useful in fine tuning semantic parsers for information extraction and\nknowledge base construction across a variety of domains. We evaluate the power\nof this approach by fine-tuning the open source UL2 language model on a subset\nof the dataset, extracting a set of implication relations from a corpus of\nproduct buying guides, and conducting human evaluations of the resulting\npredictions.\n","authors":["Luke Vilnis","Zach Fisher","Bhargav Kanagal","Patrick Murray","Sumit Sanghai"],"pdf_url":"https://arxiv.org/pdf/2212.10770v1.pdf","comment":"14 pages. Preprint"},{"id":"http://arxiv.org/abs/2212.10769v1","updated":"2022-12-21T05:02:08Z","published":"2022-12-21T05:02:08Z","title":"Uncontrolled Lexical Exposure Leads to Overestimation of Compositional\n  Generalization in Pretrained Models","summary":"  Human linguistic capacity is often characterized by compositionality and the\ngeneralization it enables -- human learners can produce and comprehend novel\ncomplex expressions by composing known parts. Several benchmarks exploit\ndistributional control across training and test to gauge compositional\ngeneralization, where certain lexical items only occur in limited contexts\nduring training. While recent work using these benchmarks suggests that\npretrained models achieve impressive generalization performance, we argue that\nexposure to pretraining data may break the aforementioned distributional\ncontrol. Using the COGS benchmark of Kim and Linzen (2020), we test two\nmodified evaluation setups that control for this issue: (1) substituting\ncontext-controlled lexical items with novel character sequences, and (2)\nsubstituting them with special tokens represented by novel embeddings. We find\nthat both of these setups lead to lower generalization performance in T5\n(Raffel et al., 2020), suggesting that previously reported results have been\noverestimated due to uncontrolled lexical exposure during pretraining. The\nperformance degradation is more extreme with novel embeddings, and the\ndegradation increases with the amount of pretraining data, highlighting an\ninteresting case of inverse scaling.\n","authors":["Najoung Kim","Tal Linzen","Paul Smolensky"],"pdf_url":"https://arxiv.org/pdf/2212.10769v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.10767v1","updated":"2022-12-21T05:01:01Z","published":"2022-12-21T05:01:01Z","title":"How Does Beam Search improve Span-Level Confidence Estimation in\n  Generative Sequence Labeling?","summary":"  Text-to-text generation models have increasingly become the go-to solution\nfor a wide variety of sequence labeling tasks (e.g., entity extraction and\ndialog slot filling). While most research has focused on the labeling accuracy,\na key aspect -- of vital practical importance -- has slipped through the\ncracks: understanding model confidence. More specifically, we lack a principled\nunderstanding of how to reliably gauge the confidence of a model in its\npredictions for each labeled span. This paper aims to provide some empirical\ninsights on estimating model confidence for generative sequence labeling. Most\nnotably, we find that simply using the decoder's output probabilities is not\nthe best in realizing well-calibrated confidence estimates. As verified over\nsix public datasets of different tasks, we show that our proposed approach --\nwhich leverages statistics from top-$k$ predictions by a beam search --\nsignificantly reduces calibration errors of the predictions of a generative\nsequence labeling model.\n","authors":["Kazuma Hashimoto","Iftekhar Naim","Karthik Raman"],"pdf_url":"https://arxiv.org/pdf/2212.10767v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10764v1","updated":"2022-12-21T04:49:55Z","published":"2022-12-21T04:49:55Z","title":"Learning List-Level Domain-Invariant Representations for Ranking","summary":"  Domain adaptation aims to transfer the knowledge acquired by models trained\non (data-rich) source domains to (low-resource) target domains, for which a\npopular method is invariant representation learning. While they have been\nstudied extensively for classification and regression problems, how they apply\nto ranking problems, where the data and metrics have a list structure, is not\nwell understood. Theoretically, we establish a domain adaptation generalization\nbound for ranking under listwise metrics such as MRR and NDCG. The bound\nsuggests an adaptation method via learning list-level domain-invariant feature\nrepresentations, whose benefits are empirically demonstrated by unsupervised\ndomain adaptation experiments on real-world ranking tasks, including passage\nreranking. A key message is that for domain adaptation, the representations\nshould be analyzed at the same level at which the metric is computed, as we\nshow that learning invariant representations at the list level is most\neffective for adaptation on ranking problems.\n","authors":["Ruicheng Xian","Honglei Zhuang","Zhen Qin","Hamed Zamani","Jing Lu","Ji Ma","Kai Hui","Han Zhao","Xuanhui Wang","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2212.10764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10758v1","updated":"2022-12-21T04:35:43Z","published":"2022-12-21T04:35:43Z","title":"ORCA: A Challenging Benchmark for Arabic Language Understanding","summary":"  Due to their crucial role in all NLP, several benchmarks have been proposed\nto evaluate pretrained language models. In spite of these efforts, no public\nbenchmark of diverse nature currently exists for evaluation of Arabic. This\nmakes it challenging to measure progress for both Arabic and multilingual\nlanguage models. This challenge is compounded by the fact that any benchmark\ntargeting Arabic needs to take into account the fact that Arabic is not a\nsingle language but rather a collection of languages and varieties. In this\nwork, we introduce ORCA, a publicly available benchmark for Arabic language\nunderstanding evaluation. ORCA is carefully constructed to cover diverse Arabic\nvarieties and a wide range of challenging Arabic understanding tasks exploiting\n60 different datasets across seven NLU task clusters. To measure current\nprogress in Arabic NLU, we use ORCA to offer a comprehensive comparison between\n18 multilingual and Arabic language models. We also provide a public\nleaderboard with a unified single-number evaluation metric (ORCA score) to\nfacilitate future research.\n","authors":["AbdelRahim Elmadany","El Moatez Billah Nagoudi","Muhammad Abdul-Mageed"],"pdf_url":"https://arxiv.org/pdf/2212.10758v1.pdf","comment":"All authors contributed equally"},{"id":"http://arxiv.org/abs/2212.10755v1","updated":"2022-12-21T04:21:46Z","published":"2022-12-21T04:21:46Z","title":"JASMINE: Arabic GPT Models for Few-Shot Learning","summary":"  Task agnostic generative pretraining (GPT) has recently proved promising for\nzero- and few-shot learning, gradually diverting attention from the expensive\nsupervised learning paradigm. Although the community is accumulating knowledge\nas to capabilities of English-language autoregressive models such as GPT-3\nadopting this generative approach, scholarship about these models remains\nacutely Anglocentric. Consequently, the community currently has serious gaps in\nits understanding of this class of models, their potential, and their societal\nimpacts in diverse settings, linguistic traditions, and cultures. To alleviate\nthis issue for Arabic, a collection of diverse languages and language varieties\nwith more than $400$ million population, we introduce JASMINE, a suite of\npowerful Arabic autoregressive Transformer language models ranging in size\nbetween 300 million-13 billion parameters. We pretrain our new models with\nlarge amounts of diverse data (400GB of text) from different Arabic varieties\nand domains. We evaluate JASMINE extensively in both intrinsic and extrinsic\nsettings, using a comprehensive benchmark for zero- and few-shot learning\nacross a wide range of NLP tasks. We also carefully develop and release a novel\nbenchmark for both automated and human evaluation of Arabic autoregressive\nmodels focused at investigating potential social biases, harms, and toxicity in\nthese models. We aim to responsibly release our models with interested\nresearchers, along with code for experimenting with them\n","authors":["El Moatez Billah Nagoudi","Muhammad Abdul-Mageed","AbdelRahim Elmadany","Alcides Alcoba Inciarte","Md Tawkat Islam Khondaker"],"pdf_url":"https://arxiv.org/pdf/2212.10755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10754v1","updated":"2022-12-21T04:21:35Z","published":"2022-12-21T04:21:35Z","title":"CORRPUS: Detecting Story Inconsistencies via Codex-Bootstrapped\n  Neurosymbolic Reasoning","summary":"  Story generation and understanding -- as with all NLG/NLU tasks -- has seen a\nsurge in neurosymbolic work. Researchers have recognized that, while large\nlanguage models (LLMs) have tremendous utility, they can be augmented with\nsymbolic means to be even better and to make up for any flaws that the neural\nnetworks might have. However, symbolic methods are extremely costly in terms of\nthe amount of time and expertise needed to create them. In this work, we\ncapitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use\nof symbolic methods for tracking the state of stories and aiding in story\nunderstanding. We show that our CoRRPUS system and abstracted prompting\nprocedures can beat current state-of-the-art structured LLM techniques on\npre-existing story understanding tasks (bAbI task 2 and Re^3) with minimal hand\nengineering. We hope that this work can help highlight the importance of\nsymbolic representations and specialized prompting for LLMs as these models\nrequire some guidance for performing reasoning tasks properly.\n","authors":["Yijiang River Dong","Lara J. Martin","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2212.10754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10750v1","updated":"2022-12-21T04:03:33Z","published":"2022-12-21T04:03:33Z","title":"PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and\n  Entailment Recognition","summary":"  The widely studied task of Natural Language Inference (NLI) requires a system\nto recognize whether one piece of text is textually entailed by another, i.e.\nwhether the entirety of its meaning can be inferred from the other. In current\nNLI datasets and models, textual entailment relations are typically defined on\nthe sentence- or paragraph-level. However, even a simple sentence often\ncontains multiple propositions, i.e. distinct units of meaning conveyed by the\nsentence. As these propositions can carry different truth values in the context\nof a given premise, we argue for the need to recognize the textual entailment\nrelation of each proposition in a sentence individually.\n  We propose PropSegmEnt, a corpus of over 35K propositions annotated by expert\nhuman raters. Our dataset structure resembles the tasks of (1) segmenting\nsentences within a document to the set of propositions, and (2) classifying the\nentailment relation of each proposition with respect to a different yet\ntopically-aligned document, i.e. documents describing the same event or entity.\nWe establish strong baselines for the segmentation and entailment tasks.\nThrough case studies on summary hallucination detection and document-level NLI,\nwe demonstrate that our conceptual framework is potentially useful for\nunderstanding and explaining the compositionality of NLI labels.\n","authors":["Sihao Chen","Senaka Buthpitiya","Alex Fabrikant","Dan Roth","Tal Schuster"],"pdf_url":"https://arxiv.org/pdf/2212.10750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.09231v3","updated":"2022-12-21T03:57:23Z","published":"2021-12-16T22:36:17Z","title":"Two-view Graph Neural Networks for Knowledge Graph Completion","summary":"  We present an effective graph neural network (GNN)-based knowledge graph\nembedding model, which we name WGE, to capture entity- and relation-focused\ngraph structures. Given a knowledge graph, WGE builds a single undirected\nentity-focused graph that views entities as nodes. WGE also constructs another\nsingle undirected graph from relation-focused constraints, which views entities\nand relations as nodes. WGE then proposes a GNN-based architecture to better\nlearn vector representations of entities and relations from these two single\nentity- and relation-focused graphs. WGE feeds the learned entity and relation\nrepresentations into a weighted score function to return the triple scores for\nknowledge graph completion. Experimental results show that WGE outperforms\ncompetitive baselines, obtaining state-of-the-art performances on seven\nbenchmark datasets for knowledge graph completion.\n","authors":["Vinh Tong","Dai Quoc Nguyen","Dinh Phung","Dat Quoc Nguyen"],"pdf_url":"https://arxiv.org/pdf/2112.09231v3.pdf","comment":"17 pages; 4 tables; 4 figures"},{"id":"http://arxiv.org/abs/2205.12680v2","updated":"2022-12-21T03:43:14Z","published":"2022-05-25T11:39:42Z","title":"Optimizing Test-Time Query Representations for Dense Retrieval","summary":"  Recent developments of dense retrieval rely on quality representations of\nqueries and contexts coming from pre-trained query and context encoders. In\nthis paper, we introduce TouR (test-time optimization of query\nrepresentations), which further optimizes instance-level query representations\nguided by signals from test-time retrieval results. We leverage a cross-encoder\nre-ranker to provide fine-grained pseudo labels over retrieval results and\niteratively optimize query representations with the gradient descent method.\nOur theoretical analysis reveals that TouR can be viewed as a generalization of\nthe classical Rocchio's algorithm for pseudo relevance feedback, and we present\ntwo variants leveraging psuedo labels as either hard binary or soft continuous\nlabels. We first apply TouR on phrase retrieval with our proposed phrase\nre-ranker. On passage retrieval, we demonstrate its effectiveness with an\noff-the-shelf re-ranker. TouR improves the end-to-end open-domain QA accuracy\nsignificantly, as well as passage retrieval performance. Compared to re-ranker,\nTouR requires a smaller number of candidates, and achieves consistently better\nperformance and runs up to 4x faster with our efficient implementation.\n","authors":["Mujeen Sung","Jungsoo Park","Jaewoo Kang","Danqi Chen","Jinhyuk Lee"],"pdf_url":"https://arxiv.org/pdf/2205.12680v2.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.10740v1","updated":"2022-12-21T03:22:24Z","published":"2022-12-21T03:22:24Z","title":"ToL: A Tensor of List-Based Unified Computation Model","summary":"  Previous computation models either have equivalent abilities in representing\nall computations but fail to provide primitive operators for programming\ncomplex algorithms or lack generalized expression ability to represent\nnewly-added computations. This article presents a unified computation model\nwith generalized expression ability and a concise set of primitive operators\nfor programming high-level algorithms. We propose a unified data abstraction --\nTensor of List, and offer a unified computation model based on Tensor of List,\nwhich we call the ToL model (in short, ToL). ToL introduces five atomic\ncomputations that can represent any elementary computation by finite\ncomposition, ensured with strict formal proof. Based on ToL, we design a\npure-functional language -- ToLang. ToLang provides a concise set of primitive\noperators that can be used to program complex big data and AI algorithms. Our\nevaluations show ToL has generalized expression ability and a built-in\nperformance indicator, born with a strictly defined computation metric --\nelementary operation count (EOPs), consistent with FLOPs within a small error\nrange.\n","authors":["Hongxiao Li","Wanling Gao","Lei Wang","Jianfeng Zhan"],"pdf_url":"https://arxiv.org/pdf/2212.10740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.02611v2","updated":"2022-12-21T03:02:43Z","published":"2021-12-05T16:17:21Z","title":"Multi-View Active Learning for Short Text Classification in\n  User-Generated Data","summary":"  Mining user-generated data often suffers from the lack of enough labeled\ndata, short document lengths, and the informal user language. In this paper, we\npropose a novel active learning model to overcome these obstacles in the tasks\ntailored for query phrases--e.g., detecting positive reports of natural\ndisasters. Our model has three novelties: 1) It is the first approach to employ\nmulti-view active learning in this domain. 2) It uses the Parzen-Rosenblatt\nwindow method to integrate the representativeness measure into multi-view\nactive learning. 3) It employs a query-by-committee strategy, based on the\nagreement between predictors, to address the usually noisy language of the\ndocuments in this domain. We evaluate our model in four publicly available\nTwitter datasets with distinctly different applications. We also compare our\nmodel with a wide range of baselines including those with multiple classifiers.\nThe experiments testify that our model is highly consistent and outperforms\nexisting models.\n","authors":["Payam Karisani","Negin Karisani","Li Xiong"],"pdf_url":"https://arxiv.org/pdf/2112.02611v2.pdf","comment":"EMNLP Findings 2022"},{"id":"http://arxiv.org/abs/2102.13196v2","updated":"2022-12-21T03:00:53Z","published":"2021-02-25T22:21:30Z","title":"Named Tensor Notation","summary":"  We propose a notation for tensors with named axes, which relieves the author,\nreader, and future implementers of machine learning models from the burden of\nkeeping track of the order of axes and the purpose of each. The notation makes\nit easy to lift operations on low-order tensors to higher order ones, for\nexample, from images to minibatches of images, or from an attention mechanism\nto multiple attention heads.\n  After a brief overview and formal definition of the notation, we illustrate\nit through several examples from modern machine learning, from building blocks\nlike attention and convolution to full models like Transformers and LeNet. We\nthen discuss differential calculus in our notation and compare with some\nalternative notations. Our proposals build on ideas from many previous papers\nand software libraries. We hope that our notation will encourage more authors\nto use named tensors, resulting in clearer papers and more precise\nimplementations.\n","authors":["David Chiang","Alexander M. Rush","Boaz Barak"],"pdf_url":"https://arxiv.org/pdf/2102.13196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10728v1","updated":"2022-12-21T02:47:52Z","published":"2022-12-21T02:47:52Z","title":"Spoken Language Understanding for Conversational AI: Recent Advances and\n  Future Direction","summary":"  When a human communicates with a machine using natural language on the web\nand online, how can it understand the human's intention and semantic context of\ntheir talk? This is an important AI task as it enables the machine to construct\na sensible answer or perform a useful action for the human. Meaning is\nrepresented at the sentence level, identification of which is known as intent\ndetection, and at the word level, a labelling task called slot filling. This\ndual-level joint task requires innovative thinking about natural language and\ndeep learning network design, and as a result, many approaches and models have\nbeen proposed and applied.\n  This tutorial will discuss how the joint task is set up and introduce Spoken\nLanguage Understanding/Natural Language Understanding (SLU/NLU) with Deep\nLearning techniques. We will cover the datasets, experiments and metrics used\nin the field. We will describe how the machine uses the latest NLP and Deep\nLearning techniques to address the joint task, including recurrent and\nattention-based Transformer networks and pre-trained models (e.g. BERT). We\nwill then look in detail at a network that allows the two levels of the task,\nintent classification and slot filling, to interact to boost performance\nexplicitly. We will do a code demonstration of a Python notebook for this model\nand attendees will have an opportunity to watch coding demo tasks on this joint\nNLU to further their understanding.\n","authors":["Soyeon Caren Han","Siqu Long","Henry Weld","Josiah Poon"],"pdf_url":"https://arxiv.org/pdf/2212.10728v1.pdf","comment":"Accepted by TheWebConf2023. arXiv admin note: substantial text\n  overlap with arXiv:2101.08091"},{"id":"http://arxiv.org/abs/2212.10726v1","updated":"2022-12-21T02:41:40Z","published":"2022-12-21T02:41:40Z","title":"Beyond Contrastive Learning: A Variational Generative Model for\n  Multilingual Retrieval","summary":"  Contrastive learning has been successfully used for retrieval of semantically\naligned sentences, but it often requires large batch sizes or careful\nengineering to work well. In this paper, we instead propose a generative model\nfor learning multilingual text embeddings which can be used to retrieve or\nscore sentence pairs. Our model operates on parallel data in $N$ languages and,\nthrough an approximation we introduce, efficiently encourages source separation\nin this multilingual setting, separating semantic information that is shared\nbetween translations from stylistic or language-specific variation. We show\ncareful large-scale comparisons between contrastive and generation-based\napproaches for learning multilingual text embeddings, a comparison that has not\nbeen done to the best of our knowledge despite the popularity of these\napproaches. We evaluate this method on a suite of tasks including semantic\nsimilarity, bitext mining, and cross-lingual question retrieval -- the last of\nwhich we introduce in this paper. Overall, our Variational Multilingual\nSource-Separation Transformer (VMSST) model outperforms both a strong\ncontrastive and generative baseline on these tasks.\n","authors":["John Wieting","Jonathan H. Clark","William W. Cohen","Graham Neubig","Taylor Berg-Kirkpatrick"],"pdf_url":"https://arxiv.org/pdf/2212.10726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10722v1","updated":"2022-12-21T02:28:07Z","published":"2022-12-21T02:28:07Z","title":"Tracing and Removing Data Errors in Natural Language Generation Datasets","summary":"  Recent work has identified noisy and misannotated data as a core cause of\nhallucinations and unfaithful outputs in Natural Language Generation (NLG)\ntasks. Consequently, identifying and removing these examples is a key open\nchallenge in creating reliable NLG systems. In this work, we introduce a\nframework to identify and remove low-quality training instances that lead to\nundesirable outputs, such as faithfulness errors in text summarization. We show\nthat existing approaches for error tracing, such as gradient-based influence\nmeasures, do not perform reliably for detecting faithfulness errors in\nsummarization. We overcome the drawbacks of existing error tracing methods\nthrough a new, contrast-based estimate that compares undesired generations to\nhuman-corrected outputs. Our proposed method can achieve a mean average\nprecision of 0.91 across synthetic tasks with known ground truth and can\nachieve a two-fold reduction in hallucinations on a real entity hallucination\nevaluation on the NYT dataset.\n","authors":["Faisal Ladhak","Esin Durmus","Tatsunori Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2212.10722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10720v1","updated":"2022-12-21T02:21:37Z","published":"2022-12-21T02:21:37Z","title":"MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via\n  Constructing Moral Discussions","summary":"  Morality in dialogue systems has raised great attention in research recently.\nA moral dialogue system could better connect users and enhance conversation\nengagement by gaining users' trust. In this paper, we propose a framework,\nMoralDial to train and evaluate moral dialogue systems. In our framework, we\nfirst explore the communication mechanisms of morality and resolve expressed\nmorality into four sub-modules. The sub-modules indicate the roadmap for\nbuilding a moral dialogue system. Based on that, we design a simple yet\neffective method: constructing moral discussions from Rules of Thumb (RoTs)\nbetween simulated specific users and the dialogue system. The constructed\ndiscussion consists of expressing, explaining, and revising the moral views in\ndialogue exchanges, which makes conversational models learn morality well in a\nnatural manner. Furthermore, we propose a novel evaluation method in the\nframework. We evaluate the multiple aspects of morality by judging the relation\nbetween dialogue responses and RoTs in discussions, where the multifaceted\nnature of morality is particularly considered. Automatic and manual experiments\ndemonstrate that our framework is promising to train and evaluate moral\ndialogue systems.\n","authors":["Hao Sun","Zhexin Zhang","Fei Mi","Yasheng Wang","Wei Liu","Jianwei Cui","Bin Wang","Qun Liu","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2212.10720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05767v3","updated":"2022-12-21T02:18:29Z","published":"2022-12-12T08:40:04Z","title":"Reasoning over Different Types of Knowledge Graphs: Static, Temporal and\n  Multi-Modal","summary":"  Knowledge graph reasoning (KGR), aiming to deduce new facts from existing\nfacts based on mined logic rules underlying knowledge graphs (KGs), has become\na fast-growing research direction. It has been proven to significantly benefit\nthe usage of KGs in many AI applications, such as question answering and\nrecommendation systems, etc. According to the graph types, the existing KGR\nmodels can be roughly divided into three categories, i.e., static models,\ntemporal models, and multi-modal models. The early works in this domain mainly\nfocus on static KGR and tend to directly apply general knowledge graph\nembedding models to the reasoning task. However, these models are not suitable\nfor more complex but practical tasks, such as inductive static KGR, temporal\nKGR, and multi-modal KGR. To this end, multiple works have been developed\nrecently, but no survey papers and open-source repositories comprehensively\nsummarize and discuss models in this important direction. To fill the gap, we\nconduct a survey for knowledge graph reasoning tracing from static to temporal\nand then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR\nmodels, and typical datasets are introduced and discussed consequently.\nMoreover, we discuss the challenges and potential opportunities. The\ncorresponding open-source repository is shared on GitHub:\nhttps://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.\n","authors":["Ke Liang","Lingyuan Meng","Meng Liu","Yue Liu","Wenxuan Tu","Siwei Wang","Sihang Zhou","Xinwang Liu","Fuchun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.05767v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2212.10714v1","updated":"2022-12-21T01:26:07Z","published":"2022-12-21T01:26:07Z","title":"Integrating Heterogeneous Domain Information into Relation Extraction: A\n  Case Study on Drug-Drug Interaction Extraction","summary":"  The development of deep neural networks has improved representation learning\nin various domains, including textual, graph structural, and relational triple\nrepresentations. This development opened the door to new relation extraction\nbeyond the traditional text-oriented relation extraction. However, research on\nthe effectiveness of considering multiple heterogeneous domain information\nsimultaneously is still under exploration, and if a model can take an advantage\nof integrating heterogeneous information, it is expected to exhibit a\nsignificant contribution to many problems in the world. This thesis works on\nDrug-Drug Interactions (DDIs) from the literature as a case study and realizes\nrelation extraction utilizing heterogeneous domain information. First, a deep\nneural relation extraction model is prepared and its attention mechanism is\nanalyzed. Next, a method to combine the drug molecular structure information\nand drug description information to the input sentence information is proposed,\nand the effectiveness of utilizing drug molecular structures and drug\ndescriptions for the relation extraction task is shown. Then, in order to\nfurther exploit the heterogeneous information, drug-related items, such as\nprotein entries, medical terms and pathways are collected from multiple\nexisting databases and a new data set in the form of a knowledge graph (KG) is\nconstructed. A link prediction task on the constructed data set is conducted to\nobtain embedding representations of drugs that contain the heterogeneous domain\ninformation. Finally, a method that integrates the input sentence information\nand the heterogeneous KG information is proposed. The proposed model is trained\nand evaluated on a widely used data set, and as a result, it is shown that\nutilizing heterogeneous domain information significantly improves the\nperformance of relation extraction from the literature.\n","authors":["Masaki Asada"],"pdf_url":"https://arxiv.org/pdf/2212.10714v1.pdf","comment":"PhD Thesis"},{"id":"http://arxiv.org/abs/2212.10708v1","updated":"2022-12-21T00:57:24Z","published":"2022-12-21T00:57:24Z","title":"Zero-shot Triplet Extraction by Template Infilling","summary":"  Triplet extraction aims to extract entities and their corresponding relations\nin unstructured text. Most existing methods train an extraction model on\nhigh-quality training data, and hence are incapable of extracting relations\nthat were not observed during training. Generalizing the model to unseen\nrelations typically requires fine-tuning on synthetic training data which is\noften noisy and unreliable. In this paper, we argue that reducing triplet\nextraction to a template filling task over a pre-trained language model can\nequip the model with zero-shot learning capabilities and enable it to leverage\nthe implicit knowledge in the language model. Embodying these ideas, we propose\na novel framework, ZETT (ZEro-shot Triplet extraction by Template infilling),\nthat is based on end-to-end generative transformers. Our experiments show that\nwithout any data augmentation or pipeline systems, ZETT can outperform previous\nstate-of-the-art models with 25% less parameters. We further show that ZETT is\nmore robust in detecting entities and can be incorporated with automatically\ngenerated templates for relations.\n","authors":["Bosung Kim","Hayate Iso","Nikita Bhutani","Estevam Hruschka","Ndapa Nakashole"],"pdf_url":"https://arxiv.org/pdf/2212.10708v1.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2212.10707v1","updated":"2022-12-21T00:56:50Z","published":"2022-12-21T00:56:50Z","title":"Extractive Text Summarization Using Generalized Additive Models with\n  Interactions for Sentence Selection","summary":"  Automatic Text Summarization (ATS) is becoming relevant with the growth of\ntextual data; however, with the popularization of public large-scale datasets,\nsome recent machine learning approaches have focused on dense models and\narchitectures that, despite producing notable results, usually turn out in\nmodels difficult to interpret. Given the challenge behind interpretable\nlearning-based text summarization and the importance it may have for evolving\nthe current state of the ATS field, this work studies the application of two\nmodern Generalized Additive Models with interactions, namely Explainable\nBoosting Machine and GAMI-Net, to the extractive summarization problem based on\nlinguistic features and binary classification.\n","authors":["Vinícius Camargo da Silva","João Paulo Papa","Kelton Augusto Pontara da Costa"],"pdf_url":"https://arxiv.org/pdf/2212.10707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10696v1","updated":"2022-12-21T00:00:01Z","published":"2022-12-21T00:00:01Z","title":"Analyzing Semantic Faithfulness of Language Models via Input\n  Intervention on Conversational Question Answering","summary":"  Transformer-based language models have been shown to be highly effective for\nseveral NLP tasks. In this paper, we consider three transformer models, BERT,\nRoBERTa, and XLNet, in both small and large version, and investigate how\nfaithful their representations are with respect to the semantic content of\ntexts. We formalize a notion of semantic faithfulness, in which the semantic\ncontent of a text should causally figure in a model's inferences in question\nanswering. We then test this notion by observing a model's behavior on\nanswering questions about a story after performing two novel semantic\ninterventions -- deletion intervention and negation intervention. While\ntransformer models achieve high performance on standard question answering\ntasks, we show that they fail to be semantically faithful once we perform these\ninterventions for a significant number of cases (~50% for deletion\nintervention, and ~20% drop in accuracy for negation intervention). We then\npropose an intervention-based training regime that can mitigate the undesirable\neffects for deletion intervention by a significant margin (from ~50% to ~6%).\nWe analyze the inner-workings of the models to better understand the\neffectiveness of intervention-based training for deletion intervention. But we\nshow that this training does not attenuate other aspects of semantic\nunfaithfulness such as the models' inability to deal with negation intervention\nor to capture the predicate-argument structure of texts. We also test\nInstructGPT, via prompting, for its ability to handle the two interventions and\nto capture predicate-argument structure. While InstructGPT models do achieve\nvery high performance on predicate-argument structure task, they fail to\nrespond adequately to our deletion and negation interventions.\n","authors":["Akshay Chaturvedi","Swarnadeep Bhar","Soumadeep Saha","Utpal Garain","Nicholas Asher"],"pdf_url":"https://arxiv.org/pdf/2212.10696v1.pdf","comment":"27 pages, 4 figures"},{"id":"http://arxiv.org/abs/2212.11382v1","updated":"2022-12-21T21:46:01Z","published":"2022-12-21T21:46:01Z","title":"Automatic Emotion Modelling in Written Stories","summary":"  Telling stories is an integral part of human communication which can evoke\nemotions and influence the affective states of the audience. Automatically\nmodelling emotional trajectories in stories has thus attracted considerable\nscholarly interest. However, as most existing works have been limited to\nunsupervised dictionary-based approaches, there is no labelled benchmark for\nthis task. We address this gap by introducing continuous valence and arousal\nannotations for an existing dataset of children's stories annotated with\ndiscrete emotion categories. We collect additional annotations for this data\nand map the originally categorical labels to the valence and arousal space.\nLeveraging recent advances in Natural Language Processing, we propose a set of\nnovel Transformer-based methods for predicting valence and arousal signals over\nthe course of written stories. We explore several strategies for fine-tuning a\npretrained ELECTRA model and study the benefits of considering a sentence's\ncontext when inferring its emotionality. Moreover, we experiment with\nadditional LSTM and Transformer layers. The best configuration achieves a\nConcordance Correlation Coefficient (CCC) of .7338 for valence and .6302 for\narousal on the test set, demonstrating the suitability of our proposed\napproach. Our code and additional annotations are made available at\nhttps://github.com/lc0197/emotion_modelling_stories.\n","authors":["Lukas Christ","Shahin Amiriparian","Manuel Milling","Ilhan Aslan","Björn W. Schuller"],"pdf_url":"https://arxiv.org/pdf/2212.11382v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2212.11353v1","updated":"2022-12-21T20:43:46Z","published":"2022-12-21T20:43:46Z","title":"Contrastive Distillation Is a Sample-Efficient Self-Supervised Loss\n  Policy for Transfer Learning","summary":"  Traditional approaches to RL have focused on learning decision policies\ndirectly from episodic decisions, while slowly and implicitly learning the\nsemantics of compositional representations needed for generalization. While\nsome approaches have been adopted to refine representations via auxiliary\nself-supervised losses while simultaneously learning decision policies,\nlearning compositional representations from hand-designed and\ncontext-independent self-supervised losses (multi-view) still adapts relatively\nslowly to the real world, which contains many non-IID subspaces requiring rapid\ndistribution shift in both time and spatial attention patterns at varying\nlevels of abstraction. In contrast, supervised language model cascades have\nshown the flexibility to adapt to many diverse manifolds, and hints of\nself-learning needed for autonomous task transfer. However, to date, transfer\nmethods for language models like few-shot learning and fine-tuning still\nrequire human supervision and transfer learning using self-learning methods has\nbeen underexplored. We propose a self-supervised loss policy called contrastive\ndistillation which manifests latent variables with high mutual information with\nboth source and target tasks from weights to tokens. We show how this\noutperforms common methods of transfer learning and suggests a useful design\naxis of trading off compute for generalizability for online transfer.\nContrastive distillation is improved through sampling from memory and suggests\na simple algorithm for more efficiently sampling negative examples for\ncontrastive losses than random sampling.\n","authors":["Chris Lengerich","Gabriel Synnaeve","Amy Zhang","Hugh Leather","Kurt Shuster","François Charton","Charysse Redwood"],"pdf_url":"https://arxiv.org/pdf/2212.11353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11311v1","updated":"2022-12-21T19:11:19Z","published":"2022-12-21T19:11:19Z","title":"What do LLMs Know about Financial Markets? A Case Study on Reddit Market\n  Sentiment Analysis","summary":"  Market sentiment analysis on social media content requires knowledge of both\nfinancial markets and social media jargon, which makes it a challenging task\nfor human raters. The resulting lack of high-quality labeled data stands in the\nway of conventional supervised learning methods. Instead, we approach this\nproblem using semi-supervised learning with a large language model (LLM). Our\npipeline generates weak financial sentiment labels for Reddit posts with an LLM\nand then uses that data to train a small model that can be served in\nproduction. We find that prompting the LLM to produce Chain-of-Thought\nsummaries and forcing it through several reasoning paths helps generate more\nstable and accurate labels, while using a regression loss further improves\ndistillation quality. With only a handful of prompts, the final model performs\non par with existing supervised models. Though production applications of our\nmodel are limited by ethical considerations, the model's competitive\nperformance points to the great potential of using LLMs for tasks that\notherwise require skill-intensive annotation.\n","authors":["Xiang Deng","Vasilisa Bashlovkina","Feng Han","Simon Baumgartner","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2212.11311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11281v1","updated":"2022-12-21T17:58:01Z","published":"2022-12-21T17:58:01Z","title":"Language models are better than humans at next-token prediction","summary":"  Current language models are considered to have sub-human capabilities at\nnatural language tasks like question-answering or writing code. However,\nlanguage models are not trained to perform well at these tasks, they are\ntrained to accurately predict the next token given previous tokes in tokenized\ntext. It is not clear whether language models are better or worse than humans\nat next token prediction. To try to answer this question, we performed two\ndistinct experiments to directly compare humans and language models on this\nfront: one measuring top-1 accuracy and the other measuring perplexity. In both\nexperiments, we find humans to be consistently \\emph{worse} than even\nrelatively small language models like GPT3-Ada at next-token prediction.\n","authors":["Buck Shlegeris","Fabien Roger","Lawrence Chan","Euan McLean"],"pdf_url":"https://arxiv.org/pdf/2212.11281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11275v1","updated":"2022-12-21T05:59:25Z","published":"2022-12-21T05:59:25Z","title":"KL Regularized Normalization Framework for Low Resource Tasks","summary":"  Large pre-trained models, such as Bert, GPT, and Wav2Vec, have demonstrated\ngreat potential for learning representations that are transferable to a wide\nvariety of downstream tasks . It is difficult to obtain a large quantity of\nsupervised data due to the limited availability of resources and time. In light\nof this, a significant amount of research has been conducted in the area of\nadopting large pre-trained datasets for diverse downstream tasks via fine\ntuning, linear probing, or prompt tuning in low resource settings.\nNormalization techniques are essential for accelerating training and improving\nthe generalization of deep neural networks and have been successfully used in a\nwide variety of applications. A lot of normalization techniques have been\nproposed but the success of normalization in low resource downstream NLP and\nspeech tasks is limited. One of the reasons is the inability to capture\nexpressiveness by rescaling parameters of normalization. We propose\nKullbackLeibler(KL) Regularized normalization (KL-Norm) which make the\nnormalized data well behaved and helps in better generalization as it reduces\nover-fitting, generalises well on out of domain distributions and removes\nirrelevant biases and features with negligible increase in model parameters and\nmemory overheads. Detailed experimental evaluation on multiple low resource NLP\nand speech tasks, demonstrates the superior performance of KL-Norm as compared\nto other popular normalization and regularization techniques.\n","authors":["Neeraj Kumar","Ankur Narang","Brejesh Lall"],"pdf_url":"https://arxiv.org/pdf/2212.11275v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2106.05469 by other authors"},{"id":"http://arxiv.org/abs/2212.11808v1","updated":"2022-12-21T04:57:59Z","published":"2022-12-21T04:57:59Z","title":"A Mutation-based Text Generation for Adversarial Machine Learning\n  Applications","summary":"  Many natural language related applications involve text generation, created\nby humans or machines. While in many of those applications machines support\nhumans, yet in few others, (e.g. adversarial machine learning, social bots and\ntrolls) machines try to impersonate humans. In this scope, we proposed and\nevaluated several mutation-based text generation approaches. Unlike\nmachine-based generated text, mutation-based generated text needs human text\nsamples as inputs. We showed examples of mutation operators but this work can\nbe extended in many aspects such as proposing new text-based mutation operators\nbased on the nature of the application.\n","authors":["Jesus Guerrero","Gongbo Liang","Izzat Alsmadi"],"pdf_url":"https://arxiv.org/pdf/2212.11808v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2212.11270v1","updated":"2022-12-21T18:58:41Z","published":"2022-12-21T18:58:41Z","title":"Generalized Decoding for Pixel, Image, and Language","summary":"  We present X-Decoder, a generalized decoding model that can predict\npixel-level segmentation and language tokens seamlessly. X-Decodert takes as\ninput two types of queries: (i) generic non-semantic queries and (ii) semantic\nqueries induced from text inputs, to decode different pixel-level and\ntoken-level outputs in the same semantic space. With such a novel design,\nX-Decoder is the first work that provides a unified way to support all types of\nimage segmentation and a variety of vision-language (VL) tasks. Further, our\ndesign enables seamless interactions across tasks at different granularities\nand brings mutual benefits by learning a common and rich pixel-level\nvisual-semantic understanding space, without any pseudo-labeling. After\npretraining on a mixed set of a limited amount of segmentation data and\nmillions of image-text pairs, X-Decoder exhibits strong transferability to a\nwide range of downstream tasks in both zero-shot and finetuning settings.\nNotably, it achieves (1) state-of-the-art results on open-vocabulary\nsegmentation and referring segmentation on eight datasets; (2) better or\ncompetitive finetuned performance to other generalist and specialist models on\nsegmentation and VL tasks; and (3) flexibility for efficient finetuning and\nnovel task composition (e.g., referring captioning and image editing). Code,\ndemo, video, and visualization are available at https://x-decoder-vl.github.io.\n","authors":["Xueyan Zou","Zi-Yi Dou","Jianwei Yang","Zhe Gan","Linjie Li","Chunyuan Li","Xiyang Dai","Harkirat Behl","Jianfeng Wang","Lu Yuan","Nanyun Peng","Lijuan Wang","Yong Jae Lee","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2212.11270v1.pdf","comment":"https://x-decoder-vl.github.io"},{"id":"http://arxiv.org/abs/2212.11263v1","updated":"2022-12-21T18:54:47Z","published":"2022-12-21T18:54:47Z","title":"3D Highlighter: Localizing Regions on 3D Shapes via Text Descriptions","summary":"  We present 3D Highlighter, a technique for localizing semantic regions on a\nmesh using text as input. A key feature of our system is the ability to\ninterpret \"out-of-domain\" localizations. Our system demonstrates the ability to\nreason about where to place non-obviously related concepts on an input 3D\nshape, such as adding clothing to a bare 3D animal model. Our method\ncontextualizes the text description using a neural field and colors the\ncorresponding region of the shape using a probability-weighted blend. Our\nneural optimization is guided by a pre-trained CLIP encoder, which bypasses the\nneed for any 3D datasets or 3D annotations. Thus, 3D Highlighter is highly\nflexible, general, and capable of producing localizations on a myriad of input\nshapes. Our code is publicly available at\nhttps://github.com/threedle/3DHighlighter.\n","authors":["Dale Decatur","Itai Lang","Rana Hanocka"],"pdf_url":"https://arxiv.org/pdf/2212.11263v1.pdf","comment":"Project page: https://threedle.github.io/3DHighlighter/"},{"id":"http://arxiv.org/abs/2212.11261v1","updated":"2022-12-21T18:54:19Z","published":"2022-12-21T18:54:19Z","title":"Contrastive Language-Vision AI Models Pretrained on Web-Scraped\n  Multimodal Data Exhibit Sexual Objectification Bias","summary":"  Nine language-vision AI models trained on web scrapes with the Contrastive\nLanguage-Image Pretraining (CLIP) objective are evaluated for evidence of a\nbias studied by psychologists: the sexual objectification of girls and women,\nwhich occurs when a person's human characteristics are disregarded and the\nperson is treated as a body or a collection of body parts. A first experiment\nuses standardized images of women from the Sexual OBjectification and EMotion\nDatabase, and finds that, commensurate with prior research in psychology, human\ncharacteristics are disassociated from images of objectified women: the model's\nrecognition of emotional state is mediated by whether the subject is fully or\npartially clothed. Embedding association tests (EATs) return significant effect\nsizes for both anger (d >.8) and sadness (d >.5). A second experiment measures\nthe effect in a representative application: an automatic image captioner\n(Antarctic Captions) includes words denoting emotion less than 50% as often for\nimages of partially clothed women than for images of fully clothed women. A\nthird experiment finds that images of female professionals (scientists,\ndoctors, executives) are likely to be associated with sexual descriptions\nrelative to images of male professionals. A fourth experiment shows that a\nprompt of \"a [age] year old girl\" generates sexualized images (as determined by\nan NSFW classifier) up to 73% of the time for VQGAN-CLIP (age 17), and up to\n40% of the time for Stable Diffusion (ages 14 and 18); the corresponding rate\nfor boys never surpasses 9%. The evidence indicates that language-vision AI\nmodels trained on automatically collected web scrapes learn biases of sexual\nobjectification, which propagate to downstream applications.\n","authors":["Robert Wolfe","Yiwei Yang","Bill Howe","Aylin Caliskan"],"pdf_url":"https://arxiv.org/pdf/2212.11261v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2212.11237v1","updated":"2022-12-21T18:07:39Z","published":"2022-12-21T18:07:39Z","title":"Not Just Pretty Pictures: Text-to-Image Generators Enable Interpretable\n  Interventions for Robust Representations","summary":"  Neural image classifiers are known to undergo severe performance degradation\nwhen exposed to input that exhibits covariate-shift with respect to the\ntraining distribution. Successful hand-crafted augmentation pipelines aim at\neither approximating the expected test domain conditions or to perturb the\nfeatures that are specific to the training environment. The development of\neffective pipelines is typically cumbersome, and produce transformations whose\nimpact on the classifier performance are hard to understand and control. In\nthis paper, we show that recent Text-to-Image (T2I) generators' ability to\nsimulate image interventions via natural-language prompts can be leveraged to\ntrain more robust models, offering a more interpretable and controllable\nalternative to traditional augmentation methods. We find that a variety of\nprompting mechanisms are effective for producing synthetic training data\nsufficient to achieve state-of-the-art performance in widely-adopted\ndomain-generalization benchmarks and reduce classifiers' dependency on spurious\nfeatures. Our work suggests that further progress in T2I generation and a\ntighter integration with other research fields may represent a significant step\ntowards the development of more robust machine learning systems.\n","authors":["Jianhao Yuan","Francesco Pinto","Adam Davies","Aarushi Gupta","Philip Torr"],"pdf_url":"https://arxiv.org/pdf/2212.11237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.00267v4","updated":"2022-12-21T17:49:08Z","published":"2022-01-02T00:56:09Z","title":"On the Cross-dataset Generalization in License Plate Recognition","summary":"  Automatic License Plate Recognition (ALPR) systems have shown remarkable\nperformance on license plates (LPs) from multiple regions due to advances in\ndeep learning and the increasing availability of datasets. The evaluation of\ndeep ALPR systems is usually done within each dataset; therefore, it is\nquestionable if such results are a reliable indicator of generalization\nability. In this paper, we propose a traditional-split versus\nleave-one-dataset-out experimental setup to empirically assess the\ncross-dataset generalization of 12 Optical Character Recognition (OCR) models\napplied to LP recognition on nine publicly available datasets with a great\nvariety in several aspects (e.g., acquisition settings, image resolution, and\nLP layouts). We also introduce a public dataset for end-to-end ALPR that is the\nfirst to contain images of vehicles with Mercosur LPs and the one with the\nhighest number of motorcycle images. The experimental results shed light on the\nlimitations of the traditional-split protocol for evaluating approaches in the\nALPR context, as there are significant drops in performance for most datasets\nwhen training and testing the models in a leave-one-dataset-out fashion.\n","authors":["Rayson Laroca","Everton V. Cardoso","Diego R. Lucio","Valter Estevam","David Menotti"],"pdf_url":"https://arxiv.org/pdf/2201.00267v4.pdf","comment":"Accepted for presentation at the International Conference on Computer\n  Vision Theory and Applications (VISAPP) 2022"},{"id":"http://arxiv.org/abs/2212.11211v1","updated":"2022-12-21T17:36:28Z","published":"2022-12-21T17:36:28Z","title":"Land Cover and Land Use Detection using Semi-Supervised Learning","summary":"  Semi-supervised learning (SSL) has made significant strides in the field of\nremote sensing. Finding a large number of labeled datasets for SSL methods is\nuncommon, and manually labeling datasets is expensive and time-consuming.\nFurthermore, accurately identifying remote sensing satellite images is more\ncomplicated than it is for conventional images. Class-imbalanced datasets are\nanother prevalent phenomenon, and models trained on these become biased towards\nthe majority classes. This becomes a critical issue with an SSL model's subpar\nperformance. We aim to address the issue of labeling unlabeled data and also\nsolve the model bias problem due to imbalanced datasets while achieving better\naccuracy. To accomplish this, we create \"artificial\" labels and train a model\nto have reasonable accuracy. We iteratively redistribute the classes through\nresampling using a distribution alignment technique. We use a variety of class\nimbalanced satellite image datasets: EuroSAT, UCM, and WHU-RS19. On UCM\nbalanced dataset, our method outperforms previous methods MSMatch and FixMatch\nby 1.21% and 0.6%, respectively. For imbalanced EuroSAT, our method outperforms\nMSMatch and FixMatch by 1.08% and 1%, respectively. Our approach significantly\nlessens the requirement for labeled data, consistently outperforms alternative\napproaches, and resolves the issue of model bias caused by class imbalance in\ndatasets.\n","authors":["Fahmida Tasnim Lisa","Md. Zarif Hossain","Sharmin Naj Mou","Shahriar Ivan","Md. Hasanul Kabir"],"pdf_url":"https://arxiv.org/pdf/2212.11211v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11192v1","updated":"2022-12-21T17:08:58Z","published":"2022-12-21T17:08:58Z","title":"Continual Learning Approaches for Anomaly Detection","summary":"  Anomaly Detection is a relevant problem that arises in numerous real-world\napplications, especially when dealing with images. However, there has been\nlittle research for this task in the Continual Learning setting. In this work,\nwe introduce a novel approach called SCALE (SCALing is Enough) to perform\nCompressed Replay in a framework for Anomaly Detection in Continual Learning\nsetting. The proposed technique scales and compresses the original images using\na Super Resolution model which, to the best of our knowledge, is studied for\nthe first time in the Continual Learning setting. SCALE can achieve a high\nlevel of compression while maintaining a high level of image reconstruction\nquality. In conjunction with other Anomaly Detection approaches, it can achieve\noptimal results. To validate the proposed approach, we use a real-world dataset\nof images with pixel-based anomalies, with the scope to provide a reliable\nbenchmark for Anomaly Detection in the context of Continual Learning, serving\nas a foundation for further advancements in the field.\n","authors":["Davide Dalle Pezze","Eugenia Anello","Chiara Masiero","Gian Antonio Susto"],"pdf_url":"https://arxiv.org/pdf/2212.11192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11187v1","updated":"2022-12-21T16:56:55Z","published":"2022-12-21T16:56:55Z","title":"Similarity Contrastive Estimation for Image and Video Soft Contrastive\n  Self-Supervised Learning","summary":"  Contrastive representation learning has proven to be an effective\nself-supervised learning method for images and videos. Most successful\napproaches are based on Noise Contrastive Estimation (NCE) and use different\nviews of an instance as positives that should be contrasted with other\ninstances, called negatives, that are considered as noise. However, several\ninstances in a dataset are drawn from the same distribution and share\nunderlying semantic information. A good data representation should contain\nrelations between the instances, or semantic similarity and dissimilarity, that\ncontrastive learning harms by considering all negatives as noise. To circumvent\nthis issue, we propose a novel formulation of contrastive learning using\nsemantic similarity between instances called Similarity Contrastive Estimation\n(SCE). Our training objective is a soft contrastive one that brings the\npositives closer and estimates a continuous distribution to push or pull\nnegative instances based on their learned similarities. We validate empirically\nour approach on both image and video representation learning. We show that SCE\nperforms competitively with the state of the art on the ImageNet linear\nevaluation protocol for fewer pretraining epochs and that it generalizes to\nseveral downstream image tasks. We also show that SCE reaches state-of-the-art\nresults for pretraining video representation and that the learned\nrepresentation can generalize to video downstream tasks.\n","authors":["Julien Denize","Jaonary Rabarisoa","Astrid Orcesi","Romain Hérault"],"pdf_url":"https://arxiv.org/pdf/2212.11187v1.pdf","comment":"Extended version of our WACV 2023 paper to video self-supervised\n  learning"},{"id":"http://arxiv.org/abs/2212.11172v1","updated":"2022-12-21T16:36:36Z","published":"2022-12-21T16:36:36Z","title":"A recurrent CNN for online object detection on raw radar frames","summary":"  Automotive radar sensors provide valuable information for advanced driving\nassistance systems (ADAS). Radars can reliably estimate the distance to an\nobject and the relative velocity, regardless of weather and light conditions.\nHowever, radar sensors suffer from low resolution and huge intra-class\nvariations in the shape of objects. Exploiting the time information (e.g.,\nmultiple frames) has been shown to help to capture better the dynamics of\nobjects and, therefore, the variation in the shape of objects. Most temporal\nradar object detectors use 3D convolutions to learn spatial and temporal\ninformation. However, these methods are often non-causal and unsuitable for\nreal-time applications. This work presents RECORD, a new recurrent CNN\narchitecture for online radar object detection. We propose an end-to-end\ntrainable architecture mixing convolutions and ConvLSTMs to learn\nspatio-temporal dependencies between successive frames. Our model is causal and\nrequires only the past information encoded in the memory of the ConvLSTMs to\ndetect objects. Our experiments show such a method's relevance for detecting\nobjects in different radar representations (range-Doppler, range-angle) and\noutperform state-of-the-art models on the ROD2021 and CARRADA datasets while\nbeing less computationally expensive. The code will be available soon.\n","authors":["Colin Decourt","Rufin VanRullen","Didier Salle","Thomas Oberlin"],"pdf_url":"https://arxiv.org/pdf/2212.11172v1.pdf","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2206.12558v3","updated":"2022-12-21T16:11:22Z","published":"2022-06-25T05:24:52Z","title":"FastBVP-Net: a lightweight pulse extraction network for measuring heart\n  rhythm via facial videos","summary":"  Remote photoplethysmography (rPPG) is an attractive camera-based health\nmonitoring method that can measure the heart rhythm from facial videos. Many\nwell-established deep-learning models have been reported to measure heart rate\n(HR) and heart rate variability (HRV). However, most of these models usually\nrequire a 30-second facial video and enormous computational resources to obtain\naccurate and robust results, which significantly limits their applications in\nreal-world scenarios. Hence, we propose a lightweight pulse extraction network,\nFastBVP-Net, to quickly measure heart rhythm via facial videos. The proposed\nFastBVP-Net uses a multi-frequency mode signal fusion (MMSF) mechanism to\ncharacterize the different modes of the raw signals in a decompose module and\nreconstruct the blood volume pulse (BVP) signal under a complex noise\nenvironment in a compose module. Meanwhile, an oversampling training scheme is\nused to solve the over-fitting problem caused by the limitations of the\ndatasets. Then, the HR and HRV can be estimated based on the extracted BVP\nsignals. Comprehensive experiments are conducted on the benchmark datasets to\nvalidate the proposed FastBVP-Net. For intra-dataset and cross-dataset testing,\nthe proposed approach achieves better performance for HR and HRV estimation\nfrom 30-second facial videos with fewer computational burdens than the current\nwell-established methods. Moreover, the proposed approach also achieves\ncompetitive results from 15-second facial videos. Therefore, the proposed\nFastBVP-Net has the potential to be applied in many real-world scenarios with\nshorter videos.\n","authors":["Jialiang Zhuang","Yuheng Chen","Yun Zhang","Xiujuan Zheng"],"pdf_url":"https://arxiv.org/pdf/2206.12558v3.pdf","comment":"9 pages, 2figures"},{"id":"http://arxiv.org/abs/2208.01489v4","updated":"2022-12-21T16:10:02Z","published":"2022-08-02T14:38:53Z","title":"Deconstructing Self-Supervised Monocular Reconstruction: The Design\n  Decisions that Matter","summary":"  This paper presents an open and comprehensive framework to systematically\nevaluate state-of-the-art contributions to self-supervised monocular depth\nestimation. This includes pretraining, backbone, architectural design choices\nand loss functions. Many papers in this field claim novelty in either\narchitecture design or loss formulation. However, simply updating the backbone\nof historical systems results in relative improvements of 25%, allowing them to\noutperform the majority of existing systems. A systematic evaluation of papers\nin this field was not straightforward. The need to compare like-with-like in\nprevious papers means that longstanding errors in the evaluation protocol are\nubiquitous in the field. It is likely that many papers were not only optimized\nfor particular datasets, but also for errors in the data and evaluation\ncriteria. To aid future research in this area, we release a modular codebase\n(https://github.com/jspenmar/monodepth_benchmark), allowing for easy evaluation\nof alternate design decisions against corrected data and evaluation criteria.\nWe re-implement, validate and re-evaluate 16 state-of-the-art contributions and\nintroduce a new dataset (SYNS-Patches) containing dense outdoor depth maps in a\nvariety of both natural and urban scenes. This allows for the computation of\ninformative metrics in complex regions such as depth boundaries.\n","authors":["Jaime Spencer","Chris Russell","Simon Hadfield","Richard Bowden"],"pdf_url":"https://arxiv.org/pdf/2208.01489v4.pdf","comment":"https://github.com/jspenmar/monodepth_benchmark"},{"id":"http://arxiv.org/abs/2212.02804v2","updated":"2022-12-21T15:54:30Z","published":"2022-12-06T07:50:00Z","title":"MUS-CDB: Mixed Uncertainty Sampling with Class Distribution Balancing\n  for Active Annotation in Aerial Object Detection","summary":"  Recent aerial object detection models rely on a large amount of labeled\ntraining data, which requires unaffordable manual labeling costs in large\naerial scenes with dense objects. Active learning is effective in reducing the\ndata labeling cost by selectively querying the informative and representative\nunlabelled samples. However, existing active learning methods are mainly with\nclass-balanced setting and image-based querying for generic object detection\ntasks, which are less applicable to aerial object detection scenario due to the\nlong-tailed class distribution and dense small objects in aerial scenes. In\nthis paper, we propose a novel active learning method for cost-effective aerial\nobject detection. Specifically, both object-level and image-level\ninformativeness are considered in the object selection to refrain from\nredundant and myopic querying. Besides, an easy-to-use class-balancing\ncriterion is incorporated to favor the minority objects to alleviate the\nlong-tailed class distribution problem in model training. To fully utilize the\nqueried information, we further devise a training loss to mine the latent\nknowledge in the undiscovered image regions. Extensive experiments are\nconducted on the DOTA-v1.0 and DOTA-v2.0 benchmarks to validate the\neffectiveness of the proposed method. The results show that it can save more\nthan 75% of the labeling cost to reach the same performance compared to the\nbaselines and state-of-the-art active object detection methods. Code is\navailable at\n\\href{https://github.com/ZJW700/MUS-CDB}{\\textit{https://github.com/ZJW700/MUS-CDB}}.\n","authors":["Dong Liang","Jing-Wei Zhang","Ying-Peng Tang","Sheng-Jun Huang"],"pdf_url":"https://arxiv.org/pdf/2212.02804v2.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.11115v1","updated":"2022-12-21T15:51:43Z","published":"2022-12-21T15:51:43Z","title":"What Makes for Good Tokenizers in Vision Transformer?","summary":"  The architecture of transformers, which recently witness booming applications\nin vision tasks, has pivoted against the widespread convolutional paradigm.\nRelying on the tokenization process that splits inputs into multiple tokens,\ntransformers are capable of extracting their pairwise relationships using\nself-attention. While being the stemming building block of transformers, what\nmakes for a good tokenizer has not been well understood in computer vision. In\nthis work, we investigate this uncharted problem from an information trade-off\nperspective. In addition to unifying and understanding existing structural\nmodifications, our derivation leads to better design strategies for vision\ntokenizers. The proposed Modulation across Tokens (MoTo) incorporates\ninter-token modeling capability through normalization. Furthermore, a\nregularization objective TokenProp is embraced in the standard training regime.\nThrough extensive experiments on various transformer architectures, we observe\nboth improved performance and intriguing properties of these two plug-and-play\ndesigns with negligible computational overhead. These observations further\nindicate the importance of the commonly-omitted designs of tokenizers in vision\ntransformer.\n","authors":["Shengju Qian","Yi Zhu","Wenbo Li","Mu Li","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2212.11115v1.pdf","comment":"To appear in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence"},{"id":"http://arxiv.org/abs/2212.11091v1","updated":"2022-12-21T15:38:12Z","published":"2022-12-21T15:38:12Z","title":"Exploring Content Relationships for Distilling Efficient GANs","summary":"  This paper proposes a content relationship distillation (CRD) to tackle the\nover-parameterized generative adversarial networks (GANs) for the\nserviceability in cutting-edge devices. In contrast to traditional\ninstance-level distillation, we design a novel GAN compression oriented\nknowledge by slicing the contents of teacher outputs into multiple fine-grained\ngranularities, such as row/column strips (global information) and image patches\n(local information), modeling the relationships among them, such as pairwise\ndistance and triplet-wise angle, and encouraging the student to capture these\nrelationships within its output contents. Built upon our proposed content-level\ndistillation, we also deploy an online teacher discriminator, which keeps\nupdating when co-trained with the teacher generator and keeps freezing when\nco-trained with the student generator for better adversarial training. We\nperform extensive experiments on three benchmark datasets, the results of which\nshow that our CRD reaches the most complexity reduction on GANs while obtaining\nthe best performance in comparison with existing methods. For example, we\nreduce MACs of CycleGAN by around 40x and parameters by over 80x, meanwhile,\n46.61 FIDs are obtained compared with these of 51.92 for the current\nstate-of-the-art. Code of this project is available at\nhttps://github.com/TheKernelZ/CRD.\n","authors":["Lizhou You","Mingbao Lin","Tie Hu","Fei Chao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2212.11091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12388v2","updated":"2022-12-21T15:08:28Z","published":"2022-10-22T08:47:25Z","title":"Diversity-Promoting Ensemble for Medical Image Segmentation","summary":"  Medical image segmentation is an actively studied task in medical imaging,\nwhere the precision of the annotations is of utter importance towards accurate\ndiagnosis and treatment. In recent years, the task has been approached with\nvarious deep learning systems, among the most popular models being U-Net. In\nthis work, we propose a novel strategy to generate ensembles of different\narchitectures for medical image segmentation, by leveraging the diversity\n(decorrelation) of the models forming the ensemble. More specifically, we\nutilize the Dice score among model pairs to estimate the correlation between\nthe outputs of the two models forming each pair. To promote diversity, we\nselect models with low Dice scores among each other. We carry out\ngastro-intestinal tract image segmentation experiments to compare our\ndiversity-promoting ensemble (DiPE) with another strategy to create ensembles\nbased on selecting the top scoring U-Net models. Our empirical results show\nthat DiPE surpasses both individual models as well as the ensemble creation\nstrategy based on selecting the top scoring models.\n","authors":["Mariana-Iuliana Georgescu","Radu Tudor Ionescu","Andreea-Iuliana Miron"],"pdf_url":"https://arxiv.org/pdf/2210.12388v2.pdf","comment":"Accepted at SAC 2023"},{"id":"http://arxiv.org/abs/2212.11042v1","updated":"2022-12-21T14:31:33Z","published":"2022-12-21T14:31:33Z","title":"Hi-LASSIE: High-Fidelity Articulated Shape and Skeleton Discovery from\n  Sparse Image Ensemble","summary":"  Automatically estimating 3D skeleton, shape, camera viewpoints, and part\narticulation from sparse in-the-wild image ensembles is a severely\nunder-constrained and challenging problem. Most prior methods rely on\nlarge-scale image datasets, dense temporal correspondence, or human annotations\nlike camera pose, 2D keypoints, and shape templates. We propose Hi-LASSIE,\nwhich performs 3D articulated reconstruction from only 20-30 online images in\nthe wild without any user-defined shape or skeleton templates. We follow the\nrecent work of LASSIE that tackles a similar problem setting and make two\nsignificant advances. First, instead of relying on a manually annotated 3D\nskeleton, we automatically estimate a class-specific skeleton from the selected\nreference image. Second, we improve the shape reconstructions with novel\ninstance-specific optimization strategies that allow reconstructions to\nfaithful fit on each instance while preserving the class-specific priors\nlearned across all images. Experiments on in-the-wild image ensembles show that\nHi-LASSIE obtains higher quality state-of-the-art 3D reconstructions despite\nrequiring minimum user input.\n","authors":["Chun-Han Yao","Wei-Chih Hung","Yuanzhen Li","Michael Rubinstein","Ming-Hsuan Yang","Varun Jampani"],"pdf_url":"https://arxiv.org/pdf/2212.11042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05047v2","updated":"2022-12-21T14:28:28Z","published":"2022-05-09T14:54:41Z","title":"Classification and mapping of low-statured 'shrubland' cover types in\n  post-agricultural landscapes of the US Northeast","summary":"  Novel plant communities reshape landscapes and pose challenges for land cover\nclassification and mapping that can constrain research and stewardship efforts.\nIn the US Northeast, emergence of low-statured woody vegetation, or shrublands,\ninstead of secondary forests in post-agricultural landscapes is well-documented\nby field studies, but poorly understood from a landscape perspective, which\nlimits the ability to systematically study and manage these lands. To address\ngaps in classification/mapping of low-statured cover types where they have been\nhistorically rare, we developed models to predict shrubland distributions at\n30m resolution across New York State (NYS), using a stacked ensemble combining\na random forest, gradient boosting machine, and artificial neural network to\nintegrate remote sensing of structural (airborne LIDAR) and optical (satellite\nimagery) properties of vegetation cover. We first classified a 1m canopy height\nmodel (CHM), derived from a patchwork of available LIDAR coverages, to define\nshrubland presence/absence. Next, these non-contiguous maps were used to train\na model ensemble based on temporally-segmented imagery to predict shrubland\nprobability for the entire study landscape (NYS). Approximately 2.5% of the CHM\ncoverage area was classified as shrubland. Models using Landsat predictors\ntrained on the classified CHM were effective at identifying shrubland (test set\nAUC=0.893, real-world AUC=0.904), in discriminating between shrub/young forest\nand other cover classes, and produced qualitatively sensible maps, even when\nextending beyond the original training data. Our results suggest that\nincorporation of airborne LiDAR, even from a discontinuous patchwork of\ncoverages, can improve land cover classification of historically rare but\nincreasingly prevalent shrubland habitats across broader areas.\n","authors":["Michael J Mahoney","Lucas K Johnson","Abigail Z Guinan","Colin M Beier"],"pdf_url":"https://arxiv.org/pdf/2205.05047v2.pdf","comment":"43 pages (35 main text, 8 supplementary materials); 11 figures (10\n  main text, 1 supplementary materials), 10 tables (4 main text, 6\n  supplementary materials)"},{"id":"http://arxiv.org/abs/2212.10319v2","updated":"2022-12-21T14:26:26Z","published":"2022-12-20T15:11:57Z","title":"Image quality prediction using synthetic and natural codebooks:\n  comparative results","summary":"  We investigate a model for image/video quality assessment based on building a\nset of codevectors representing in a sense some basic properties of images,\nsimilar to well-known CORNIA model. We analyze the codebook building method and\npropose some modifications for it. Also the algorithm is investigated from the\npoint of inference time reduction. Both natural and synthetic images are used\nfor building codebooks and some analysis of synthetic images used for codebooks\nis provided. It is demonstrated the results on quality assessment may be\nimproves with the use if synthetic images for codebook construction. We also\ndemonstrate regimes of the algorithm in which real time execution on CPU is\npossible for sufficiently high correlations with mean opinion score (MOS).\nVarious pooling strategies are considered as well as the problem of metric\nsensitivity to bitrate.\n","authors":["Maxim Koroteev","Kirill Aistov","Valeriy Berezovskiy","Pavel Frolov"],"pdf_url":"https://arxiv.org/pdf/2212.10319v2.pdf","comment":"18 pages, 8 figures"},{"id":"http://arxiv.org/abs/2210.16053v3","updated":"2022-12-21T14:20:40Z","published":"2022-10-28T10:58:53Z","title":"Automated analysis of diabetic retinopathy using vessel segmentation\n  maps as inductive bias","summary":"  Recent studies suggest that early stages of diabetic retinopathy (DR) can be\ndiagnosed by monitoring vascular changes in the deep vascular complex. In this\nwork, we investigate a novel method for automated DR grading based on optical\ncoherence tomography angiography (OCTA) images. Our work combines OCTA scans\nwith their vessel segmentations, which then serve as inputs to task specific\nnetworks for lesion segmentation, image quality assessment and DR grading. For\nthis, we generate synthetic OCTA images to train a segmentation network that\ncan be directly applied on real OCTA data. We test our approach on MICCAI\n2022's DR analysis challenge (DRAC). In our experiments, the proposed method\nperforms equally well as the baseline model.\n","authors":["Linus Kreitner","Ivan Ezhov","Daniel Rueckert","Johannes C. Paetzold","Martin J. Menten"],"pdf_url":"https://arxiv.org/pdf/2210.16053v3.pdf","comment":"Submission for MICCAI 2022 Diabetic Retinopathy Analysis Challenge\n  (DRAC) Proceedings, DOI: 10.5281/zenodo.6362349"},{"id":"http://arxiv.org/abs/2212.11030v1","updated":"2022-12-21T14:11:46Z","published":"2022-12-21T14:11:46Z","title":"Deep set conditioned latent representations for action recognition","summary":"  In recent years multi-label, multi-class video action recognition has gained\nsignificant popularity. While reasoning over temporally connected atomic\nactions is mundane for intelligent species, standard artificial neural networks\n(ANN) still struggle to classify them. In the real world, atomic actions often\ntemporally connect to form more complex composite actions. The challenge lies\nin recognising composite action of varying durations while other distinct\ncomposite or atomic actions occur in the background. Drawing upon the success\nof relational networks, we propose methods that learn to reason over the\nsemantic concept of objects and actions. We empirically show how ANNs benefit\nfrom pretraining, relational inductive biases and unordered set-based latent\nrepresentations. In this paper we propose deep set conditioned I3D (SCI3D), a\ntwo stream relational network that employs latent representation of state and\nvisual representation for reasoning over events and actions. They learn to\nreason about temporally connected actions in order to identify all of them in\nthe video. The proposed method achieves an improvement of around 1.49% mAP in\natomic action recognition and 17.57% mAP in composite action recognition, over\na I3D-NL baseline, on the CATER dataset.\n","authors":["Akash Singh","Tom De Schepper","Kevin Mets","Peter Hellinckx","Jose Oramas","Steven Latre"],"pdf_url":"https://arxiv.org/pdf/2212.11030v1.pdf","comment":"Conference VISAPP 2022, 11 pages,5 figures, 2 Tables, 6 plots"},{"id":"http://arxiv.org/abs/2212.11017v1","updated":"2022-12-21T13:49:19Z","published":"2022-12-21T13:49:19Z","title":"Object detection-based inspection of power line insulators: Incipient\n  fault detection in the low data-regime","summary":"  Deep learning-based object detection is a powerful approach for detecting\nfaulty insulators in power lines. This involves training an object detection\nmodel from scratch, or fine tuning a model that is pre-trained on benchmark\ncomputer vision datasets. This approach works well with a large number of\ninsulator images, but can result in unreliable models in the low data regime.\nThe current literature mainly focuses on detecting the presence or absence of\ninsulator caps, which is a relatively easy detection task, and does not\nconsider detection of finer faults such as flashed and broken disks. In this\narticle, we formulate three object detection tasks for insulator and asset\ninspection from aerial images, focusing on incipient faults in disks. We curate\na large reference dataset of insulator images that can be used to learn robust\nfeatures for detecting healthy and faulty insulators. We study the advantage of\nusing this dataset in the low target data regime by pre-training on the\nreference dataset followed by fine-tuning on the target dataset. The results\nsuggest that object detection models can be used to detect faults in insulators\nat a much incipient stage, and that transfer learning adds value depending on\nthe type of object detection model. We identify key factors that dictate\nperformance in the low data-regime and outline potential approaches to improve\nthe state-of-the-art.\n","authors":["Laya Das","Mohammad Hossein Saadat","Blazhe Gjorgiev","Etienne Auger","Giovanni Sansavini"],"pdf_url":"https://arxiv.org/pdf/2212.11017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11005v1","updated":"2022-12-21T13:19:25Z","published":"2022-12-21T13:19:25Z","title":"Revisiting Residual Networks for Adversarial Robustness: An\n  Architectural Perspective","summary":"  Efforts to improve the adversarial robustness of convolutional neural\nnetworks have primarily focused on developing more effective adversarial\ntraining methods. In contrast, little attention was devoted to analyzing the\nrole of architectural elements (such as topology, depth, and width) on\nadversarial robustness. This paper seeks to bridge this gap and present a\nholistic study on the impact of architectural design on adversarial robustness.\nWe focus on residual networks and consider architecture design at the block\nlevel, i.e., topology, kernel size, activation, and normalization, as well as\nat the network scaling level, i.e., depth and width of each block in the\nnetwork. In both cases, we first derive insights through systematic ablative\nexperiments. Then we design a robust residual block, dubbed RobustResBlock, and\na compound scaling rule, dubbed RobustScaling, to distribute depth and width at\nthe desired FLOP count. Finally, we combine RobustResBlock and RobustScaling\nand present a portfolio of adversarially robust residual networks,\nRobustResNets, spanning a broad spectrum of model capacities. Experimental\nvalidation across multiple datasets and adversarial attacks demonstrate that\nRobustResNets consistently outperform both the standard WRNs and other existing\nrobust architectures, achieving state-of-the-art AutoAttack robust accuracy of\n61.1% without additional data and 63.7% with 500K external data while being\n$2\\times$ more compact in terms of parameters. Code is available at \\url{\nhttps://github.com/zhichao-lu/robust-residual-network}\n","authors":["Shihua Huang","Zhichao Lu","Kalyanmoy Deb","Vishnu Naresh Boddeti"],"pdf_url":"https://arxiv.org/pdf/2212.11005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.14316v2","updated":"2022-12-21T13:18:10Z","published":"2022-03-27T14:28:16Z","title":"MutexMatch: Semi-Supervised Learning with Mutex-Based Consistency\n  Regularization","summary":"  The core issue in semi-supervised learning (SSL) lies in how to effectively\nleverage unlabeled data, whereas most existing methods tend to put a great\nemphasis on the utilization of high-confidence samples yet seldom fully explore\nthe usage of low-confidence samples. In this paper, we aim to utilize\nlow-confidence samples in a novel way with our proposed mutex-based consistency\nregularization, namely MutexMatch. Specifically, the high-confidence samples\nare required to exactly predict \"what it is\" by conventional True-Positive\nClassifier, while the low-confidence samples are employed to achieve a simpler\ngoal -- to predict with ease \"what it is not\" by True-Negative Classifier. In\nthis sense, we not only mitigate the pseudo-labeling errors but also make full\nuse of the low-confidence unlabeled data by consistency of dissimilarity\ndegree. MutexMatch achieves superior performance on multiple benchmark\ndatasets, i.e., CIFAR-10, CIFAR-100, SVHN, STL-10, mini-ImageNet and\nTiny-ImageNet. More importantly, our method further shows superiority when the\namount of labeled data is scarce, e.g., 92.23% accuracy with only 20 labeled\ndata on CIFAR-10. Our code and model weights have been released at\nhttps://github.com/NJUyued/MutexMatch4SSL.\n","authors":["Yue Duan","Zhen Zhao","Lei Qi","Lei Wang","Luping Zhou","Yinghuan Shi","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2203.14316v2.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)"},{"id":"http://arxiv.org/abs/2210.05593v2","updated":"2022-12-21T12:56:26Z","published":"2022-10-11T16:25:38Z","title":"Prototypical VoteNet for Few-Shot 3D Point Cloud Object Detection","summary":"  Most existing 3D point cloud object detection approaches heavily rely on\nlarge amounts of labeled training data. However, the labeling process is costly\nand time-consuming. This paper considers few-shot 3D point cloud object\ndetection, where only a few annotated samples of novel classes are needed with\nabundant samples of base classes. To this end, we propose Prototypical VoteNet\nto recognize and localize novel instances, which incorporates two new modules:\nPrototypical Vote Module (PVM) and Prototypical Head Module (PHM).\nSpecifically, as the 3D basic geometric structures can be shared among\ncategories, PVM is designed to leverage class-agnostic geometric prototypes,\nwhich are learned from base classes, to refine local features of novel\ncategories.Then PHM is proposed to utilize class prototypes to enhance the\nglobal feature of each object, facilitating subsequent object localization and\nclassification, which is trained by the episodic training strategy. To evaluate\nthe model in this new setting, we contribute two new benchmark datasets,\nFS-ScanNet and FS-SUNRGBD. We conduct extensive experiments to demonstrate the\neffectiveness of Prototypical VoteNet, and our proposed method shows\nsignificant and consistent improvements compared to baselines on two benchmark\ndatasets.\n","authors":["Shizhen Zhao","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2210.05593v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.10988v1","updated":"2022-12-21T12:50:31Z","published":"2022-12-21T12:50:31Z","title":"Attention-Aware Anime Line Drawing Colorization","summary":"  Automatic colorization of anime line drawing has attracted much attention in\nrecent years since it can substantially benefit the animation industry.\nUser-hint based methods are the mainstream approach for line drawing\ncolorization, while reference-based methods offer a more intuitive approach.\nNevertheless, although reference-based methods can improve feature aggregation\nof the reference image and the line drawing, the colorization results are not\ncompelling in terms of color consistency or semantic correspondence. In this\npaper, we introduce an attention-based model for anime line drawing\ncolorization, in which a channel-wise and spatial-wise Convolutional Attention\nmodule is used to improve the ability of the encoder for feature extraction and\nkey area perception, and a Stop-Gradient Attention module with cross-attention\nand self-attention is used to tackle the cross-domain long-range dependency\nproblem. Extensive experiments show that our method outperforms other SOTA\nmethods, with more accurate line structure and semantic color information.\n","authors":["Yu Cao","Hao Tian","P. Y. Mok"],"pdf_url":"https://arxiv.org/pdf/2212.10988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10390v2","updated":"2022-12-21T12:47:03Z","published":"2022-12-20T16:17:40Z","title":"ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic\n  Segmentation","summary":"  State-of-the-art 3D semantic segmentation models are trained on the\noff-the-shelf public benchmarks, but they often face the major challenge when\nthese well-trained models are deployed to a new domain. In this paper, we\npropose an Active-and-Adaptive Segmentation (ADAS) baseline to enhance the weak\ncross-domain generalization ability of a well-trained 3D segmentation model,\nand bridge the point distribution gap between domains. Specifically, before the\ncross-domain adaptation stage begins, ADAS performs an active sampling\noperation to select a maximally-informative subset from both source and target\ndomains for effective adaptation, reducing the adaptation difficulty under 3D\nscenarios. Benefiting from the rise of multi-modal 2D-3D datasets, ADAS\nutilizes a cross-modal attention-based feature fusion module that can extract a\nrepresentative pair of image features and point features to achieve a\nbi-directional image-point feature interaction for better safe adaptation.\nExperimentally, ADAS is verified to be effective in many cross-domain settings\nincluding: 1) Unsupervised Domain Adaptation (UDA), which means that all\nsamples from target domain are unlabeled; 2) Unsupervised Few-shot Domain\nAdaptation (UFDA) which means that only a few unlabeled samples are available\nin the unlabeled target domain; 3) Active Domain Adaptation (ADA) which means\nthat the selected target samples by ADAS are manually annotated. Their results\ndemonstrate that ADAS achieves a significant accuracy gain by easily coupling\nADAS with self-training methods or off-the-shelf UDA works.\n","authors":["Ben Fei","Siyuan Huang","Jiakang Yuan","Botian Shi","Bo Zhang","Tao Chen","Min Dou","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2212.10390v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10957v1","updated":"2022-12-21T11:49:43Z","published":"2022-12-21T11:49:43Z","title":"TruFor: Leveraging all-round clues for trustworthy image forgery\n  detection and localization","summary":"  In this paper we present TruFor, a forensic framework that can be applied to\na large variety of image manipulation methods, from classic cheapfakes to more\nrecent manipulations based on deep learning. We rely on the extraction of both\nhigh-level and low-level traces through a transformer-based fusion architecture\nthat combines the RGB image and a learned noise-sensitive fingerprint. The\nlatter learns to embed the artifacts related to the camera internal and\nexternal processing by training only on real data in a self-supervised manner.\nForgeries are detected as deviations from the expected regular pattern that\ncharacterizes each pristine image. Looking for anomalies makes the approach\nable to robustly detect a variety of local manipulations, ensuring\ngeneralization. In addition to a pixel-level localization map and a whole-image\nintegrity score, our approach outputs a reliability map that highlights areas\nwhere localization predictions may be error-prone. This is particularly\nimportant in forensic applications in order to reduce false alarms and allow\nfor a large scale analysis. Extensive experiments on several datasets show that\nour method is able to reliably detect and localize both cheapfakes and\ndeepfakes manipulations outperforming state-of-the-art works. Code will be\npublicly available at https://grip-unina.github.io/TruFor/\n","authors":["Fabrizio Guillaro","Davide Cozzolino","Avneesh Sud","Nicholas Dufour","Luisa Verdoliva"],"pdf_url":"https://arxiv.org/pdf/2212.10957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10950v1","updated":"2022-12-21T11:43:20Z","published":"2022-12-21T11:43:20Z","title":"Incremental Learning for Neural Radiance Field with Uncertainty-Filtered\n  Knowledge Distillation","summary":"  Recent neural radiance field (NeRF) representation has achieved great success\nin the tasks of novel view synthesis and 3D reconstruction. However, they\nsuffer from the catastrophic forgetting problem when continuously learning from\nstreaming data without revisiting the previous training data. This limitation\nprohibits the application of existing NeRF models to scenarios where images\ncome in sequentially. In view of this, we explore the task of incremental\nlearning for neural radiance field representation in this work. We first\npropose a student-teacher pipeline to mitigate the catastrophic forgetting\nproblem. Specifically, we iterate the process of using the student as the\nteacher at the end of each incremental step and let the teacher guide the\ntraining of the student in the next step. In this way, the student network is\nable to learn new information from the streaming data and retain old knowledge\nfrom the teacher network simultaneously. Given that not all information from\nthe teacher network is helpful since it is only trained with the old data, we\nfurther introduce a random inquirer and an uncertainty-based filter to filter\nuseful information. We conduct experiments on the NeRF-synthetic360 and\nNeRF-real360 datasets, where our approach significantly outperforms the\nbaselines by 7.3% and 25.2% in terms of PSNR. Furthermore, we also show that\nour approach can be applied to the large-scale camera facing-outwards dataset\nScanNet, where we surpass the baseline by 60.0% in PSNR.\n","authors":["Mengqi Guo","Chen Li","Gim Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2212.10950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.11141v2","updated":"2022-12-21T11:42:51Z","published":"2021-11-22T12:05:27Z","title":"Learning Generalized Visual Odometry Using Position-Aware Optical Flow\n  and Geometric Bundle Adjustment","summary":"  Recent visual odometry (VO) methods incorporating geometric algorithm into\ndeep-learning architecture have shown outstanding performance on the\nchallenging monocular VO task. Despite encouraging results are shown, previous\nmethods ignore the requirement of generalization capability under noisy\nenvironment and various scenes. To address this challenging issue, this work\nfirst proposes a novel optical flow network (PANet). Compared with previous\nmethods that predict optical flow as a direct regression task, our PANet\ncomputes optical flow by predicting it into the discrete position space with\noptical flow probability volume, and then converting it to optical flow. Next,\nwe improve the bundle adjustment module to fit the self-supervised training\npipeline by introducing multiple sampling, ego-motion initialization, dynamic\ndamping factor adjustment, and Jacobi matrix weighting. In addition, a novel\nnormalized photometric loss function is advanced to improve the depth\nestimation accuracy. The experiments show that the proposed system not only\nachieves comparable performance with other state-of-the-art self-supervised\nlearning-based methods on the KITTI dataset, but also significantly improves\nthe generalization capability compared with geometry-based, learning-based and\nhybrid VO systems on the noisy KITTI and the challenging outdoor (KAIST)\nscenes.\n","authors":["Yijun Cao","Xianshi Zhang","Fuya Luo","Peng Peng","Yongjie Li"],"pdf_url":"https://arxiv.org/pdf/2111.11141v2.pdf","comment":"35 pages, 6 figures"},{"id":"http://arxiv.org/abs/2212.10939v1","updated":"2022-12-21T11:28:52Z","published":"2022-12-21T11:28:52Z","title":"Joint Embedding of 2D and 3D Networks for Medical Image Anomaly\n  Detection","summary":"  Obtaining ground truth data in medical imaging has difficulties due to the\nfact that it requires a lot of annotating time from the experts in the field.\nAlso, when trained with supervised learning, it detects only the cases included\nin the labels. In real practice, we want to also open to other possibilities\nthan the named cases while examining the medical images. As a solution, the\nneed for anomaly detection that can detect and localize abnormalities by\nlearning the normal characteristics using only normal images is emerging. With\nmedical image data, we can design either 2D or 3D networks of self-supervised\nlearning for anomaly detection task. Although 3D networks, which learns 3D\nstructures of the human body, show good performance in 3D medical image anomaly\ndetection, they cannot be stacked in deeper layers due to memory problems.\nWhile 2D networks have advantage in feature detection, they lack 3D context\ninformation. In this paper, we develop a method for combining the strength of\nthe 3D network and the strength of the 2D network through joint embedding. We\nalso propose the pretask of self-supervised learning to make it possible for\nthe networks to learn efficiently. Through the experiments, we show that the\nproposed method achieves better performance in both classification and\nsegmentation tasks compared to the SoTA method.\n","authors":["Inha Kang","Jinah Park"],"pdf_url":"https://arxiv.org/pdf/2212.10939v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.10937v1","updated":"2022-12-21T11:25:07Z","published":"2022-12-21T11:25:07Z","title":"DCC: A Cascade based Approach to Detect Communities in Social Networks","summary":"  Community detection in Social Networks is associated with finding and\ngrouping the most similar nodes inherent in the network. These similar nodes\nare identified by computing tie strength. Stronger ties indicates higher\nproximity shared by connected node pairs. This work is motivated by\nGranovetter's argument that suggests that strong ties lies within densely\nconnected nodes and the theory that community cores in real-world networks are\ndensely connected. In this paper, we have introduced a novel method called\n\\emph{Disjoint Community detection using Cascades (DCC)} which demonstrates the\neffectiveness of a new local density based tie strength measure on detecting\ncommunities. Here, tie strength is utilized to decide the paths followed for\npropagating information. The idea is to crawl through the tuple information of\ncascades towards the community core guided by increasing tie strength.\nConsidering the cascade generation step, a novel preferential membership method\nhas been developed to assign community labels to unassigned nodes. The efficacy\nof $DCC$ has been analyzed based on quality and accuracy on several real-world\ndatasets and baseline community detection algorithms.\n","authors":["Soumita Das","Anupam Biswas","Akrati Saxena"],"pdf_url":"https://arxiv.org/pdf/2212.10937v1.pdf","comment":"To be published in CHSN-2022"},{"id":"http://arxiv.org/abs/2207.13492v2","updated":"2022-12-21T10:55:11Z","published":"2022-07-27T12:27:57Z","title":"Time to augment self-supervised visual representation learning","summary":"  Biological vision systems are unparalleled in their ability to learn visual\nrepresentations without supervision. In machine learning, self-supervised\nlearning (SSL) has led to major advances in forming object representations in\nan unsupervised fashion. Such systems learn representations invariant to\naugmentation operations over images, like cropping or flipping. In contrast,\nbiological vision systems exploit the temporal structure of the visual\nexperience during natural interactions with objects. This gives access to\n\"augmentations\" not commonly used in SSL, like watching the same object from\nmultiple viewpoints or against different backgrounds. Here, we systematically\ninvestigate and compare the potential benefits of such time-based augmentations\nduring natural interactions for learning object categories. Our results show\nthat time-based augmentations achieve large performance gains over\nstate-of-the-art image augmentations. Specifically, our analyses reveal that:\n1) 3-D object manipulations drastically improve the learning of object\ncategories; 2) viewing objects against changing backgrounds is important for\nlearning to discard background-related information from the latent\nrepresentation. Overall, we conclude that time-based augmentations during\nnatural interactions with objects can substantially improve self-supervised\nlearning, narrowing the gap between artificial and biological vision systems.\n","authors":["Arthur Aubret","Markus Ernst","Céline Teulière","Jochen Triesch"],"pdf_url":"https://arxiv.org/pdf/2207.13492v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2210.15663v2","updated":"2022-12-21T10:25:40Z","published":"2022-10-27T17:59:50Z","title":"Deep Generative Models on 3D Representations: A Survey","summary":"  Generative models, as an important family of statistical modeling, target\nlearning the observed data distribution via generating new instances. Along\nwith the rise of neural networks, deep generative models, such as variational\nautoencoders (VAEs) and generative adversarial network (GANs), have made\ntremendous progress in 2D image synthesis. Recently, researchers switch their\nattentions from the 2D space to the 3D space considering that 3D data better\naligns with our physical world and hence enjoys great potential in practice.\nHowever, unlike a 2D image, which owns an efficient representation (i.e., pixel\ngrid) by nature, representing 3D data could face far more challenges.\nConcretely, we would expect an ideal 3D representation to be capable enough to\nmodel shapes and appearances in details, and to be highly efficient so as to\nmodel high-resolution data with fast speed and low memory cost. However,\nexisting 3D representations, such as point clouds, meshes, and recent neural\nfields, usually fail to meet the above requirements simultaneously. In this\nsurvey, we make a thorough review of the development of 3D generation,\nincluding 3D shape generation and 3D-aware image synthesis, from the\nperspectives of both algorithms and more importantly representations. We hope\nthat our discussion could help the community track the evolution of this field\nand further spark some innovative ideas to advance this challenging task.\n","authors":["Zifan Shi","Sida Peng","Yinghao Xu","Yiyi Liao","Yujun Shen"],"pdf_url":"https://arxiv.org/pdf/2210.15663v2.pdf","comment":"Github: https://github.com/justimyhxu/awesome-3D-generation"},{"id":"http://arxiv.org/abs/2212.10888v1","updated":"2022-12-21T09:58:14Z","published":"2022-12-21T09:58:14Z","title":"A Survey of Mix-based Data Augmentation: Taxonomy, Methods,\n  Applications, and Explainability","summary":"  Data augmentation (DA) is indispensable in modern machine learning and deep\nneural networks. The basic idea of DA is to construct new training data to\nimprove the model's generalization by adding slightly disturbed versions of\nexisting data or synthesizing new data. In this work, we review a small but\nessential subset of DA -- Mix-based Data Augmentation (MixDA) that generates\nnovel samples by mixing multiple examples. Unlike conventional DA approaches\nbased on a single-sample operation or requiring domain knowledge, MixDA is more\ngeneral in creating a broad spectrum of new data and has received increasing\nattention in the community. We begin with proposing a new taxonomy classifying\nMixDA into, Mixup-based, Cutmix-based, and hybrid approaches according to a\nhierarchical view of the data mix. Various MixDA techniques are then\ncomprehensively reviewed in a more fine-grained way. Owing to its\ngeneralization, MixDA has penetrated a variety of applications which are also\ncompletely reviewed in this work. We also examine why MixDA works from\ndifferent aspects of improving model performance, generalization, and\ncalibration while explaining the model behavior based on the properties of\nMixDA. Finally, we recapitulate the critical findings and fundamental\nchallenges of current MixDA studies, and outline the potential directions for\nfuture works. Different from previous related works that summarize the DA\napproaches in a specific domain (e.g., images or natural language processing)\nor only review a part of MixDA studies, we are the first to provide a\nsystematical survey of MixDA in terms of its taxonomy, methodology,\napplications, and explainability. This work can serve as a roadmap to MixDA\ntechniques and application reviews while providing promising directions for\nresearchers interested in this exciting area.\n","authors":["Chengtai Cao","Fan Zhou","Yurou Dai","Jianping Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10881v1","updated":"2022-12-21T09:47:52Z","published":"2022-12-21T09:47:52Z","title":"In-Sensor & Neuromorphic Computing are all you need for Energy Efficient\n  Computer Vision","summary":"  Due to the high activation sparsity and use of accumulates (AC) instead of\nexpensive multiply-and-accumulates (MAC), neuromorphic spiking neural networks\n(SNNs) have emerged as a promising low-power alternative to traditional DNNs\nfor several computer vision (CV) applications. However, most existing SNNs\nrequire multiple time steps for acceptable inference accuracy, hindering\nreal-time deployment and increasing spiking activity and, consequently, energy\nconsumption. Recent works proposed direct encoding that directly feeds the\nanalog pixel values in the first layer of the SNN in order to significantly\nreduce the number of time steps. Although the overhead for the first layer MACs\nwith direct encoding is negligible for deep SNNs and the CV processing is\nefficient using SNNs, the data transfer between the image sensors and the\ndownstream processing costs significant bandwidth and may dominate the total\nenergy. To mitigate this concern, we propose an in-sensor computing\nhardware-software co-design framework for SNNs targeting image recognition\ntasks. Our approach reduces the bandwidth between sensing and processing by\n12-96x and the resulting total energy by 2.32x compared to traditional CV\nprocessing, with a 3.8% reduction in accuracy on ImageNet.\n","authors":["Gourav Datta","Zeyu Liu","Md Abdullah-Al Kaiser","Souvik Kundu","Joe Mathai","Zihan Yin","Ajey P. Jacob","Akhilesh R. Jaiswal","Peter A. Beerel"],"pdf_url":"https://arxiv.org/pdf/2212.10881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07413v3","updated":"2022-12-21T09:47:49Z","published":"2022-09-15T16:10:16Z","title":"EZNAS: Evolving Zero Cost Proxies For Neural Architecture Scoring","summary":"  Neural Architecture Search (NAS) has significantly improved productivity in\nthe design and deployment of neural networks (NN). As NAS typically evaluates\nmultiple models by training them partially or completely, the improved\nproductivity comes at the cost of significant carbon footprint. To alleviate\nthis expensive training routine, zero-shot/cost proxies analyze an NN at\ninitialization to generate a score, which correlates highly with its true\naccuracy. Zero-cost proxies are currently designed by experts conducting\nmultiple cycles of empirical testing on possible algorithms, datasets, and\nneural architecture design spaces. This experimentation lowers productivity and\nis an unsustainable approach towards zero-cost proxy design as deep learning\nuse-cases diversify in nature. Additionally, existing zero-cost proxies fail to\ngeneralize across neural architecture design spaces. In this paper, we propose\na genetic programming framework to automate the discovery of zero-cost proxies\nfor neural architecture scoring. Our methodology efficiently discovers an\ninterpretable and generalizable zero-cost proxy that gives state of the art\nscore-accuracy correlation on all datasets and search spaces of NASBench-201\nand Network Design Spaces (NDS). We believe that this research indicates a\npromising direction towards automatically discovering zero-cost proxies that\ncan work across network architecture design spaces, datasets, and tasks.\n","authors":["Yash Akhauri","J. Pablo Munoz","Nilesh Jain","Ravi Iyer"],"pdf_url":"https://arxiv.org/pdf/2209.07413v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10428v2","updated":"2022-12-21T09:45:53Z","published":"2022-12-20T17:06:32Z","title":"HouseCat6D -- A Large-Scale Multi-Modal Category Level 6D Object Pose\n  Dataset with Household Objects in Realistic Scenarios","summary":"  Estimating the 6D pose of objects is one of the major fields in 3D computer\nvision. Since the promising outcomes from instance-level pose estimation, the\nresearch trends are heading towards category-level pose estimation for more\npractical application scenarios. However, unlike well-established\ninstance-level pose datasets, available category-level datasets lack annotation\nquality and provided pose quantity. We propose the new category level 6D pose\ndataset HouseCat6D featuring 1) Multi-modality of Polarimetric RGB+P and Depth,\n2) Highly diverse 194 objects of 10 household object categories including 2\nphotometrically challenging categories, 3) High-quality pose annotation with an\nerror range of only 1.35 mm to 1.74 mm, 4) 41 large scale scenes with extensive\nviewpoint coverage, 5) Checkerboard-free environment throughout the entire\nscene. We also provide benchmark results of state-of-the-art category-level\npose estimation networks.\n","authors":["HyunJun Jung","Shun-Cheng Wu","Patrick Ruhkamp","Hannah Schieber","Pengyuan Wang","Giulia Rizzoli","Hongcheng Zhao","Sven Damian Meier","Daniel Roth","Nassir Navab","Benjamin Busam"],"pdf_url":"https://arxiv.org/pdf/2212.10428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10878v1","updated":"2022-12-21T09:41:25Z","published":"2022-12-21T09:41:25Z","title":"Automatic Network Adaptation for Ultra-Low Uniform-Precision\n  Quantization","summary":"  Uniform-precision neural network quantization has gained popularity since it\nsimplifies densely packed arithmetic unit for high computing capability.\nHowever, it ignores heterogeneous sensitivity to the impact of quantization\nerrors across the layers, resulting in sub-optimal inference accuracy. This\nwork proposes a novel neural architecture search called neural channel\nexpansion that adjusts the network structure to alleviate accuracy degradation\nfrom ultra-low uniform-precision quantization. The proposed method selectively\nexpands channels for the quantization sensitive layers while satisfying\nhardware constraints (e.g., FLOPs, PARAMs). Based on in-depth analysis and\nexperiments, we demonstrate that the proposed method can adapt several popular\nnetworks channels to achieve superior 2-bit quantization accuracy on CIFAR10\nand ImageNet. In particular, we achieve the best-to-date Top-1/Top-5 accuracy\nfor 2-bit ResNet50 with smaller FLOPs and the parameter size.\n","authors":["Seongmin Park","Beomseok Kwon","Jieun Lim","Kyuyoung Sim","Taeho Kim","Jungwook Choi"],"pdf_url":"https://arxiv.org/pdf/2212.10878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10877v1","updated":"2022-12-21T09:40:23Z","published":"2022-12-21T09:40:23Z","title":"TMS-Net: A Segmentation Network Coupled With A Run-time Quality Control\n  Method For Robust Cardiac Image Segmentation","summary":"  Recently, deep networks have shown impressive performance for the\nsegmentation of cardiac Magnetic Resonance Imaging (MRI) images. However, their\nachievement is proving slow to transition to widespread use in medical clinics\nbecause of robustness issues leading to low trust of clinicians to their\nresults. Predicting run-time quality of segmentation masks can be useful to\nwarn clinicians against poor results. Despite its importance, there are few\nstudies on this problem. To address this gap, we propose a quality control\nmethod based on the agreement across decoders of a multi-view network, TMS-Net,\nmeasured by the cosine similarity. The network takes three view inputs resliced\nfrom the same 3D image along different axes. Different from previous multi-view\nnetworks, TMS-Net has a single encoder and three decoders, leading to better\nnoise robustness, segmentation performance and run-time quality estimation in\nour experiments on the segmentation of the left atrium on STACOM 2013 and\nSTACOM 2018 challenge datasets. We also present a way to generate poor\nsegmentation masks by using noisy images generated with engineered noise and\nRician noise to simulate undertraining, high anisotropy and poor imaging\nsettings problems. Our run-time quality estimation method show a good\nclassification of poor and good quality segmentation masks with an AUC reaching\nto 0.97 on STACOM 2018. We believe that TMS-Net and our run-time quality\nestimation method has a high potential to increase the thrust of clinicians to\nautomatic image analysis tools.\n","authors":["Fatmatulzehra Uslu","Anil A. Bharath"],"pdf_url":"https://arxiv.org/pdf/2212.10877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.11553v4","updated":"2022-12-21T09:38:50Z","published":"2022-08-24T13:55:15Z","title":"Improving video retrieval using multilingual knowledge transfer","summary":"  Video retrieval has seen tremendous progress with the development of\nvision-language models. However, further improving these models require\nadditional labelled data which is a huge manual effort. In this paper, we\npropose a framework MKTVR, that utilizes knowledge transfer from a multilingual\nmodel to boost the performance of video retrieval. We first use\nstate-of-the-art machine translation models to construct pseudo ground-truth\nmultilingual video-text pairs. We then use this data to learn a video-text\nrepresentation where English and non-English text queries are represented in a\ncommon embedding space based on pretrained multilingual models. We evaluate our\nproposed approach on four English video retrieval datasets such as MSRVTT,\nMSVD, DiDeMo and Charades. Experimental results demonstrate that our approach\nachieves state-of-the-art results on all datasets outperforming previous\nmodels. Finally, we also evaluate our model on a multilingual video-retrieval\ndataset encompassing six languages and show that our model outperforms previous\nmultilingual video retrieval models in a zero-shot setting.\n","authors":["Avinash Madasu","Estelle Aflalo","Gabriela Ben Melech Stan","Shao-Yen Tseng","Gedas Bertasius","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2208.11553v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10870v1","updated":"2022-12-21T09:26:40Z","published":"2022-12-21T09:26:40Z","title":"MoQuad: Motion-focused Quadruple Construction for Video Contrastive\n  Learning","summary":"  Learning effective motion features is an essential pursuit of video\nrepresentation learning. This paper presents a simple yet effective sample\nconstruction strategy to boost the learning of motion features in video\ncontrastive learning. The proposed method, dubbed Motion-focused Quadruple\nConstruction (MoQuad), augments the instance discrimination by meticulously\ndisturbing the appearance and motion of both the positive and negative samples\nto create a quadruple for each video instance, such that the model is\nencouraged to exploit motion information. Unlike recent approaches that create\nextra auxiliary tasks for learning motion features or apply explicit temporal\nmodelling, our method keeps the simple and clean contrastive learning paradigm\n(i.e.,SimCLR) without multi-task learning or extra modelling. In addition, we\ndesign two extra training strategies by analyzing initial MoQuad experiments.\nBy simply applying MoQuad to SimCLR, extensive experiments show that we achieve\nsuperior performance on downstream tasks compared to the state of the arts.\nNotably, on the UCF-101 action recognition task, we achieve 93.7% accuracy\nafter pre-training the model on Kinetics-400 for only 200 epochs, surpassing\nvarious previous methods\n","authors":["Yuan Liu","Jiacheng Chen","Hao Wu"],"pdf_url":"https://arxiv.org/pdf/2212.10870v1.pdf","comment":"ECCV2022 WorkShop"},{"id":"http://arxiv.org/abs/2206.07326v2","updated":"2022-12-21T09:19:46Z","published":"2022-06-15T07:12:23Z","title":"Recent Advances in Scene Image Representation and Classification","summary":"  With the rise of deep learning algorithms nowadays, scene image\nrepresentation methods have achieved a significant performance boost in\nclassification. However, the performance is still limited because the scene\nimages are mostly complex having higher intra-class dissimilarity and\ninter-class similarity problems. To deal with such problems, there have been\nseveral methods proposed in the literature with their advantages and\nlimitations. A detailed study of previous works is necessary to understand\ntheir advantages and disadvantages in image representation and classification\nproblems. In this paper, we review the existing scene image representation\nmethods that are being widely used for image classification. For this, we,\nfirst, devise the taxonomy using the seminal existing methods proposed in the\nliterature to this date {using deep learning (DL)-based, computer vision\n(CV)-based, and search engine (SE)-based methods}. Next, we compare their\nperformance both qualitatively (e.g., quality of outputs, pros/cons, etc.) and\nquantitatively (e.g., accuracy). Last, we speculate on the prominent research\ndirections in scene image representation tasks using {keyword growth and\ntimeline analysis.} Overall, this survey provides in-depth insights and\napplications of recent scene image representation methods under three different\nmethods.\n","authors":["Chiranjibi Sitaula","Tej Bahadur Shahi","Faezeh Marzbanrad","Jagannath Aryal"],"pdf_url":"https://arxiv.org/pdf/2206.07326v2.pdf","comment":"This paper is under review in Multimedia Tools and Applications\n  (Springer) journal. This article may be deleted or updated based on the\n  policies of the journal"},{"id":"http://arxiv.org/abs/2210.04561v3","updated":"2022-12-21T09:08:52Z","published":"2022-10-10T11:01:57Z","title":"A Comprehensive Survey of Data Augmentation in Visual Reinforcement\n  Learning","summary":"  Visual reinforcement learning (RL), which makes decisions directly from\nhigh-dimensional visual inputs, has demonstrated significant potential in\nvarious domains. However, deploying visual RL techniques in the real world\nremains challenging due to their low sample efficiency and large generalization\ngaps. To tackle these obstacles, data augmentation (DA) has become a widely\nused technique in visual RL for acquiring sample-efficient and generalizable\npolicies by diversifying the training data. This survey aims to provide a\ntimely and essential review of DA techniques in visual RL in recognition of the\nthriving development in this field. In particular, we propose a unified\nframework for analyzing visual RL and understanding the role of DA in it. We\nthen present a principled taxonomy of the existing augmentation techniques used\nin visual RL and conduct an in-depth discussion on how to better leverage\naugmented data in different scenarios. Moreover, we report a systematic\nempirical evaluation of DA-based techniques in visual RL and conclude by\nhighlighting the directions for future research. As the first comprehensive\nsurvey of DA in visual RL, this work is expected to offer valuable guidance to\nthis emerging field.\n","authors":["Guozheng Ma","Zhen Wang","Zhecheng Yuan","Xueqian Wang","Bo Yuan","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2210.04561v3.pdf","comment":"A well-classified paper list that will be continuously updated can be\n  found at https://github.com/Guozheng-Ma/DA-in-visualRL"},{"id":"http://arxiv.org/abs/2212.09247v2","updated":"2022-12-21T08:58:14Z","published":"2022-12-19T04:49:26Z","title":"ColoristaNet for Photorealistic Video Style Transfer","summary":"  Photorealistic style transfer aims to transfer the artistic style of an image\nonto an input image or video while keeping photorealism. In this paper, we\nthink it's the summary statistics matching scheme in existing algorithms that\nleads to unrealistic stylization. To avoid employing the popular Gram loss, we\npropose a self-supervised style transfer framework, which contains a style\nremoval part and a style restoration part. The style removal network removes\nthe original image styles, and the style restoration network recovers image\nstyles in a supervised manner. Meanwhile, to address the problems in current\nfeature transformation methods, we propose decoupled instance normalization to\ndecompose feature transformation into style whitening and restylization. It\nworks quite well in ColoristaNet and can transfer image styles efficiently\nwhile keeping photorealism. To ensure temporal coherency, we also incorporate\noptical flow methods and ConvLSTM to embed contextual information. Experiments\ndemonstrates that ColoristaNet can achieve better stylization effects when\ncompared with state-of-the-art algorithms.\n","authors":["Xiaowen Qiu","Ruize Xu","Boan He","Yingtao Zhang","Wenqiang Zhang","Weifeng Ge"],"pdf_url":"https://arxiv.org/pdf/2212.09247v2.pdf","comment":"30 pages, 29 figures"},{"id":"http://arxiv.org/abs/2212.10846v1","updated":"2022-12-21T08:39:36Z","published":"2022-12-21T08:39:36Z","title":"From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language\n  Models","summary":"  Large language models (LLMs) have demonstrated excellent zero-shot\ngeneralization to new language tasks. However, effective utilization of LLMs\nfor zero-shot visual question-answering (VQA) remains challenging, primarily\ndue to the modality disconnection and task disconnection between LLM and VQA\ntask. End-to-end training on vision and language data may bridge the\ndisconnections, but is inflexible and computationally expensive. To address\nthis issue, we propose \\emph{Img2Prompt}, a plug-and-play module that provides\nthe prompts that can bridge the aforementioned modality and task\ndisconnections, so that LLMs can perform zero-shot VQA tasks without end-to-end\ntraining. In order to provide such prompts, we further employ LLM-agnostic\nmodels to provide prompts that can describe image content and self-constructed\nquestion-answer pairs, which can effectively guide LLM to perform zero-shot VQA\ntasks. Img2Prompt offers the following benefits: 1) It can flexibly work with\nvarious LLMs to perform VQA. 2)~Without the needing of end-to-end training, it\nsignificantly reduces the cost of deploying LLM for zero-shot VQA tasks. 3) It\nachieves comparable or better performance than methods relying on end-to-end\ntraining. For example, we outperform Flamingo~\\cite{Deepmind:Flamingo2022} by\n5.6\\% on VQAv2. On the challenging A-OKVQA dataset, our method even outperforms\nfew-shot methods by as much as 20\\%.\n","authors":["Jiaxian Guo","Junnan Li","Dongxu Li","Anthony Meng Huat Tiong","Boyang Li","Dacheng Tao","Steven C. H. Hoi"],"pdf_url":"https://arxiv.org/pdf/2212.10846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.15093v3","updated":"2022-12-21T08:21:05Z","published":"2021-05-31T16:22:33Z","title":"Pho(SC)-CTC -- A Hybrid Approach Towards Zero-shot Word Image\n  Recognition","summary":"  Annotating words in a historical document image archive for word image\nrecognition purpose demands time and skilled human resource (like historians,\npaleographers). In a real-life scenario, obtaining sample images for all\npossible words is also not feasible. However, Zero-shot learning methods could\naptly be used to recognize unseen/out-of-lexicon words in such historical\ndocument images. Based on previous state-of-the-art method for zero-shot word\nrecognition Pho(SC)Net, we propose a hybrid model based on the CTC framework\n(Pho(SC)-CTC) that takes advantage of the rich features learned by Pho(SC)Net\nfollowed by a connectionist temporal classification (CTC) framework to perform\nthe final classification. Encouraging results were obtained on two publicly\navailable historical document datasets and one synthetic handwritten dataset,\nwhich justifies the efficacy of Pho(SC)-CTC and Pho(SC)Net.\n","authors":["Ravi Bhatt","Anuj Rai","Narayanan C. Krishnan","Sukalpa Chanda"],"pdf_url":"https://arxiv.org/pdf/2105.15093v3.pdf","comment":"Accepted (International Journal on Document Analysis and\n  Recognition). This paper is the extension of the paper titled \"Pho(SC)Net: An\n  Approach Towards Zero-shot Word Image Recognition in Historical Documents\"\n  published in ICDAR 2021"},{"id":"http://arxiv.org/abs/2212.10836v1","updated":"2022-12-21T08:13:43Z","published":"2022-12-21T08:13:43Z","title":"Towards Rapid Prototyping and Comparability in Active Learning for Deep\n  Object Detection","summary":"  Active learning as a paradigm in deep learning is especially important in\napplications involving intricate perception tasks such as object detection\nwhere labels are difficult and expensive to acquire. Development of active\nlearning methods in such fields is highly computationally expensive and time\nconsuming which obstructs the progression of research and leads to a lack of\ncomparability between methods. In this work, we propose and investigate a\nsandbox setup for rapid development and transparent evaluation of active\nlearning in deep object detection. Our experiments with commonly used\nconfigurations of datasets and detection architectures found in the literature\nshow that results obtained in our sandbox environment are representative of\nresults on standard configurations. The total compute time to obtain results\nand assess the learning behavior can thereby be reduced by factors of up to 14\nwhen comparing with Pascal VOC and up to 32 when comparing with BDD100k. This\nallows for testing and evaluating data acquisition and labeling strategies in\nunder half a day and contributes to the transparency and development speed in\nthe field of active learning for object detection.\n","authors":["Tobias Riedlinger","Marius Schubert","Karsten Kahl","Hanno Gottschalk","Matthias Rottmann"],"pdf_url":"https://arxiv.org/pdf/2212.10836v1.pdf","comment":"17 pages, 12 figures, 9 tables"},{"id":"http://arxiv.org/abs/2211.05719v3","updated":"2022-12-21T08:12:46Z","published":"2022-11-10T17:37:04Z","title":"MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal\n  Open-domain Conversation","summary":"  Responding with multi-modal content has been recognized as an essential\ncapability for an intelligent conversational agent. In this paper, we introduce\nthe MMDialog dataset to better facilitate multi-modal conversation. MMDialog is\ncomposed of a curated set of 1.08 million real-world dialogues with 1.53\nmillion unique images across 4,184 topics. MMDialog has two main and unique\nadvantages. First, it is the largest multi-modal conversation dataset by the\nnumber of dialogues by 88x. Second, it contains massive topics to generalize\nthe open-domain. To build engaging dialogue system with this dataset, we\npropose and normalize two response producing tasks based on retrieval and\ngenerative scenarios. In addition, we build two baselines for above tasks with\nstate-of-the-art techniques and report their experimental performance. We also\npropose a novel evaluation metric MM-Relevance to measure the multi-modal\nresponses. Our dataset and scripts are available in\nhttps://github.com/victorsungo/MMDialog.\n","authors":["Jiazhan Feng","Qingfeng Sun","Can Xu","Pu Zhao","Yaming Yang","Chongyang Tao","Dongyan Zhao","Qingwei Lin"],"pdf_url":"https://arxiv.org/pdf/2211.05719v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.00442v2","updated":"2022-12-21T07:22:46Z","published":"2022-12-01T11:24:47Z","title":"MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term\n  Motion-Guided Temporal Attention for 3D Object Detection","summary":"  Most scanning LiDAR sensors generate a sequence of point clouds in real-time.\nWhile conventional 3D object detectors use a set of unordered LiDAR points\nacquired over a fixed time interval, recent studies have revealed that\nsubstantial performance improvement can be achieved by exploiting the\nspatio-temporal context present in a sequence of LiDAR point sets. In this\npaper, we propose a novel 3D object detection architecture, which can encode\nLiDAR point cloud sequences acquired by multiple successive scans. The encoding\nprocess of the point cloud sequence is performed on two different time scales.\nWe first design a short-term motion-aware voxel encoding that captures the\nshort-term temporal changes of point clouds driven by the motion of objects in\neach voxel. We also propose long-term motion-guided bird's eye view (BEV)\nfeature enhancement that adaptively aligns and aggregates the BEV feature maps\nobtained by the short-term voxel encoding by utilizing the dynamic motion\ncontext inferred from the sequence of the feature maps. The experiments\nconducted on the public nuScenes benchmark demonstrate that the proposed 3D\nobject detector offers significant improvements in performance compared to the\nbaseline methods and that it sets a state-of-the-art performance for certain 3D\nobject detection categories. Code is available at\nhttps://github.com/HYjhkoh/MGTANet.git\n","authors":["Junho Koh","Junhyung Lee","Youngwoo Lee","Jaekyum Kim","Jun Won Choi"],"pdf_url":"https://arxiv.org/pdf/2212.00442v2.pdf","comment":"Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI'23)"},{"id":"http://arxiv.org/abs/2212.10817v1","updated":"2022-12-21T07:11:39Z","published":"2022-12-21T07:11:39Z","title":"High-fidelity Direct Contrast Synthesis from Magnetic Resonance\n  Fingerprinting","summary":"  Magnetic Resonance Fingerprinting (MRF) is an efficient quantitative MRI\ntechnique that can extract important tissue and system parameters such as T1,\nT2, B0, and B1 from a single scan. This property also makes it attractive for\nretrospectively synthesizing contrast-weighted images. In general,\ncontrast-weighted images like T1-weighted, T2-weighted, etc., can be\nsynthesized directly from parameter maps through spin-dynamics simulation\n(i.e., Bloch or Extended Phase Graph models). However, these approaches often\nexhibit artifacts due to imperfections in the mapping, the sequence modeling,\nand the data acquisition. Here we propose a supervised learning-based method\nthat directly synthesizes contrast-weighted images from the MRF data without\ngoing through the quantitative mapping and spin-dynamics simulation. To\nimplement our direct contrast synthesis (DCS) method, we deploy a conditional\nGenerative Adversarial Network (GAN) framework and propose a multi-branch U-Net\nas the generator. The input MRF data are used to directly synthesize\nT1-weighted, T2-weighted, and fluid-attenuated inversion recovery (FLAIR)\nimages through supervised training on paired MRF and target spin echo-based\ncontrast-weighted scans. In-vivo experiments demonstrate excellent image\nquality compared to simulation-based contrast synthesis and previous DCS\nmethods, both visually as well as by quantitative metrics. We also demonstrate\ncases where our trained model is able to mitigate in-flow and spiral\noff-resonance artifacts that are typically seen in MRF reconstructions and thus\nmore faithfully represent conventional spin echo-based contrast-weighted\nimages.\n","authors":["Ke Wang","Mariya Doneva","Jakob Meineke","Thomas Amthor","Ekin Karasan","Fei Tan","Jonathan I. Tamir","Stella X. Yu","Michael Lustig"],"pdf_url":"https://arxiv.org/pdf/2212.10817v1.pdf","comment":"19 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.10812v1","updated":"2022-12-21T07:02:11Z","published":"2022-12-21T07:02:11Z","title":"Secure and Privacy Preserving Proxy Biometrics Identities","summary":"  With large-scale adaption to biometric based applications, security and\nprivacy of biometrics is utmost important especially when operating in\nunsupervised online mode. This work proposes a novel approach for generating\nnew artificial fingerprints also called proxy fingerprints that are natural\nlooking, non-invertible, revocable and privacy preserving. These proxy\nbiometrics can be generated from original ones only with the help of a\nuser-specific key. Instead of using the original fingerprint, these proxy\ntemplates can be used anywhere with same convenience. The manuscripts walks\nthrough an interesting way in which proxy fingerprints of different types can\nbe generated and how they can be combined with use-specific keys to provide\nrevocability and cancelability in case of compromise. Using the proposed\napproach a proxy dataset is generated from samples belonging to Anguli\nfingerprint database. Matching experiments were performed on the new set which\nis 5 times larger than the original, and it was found that their performance is\nat par with 0 FAR and 0 FRR in the stolen key, safe key scenarios. Other\nparameters on revocability and diversity are also analyzed for protection\nperformance.\n","authors":["Harkeerat Kaur","Rishabh Shukla","Isao Echizen","Pritee Khanna"],"pdf_url":"https://arxiv.org/pdf/2212.10812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10806v1","updated":"2022-12-21T06:56:22Z","published":"2022-12-21T06:56:22Z","title":"Semi-Supervised Learning of Monocular Depth Estimation via Consistency\n  Regularization with K-way Disjoint Masking","summary":"  Semi-Supervised Learning (SSL) has recently accomplished successful\nachievements in various fields such as image classification, object detection,\nand semantic segmentation, which typically require a lot of labour to construct\nground-truth. Especially in the depth estimation task, annotating training data\nis very costly and time-consuming, and thus recent SSL regime seems an\nattractive solution. In this paper, for the first time, we introduce a novel\nframework for semi-supervised learning of monocular depth estimation networks,\nusing consistency regularization to mitigate the reliance on large ground-truth\ndepth data. We propose a novel data augmentation approach, called K-way\ndisjoint masking, which allows the network for learning how to reconstruct\ninvisible regions so that the model not only becomes robust to perturbations\nbut also generates globally consistent output depth maps. Experiments on the\nKITTI and NYU-Depth-v2 datasets demonstrate the effectiveness of each component\nin our pipeline, robustness to the use of fewer and fewer annotated images, and\nsuperior results compared to other state-of-the-art, semi-supervised methods\nfor monocular depth estimation. Our code is available at\nhttps://github.com/KU-CVLAB/MaskingDepth.\n","authors":["Jongbeom Baek","Gyeongnyeon Kim","Seonghoon Park","Honggyu An","Matteo Poggi","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2212.10806v1.pdf","comment":"Project page: https://github.com/KU-CVLAB/MaskingDepth"},{"id":"http://arxiv.org/abs/2212.10805v1","updated":"2022-12-21T06:56:14Z","published":"2022-12-21T06:56:14Z","title":"Beyond Information Exchange: An Approach to Deploy Network Properties\n  for Information Diffusion","summary":"  Information diffusion in Online Social Networks is a new and crucial problem\nin social network analysis field and requires significant research attention.\nEfficient diffusion of information are of critical importance in diverse\nsituations such as; pandemic prevention, advertising, marketing etc. Although\nseveral mathematical models have been developed till date, but previous works\nlacked systematic analysis and exploration of the influence of neighborhood for\ninformation diffusion. In this paper, we have proposed Common Neighborhood\nStrategy (CNS) algorithm for information diffusion that demonstrates the role\nof common neighborhood in information propagation throughout the network. The\nperformance of CNS algorithm is evaluated on several real-world datasets in\nterms of diffusion speed and diffusion outspread and compared with several\nwidely used information diffusion models. Empirical results show CNS algorithm\nenables better information diffusion both in terms of diffusion speed and\ndiffusion outspread.\n","authors":["Soumita Das","Anupam Biswas","Ravi Kishore Devarapalli"],"pdf_url":"https://arxiv.org/pdf/2212.10805v1.pdf","comment":"To be published in BigDML 2021"},{"id":"http://arxiv.org/abs/2212.10797v1","updated":"2022-12-21T06:43:46Z","published":"2022-12-21T06:43:46Z","title":"Direct Comparative Analysis of Nature-inspired Optimization Algorithms\n  on Community Detection Problem in Social Networks","summary":"  Nature-inspired optimization Algorithms (NIOAs) are nowadays a popular choice\nfor community detection in social networks. Community detection problem in\nsocial network is treated as optimization problem, where the objective is to\neither maximize the connection within the community or minimize connections\nbetween the communities. To apply NIOAs, either of the two, or both objectives\nare explored. Since NIOAs mostly exploit randomness in their strategies, it is\nnecessary to analyze their performance for specific applications. In this\npaper, NIOAs are analyzed on the community detection problem. A direct\ncomparison approach is followed to perform pairwise comparison of NIOAs. The\nperformance is measured in terms of five scores designed based on prasatul\nmatrix and also with average isolability. Three widely used real-world social\nnetworks and four NIOAs are considered for analyzing the quality of communities\ngenerated by NIOAs.\n","authors":["Soumita Das","Bijita Singha","Alberto Tonda","Anupam Biswas"],"pdf_url":"https://arxiv.org/pdf/2212.10797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08412v2","updated":"2022-12-21T06:11:44Z","published":"2022-07-18T07:21:56Z","title":"Multi-branch Cascaded Swin Transformers with Attention to k-space\n  Sampling Pattern for Accelerated MRI Reconstruction","summary":"  Global correlations are widely seen in human anatomical structures due to\nsimilarity across tissues and bones. These correlations are reflected in\nmagnetic resonance imaging (MRI) scans as a result of close-range proton\ndensity and T1/T2 parameters. Furthermore, to achieve accelerated MRI, k-space\ndata are undersampled which causes global aliasing artifacts. Convolutional\nneural network (CNN) models are widely utilized for accelerated MRI\nreconstruction, but those models are limited in capturing global correlations\ndue to the intrinsic locality of the convolution operation. The\nself-attention-based transformer models are capable of capturing global\ncorrelations among image features, however, the current contributions of\ntransformer models for MRI reconstruction are minute. The existing\ncontributions mostly provide CNN-transformer hybrid solutions and rarely\nleverage the physics of MRI. In this paper, we propose a physics-based\nstand-alone (convolution free) transformer model titled, the Multi-head\nCascaded Swin Transformers (McSTRA) for accelerated MRI reconstruction. McSTRA\ncombines several interconnected MRI physics-related concepts with the\ntransformer networks: it exploits global MR features via the shifted window\nself-attention mechanism; it extracts MR features belonging to different\nspectral components separately using a multi-head setup; it iterates between\nintermediate de-aliasing and k-space correction via a cascaded network with\ndata consistency in k-space and intermediate loss computations; furthermore, we\npropose a novel positional embedding generation mechanism to guide\nself-attention utilizing the point spread function corresponding to the\nundersampling mask. Our model significantly outperforms state-of-the-art MRI\nreconstruction methods both visually and quantitatively while depicting\nimproved resolution and removal of aliasing artifacts.\n","authors":["Mevan Ekanayake","Kamlesh Pawar","Mehrtash Harandi","Gary Egan","Zhaolin Chen"],"pdf_url":"https://arxiv.org/pdf/2207.08412v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10772v1","updated":"2022-12-21T05:08:37Z","published":"2022-12-21T05:08:37Z","title":"Low-Light Image and Video Enhancement: A Comprehensive Survey and Beyond","summary":"  This paper presents a comprehensive survey of low-light image and video\nenhancement. We begin with the challenging mixed over-/under-exposed images,\nwhich are under-performed by existing methods. To this end, we propose two\nvariants of the SICE dataset named SICE_Grad and SICE_Mix. Next, we introduce\nNight Wenzhou, a large-scale, high-resolution video dataset, to address the\nissue of the lack of a low-light video dataset that discount the use of\nlow-light image enhancement (LLIE) to videos. The Night Wenzhou dataset is\nchallenging since it consists of fast-moving aerial scenes and streetscapes\nwith varying illuminations and degradation. We conduct extensive key technique\nanalysis and experimental comparisons for representative LLIE approaches using\nthese newly proposed datasets and the current benchmark datasets. Finally, we\naddress unresolved issues and propose future research topics for the LLIE\ncommunity.\n","authors":["Shen Zheng","Yiling Ma","Jinqian Pan","Changjie Lu","Gaurav Gupta"],"pdf_url":"https://arxiv.org/pdf/2212.10772v1.pdf","comment":"10 pages, 8 tables, and 13 figures"},{"id":"http://arxiv.org/abs/2212.10766v1","updated":"2022-12-21T04:56:41Z","published":"2022-12-21T04:56:41Z","title":"Class Prototype-based Cleaner for Label Noise Learning","summary":"  Semi-supervised learning based methods are current SOTA solutions to the\nnoisy-label learning problem, which rely on learning an unsupervised label\ncleaner first to divide the training samples into a labeled set for clean data\nand an unlabeled set for noise data. Typically, the cleaner is obtained via\nfitting a mixture model to the distribution of per-sample training losses.\nHowever, the modeling procedure is \\emph{class agnostic} and assumes the loss\ndistributions of clean and noise samples are the same across different classes.\nUnfortunately, in practice, such an assumption does not always hold due to the\nvarying learning difficulty of different classes, thus leading to sub-optimal\nlabel noise partition criteria. In this work, we reveal this long-ignored\nproblem and propose a simple yet effective solution, named \\textbf{C}lass\n\\textbf{P}rototype-based label noise \\textbf{C}leaner (\\textbf{CPC}). Unlike\nprevious works treating all the classes equally, CPC fully considers loss\ndistribution heterogeneity and applies class-aware modulation to partition the\nclean and noise data. CPC takes advantage of loss distribution modeling and\nintra-class consistency regularization in feature space simultaneously and thus\ncan better distinguish clean and noise labels. We theoretically justify the\neffectiveness of our method by explaining it from the Expectation-Maximization\n(EM) framework. Extensive experiments are conducted on the noisy-label\nbenchmarks CIFAR-10, CIFAR-100, Clothing1M and WebVision. The results show that\nCPC consistently brings about performance improvement across all benchmarks.\nCodes and pre-trained models will be released at\n\\url{https://github.com/hjjpku/CPC.git}.\n","authors":["Jingjia Huang","Yuanqi Chen","Jiashi Feng","Xinglong Wu"],"pdf_url":"https://arxiv.org/pdf/2212.10766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.05723v3","updated":"2022-12-21T04:47:18Z","published":"2022-01-15T01:10:34Z","title":"Learning Temporally and Semantically Consistent Unpaired Video-to-video\n  Translation Through Pseudo-Supervision From Synthetic Optical Flow","summary":"  Unpaired video-to-video translation aims to translate videos between a source\nand a target domain without the need of paired training data, making it more\nfeasible for real applications. Unfortunately, the translated videos generally\nsuffer from temporal and semantic inconsistency. To address this, many existing\nworks adopt spatiotemporal consistency constraints incorporating temporal\ninformation based on motion estimation. However, the inaccuracies in the\nestimation of motion deteriorate the quality of the guidance towards\nspatiotemporal consistency, which leads to unstable translation. In this work,\nwe propose a novel paradigm that regularizes the spatiotemporal consistency by\nsynthesizing motions in input videos with the generated optical flow instead of\nestimating them. Therefore, the synthetic motion can be applied in the\nregularization paradigm to keep motions consistent across domains without the\nrisk of errors in motion estimation. Thereafter, we utilize our unsupervised\nrecycle and unsupervised spatial loss, guided by the pseudo-supervision\nprovided by the synthetic optical flow, to accurately enforce spatiotemporal\nconsistency in both domains. Experiments show that our method is versatile in\nvarious scenarios and achieves state-of-the-art performance in generating\ntemporally and semantically consistent videos. Code is available at:\nhttps://github.com/wangkaihong/Unsup_Recycle_GAN/.\n","authors":["Kaihong Wang","Kumar Akash","Teruhisa Misu"],"pdf_url":"https://arxiv.org/pdf/2201.05723v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14703v3","updated":"2022-12-21T04:47:09Z","published":"2022-11-27T02:40:33Z","title":"Exploring Consistency in Cross-Domain Transformer for Domain Adaptive\n  Semantic Segmentation","summary":"  While transformers have greatly boosted performance in semantic segmentation,\ndomain adaptive transformers are not yet well explored. We identify that the\ndomain gap can cause discrepancies in self-attention. Due to this gap, the\ntransformer attends to spurious regions or pixels, which deteriorates accuracy\non the target domain. We propose to perform adaptation on attention maps with\ncross-domain attention layers that share features between the source and the\ntarget domains. Specifically, we impose consistency between predictions from\ncross-domain attention and self-attention modules to encourage similar\ndistribution in the attention and output of the model across domains, i.e.,\nattention-level and output-level alignment. We also enforce consistency in\nattention maps between different augmented views to further strengthen the\nattention-based alignment. Combining these two components, our method mitigates\nthe discrepancy in attention maps across domains and further boosts the\nperformance of the transformer under unsupervised domain adaptation settings.\nOur model outperforms the existing state-of-the-art baseline model on three\nwidely used benchmarks, including GTAV-to-Cityscapes by 1.3 percent point (pp),\nSynthia-to-Cityscapes by 0.6 pp, and Cityscapes-to-ACDC by 1.1 pp, on average.\nAdditionally, we verify the effectiveness and generalizability of our method\nthrough extensive experiments. Our code will be publicly available.\n","authors":["Kaihong Wang","Donghyun Kim","Rogerio Feris","Kate Saenko","Margrit Betke"],"pdf_url":"https://arxiv.org/pdf/2211.14703v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10746v1","updated":"2022-12-21T03:30:43Z","published":"2022-12-21T03:30:43Z","title":"SLGTformer: An Attention-Based Approach to Sign Language Recognition","summary":"  Sign language is the preferred method of communication of deaf or mute\npeople, but similar to any language, it is difficult to learn and represents a\nsignificant barrier for those who are hard of hearing or unable to speak. A\nperson's entire frontal appearance dictates and conveys specific meaning.\nHowever, this frontal appearance can be quantified as a temporal sequence of\nhuman body pose, leading to Sign Language Recognition through the learning of\nspatiotemporal dynamics of skeleton keypoints. I propose a novel,\nattention-based approach to Sign Language Recognition exclusively built upon\ndecoupled graph and temporal self-attention: the Sign Language Graph Time\nTransformer (SLGTformer). SLGTformer first deconstructs spatiotemporal pose\nsequences separately into spatial graphs and temporal windows. SLGTformer then\nleverages novel Learnable Graph Relative Positional Encodings (LGRPE) to guide\nspatial self-attention with the graph neighborhood context of the human\nskeleton. By modeling the temporal dimension as intra- and inter-window\ndynamics, I introduce Temporal Twin Self-Attention (TTSA) as the combination of\nlocally-grouped temporal attention (LTA) and global sub-sampled temporal\nattention (GSTA). I demonstrate the effectiveness of SLGTformer on the\nWorld-Level American Sign Language (WLASL) dataset, achieving state-of-the-art\nperformance with an ensemble-free approach on the keypoint modality.\n","authors":["Neil Song"],"pdf_url":"https://arxiv.org/pdf/2212.10746v1.pdf","comment":"12 pages, 3 figures, The code is available at\n  \\url{https://github.com/neilsong/slt}"},{"id":"http://arxiv.org/abs/2212.10744v1","updated":"2022-12-21T03:28:30Z","published":"2022-12-21T03:28:30Z","title":"An Audio-Visual Speech Separation Model Inspired by\n  Cortico-Thalamo-Cortical Circuits","summary":"  Audio-visual approaches involving visual inputs have laid the foundation for\nrecent progress in speech separation. However, the optimization of the\nconcurrent usage of auditory and visual inputs is still an active research\narea. Inspired by the cortico-thalamo-cortical circuit, in which the sensory\nprocessing mechanisms of different modalities modulate one another via the\nnon-lemniscal sensory thalamus, we propose a novel cortico-thalamo-cortical\nneural network (CTCNet) for audio-visual speech separation (AVSS). First, the\nCTCNet learns hierarchical auditory and visual representations in a bottom-up\nmanner in separate auditory and visual subnetworks, mimicking the functions of\nthe auditory and visual cortical areas. Then, inspired by the large number of\nconnections between cortical regions and the thalamus, the model fuses the\nauditory and visual information in a thalamic subnetwork through top-down\nconnections. Finally, the model transmits this fused information back to the\nauditory and visual subnetworks, and the above process is repeated several\ntimes. The results of experiments on three speech separation benchmark datasets\nshow that CTCNet remarkably outperforms existing AVSS methods with\nconsiderablely fewer parameters. These results suggest that mimicking the\nanatomical connectome of the mammalian brain has great potential for advancing\nthe development of deep neural networks. Project repo is\nhttps://github.com/JusperLee/CTCNet.\n","authors":["Kai Li","Fenghua Xie","Hang Chen","Kexin Yuan","Xiaolin Hu"],"pdf_url":"https://arxiv.org/pdf/2212.10744v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.10132v2","updated":"2022-12-21T03:24:23Z","published":"2022-12-20T10:01:23Z","title":"Content Adaptive Latents and Decoder for Neural Image Compression","summary":"  In recent years, neural image compression (NIC) algorithms have shown\npowerful coding performance. However, most of them are not adaptive to the\nimage content. Although several content adaptive methods have been proposed by\nupdating the encoder-side components, the adaptability of both latents and the\ndecoder is not well exploited. In this work, we propose a new NIC framework\nthat improves the content adaptability on both latents and the decoder.\nSpecifically, to remove redundancy in the latents, our content adaptive channel\ndropping (CACD) method automatically selects the optimal quality levels for the\nlatents spatially and drops the redundant channels. Additionally, we propose\nthe content adaptive feature transformation (CAFT) method to improve\ndecoder-side content adaptability by extracting the characteristic information\nof the image content, which is then used to transform the features in the\ndecoder side. Experimental results demonstrate that our proposed methods with\nthe encoder-side updating algorithm achieve the state-of-the-art performance.\n","authors":["Guanbo Pan","Guo Lu","Zhihao Hu","Dong Xu"],"pdf_url":"https://arxiv.org/pdf/2212.10132v2.pdf","comment":"V1 is accepted to ECCV 2022. V2 is the improved version"},{"id":"http://arxiv.org/abs/2212.10735v1","updated":"2022-12-21T03:02:18Z","published":"2022-12-21T03:02:18Z","title":"NADBenchmarks -- a compilation of Benchmark Datasets for Machine\n  Learning Tasks related to Natural Disasters","summary":"  Climate change has increased the intensity, frequency, and duration of\nextreme weather events and natural disasters across the world. While the\nincreased data on natural disasters improves the scope of machine learning (ML)\nin this field, progress is relatively slow. One bottleneck is the lack of\nbenchmark datasets that would allow ML researchers to quantify their progress\nagainst a standard metric. The objective of this short paper is to explore the\nstate of benchmark datasets for ML tasks related to natural disasters,\ncategorizing them according to the disaster management cycle. We compile a list\nof existing benchmark datasets introduced in the past five years. We propose a\nweb platform - NADBenchmarks - where researchers can search for benchmark\ndatasets for natural disasters, and we develop a preliminary version of such a\nplatform using our compiled list. This paper is intended to aid researchers in\nfinding benchmark datasets to train their ML models on, and provide general\ndirections for topics where they can contribute new benchmark datasets.\n","authors":["Adiba Mahbub Proma","Md Saiful Islam","Stela Ciko","Raiyan Abdul Baten","Ehsan Hoque"],"pdf_url":"https://arxiv.org/pdf/2212.10735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.07513v2","updated":"2022-12-21T03:01:34Z","published":"2022-04-15T15:16:01Z","title":"Synthesizing Informative Training Samples with GAN","summary":"  Remarkable progress has been achieved in synthesizing photo-realistic images\nwith generative adversarial networks (GANs). Recently, GANs are utilized as the\ntraining sample generator when obtaining or storing real training data is\nexpensive even infeasible. However, traditional GANs generated images are not\nas informative as the real training samples when being used to train deep\nneural networks. In this paper, we propose a novel method to synthesize\nInformative Training samples with GAN (IT-GAN). Specifically, we freeze a\npre-trained GAN model and learn the informative latent vectors that correspond\nto informative training samples. The synthesized images are required to\npreserve information for training deep neural networks rather than visual\nreality or fidelity. Experiments verify that the deep neural networks can learn\nfaster and achieve better performance when being trained with our IT-GAN\ngenerated images. We also show that our method is a promising solution to\ndataset condensation problem.\n","authors":["Bo Zhao","Hakan Bilen"],"pdf_url":"https://arxiv.org/pdf/2204.07513v2.pdf","comment":"NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research,\n  https://openreview.net/forum?id=frAv0jtUMfS"},{"id":"http://arxiv.org/abs/2212.10729v1","updated":"2022-12-21T02:48:15Z","published":"2022-12-21T02:48:15Z","title":"UnICLAM:Contrastive Representation Learning with Adversarial Masking for\n  Unified and Interpretable Medical Vision Question Answering","summary":"  Medical Visual Question Answering (Medical-VQA) aims to answer clinical\nquestions regarding radiology images, assisting doctors with decision-making\noptions. Nevertheless, current Medical-VQA models learn cross-modal\nrepresentations through residing vision and texture encoders in dual separate\nspaces, which lead to indirect semantic alignment. In this paper, we propose\nUnICLAM, a Unified and Interpretable Medical-VQA model through Contrastive\nRepresentation Learning with Adversarial Masking. Specifically, to learn an\naligned image-text representation, we first establish a unified dual-stream\npre-training structure with the gradually soft-parameter sharing strategy.\nTechnically, the proposed strategy learns a constraint for the vision and\ntexture encoders to be close in a same space, which is gradually loosened as\nthe higher number of layers. Moreover, for grasping the semantic\nrepresentation, we extend the unified Adversarial Masking data augmentation\nstrategy to the contrastive representation learning of vision and text in a\nunified manner, alleviating the meaningless of the commonly used random mask.\nConcretely, while the encoder training minimizes the distance between the\noriginal feature and the masking feature, the adversarial masking model keeps\nadversarial learning to conversely maximize the distance. Furthermore, we also\nintuitively take a further exploration of the unified adversarial masking\nstrategy, which improves the potential ante-hoc interpretability with\nremarkable performance and efficiency. Experimental results on VQA-RAD and\nSLAKE public benchmarks demonstrate that UnICLAM outperforms the existing 11\nstate-of-the-art Medical-VQA models. More importantly, we make an additional\ndiscussion about the performance of UnICLAM in diagnosing heart failure,\nverifying that UnICLAM exhibits superior few-shot adaption performance in\npractical disease diagnosis.\n","authors":["Chenlu Zhan","Peng Peng","Hongsen Wang","Tao Chen","Hongwei Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10724v1","updated":"2022-12-21T02:35:46Z","published":"2022-12-21T02:35:46Z","title":"Investigation of Network Architecture for Multimodal Head-and-Neck Tumor\n  Segmentation","summary":"  Inspired by the recent success of Transformers for Natural Language\nProcessing and vision Transformer for Computer Vision, many researchers in the\nmedical imaging community have flocked to Transformer-based networks for\nvarious main stream medical tasks such as classification, segmentation, and\nestimation. In this study, we analyze, two recently published Transformer-based\nnetwork architectures for the task of multimodal head-and-tumor segmentation\nand compare their performance to the de facto standard 3D segmentation network\n- the nnU-Net. Our results showed that modeling long-range dependencies may be\nhelpful in cases where large structures are present and/or large field of view\nis needed. However, for small structures such as head-and-neck tumor, the\nconvolution-based U-Net architecture seemed to perform well, especially when\ntraining dataset is small and computational resource is limited.\n","authors":["Ye Li","Junyu Chen","Se-in Jang","Kuang Gong","Quanzheng Li"],"pdf_url":"https://arxiv.org/pdf/2212.10724v1.pdf","comment":"Accepted for oral presentation by IEEE Medical Imaging Conference\n  2022"},{"id":"http://arxiv.org/abs/2010.12061v3","updated":"2022-12-21T00:30:52Z","published":"2020-10-11T21:31:14Z","title":"Simple Neighborhood Representative Pre-processing Boosts Outlier\n  Detectors","summary":"  Over the decades, traditional outlier detectors have ignored the group-level\nfactor when calculating outlier scores for objects in data by evaluating only\nthe object-level factor, failing to capture the collective outliers. To\nmitigate this issue, we present a method called neighborhood representative\n(NR), which empowers all the existing outlier detectors to efficiently detect\noutliers, including collective outliers, while maintaining their computational\nintegrity. It achieves this by selecting representative objects, scoring these\nobjects, then applies the score of the representative objects to its collective\nobjects. Without altering existing detectors, NR is compatible with existing\ndetectors, while improving performance on real world datasets with +8% (0.72 to\n0.78 AUC) relative to state-of-the-art outlier detectors.\n","authors":["Jiawei Yang","Yu Chen","Sylwan Rahardja"],"pdf_url":"https://arxiv.org/pdf/2010.12061v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10699v1","updated":"2022-12-21T00:20:01Z","published":"2022-12-21T00:20:01Z","title":"PaletteNeRF: Palette-based Appearance Editing of Neural Radiance Fields","summary":"  Recent advances in neural radiance fields have enabled the high-fidelity 3D\nreconstruction of complex scenes for novel view synthesis. However, it remains\nunderexplored how the appearance of such representations can be efficiently\nedited while maintaining photorealism.\n  In this work, we present PaletteNeRF, a novel method for photorealistic\nappearance editing of neural radiance fields (NeRF) based on 3D color\ndecomposition. Our method decomposes the appearance of each 3D point into a\nlinear combination of palette-based bases (i.e., 3D segmentations defined by a\ngroup of NeRF-type functions) that are shared across the scene. While our\npalette-based bases are view-independent, we also predict a view-dependent\nfunction to capture the color residual (e.g., specular shading). During\ntraining, we jointly optimize the basis functions and the color palettes, and\nwe also introduce novel regularizers to encourage the spatial coherence of the\ndecomposition.\n  Our method allows users to efficiently edit the appearance of the 3D scene by\nmodifying the color palettes. We also extend our framework with compressed\nsemantic features for semantic-aware appearance editing. We demonstrate that\nour technique is superior to baseline methods both quantitatively and\nqualitatively for appearance editing of complex real-world scenes.\n","authors":["Zhengfei Kuang","Fujun Luan","Sai Bi","Zhixin Shu","Gordon Wetzstein","Kalyan Sunkavalli"],"pdf_url":"https://arxiv.org/pdf/2212.10699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11418v1","updated":"2022-12-21T23:59:13Z","published":"2022-12-21T23:59:13Z","title":"Cattle Detection Occlusion Problem","summary":"  The management of cattle over a huge area is still a challenging problem in\nthe farming sector. With evolution in technology, Unmanned aerial vehicles\n(UAVs) with consumer level digital cameras are becoming a popular alternative\nto manual animal censuses for livestock estimation since they are less risky\nand expensive.This paper evaluated and compared the cutting-edge object\ndetection algorithms, YOLOv7,RetinaNet with ResNet50 backbone, RetinaNet with\nEfficientNet and mask RCNN. It aims to improve the occlusion problem that is to\ndetect hidden cattle from a huge dataset captured by drones using deep learning\nalgorithms for accurate cattle detection. Experimental results showed YOLOv7\nwas superior with precision of 0.612 when compared to the other two algorithms.\nThe proposed method proved superior to the usual competing algorithms for cow\nface detection, especially in very difficult cases.\n","authors":["Aparna Mendu","Bhavya Sehgal","Vaishnavi Mendu"],"pdf_url":"https://arxiv.org/pdf/2212.11418v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1701.01611 by other authors"},{"id":"http://arxiv.org/abs/2212.11409v1","updated":"2022-12-21T23:28:53Z","published":"2022-12-21T23:28:53Z","title":"DExT: Detector Explanation Toolkit","summary":"  State-of-the-art object detectors are treated as black boxes due to their\nhighly non-linear internal computations. Even with unprecedented advancements\nin detector performance, the inability to explain how their outputs are\ngenerated limits their use in safety-critical applications. Previous work fails\nto produce explanations for both bounding box and classification decisions, and\ngenerally make individual explanations for various detectors. In this paper, we\npropose an open-source Detector Explanation Toolkit (DExT) which implements the\nproposed approach to generate a holistic explanation for all detector decisions\nusing certain gradient-based explanation methods. We suggests various\nmulti-object visualization methods to merge the explanations of multiple\nobjects detected in an image as well as the corresponding detections in a\nsingle image. The quantitative evaluation show that the Single Shot MultiBox\nDetector (SSD) is more faithfully explained compared to other detectors\nregardless of the explanation methods. Both quantitative and human-centric\nevaluations identify that SmoothGrad with Guided Backpropagation (GBP) provides\nmore trustworthy explanations among selected methods across all detectors. We\nexpect that DExT will motivate practitioners to evaluate object detectors from\nthe interpretability perspective by explaining both bounding box and\nclassification decisions.\n","authors":["Deepan Chakravarthi Padmanabhan","Matias Valdenegro-Toro"],"pdf_url":"https://arxiv.org/pdf/2212.11409v1.pdf","comment":"21 pages, with supplementary"},{"id":"http://arxiv.org/abs/2012.02124v2","updated":"2022-12-21T23:10:50Z","published":"2020-12-03T18:00:16Z","title":"Generalized Object Detection on Fisheye Cameras for Autonomous Driving:\n  Dataset, Representations and Baseline","summary":"  Object detection is a comprehensively studied problem in autonomous driving.\nHowever, it has been relatively less explored in the case of fisheye cameras.\nThe standard bounding box fails in fisheye cameras due to the strong radial\ndistortion, particularly in the image's periphery. We explore better\nrepresentations like oriented bounding box, ellipse, and generic polygon for\nobject detection in fisheye images in this work. We use the IoU metric to\ncompare these representations using accurate instance segmentation ground\ntruth. We design a novel curved bounding box model that has optimal properties\nfor fisheye distortion models. We also design a curvature adaptive perimeter\nsampling method for obtaining polygon vertices, improving relative mAP score by\n4.9% compared to uniform sampling. Overall, the proposed polygon model improves\nmIoU relative accuracy by 40.3%. It is the first detailed study on object\ndetection on fisheye cameras for autonomous driving scenarios to the best of\nour knowledge. The dataset comprising of 10,000 images along with all the\nobject representations ground truth will be made public to encourage further\nresearch. We summarize our work in a short video with qualitative results at\nhttps://youtu.be/iLkOzvJpL-A.\n","authors":["Hazem Rashed","Eslam Mohamed","Ganesh Sistu","Varun Ravi Kumar","Ciaran Eising","Ahmad El-Sallab","Senthil Yogamani"],"pdf_url":"https://arxiv.org/pdf/2012.02124v2.pdf","comment":"Camera ready version. Accepted for presentation at Winter Conference\n  on Applications of Computer Vision 2021. Dataset is shared at\n  https://drive.google.com/drive/folders/1bobmY2wlIBozeU5ZgPfYPqVAnpPw4QrM"},{"id":"http://arxiv.org/abs/2204.03083v2","updated":"2022-12-21T23:07:27Z","published":"2022-04-06T20:51:40Z","title":"Audio-Visual Person-of-Interest DeepFake Detection","summary":"  Face manipulation technology is advancing very rapidly, and new methods are\nbeing proposed day by day. The aim of this work is to propose a deepfake\ndetector that can cope with the wide variety of manipulation methods and\nscenarios encountered in the real world. Our key insight is that each person\nhas specific biometric characteristics that a synthetic generator cannot likely\nreproduce. Accordingly, we extract high-level audio-visual biometric features\nwhich characterize the identity of a person, and use them to create a\nperson-of-interest (POI) deepfake detector. We leverage a contrastive learning\nparadigm to learn the moving-face and audio segment embeddings that are most\ndiscriminative for each identity. As a result, when the video and/or audio of a\nperson is manipulated, its representation in the embedding space becomes\ninconsistent with the real identity, allowing reliable detection. Training is\ncarried out exclusively on real talking-face videos, thus the detector does not\ndepend on any specific manipulation method and yields the highest\ngeneralization ability. In addition, our method can detect both single-modality\n(audio-only, video-only) and multi-modality (audio-video) attacks, and is\nrobust to low-quality or corrupted videos by building only on high-level\nsemantic features. Experiments on a wide variety of datasets confirm that our\nmethod ensures a SOTA performance, with an average improvement in terms of AUC\nof around 3%, 10%, and 4% for high-quality, low quality, and attacked videos,\nrespectively. https://github.com/grip-unina/poi-forensics\n","authors":["Davide Cozzolino","Matthias Nießner","Luisa Verdoliva"],"pdf_url":"https://arxiv.org/pdf/2204.03083v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.12763v5","updated":"2022-12-21T22:50:02Z","published":"2021-05-26T18:02:59Z","title":"An Online Learning System for Wireless Charging Alignment using\n  Surround-view Fisheye Cameras","summary":"  Electric Vehicles are increasingly common, with inductive chargepads being\nconsidered a convenient and efficient means of charging electric vehicles.\nHowever, drivers are typically poor at aligning the vehicle to the necessary\naccuracy for efficient inductive charging, making the automated alignment of\nthe two charging plates desirable. In parallel to the electrification of the\nvehicular fleet, automated parking systems that make use of surround-view\ncamera systems are becoming increasingly popular. In this work, we propose a\nsystem based on the surround-view camera architecture to detect, localize, and\nautomatically align the vehicle with the inductive chargepad. The visual design\nof the chargepads is not standardized and not necessarily known beforehand.\nTherefore, a system that relies on offline training will fail in some\nsituations. Thus, we propose a self-supervised online learning method that\nleverages the driver's actions when manually aligning the vehicle with the\nchargepad and combine it with weak supervision from semantic segmentation and\ndepth to learn a classifier to auto-annotate the chargepad in the video for\nfurther training. In this way, when faced with a previously unseen chargepad,\nthe driver needs only manually align the vehicle a single time. As the\nchargepad is flat on the ground, it is not easy to detect it from a distance.\nThus, we propose using a Visual SLAM pipeline to learn landmarks relative to\nthe chargepad to enable alignment from a greater range. We demonstrate the\nworking system on an automated vehicle as illustrated in the video at\nhttps://youtu.be/_cLCmkW4UYo. To encourage further research, we will share a\nchargepad dataset used in this work.\n","authors":["Ashok Dahal","Varun Ravi Kumar","Senthil Yogamani","Ciaran Eising"],"pdf_url":"https://arxiv.org/pdf/2105.12763v5.pdf","comment":"Accepted for publication at IEEE Transactions on Intelligent\n  Transportation Systems. Chargepad Dataset is shared at\n  https://drive.google.com/drive/folders/1KeLFIqOnhU2CGsD0vbiN9UqKmBSyHERd"},{"id":"http://arxiv.org/abs/2212.11377v1","updated":"2022-12-21T21:36:52Z","published":"2022-12-21T21:36:52Z","title":"ReVISE: Self-Supervised Speech Resynthesis with Visual Input for\n  Universal and Generalized Speech Enhancement","summary":"  Prior works on improving speech quality with visual input typically study\neach type of auditory distortion separately (e.g., separation, inpainting,\nvideo-to-speech) and present tailored algorithms. This paper proposes to unify\nthese subjects and study Generalized Speech Enhancement, where the goal is not\nto reconstruct the exact reference clean signal, but to focus on improving\ncertain aspects of speech. In particular, this paper concerns intelligibility,\nquality, and video synchronization. We cast the problem as audio-visual speech\nresynthesis, which is composed of two steps: pseudo audio-visual speech\nrecognition (P-AVSR) and pseudo text-to-speech synthesis (P-TTS). P-AVSR and\nP-TTS are connected by discrete units derived from a self-supervised speech\nmodel. Moreover, we utilize self-supervised audio-visual speech model to\ninitialize P-AVSR. The proposed model is coined ReVISE. ReVISE is the first\nhigh-quality model for in-the-wild video-to-speech synthesis and achieves\nsuperior performance on all LRS3 audio-visual enhancement tasks with a single\nmodel. To demonstrates its applicability in the real world, ReVISE is also\nevaluated on EasyCom, an audio-visual benchmark collected under challenging\nacoustic conditions with only 1.6 hours of training data. Similarly, ReVISE\ngreatly suppresses noise and improves quality. Project page:\nhttps://wnhsu.github.io/ReVISE.\n","authors":["Wei-Ning Hsu","Tal Remez","Bowen Shi","Jacob Donley","Yossi Adi"],"pdf_url":"https://arxiv.org/pdf/2212.11377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11376v1","updated":"2022-12-21T21:34:00Z","published":"2022-12-21T21:34:00Z","title":"Artistic Arbitrary Style Transfer","summary":"  Arbitrary Style Transfer is a technique used to produce a new image from two\nimages: a content image, and a style image. The newly produced image is unseen\nand is generated from the algorithm itself. Balancing the structure and style\ncomponents has been the major challenge that other state-of-the-art algorithms\nhave tried to solve. Despite all the efforts, it's still a major challenge to\napply the artistic style that was originally created on top of the structure of\nthe content image while maintaining consistency. In this work, we solved these\nproblems by using a Deep Learning approach using Convolutional Neural Networks.\nOur implementation will first extract foreground from the background using the\npre-trained Detectron 2 model from the content image, and then apply the\nArbitrary Style Transfer technique that is used in SANet. Once we have the two\nstyled images, we will stitch the two chunks of images after the process of\nstyle transfer for the complete end piece.\n","authors":["Weiting Li","Rahul Vyas","Ramya Sree Penta"],"pdf_url":"https://arxiv.org/pdf/2212.11376v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.11375v1","updated":"2022-12-21T21:32:36Z","published":"2022-12-21T21:32:36Z","title":"Semi-supervised GAN for Bladder Tissue Classification in Multi-Domain\n  Endoscopic Images","summary":"  Objective: Accurate visual classification of bladder tissue during\nTrans-Urethral Resection of Bladder Tumor (TURBT) procedures is essential to\nimprove early cancer diagnosis and treatment. During TURBT interventions, White\nLight Imaging (WLI) and Narrow Band Imaging (NBI) techniques are used for\nlesion detection. Each imaging technique provides diverse visual information\nthat allows clinicians to identify and classify cancerous lesions. Computer\nvision methods that use both imaging techniques could improve endoscopic\ndiagnosis. We address the challenge of tissue classification when annotations\nare available only in one domain, in our case WLI, and the endoscopic images\ncorrespond to an unpaired dataset, i.e. there is no exact equivalent for every\nimage in both NBI and WLI domains. Method: We propose a semi-surprised\nGenerative Adversarial Network (GAN)-based method composed of three main\ncomponents: a teacher network trained on the labeled WLI data; a\ncycle-consistency GAN to perform unpaired image-to-image translation, and a\nmulti-input student network. To ensure the quality of the synthetic images\ngenerated by the proposed GAN we perform a detailed quantitative, and\nqualitative analysis with the help of specialists. Conclusion: The overall\naverage classification accuracy, precision, and recall obtained with the\nproposed method for tissue classification are 0.90, 0.88, and 0.89\nrespectively, while the same metrics obtained in the unlabeled domain (NBI) are\n0.92, 0.64, and 0.94 respectively. The quality of the generated images is\nreliable enough to deceive specialists. Significance: This study shows the\npotential of using semi-supervised GAN-based classification to improve bladder\ntissue classification when annotations are limited in multi-domain data.\n","authors":["Jorge F. Lazo","Benoit Rosa","Michele Catellani","Matteo Fontana","Francesco A. Mistretta","Gennaro Musi","Ottavio de Cobelli","Michel de Mathelin","Elena De Momi"],"pdf_url":"https://arxiv.org/pdf/2212.11375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11369v1","updated":"2022-12-21T21:14:35Z","published":"2022-12-21T21:14:35Z","title":"MM811 Project Report: Cloud Detection and Removal in Satellite Images","summary":"  For satellite images, the presence of clouds presents a problem as clouds\nobscure more than half to two-thirds of the ground information. This problem\ncauses many issues for reliability in a noise-free environment to communicate\ndata and other applications that need seamless monitoring. Removing the clouds\nfrom the images while keeping the background pixels intact can help address the\nmentioned issues. Recently, deep learning methods have become popular for\nresearching cloud removal by demonstrating promising results, among which\nGenerative Adversarial Networks (GAN) have shown considerably better\nperformance. In this project, we aim to address cloud removal from satellite\nimages using AttentionGAN and then compare our results by reproducing the\nresults obtained using traditional GANs and auto-encoders. We use RICE dataset.\nThe outcome of this project can be used to develop applications that require\ncloud-free satellite images. Moreover, our results could be helpful for making\nfurther research improvements.\n","authors":["Dale Chen-Song","Erfan Khalaji","Vaishali Rani"],"pdf_url":"https://arxiv.org/pdf/2212.11369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11363v1","updated":"2022-12-21T21:05:16Z","published":"2022-12-21T21:05:16Z","title":"Lightweight Monocular Depth Estimation","summary":"  Monocular depth estimation can play an important role in addressing the issue\nof deriving scene geometry from 2D images. It has been used in a variety of\nindustries, including robots, self-driving cars, scene comprehension, 3D\nreconstructions, and others. The goal of our method is to create a lightweight\nmachine-learning model in order to predict the depth value of each pixel given\nonly a single RGB image as input with the Unet structure of the image\nsegmentation network. We use the NYU Depth V2 dataset to test the structure and\ncompare the result with other methods. The proposed method achieves relatively\nhigh accuracy and low rootmean-square error.\n","authors":["Ruilin Ma","Shiyao Chen","Qin Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11345v1","updated":"2022-12-21T20:34:33Z","published":"2022-12-21T20:34:33Z","title":"Knowledge-driven Scene Priors for Semantic Audio-Visual Embodied\n  Navigation","summary":"  Generalisation to unseen contexts remains a challenge for embodied navigation\nagents. In the context of semantic audio-visual navigation (SAVi) tasks, the\nnotion of generalisation should include both generalising to unseen indoor\nvisual scenes as well as generalising to unheard sounding objects. However,\nprevious SAVi task definitions do not include evaluation conditions on truly\nnovel sounding objects, resorting instead to evaluating agents on unheard sound\nclips of known objects; meanwhile, previous SAVi methods do not include\nexplicit mechanisms for incorporating domain knowledge about object and region\nsemantics. These weaknesses limit the development and assessment of models'\nabilities to generalise their learned experience. In this work, we introduce\nthe use of knowledge-driven scene priors in the semantic audio-visual embodied\nnavigation task: we combine semantic information from our novel knowledge graph\nthat encodes object-region relations, spatial knowledge from dual Graph Encoder\nNetworks, and background knowledge from a series of pre-training tasks -- all\nwithin a reinforcement learning framework for audio-visual navigation. We also\ndefine a new audio-visual navigation sub-task, where agents are evaluated on\nnovel sounding objects, as opposed to unheard clips of known objects. We show\nimprovements over strong baselines in generalisation to unseen regions and\nnovel sounding objects, within the Habitat-Matterport3D simulation environment,\nunder the SoundSpaces task.\n","authors":["Gyan Tatiya","Jonathan Francis","Luca Bondi","Ingrid Navarro","Eric Nyberg","Jivko Sinapov","Jean Oh"],"pdf_url":"https://arxiv.org/pdf/2212.11345v1.pdf","comment":"19 pages, 8 figures, 9 tables"},{"id":"http://arxiv.org/abs/2212.11344v1","updated":"2022-12-21T20:31:39Z","published":"2022-12-21T20:31:39Z","title":"Advanced Baseline for 3D Human Pose Estimation: A Two-Stage Approach","summary":"  Human pose estimation has been widely applied in various industries. While\nrecent decades have witnessed the introduction of many advanced two-dimensional\n(2D) human pose estimation solutions, three-dimensional (3D) human pose\nestimation is still an active research field in computer vision. Generally\nspeaking, 3D human pose estimation methods can be divided into two categories:\nsingle-stage and two-stage. In this paper, we focused on the 2D-to-3D lifting\nprocess in the two-stage methods and proposed a more advanced baseline model\nfor 3D human pose estimation, based on the existing solutions. Our improvements\ninclude optimization of machine learning models and multiple parameters, as\nwell as introduction of a weighted loss to the training model. Finally, we used\nthe Human3.6M benchmark to test the final performance and it did produce\nsatisfactory results.\n","authors":["Zichen Gui","Jungang Luo"],"pdf_url":"https://arxiv.org/pdf/2212.11344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.09378v2","updated":"2022-12-21T19:09:26Z","published":"2021-08-20T21:21:26Z","title":"A Multiple-View Geometric Model for Specularity Prediction on General\n  Curved Surfaces","summary":"  Specularity prediction is essential to many computer vision applications,\ngiving important visual cues usable in Augmented Reality (AR), Simultaneous\nLocalisation and Mapping (SLAM), 3D reconstruction and material modeling.\nHowever, it is a challenging task requiring numerous information from the scene\nincluding the camera pose, the geometry of the scene, the light sources and the\nmaterial properties. Our previous work addressed this task by creating an\nexplicit model using an ellipsoid whose projection fits the specularity image\ncontours for a given camera pose. These ellipsoid-based approaches belong to a\nfamily of models called JOint-LIght MAterial Specularity (JOLIMAS), which we\nhave gradually improved by removing assumptions on the scene geometry. However,\nour most recent approach is still limited to uniformly curved surfaces. This\npaper generalises JOLIMAS to any surface geometry while improving the quality\nof specularity prediction, without sacrificing computation performances. The\nproposed method establishes a link between surface curvature and specularity\nshape in order to lift the geometric assumptions made in previous work.\nContrary to previous work, our new model is built from a physics-based local\nillumination model namely Torrance-Sparrow, providing an improved\nreconstruction. Specularity prediction using our new model is tested against\nthe most recent JOLIMAS version on both synthetic and real sequences with\nobjects of various general shapes. Our method outperforms previous approaches\nin specularity prediction, including the real-time setup, as shown in the\nsupplementary videos.\n","authors":["Alexandre Morgand","Mohamed Tamaazousti","Adrien Bartoli"],"pdf_url":"https://arxiv.org/pdf/2108.09378v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12055v2","updated":"2022-12-21T12:52:12Z","published":"2022-10-21T15:49:16Z","title":"Query Semantic Reconstruction for Background in Few-Shot Segmentation","summary":"  Few-shot segmentation (FSS) aims to segment unseen classes using a few\nannotated samples. Typically, a prototype representing the foreground class is\nextracted from annotated support image(s) and is matched to features\nrepresenting each pixel in the query image. However, models learnt in this way\nare insufficiently discriminatory, and often produce false positives:\nmisclassifying background pixels as foreground. Some FSS methods try to address\nthis issue by using the background in the support image(s) to help identify the\nbackground in the query image. However, the backgrounds of theses images is\noften quite distinct, and hence, the support image background information is\nuninformative. This article proposes a method, QSR, that extracts the\nbackground from the query image itself, and as a result is better able to\ndiscriminate between foreground and background features in the query image.\nThis is achieved by modifying the training process to associate prototypes with\nclass labels including known classes from the training data and latent classes\nrepresenting unknown background objects. This class information is then used to\nextract a background prototype from the query image. To successfully associate\nprototypes with class labels and extract a background prototype that is capable\nof predicting a mask for the background regions of the image, the machinery for\nextracting and using foreground prototypes is induced to become more\ndiscriminative between different classes. Experiments for both 1-shot and\n5-shot FSS on both the PASCAL-5i and COCO-20i datasets demonstrate that the\nproposed method results in a significant improvement in performance for the\nbaseline methods it is applied to. As QSR operates only during training, these\nimproved results are produced with no extra computational complexity during\ntesting.\n","authors":["Haoyan Guan","Michael Spratling"],"pdf_url":"https://arxiv.org/pdf/2210.12055v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11677v1","updated":"2022-12-21T07:54:02Z","published":"2022-12-21T07:54:02Z","title":"DuAT: Dual-Aggregation Transformer Network for Medical Image\n  Segmentation","summary":"  Transformer-based models have been widely demonstrated to be successful in\ncomputer vision tasks by modelling long-range dependencies and capturing global\nrepresentations. However, they are often dominated by features of large\npatterns leading to the loss of local details (e.g., boundaries and small\nobjects), which are critical in medical image segmentation. To alleviate this\nproblem, we propose a Dual-Aggregation Transformer Network called DuAT, which\nis characterized by two innovative designs, namely, the Global-to-Local Spatial\nAggregation (GLSA) and Selective Boundary Aggregation (SBA) modules. The GLSA\nhas the ability to aggregate and represent both global and local spatial\nfeatures, which are beneficial for locating large and small objects,\nrespectively. The SBA module is used to aggregate the boundary characteristic\nfrom low-level features and semantic information from high-level features for\nbetter preserving boundary details and locating the re-calibration objects.\nExtensive experiments in six benchmark datasets demonstrate that our proposed\nmodel outperforms state-of-the-art methods in the segmentation of skin lesion\nimages, and polyps in colonoscopy images. In addition, our approach is more\nrobust than existing methods in various challenging situations such as small\nobject segmentation and ambiguous object boundaries.\n","authors":["Feilong Tang","Qiming Huang","Jinfeng Wang","Xianxu Hou","Jionglong Su","Jingxin Liu"],"pdf_url":"https://arxiv.org/pdf/2212.11677v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.05035v2","updated":"2022-12-21T18:12:28Z","published":"2022-12-05T06:25:24Z","title":"COVID-19 Activity Risk Calculator as a Gamified Public Health\n  Intervention Tool","summary":"  Public health intervention techniques have been highly significant in\nreducing the negative impact of several epidemics and pandemics. Among all of\nthe wide-spread diseases, one of the most dangerous one has been severe acute\nrespiratory syndrome coronavirus 2 (SARS-CoV-2) or Coronavirus disease 2019\n(COVID-19). The impact of the virus has been observed in over 200 countries\nleading to hospitalizations and deaths of millions of people. Currently\nexisting COVID-19 risk estimation tools provided to the general public have\nbeen highly variable during the pandemic due to its dependency on rapidly\nevolving factors such as community transmission levels and variants. There has\nalso been confusion surrounding certain personal protective strategies such as\nrisk reduction by mask-wearing and vaccination. In order to create a simplified\neasy-to-use tool for estimating different individual risks associated with\ncarrying out daily-life activity, we developed COVID-19 Activity Risk\nCalculator (CovARC). CovARC serves as a gamified public health intervention as\nusers can \"play with\" how different risks associated with COVID-19 would change\ndepending on several different factors when carrying out a daily routine\nactivity. Empowering the public to make informed, data-driven decisions about\nsafely engaging in activities may help to reduce COVID- 19 levels in the\ncommunity. In this study, we demonstrate a streamlined, scalable and accurate\nCOVID-19 risk calculation system. Our study also showcases quantitatively, the\nincreased impact of interventions such as vaccination and mask-wearing when\ncases are higher, which could prove as a validity to inform and support policy\ndecisions around mask mandate case thresholds and other non-pharmaceutical\ninterventions.\n","authors":["Shreyasvi Natraj","Malhar Bhide","Nathan Yap","Meng Liu","Agrima Seth","Christin Glorioso"],"pdf_url":"https://arxiv.org/pdf/2212.05035v2.pdf","comment":"11 pages, 6 figures (main paper + 1 figure supplementary section.)"},{"id":"http://arxiv.org/abs/2112.09727v2","updated":"2022-12-21T16:53:43Z","published":"2021-12-17T19:22:37Z","title":"Rank4Class: A Ranking Formulation for Multiclass Classification","summary":"  Multiclass classification (MCC) is a fundamental machine learning problem of\nclassifying each instance into one of a predefined set of classes. In the deep\nlearning era, extensive efforts have been spent on developing more powerful\nneural embedding models to better represent the instance for improving MCC\nperformance. In this paper, we do not aim to propose new neural models for\ninstance representation learning, but to show that it is promising to boost MCC\nperformance with a novel formulation through the lens of ranking. In\nparticular, by viewing MCC as to rank classes for an instance, we first argue\nthat ranking metrics, such as Normalized Discounted Cumulative Gain, can be\nmore informative than the commonly used Top-$K$ metrics. We further demonstrate\nthat the dominant neural MCC recipe can be transformed to a neural ranking\nframework. Based on such generalization, we show that it is intuitive to\nleverage advanced techniques from the learning to rank literature to improve\nthe MCC performance out of the box. Extensive empirical results on both text\nand image classification tasks with diverse datasets and backbone neural models\nshow the value of our proposed framework.\n","authors":["Nan Wang","Zhen Qin","Le Yan","Honglei Zhuang","Xuanhui Wang","Michael Bendersky","Marc Najork"],"pdf_url":"https://arxiv.org/pdf/2112.09727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11080v1","updated":"2022-12-21T15:27:52Z","published":"2022-12-21T15:27:52Z","title":"Is it worth it? An experimental comparison of six deep- and classical\n  machine learning methods for unsupervised anomaly detection in time series","summary":"  The detection of anomalies in time series data is crucial in a wide range of\napplications, such as system monitoring, health care or cyber security. While\nthe vast number of available methods makes selecting the right method for a\ncertain application hard enough, different methods have different strengths,\ne.g. regarding the type of anomalies they are able to find. In this work, we\ncompare six unsupervised anomaly detection methods with different complexities\nto answer the questions: Are the more complex methods usually performing\nbetter? And are there specific anomaly types that those method are tailored to?\nThe comparison is done on the UCR anomaly archive, a recent benchmark dataset\nfor anomaly detection. We compare the six methods by analyzing the experimental\nresults on a dataset- and anomaly type level after tuning the necessary\nhyperparameter for each method. Additionally we examine the ability of\nindividual methods to incorporate prior knowledge about the anomalies and\nanalyse the differences of point-wise and sequence wise features. We show with\nbroad experiments, that the classical machine learning methods show a superior\nperformance compared to the deep learning methods across a wide range of\nanomaly types.\n","authors":["Ferdinand Rewicki","Joachim Denzler","Julia Niebling"],"pdf_url":"https://arxiv.org/pdf/2212.11080v1.pdf","comment":"15 Pages, The repository to reproduce the results is available at\n  https://gitlab.com/dlr-dw/is-it-worth-it-benchmark"},{"id":"http://arxiv.org/abs/2210.10555v2","updated":"2022-12-21T12:39:41Z","published":"2022-10-19T13:56:49Z","title":"Data-Augmented Counterfactual Learning for Bundle Recommendation","summary":"  Bundle Recommendation (BR) aims at recommending bundled items on online\ncontent or e-commerce platform, such as song lists on a music platform or book\nlists on a reading website. Several graph based models have achieved\nstate-of-the-art performance on BR task. But their performance is still\nsub-optimal, since the data sparsity problem tends to be more severe in real\nbundle recommendation scenarios, which limits graph-based models from more\nsufficient learning. In this paper, we propose a novel graph learning paradigm\ncalled Counterfactual Learning for Bundle Recommendation (CLBR) to mitigate the\nimpact of data sparsity problem and improve bundle recommendation. Our paradigm\nconsists of two main parts: counterfactual data augmentation and counterfactual\nconstraint. The main idea of our paradigm lies in answering the counterfactual\nquestions: \"What would a user interact with if his/her interaction history\nchanges?\" \"What would a user interact with if the bundle-item affiliation\nrelations change?\" In counterfactual data augmentation, we design a heuristic\nsampler to generate counterfactual graph views for graph-based models, which\nhas better noise controlling than the stochastic sampler. We further propose\ncounterfactual loss to constrain model learning for mitigating the effects of\nresidual noise in augmented data and achieving more sufficient model\noptimization. Further theoretical analysis demonstrates the rationality of our\ndesign. Extensive experiments of BR models applied with our paradigm on two\nreal-world datasets are conducted to verify the effectiveness of the paradigm.\n","authors":["Shixuan Zhu","Qi Shen","Yiming Zhang","Zhenwei Dong","Zhihua Wei"],"pdf_url":"https://arxiv.org/pdf/2210.10555v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2212.10960v1","updated":"2022-12-21T12:03:12Z","published":"2022-12-21T12:03:12Z","title":"The Ties that matter: From the perspective of Similarity Measure in\n  Online Social Networks","summary":"  Online Social Networks have embarked on the importance of connection strength\nmeasures which has a broad array of applications such as, analyzing diffusion\nbehaviors, community detection, link predictions, recommender systems. Though\nthere are some existing connection strength measures, the density that a\nconnection shares with it's neighbors and the directionality aspect has not\nreceived much attention. In this paper, we have proposed an asymmetric edge\nsimilarity measure namely, Neighborhood Density-based Edge Similarity (NDES)\nwhich provides a fundamental support to derive the strength of connection. The\ntime complexity of NDES is $O(nk^2)$. An application of NDES for community\ndetection in social network is shown. We have considered a similarity based\ncommunity detection technique and substituted its similarity measure with NDES.\nThe performance of NDES is evaluated on several small real-world datasets in\nterms of the effectiveness in detecting communities and compared with three\nwidely used similarity measures. Empirical results show NDES enables detecting\ncomparatively better communities both in terms of accuracy and quality.\n","authors":["Soumita Das","Anupam Biswas"],"pdf_url":"https://arxiv.org/pdf/2212.10960v1.pdf","comment":"To be published in MINDS-2021"},{"id":"http://arxiv.org/abs/2212.10937v1","updated":"2022-12-21T11:25:07Z","published":"2022-12-21T11:25:07Z","title":"DCC: A Cascade based Approach to Detect Communities in Social Networks","summary":"  Community detection in Social Networks is associated with finding and\ngrouping the most similar nodes inherent in the network. These similar nodes\nare identified by computing tie strength. Stronger ties indicates higher\nproximity shared by connected node pairs. This work is motivated by\nGranovetter's argument that suggests that strong ties lies within densely\nconnected nodes and the theory that community cores in real-world networks are\ndensely connected. In this paper, we have introduced a novel method called\n\\emph{Disjoint Community detection using Cascades (DCC)} which demonstrates the\neffectiveness of a new local density based tie strength measure on detecting\ncommunities. Here, tie strength is utilized to decide the paths followed for\npropagating information. The idea is to crawl through the tuple information of\ncascades towards the community core guided by increasing tie strength.\nConsidering the cascade generation step, a novel preferential membership method\nhas been developed to assign community labels to unassigned nodes. The efficacy\nof $DCC$ has been analyzed based on quality and accuracy on several real-world\ndatasets and baseline community detection algorithms.\n","authors":["Soumita Das","Anupam Biswas","Akrati Saxena"],"pdf_url":"https://arxiv.org/pdf/2212.10937v1.pdf","comment":"To be published in CHSN-2022"},{"id":"http://arxiv.org/abs/2212.10901v1","updated":"2022-12-21T10:20:54Z","published":"2022-12-21T10:20:54Z","title":"RECAP: Retrieval Augmented Music Captioner","summary":"  With the prevalence of stream media platforms serving music search and\nrecommendation, interpreting music by understanding audio and lyrics\ninteractively has become an important and challenging task. However, many\nprevious works focus on refining individual components of encoder-decoder\narchitecture mapping music to caption tokens, ignoring the potential usage of\naudio and lyrics correspondence. In this paper, we propose to explicitly learn\nthe multi-modal alignment with retrieval augmentation by contrastive learning.\nBy learning audio-lyrics correspondence, the model is guided to learn better\ncross-modal attention weights, thus generating high-quality caption words. We\nprovide both theoretical and empirical results that demonstrate the advantage\nof the proposed method.\n","authors":["Zihao He","Weituo Hao","Xuchen Song"],"pdf_url":"https://arxiv.org/pdf/2212.10901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11127v3","updated":"2022-12-21T09:15:56Z","published":"2022-05-23T08:34:25Z","title":"Fairness in Recommender Systems: Research Landscape and Future\n  Directions","summary":"  Recommender systems can strongly influence which information we see online,\ne.g., on social media, and thus impact our beliefs, decisions, and actions. At\nthe same time, these systems can create substantial business value for\ndifferent stakeholders. Given the growing potential impact of such AI-based\nsystems on individuals, organizations, and society, questions of fairness have\ngained increased attention in recent years. However, research on fairness in\nrecommender systems is still a developing area. In this survey, we first review\nthe fundamental concepts and notions of fairness that were put forward in the\narea in the recent past.\n  Afterward, through a review of more than 150 scholarly publications, we\npresent an overview of how research in this field is currently operationalized,\ne.g., in terms of general research methodology, fairness measures, and\nalgorithmic approaches. Overall, our analysis of recent works points to\nspecific research gaps. In particular, we find that in many research works in\ncomputer science, very abstract problem operationalizations are prevalent, and\nquestions of the underlying normative claims and what represents a fair\nrecommendation in the context of a given application are often not discussed in\ndepth. These observations call for more interdisciplinary research to address\nfairness in recommendation in a more comprehensive and impactful manner.\n","authors":["Yashar Deldjoo","Dietmar Jannach","Alejandro Bellogin","Alessandro Difonzo","Dario Zanzonelli"],"pdf_url":"https://arxiv.org/pdf/2205.11127v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10805v1","updated":"2022-12-21T06:56:14Z","published":"2022-12-21T06:56:14Z","title":"Beyond Information Exchange: An Approach to Deploy Network Properties\n  for Information Diffusion","summary":"  Information diffusion in Online Social Networks is a new and crucial problem\nin social network analysis field and requires significant research attention.\nEfficient diffusion of information are of critical importance in diverse\nsituations such as; pandemic prevention, advertising, marketing etc. Although\nseveral mathematical models have been developed till date, but previous works\nlacked systematic analysis and exploration of the influence of neighborhood for\ninformation diffusion. In this paper, we have proposed Common Neighborhood\nStrategy (CNS) algorithm for information diffusion that demonstrates the role\nof common neighborhood in information propagation throughout the network. The\nperformance of CNS algorithm is evaluated on several real-world datasets in\nterms of diffusion speed and diffusion outspread and compared with several\nwidely used information diffusion models. Empirical results show CNS algorithm\nenables better information diffusion both in terms of diffusion speed and\ndiffusion outspread.\n","authors":["Soumita Das","Anupam Biswas","Ravi Kishore Devarapalli"],"pdf_url":"https://arxiv.org/pdf/2212.10805v1.pdf","comment":"To be published in BigDML 2021"},{"id":"http://arxiv.org/abs/2212.10786v1","updated":"2022-12-21T06:00:22Z","published":"2022-12-21T06:00:22Z","title":"Multi-hop Evidence Retrieval for Cross-document Relation Extraction","summary":"  Relation Extraction (RE) has been extended to cross-document scenarios\nbecause many relations are not simply described in a single document. This\ninevitably brings the challenge of efficient open-space evidence retrieval to\nsupport the inference of cross-document relations, along with the challenge of\nmulti-hop reasoning on top of entities and evidence scattered in an open set of\ndocuments. To combat these challenges, we propose Mr.CoD, a multi-hop evidence\nretrieval method based on evidence path mining and ranking with adapted dense\nretrievers. We explore multiple variants of retrievers to show evidence\nretrieval is an essential part in cross-document RE. Experiments on CodRED show\nthat evidence retrieval with Mr.Cod effectively acquires cross-document\nevidence that essentially supports open-setting cross-document RE.\nAdditionally, we show that Mr.CoD facilitates evidence retrieval and boosts\nend-to-end RE performance with effective multi-hop reasoning in both closed and\nopen settings of RE.\n","authors":["Keming Lu","I-Hung Hsu","Wenxuan Zhou","Mingyu Derek Ma","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10786v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.10764v1","updated":"2022-12-21T04:49:55Z","published":"2022-12-21T04:49:55Z","title":"Learning List-Level Domain-Invariant Representations for Ranking","summary":"  Domain adaptation aims to transfer the knowledge acquired by models trained\non (data-rich) source domains to (low-resource) target domains, for which a\npopular method is invariant representation learning. While they have been\nstudied extensively for classification and regression problems, how they apply\nto ranking problems, where the data and metrics have a list structure, is not\nwell understood. Theoretically, we establish a domain adaptation generalization\nbound for ranking under listwise metrics such as MRR and NDCG. The bound\nsuggests an adaptation method via learning list-level domain-invariant feature\nrepresentations, whose benefits are empirically demonstrated by unsupervised\ndomain adaptation experiments on real-world ranking tasks, including passage\nreranking. A key message is that for domain adaptation, the representations\nshould be analyzed at the same level at which the metric is computed, as we\nshow that learning invariant representations at the list level is most\neffective for adaptation on ranking problems.\n","authors":["Ruicheng Xian","Honglei Zhuang","Zhen Qin","Hamed Zamani","Jing Lu","Ji Ma","Kai Hui","Han Zhao","Xuanhui Wang","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2212.10764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10762v1","updated":"2022-12-21T04:49:21Z","published":"2022-12-21T04:49:21Z","title":"AgAsk: An Agent to Help Answer Farmer's Questions From Scientific\n  Documents","summary":"  Decisions in agriculture are increasingly data-driven; however, valuable\nagricultural knowledge is often locked away in free-text reports, manuals and\njournal articles. Specialised search systems are needed that can mine\nagricultural information to provide relevant answers to users' questions. This\npaper presents AgAsk -- an agent able to answer natural language agriculture\nquestions by mining scientific documents.\n  We carefully survey and analyse farmers' information needs. On the basis of\nthese needs we release an information retrieval test collection comprising real\nquestions, a large collection of scientific documents split in passages, and\nground truth relevance assessments indicating which passages are relevant to\neach question.\n  We implement and evaluate a number of information retrieval models to answer\nfarmers questions, including two state-of-the-art neural ranking models. We\nshow that neural rankers are highly effective at matching passages to questions\nin this context.\n  Finally, we propose a deployment architecture for AgAsk that includes a\nclient based on the Telegram messaging platform and retrieval model deployed on\ncommodity hardware.\n  The test collection we provide is intended to stimulate more research in\nmethods to match natural language to answers in scientific documents. While the\nretrieval models were evaluated in the agriculture domain, they are\ngeneralisable and of interest to others working on similar problems.\n  The test collection is available at:\n\\url{https://github.com/ielab/agvaluate}.\n","authors":["Bevan Koopman","Ahmed Mourad","Hang Li","Anton van der Vegt","Shengyao Zhuang","Simon Gibson","Yash Dang","David Lawrence","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2212.10762v1.pdf","comment":"17 pages, submitted to IJDL"},{"id":"http://arxiv.org/abs/2205.12680v2","updated":"2022-12-21T03:43:14Z","published":"2022-05-25T11:39:42Z","title":"Optimizing Test-Time Query Representations for Dense Retrieval","summary":"  Recent developments of dense retrieval rely on quality representations of\nqueries and contexts coming from pre-trained query and context encoders. In\nthis paper, we introduce TouR (test-time optimization of query\nrepresentations), which further optimizes instance-level query representations\nguided by signals from test-time retrieval results. We leverage a cross-encoder\nre-ranker to provide fine-grained pseudo labels over retrieval results and\niteratively optimize query representations with the gradient descent method.\nOur theoretical analysis reveals that TouR can be viewed as a generalization of\nthe classical Rocchio's algorithm for pseudo relevance feedback, and we present\ntwo variants leveraging psuedo labels as either hard binary or soft continuous\nlabels. We first apply TouR on phrase retrieval with our proposed phrase\nre-ranker. On passage retrieval, we demonstrate its effectiveness with an\noff-the-shelf re-ranker. TouR improves the end-to-end open-domain QA accuracy\nsignificantly, as well as passage retrieval performance. Compared to re-ranker,\nTouR requires a smaller number of candidates, and achieves consistently better\nperformance and runs up to 4x faster with our efficient implementation.\n","authors":["Mujeen Sung","Jungsoo Park","Jaewoo Kang","Danqi Chen","Jinhyuk Lee"],"pdf_url":"https://arxiv.org/pdf/2205.12680v2.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.05767v3","updated":"2022-12-21T02:18:29Z","published":"2022-12-12T08:40:04Z","title":"Reasoning over Different Types of Knowledge Graphs: Static, Temporal and\n  Multi-Modal","summary":"  Knowledge graph reasoning (KGR), aiming to deduce new facts from existing\nfacts based on mined logic rules underlying knowledge graphs (KGs), has become\na fast-growing research direction. It has been proven to significantly benefit\nthe usage of KGs in many AI applications, such as question answering and\nrecommendation systems, etc. According to the graph types, the existing KGR\nmodels can be roughly divided into three categories, i.e., static models,\ntemporal models, and multi-modal models. The early works in this domain mainly\nfocus on static KGR and tend to directly apply general knowledge graph\nembedding models to the reasoning task. However, these models are not suitable\nfor more complex but practical tasks, such as inductive static KGR, temporal\nKGR, and multi-modal KGR. To this end, multiple works have been developed\nrecently, but no survey papers and open-source repositories comprehensively\nsummarize and discuss models in this important direction. To fill the gap, we\nconduct a survey for knowledge graph reasoning tracing from static to temporal\nand then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR\nmodels, and typical datasets are introduced and discussed consequently.\nMoreover, we discuss the challenges and potential opportunities. The\ncorresponding open-source repository is shared on GitHub:\nhttps://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.\n","authors":["Ke Liang","Lingyuan Meng","Meng Liu","Yue Liu","Wenxuan Tu","Siwei Wang","Sihang Zhou","Xinwang Liu","Fuchun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.05767v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2212.11277v1","updated":"2022-12-21T09:46:12Z","published":"2022-12-21T09:46:12Z","title":"Audio Denoising for Robust Audio Fingerprinting","summary":"  Music discovery services let users identify songs from short mobile\nrecordings. These solutions are often based on Audio Fingerprinting, and rely\nmore specifically on the extraction of spectral peaks in order to be robust to\na number of distortions. Few works have been done to study the robustness of\nthese algorithms to background noise captured in real environments. In\nparticular, AFP systems still struggle when the signal to noise ratio is low,\ni.e when the background noise is strong. In this project, we tackle this\nproblematic with Deep Learning. We test a new hybrid strategy which consists of\ninserting a denoising DL model in front of a peak-based AFP algorithm. We\nsimulate noisy music recordings using a realistic data augmentation pipeline,\nand train a DL model to denoise them. The denoising model limits the impact of\nbackground noise on the AFP system's extracted peaks, improving its robustness\nto noise. We further propose a novel loss function to adapt the DL model to the\nconsidered AFP system, increasing its precision in terms of retrieved spectral\npeaks. To the best of our knowledge, this hybrid strategy has not been tested\nbefore.\n","authors":["Kamil Akesbi"],"pdf_url":"https://arxiv.org/pdf/2212.11277v1.pdf","comment":"63 pages, master thesis"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2212.11268v1","updated":"2022-12-21T18:58:24Z","published":"2022-12-21T18:58:24Z","title":"Personalized Decentralized Multi-Task Learning Over Dynamic\n  Communication Graphs","summary":"  Decentralized and federated learning algorithms face data heterogeneity as\none of the biggest challenges, especially when users want to learn a specific\ntask. Even when personalized headers are used concatenated to a shared network\n(PF-MTL), aggregating all the networks with a decentralized algorithm can\nresult in performance degradation as a result of heterogeneity in the data. Our\nalgorithm uses exchanged gradients to calculate the correlations among tasks\nautomatically, and dynamically adjusts the communication graph to connect\nmutually beneficial tasks and isolate those that may negatively impact each\nother. This algorithm improves the learning performance and leads to faster\nconvergence compared to the case where all clients are connected to each other\nregardless of their correlations. We conduct experiments on a synthetic\nGaussian dataset and a large-scale celebrity attributes (CelebA) dataset. The\nexperiment with the synthetic data illustrates that our proposed method is\ncapable of detecting tasks that are positively and negatively correlated.\nMoreover, the results of the experiments with CelebA demonstrate that the\nproposed method may produce significantly faster training results than\nfully-connected networks.\n","authors":["Matin Mortaheb","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2212.11268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11261v1","updated":"2022-12-21T18:54:19Z","published":"2022-12-21T18:54:19Z","title":"Contrastive Language-Vision AI Models Pretrained on Web-Scraped\n  Multimodal Data Exhibit Sexual Objectification Bias","summary":"  Nine language-vision AI models trained on web scrapes with the Contrastive\nLanguage-Image Pretraining (CLIP) objective are evaluated for evidence of a\nbias studied by psychologists: the sexual objectification of girls and women,\nwhich occurs when a person's human characteristics are disregarded and the\nperson is treated as a body or a collection of body parts. A first experiment\nuses standardized images of women from the Sexual OBjectification and EMotion\nDatabase, and finds that, commensurate with prior research in psychology, human\ncharacteristics are disassociated from images of objectified women: the model's\nrecognition of emotional state is mediated by whether the subject is fully or\npartially clothed. Embedding association tests (EATs) return significant effect\nsizes for both anger (d >.8) and sadness (d >.5). A second experiment measures\nthe effect in a representative application: an automatic image captioner\n(Antarctic Captions) includes words denoting emotion less than 50% as often for\nimages of partially clothed women than for images of fully clothed women. A\nthird experiment finds that images of female professionals (scientists,\ndoctors, executives) are likely to be associated with sexual descriptions\nrelative to images of male professionals. A fourth experiment shows that a\nprompt of \"a [age] year old girl\" generates sexualized images (as determined by\nan NSFW classifier) up to 73% of the time for VQGAN-CLIP (age 17), and up to\n40% of the time for Stable Diffusion (ages 14 and 18); the corresponding rate\nfor boys never surpasses 9%. The evidence indicates that language-vision AI\nmodels trained on automatically collected web scrapes learn biases of sexual\nobjectification, which propagate to downstream applications.\n","authors":["Robert Wolfe","Yiwei Yang","Bill Howe","Aylin Caliskan"],"pdf_url":"https://arxiv.org/pdf/2212.11261v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2212.11254v1","updated":"2022-12-21T18:30:22Z","published":"2022-12-21T18:30:22Z","title":"Adapting to Latent Subgroup Shifts via Concepts and Proxies","summary":"  We address the problem of unsupervised domain adaptation when the source\ndomain differs from the target domain because of a shift in the distribution of\na latent subgroup. When this subgroup confounds all observed data, neither\ncovariate shift nor label shift assumptions apply. We show that the optimal\ntarget predictor can be non-parametrically identified with the help of concept\nand proxy variables available only in the source domain, and unlabeled data\nfrom the target. The identification results are constructive, immediately\nsuggesting an algorithm for estimating the optimal predictor in the target. For\ncontinuous observations, when this algorithm becomes impractical, we propose a\nlatent variable model specific to the data generation process at hand. We show\nhow the approach degrades as the size of the shift changes, and verify that it\noutperforms both covariate and label shift adjustment.\n","authors":["Ibrahim Alabdulmohsin","Nicole Chiou","Alexander D'Amour","Arthur Gretton","Sanmi Koyejo","Matt J. Kusner","Stephen R. Pfohl","Olawale Salaudeen","Jessica Schrouff","Katherine Tsai"],"pdf_url":"https://arxiv.org/pdf/2212.11254v1.pdf","comment":"Authors listed in alphabetical order"},{"id":"http://arxiv.org/abs/1906.02314v6","updated":"2022-12-21T18:22:35Z","published":"2019-06-05T21:16:48Z","title":"A Tunable Loss Function for Robust Classification: Calibration,\n  Landscape, and Generalization","summary":"  We introduce a tunable loss function called $\\alpha$-loss, parameterized by\n$\\alpha \\in (0,\\infty]$, which interpolates between the exponential loss\n($\\alpha = 1/2$), the log-loss ($\\alpha = 1$), and the 0-1 loss ($\\alpha =\n\\infty$), for the machine learning setting of classification. Theoretically, we\nillustrate a fundamental connection between $\\alpha$-loss and Arimoto\nconditional entropy, verify the classification-calibration of $\\alpha$-loss in\norder to demonstrate asymptotic optimality via Rademacher complexity\ngeneralization techniques, and build-upon a notion called strictly local\nquasi-convexity in order to quantitatively characterize the optimization\nlandscape of $\\alpha$-loss. Practically, we perform class imbalance,\nrobustness, and classification experiments on benchmark image datasets using\nconvolutional-neural-networks. Our main practical conclusion is that certain\ntasks may benefit from tuning $\\alpha$-loss away from log-loss ($\\alpha = 1$),\nand to this end we provide simple heuristics for the practitioner. In\nparticular, navigating the $\\alpha$ hyperparameter can readily provide superior\nmodel robustness to label flips ($\\alpha > 1$) and sensitivity to imbalanced\nclasses ($\\alpha < 1$).\n","authors":["Tyler Sypherd","Mario Diaz","John Kevin Cava","Gautam Dasarathy","Peter Kairouz","Lalitha Sankar"],"pdf_url":"https://arxiv.org/pdf/1906.02314v6.pdf","comment":"Published at the Transactions on Information Theory"},{"id":"http://arxiv.org/abs/2212.11234v1","updated":"2022-12-21T17:59:11Z","published":"2022-12-21T17:59:11Z","title":"Improving Narrative Relationship Embeddings by Training with Additional\n  Inverse-Relationship Constraints","summary":"  We consider the problem of embedding character-entity relationships from the\nreduced semantic space of narratives, proposing and evaluating the assumption\nthat these relationships hold under a reflection operation. We analyze this\nassumption and compare the approach to a baseline state-of-the-art model with a\nunique evaluation that simulates efficacy on a downstream clustering task with\nhuman-created labels. Although our model creates clusters that achieve\nSilhouette scores of -.084, outperforming the baseline -.227, our analysis\nreveals that the models approach the task much differently and perform well on\nvery different examples. We conclude that our assumption might be useful for\nspecific types of data and should be evaluated on a wider range of tasks.\n","authors":["Mikolaj Figurski"],"pdf_url":"https://arxiv.org/pdf/2212.11234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11221v1","updated":"2022-12-21T17:48:01Z","published":"2022-12-21T17:48:01Z","title":"A Nearly Tight Bound for Fitting an Ellipsoid to Gaussian Random Points","summary":"  We prove that for $c>0$ a sufficiently small universal constant that a random\nset of $c d^2/\\log^4(d)$ independent Gaussian random points in $\\mathbb{R}^d$\nlie on a common ellipsoid with high probability. This nearly establishes a\nconjecture of~\\cite{SaundersonCPW12}, within logarithmic factors. The latter\nconjecture has attracted significant attention over the past decade, due to its\nconnections to machine learning and sum-of-squares lower bounds for certain\nstatistical problems.\n","authors":["Daniel M. Kane","Ilias Diakonikolas"],"pdf_url":"https://arxiv.org/pdf/2212.11221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05081v2","updated":"2022-12-21T17:46:25Z","published":"2022-12-09T19:00:18Z","title":"FAIR AI Models in High Energy Physics","summary":"  The findable, accessible, interoperable, and reusable (FAIR) data principles\nhave provided a framework for examining, evaluating, and improving how we share\ndata with the aim of facilitating scientific discovery. Efforts have been made\nto generalize these principles to research software and other digital products.\nArtificial intelligence (AI) models -- algorithms that have been trained on\ndata rather than explicitly programmed -- are an important target for this\nbecause of the ever-increasing pace with which AI is transforming scientific\nand engineering domains. In this paper, we propose a practical definition of\nFAIR principles for AI models and create a FAIR AI project template that\npromotes adherence to these principles. We demonstrate how to implement these\nprinciples using a concrete example from experimental high energy physics: a\ngraph neural network for identifying Higgs bosons decaying to bottom quarks. We\nstudy the robustness of these FAIR AI models and their portability across\nhardware architectures and software frameworks, and report new insights on the\ninterpretability of AI predictions by studying the interplay between FAIR\ndatasets and AI models. Enabled by publishing FAIR AI models, these studies\npave the way toward reliable and automated AI-driven scientific discovery.\n","authors":["Javier Duarte","Haoyang Li","Avik Roy","Ruike Zhu","E. A. Huerta","Daniel Diaz","Philip Harris","Raghav Kansal","Daniel S. Katz","Ishaan H. Kavoori","Volodymyr V. Kindratenko","Farouk Mokhtar","Mark S. Neubauer","Sang Eon Park","Melissa Quinnan","Roger Rusack","Zhizhen Zhao"],"pdf_url":"https://arxiv.org/pdf/2212.05081v2.pdf","comment":"32 pages, 8 figures, 9 tables"},{"id":"http://arxiv.org/abs/2207.00611v3","updated":"2022-12-21T17:37:27Z","published":"2022-07-01T18:11:12Z","title":"FAIR principles for AI models with a practical application for\n  accelerated high energy diffraction microscopy","summary":"  A concise and measurable set of FAIR (Findable, Accessible, Interoperable and\nReusable) principles for scientific data is transforming the state-of-practice\nfor data management and stewardship, supporting and enabling discovery and\ninnovation. Learning from this initiative, and acknowledging the impact of\nartificial intelligence (AI) in the practice of science and engineering, we\nintroduce a set of practical, concise, and measurable FAIR principles for AI\nmodels. We showcase how to create and share FAIR data and AI models within a\nunified computational framework combining the following elements: the Advanced\nPhoton Source at Argonne National Laboratory, the Materials Data Facility, the\nData and Learning Hub for Science, and funcX, and the Argonne Leadership\nComputing Facility (ALCF), in particular the ThetaGPU supercomputer and the\nSambaNova DataScale system at the ALCF AI Testbed. We describe how this\ndomain-agnostic computational framework may be harnessed to enable autonomous\nAI-driven discovery.\n","authors":["Nikil Ravi","Pranshu Chaturvedi","E. A. Huerta","Zhengchun Liu","Ryan Chard","Aristana Scourtas","K. J. Schmidt","Kyle Chard","Ben Blaiszik","Ian Foster"],"pdf_url":"https://arxiv.org/pdf/2207.00611v3.pdf","comment":"11 pages, 3 figures; Accepted to Scientific Data; for press release\n  see\n  https://www.anl.gov/article/argonne-scientists-promote-fair-standards-for-managing-artificial-intelligence-models\n  and\n  https://www.ncsa.illinois.edu/ncsa-student-researchers-lead-authors-on-award-winning-paper;\n  Received 2022 HPCwire Readers' Choice Award on Best Use of High Performance\n  Data Analytics & Artificial Intelligence"},{"id":"http://arxiv.org/abs/2212.11209v1","updated":"2022-12-21T17:30:17Z","published":"2022-12-21T17:30:17Z","title":"A Theoretical Study of The Effects of Adversarial Attacks on Sparse\n  Regression","summary":"  This paper analyzes $\\ell_1$ regularized linear regression under the\nchallenging scenario of having only adversarially corrupted data for training.\nWe use the primal-dual witness paradigm to provide provable performance\nguarantees for the support of the estimated regression parameter vector to\nmatch the actual parameter. Our theoretical analysis shows the\ncounter-intuitive result that an adversary can influence sample complexity by\ncorrupting the irrelevant features, i.e., those corresponding to zero\ncoefficients of the regression parameter vector, which, consequently, do not\naffect the dependent variable. As any adversarially robust algorithm has its\nlimitations, our theoretical analysis identifies the regimes under which the\nlearning algorithm and adversary can dominate over each other. It helps us to\nanalyze these fundamental limits and address critical scientific questions of\nwhich parameters (like mutual incoherence, the maximum and minimum eigenvalue\nof the covariance matrix, and the budget of adversarial perturbation) play a\nrole in the high or low probability of success of the LASSO algorithm. Also,\nthe derived sample complexity is logarithmic with respect to the size of the\nregression parameter vector, and our theoretical claims are validated by\nempirical analysis on synthetic and real-world datasets.\n","authors":["Deepak Maurya","Jean Honorio"],"pdf_url":"https://arxiv.org/pdf/2212.11209v1.pdf","comment":"first version"},{"id":"http://arxiv.org/abs/2212.11207v1","updated":"2022-12-21T17:28:07Z","published":"2022-12-21T17:28:07Z","title":"A Seven-Layer Model for Standardising AI Fairness Assessment","summary":"  Problem statement: Standardisation of AI fairness rules and benchmarks is\nchallenging because AI fairness and other ethical requirements depend on\nmultiple factors such as context, use case, type of the AI system, and so on.\nIn this paper, we elaborate that the AI system is prone to biases at every\nstage of its lifecycle, from inception to its usage, and that all stages\nrequire due attention for mitigating AI bias. We need a standardised approach\nto handle AI fairness at every stage. Gap analysis: While AI fairness is a hot\nresearch topic, a holistic strategy for AI fairness is generally missing. Most\nresearchers focus only on a few facets of AI model-building. Peer review shows\nexcessive focus on biases in the datasets, fairness metrics, and algorithmic\nbias. In the process, other aspects affecting AI fairness get ignored. The\nsolution proposed: We propose a comprehensive approach in the form of a novel\nseven-layer model, inspired by the Open System Interconnection (OSI) model, to\nstandardise AI fairness handling. Despite the differences in the various\naspects, most AI systems have similar model-building stages. The proposed model\nsplits the AI system lifecycle into seven abstraction layers, each\ncorresponding to a well-defined AI model-building or usage stage. We also\nprovide checklists for each layer and deliberate on potential sources of bias\nin each layer and their mitigation methodologies. This work will facilitate\nlayer-wise standardisation of AI fairness rules and benchmarking parameters.\n","authors":["Avinash Agarwal","Harsh Agarwal"],"pdf_url":"https://arxiv.org/pdf/2212.11207v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2212.11205v1","updated":"2022-12-21T17:22:27Z","published":"2022-12-21T17:22:27Z","title":"Vulnerabilities of Deep Learning-Driven Semantic Communications to\n  Backdoor (Trojan) Attacks","summary":"  This paper highlights vulnerabilities of deep learning-driven semantic\ncommunications to backdoor (Trojan) attacks. Semantic communications aims to\nconvey a desired meaning while transferring information from a transmitter to\nits receiver. An encoder-decoder pair that is represented by two deep neural\nnetworks (DNNs) as part of an autoencoder is trained to reconstruct signals\nsuch as images at the receiver by transmitting latent features of small size\nover a limited number of channel uses. In the meantime, another DNN of a\nsemantic task classifier at the receiver is jointly trained with the\nautoencoder to check the meaning conveyed to the receiver. The complex decision\nspace of the DNNs makes semantic communications susceptible to adversarial\nmanipulations. In a backdoor (Trojan) attack, the adversary adds triggers to a\nsmall portion of training samples and changes the label to a target label. When\nthe transfer of images is considered, the triggers can be added to the images\nor equivalently to the corresponding transmitted or received signals. In test\ntime, the adversary activates these triggers by providing poisoned samples as\ninput to the encoder (or decoder) of semantic communications. The backdoor\nattack can effectively change the semantic information transferred for the\npoisoned input samples to a target meaning. As the performance of semantic\ncommunications improves with the signal-to-noise ratio and the number of\nchannel uses, the success of the backdoor attack increases as well. Also,\nincreasing the Trojan ratio in training data makes the attack more successful.\nIn the meantime, the effect of this attack on the unpoisoned input samples\nremains limited. Overall, this paper shows that the backdoor attack poses a\nserious threat to semantic communications and presents novel design guidelines\nto preserve the meaning of transferred information in the presence of backdoor\nattacks.\n","authors":["Yalin E. Sagduyu","Tugba Erpek","Sennur Ulukus","Aylin Yener"],"pdf_url":"https://arxiv.org/pdf/2212.11205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11201v1","updated":"2022-12-21T17:16:42Z","published":"2022-12-21T17:16:42Z","title":"Deep Reinforcement Learning for Trajectory Path Planning and Distributed\n  Inference in Resource-Constrained UAV Swarms","summary":"  The deployment flexibility and maneuverability of Unmanned Aerial Vehicles\n(UAVs) increased their adoption in various applications, such as wildfire\ntracking, border monitoring, etc. In many critical applications, UAVs capture\nimages and other sensory data and then send the captured data to remote servers\nfor inference and data processing tasks. However, this approach is not always\npractical in real-time applications due to the connection instability, limited\nbandwidth, and end-to-end latency. One promising solution is to divide the\ninference requests into multiple parts (layers or segments), with each part\nbeing executed in a different UAV based on the available resources.\n  Furthermore, some applications require the UAVs to traverse certain areas and\ncapture incidents; thus, planning their paths becomes critical particularly, to\nreduce the latency of making the collaborative inference process. Specifically,\nplanning the UAVs trajectory can reduce the data transmission latency by\ncommunicating with devices in the same proximity while mitigating the\ntransmission interference.\n  This work aims to design a model for distributed collaborative inference\nrequests and path planning in a UAV swarm while respecting the resource\nconstraints due to the computational load and memory usage of the inference\nrequests. The model is formulated as an optimization problem and aims to\nminimize latency. The formulated problem is NP-hard so finding the optimal\nsolution is quite complex; thus, this paper introduces a real-time and dynamic\nsolution for online applications using deep reinforcement learning. We conduct\nextensive simulations and compare our results to the-state-of-the-art studies\ndemonstrating that our model outperforms the competing models.\n","authors":["Marwan Dhuheir","Emna Baccour","Aiman Erbad","Sinan Sabeeh Al-Obaidi","Mounir Hamdi"],"pdf_url":"https://arxiv.org/pdf/2212.11201v1.pdf","comment":"accepted journal paper at IEEE Internet of Things Journal"},{"id":"http://arxiv.org/abs/2212.11194v1","updated":"2022-12-21T17:10:55Z","published":"2022-12-21T17:10:55Z","title":"Free-Rider Games for Federated Learning with Selfish Clients in NextG\n  Wireless Networks","summary":"  This paper presents a game theoretic framework for participation and\nfree-riding in federated learning (FL), and determines the Nash equilibrium\nstrategies when FL is executed over wireless links. To support spectrum sensing\nfor NextG communications, FL is used by clients, namely spectrum sensors with\nlimited training datasets and computation resources, to train a wireless signal\nclassifier while preserving privacy. In FL, a client may be free-riding, i.e.,\nit does not participate in FL model updates, if the computation and\ntransmission cost for FL participation is high, and receives the global model\n(learned by other clients) without incurring a cost. However, the free-riding\nbehavior may potentially decrease the global accuracy due to lack of\ncontribution to global model learning. This tradeoff leads to a non-cooperative\ngame where each client aims to individually maximize its utility as the\ndifference between the global model accuracy and the cost of FL participation.\nThe Nash equilibrium strategies are derived for free-riding probabilities such\nthat no client can unilaterally increase its utility given the strategies of\nits opponents remain the same. The free-riding probability increases with the\nFL participation cost and the number of clients, and a significant optimality\ngap exists in Nash equilibrium with respect to the joint optimization for all\nclients. The optimality gap increases with the number of clients and the\nmaximum gap is evaluated as a function of the cost. These results quantify the\nimpact of free-riding on the resilience of FL in NextG networks and indicate\noperational modes for FL participation.\n","authors":["Yalin E. Sagduyu"],"pdf_url":"https://arxiv.org/pdf/2212.11194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10343v2","updated":"2022-12-21T17:03:30Z","published":"2022-12-20T15:26:39Z","title":"Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio\n  Access Technologies","summary":"  The evolution of wireless communications into 6G and beyond is expected to\nrely on new machine learning (ML)-based capabilities. These can enable\nproactive decisions and actions from wireless-network components to sustain\nquality-of-service (QoS) and user experience. Moreover, new use cases in the\narea of vehicular and industrial communications will emerge. Specifically in\nthe area of vehicle communication, vehicle-to-everything (V2X) schemes will\nbenefit strongly from such advances. With this in mind, we have conducted a\ndetailed measurement campaign with the purpose of enabling a plethora of\ndiverse ML-based studies. The resulting datasets offer GPS-located wireless\nmeasurements across diverse urban environments for both cellular (with two\ndifferent operators) and sidelink radio access technologies, thus enabling a\nvariety of different studies towards V2X. The datasets are labeled and sampled\nwith a high time resolution. Furthermore, we make the data publicly available\nwith all the necessary information to support the on-boarding of new\nresearchers. We provide an initial analysis of the data showing some of the\nchallenges that ML needs to overcome and the features that ML can leverage, as\nwell as some hints at potential research studies.\n","authors":["Rodrigo Hernangómez","Philipp Geuer","Alexandros Palaios","Daniel Schäufele","Cara Watermann","Khawla Taleb-Bouhemadi","Mohammad Parvini","Anton Krause","Sanket Partani","Christian Vielhaus","Martin Kasparick","Daniel F. Külzer","Friedrich Burmeister","Sławomir Stańczak","Gerhard Fettweis","Hans D. Schotten","Frank H. P. Fitzek"],"pdf_url":"https://arxiv.org/pdf/2212.10343v2.pdf","comment":"5 pages, 6 figures. Submitted to a conference. Dataset available at\n  https://ieee-dataport.org/open-access/berlin-v2x"},{"id":"http://arxiv.org/abs/2212.11187v1","updated":"2022-12-21T16:56:55Z","published":"2022-12-21T16:56:55Z","title":"Similarity Contrastive Estimation for Image and Video Soft Contrastive\n  Self-Supervised Learning","summary":"  Contrastive representation learning has proven to be an effective\nself-supervised learning method for images and videos. Most successful\napproaches are based on Noise Contrastive Estimation (NCE) and use different\nviews of an instance as positives that should be contrasted with other\ninstances, called negatives, that are considered as noise. However, several\ninstances in a dataset are drawn from the same distribution and share\nunderlying semantic information. A good data representation should contain\nrelations between the instances, or semantic similarity and dissimilarity, that\ncontrastive learning harms by considering all negatives as noise. To circumvent\nthis issue, we propose a novel formulation of contrastive learning using\nsemantic similarity between instances called Similarity Contrastive Estimation\n(SCE). Our training objective is a soft contrastive one that brings the\npositives closer and estimates a continuous distribution to push or pull\nnegative instances based on their learned similarities. We validate empirically\nour approach on both image and video representation learning. We show that SCE\nperforms competitively with the state of the art on the ImageNet linear\nevaluation protocol for fewer pretraining epochs and that it generalizes to\nseveral downstream image tasks. We also show that SCE reaches state-of-the-art\nresults for pretraining video representation and that the learned\nrepresentation can generalize to video downstream tasks.\n","authors":["Julien Denize","Jaonary Rabarisoa","Astrid Orcesi","Romain Hérault"],"pdf_url":"https://arxiv.org/pdf/2212.11187v1.pdf","comment":"Extended version of our WACV 2023 paper to video self-supervised\n  learning"},{"id":"http://arxiv.org/abs/2109.03386v3","updated":"2022-12-21T16:56:41Z","published":"2021-09-08T01:26:46Z","title":"On Characterizing the Trade-off in Invariant Representation Learning","summary":"  Many applications of representation learning, such as privacy preservation,\nalgorithmic fairness, and domain adaptation, desire explicit control over\nsemantic information being discarded. This goal is formulated as satisfying two\nobjectives: maximizing utility for predicting a target attribute while\nsimultaneously being invariant (independent) to a known semantic attribute.\nSolutions to invariant representation learning (IRepL) problems lead to a\ntrade-off between utility and invariance when they are competing. While\nexisting works study bounds on this trade-off, two questions remain\noutstanding: 1) What is the exact trade-off between utility and invariance? and\n2) What are the encoders (mapping the data to a representation) that achieve\nthe trade-off, and how can we estimate it from training data? This paper\naddresses these questions for IRepLs in reproducing kernel Hilbert spaces\n(RKHS)s. Under the assumption that the distribution of a low-dimensional\nprojection of high-dimensional data is approximately normal, we derive a\nclosed-form solution for the global optima of the underlying optimization\nproblem for encoders in RKHSs. This yields closed formulae for a near-optimal\ntrade-off, corresponding optimal representation dimensionality, and the\ncorresponding encoder(s). We also numerically quantify the trade-off on\nrepresentative problems and compare them to those achieved by baseline IRepL\nalgorithms.\n","authors":["Bashir Sadeghi","Sepehr Dehdashtian","Vishnu Boddeti"],"pdf_url":"https://arxiv.org/pdf/2109.03386v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.13352v2","updated":"2022-12-21T16:54:56Z","published":"2022-03-24T21:54:49Z","title":"Does human speech follow Benford's Law?","summary":"  Researchers have observed that the frequencies of leading digits in many\nman-made and naturally occurring datasets follow a logarithmic curve, with\ndigits that start with the number 1 accounting for $\\sim 30\\%$ of all numbers\nin the dataset and digits that start with the number 9 accounting for $\\sim\n5\\%$ of all numbers in the dataset. This phenomenon, known as Benford's Law, is\nhighly repeatable and appears in lists of numbers from electricity bills, stock\nprices, tax returns, house prices, death rates, lengths of rivers, and\nnaturally occurring images. In this paper we demonstrate that human speech\nspectra also follow Benford's Law on average. That is, when averaged over many\nspeakers, the frequencies of leading digits in speech magnitude spectra follow\nthis distribution, although with some variability at the individual sample\nlevel. We use this observation to motivate a new set of features that can be\nefficiently extracted from speech and demonstrate that these features can be\nused to classify between human speech and synthetic speech.\n","authors":["Leo Hsu","Visar Berisha"],"pdf_url":"https://arxiv.org/pdf/2203.13352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.09727v2","updated":"2022-12-21T16:53:43Z","published":"2021-12-17T19:22:37Z","title":"Rank4Class: A Ranking Formulation for Multiclass Classification","summary":"  Multiclass classification (MCC) is a fundamental machine learning problem of\nclassifying each instance into one of a predefined set of classes. In the deep\nlearning era, extensive efforts have been spent on developing more powerful\nneural embedding models to better represent the instance for improving MCC\nperformance. In this paper, we do not aim to propose new neural models for\ninstance representation learning, but to show that it is promising to boost MCC\nperformance with a novel formulation through the lens of ranking. In\nparticular, by viewing MCC as to rank classes for an instance, we first argue\nthat ranking metrics, such as Normalized Discounted Cumulative Gain, can be\nmore informative than the commonly used Top-$K$ metrics. We further demonstrate\nthat the dominant neural MCC recipe can be transformed to a neural ranking\nframework. Based on such generalization, we show that it is intuitive to\nleverage advanced techniques from the learning to rank literature to improve\nthe MCC performance out of the box. Extensive empirical results on both text\nand image classification tasks with diverse datasets and backbone neural models\nshow the value of our proposed framework.\n","authors":["Nan Wang","Zhen Qin","Le Yan","Honglei Zhuang","Xuanhui Wang","Michael Bendersky","Marc Najork"],"pdf_url":"https://arxiv.org/pdf/2112.09727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08036v2","updated":"2022-12-21T16:44:32Z","published":"2022-11-15T10:36:21Z","title":"Provably Reliable Large-Scale Sampling from Gaussian Processes","summary":"  When comparing approximate Gaussian process (GP) models, it can be helpful to\nbe able to generate data from any GP. If we are interested in how approximate\nmethods perform at scale, we may wish to generate very large synthetic datasets\nto evaluate them. Na\\\"{i}vely doing so would cost \\(\\mathcal{O}(n^3)\\) flops\nand \\(\\mathcal{O}(n^2)\\) memory to generate a size \\(n\\) sample. We demonstrate\nhow to scale such data generation to large \\(n\\) whilst still providing\nguarantees that, with high probability, the sample is indistinguishable from a\nsample from the desired GP.\n","authors":["Anthony Stephenson","Robert Allison","Edward Pyzer-Knapp"],"pdf_url":"https://arxiv.org/pdf/2211.08036v2.pdf","comment":"Main article 4 pages + 14 pages of supplementary material. To be\n  published in NeurIPS 2022 Proceedings Workshop on \"Gaussian Processes,\n  Spatiotemporal Modeling, and Decision-making Systems\""},{"id":"http://arxiv.org/abs/2212.05581v2","updated":"2022-12-21T16:44:27Z","published":"2022-12-11T19:07:34Z","title":"Efficient Relation-aware Neighborhood Aggregation in Graph Neural\n  Networks via Tensor Decomposition","summary":"  Many Graph Neural Networks (GNNs) are proposed for KG embedding. However,\nlots of these methods neglect the importance of the information of relations\nand combine it with the information of entities inefficiently and mostly\nadditively, leading to low expressiveness. To address this issue, we introduce\na general knowledge graph encoder incorporating tensor decomposition in the\naggregation function of Relational Graph Convolutional Network (R-GCN). In our\nmodel, the parameters of a low-rank core projection tensor, used to transform\nneighbor entities, are shared across relations to benefit from multi-task\nlearning and produce expressive relation-aware representations. Besides, we\npropose a low-rank estimation of the core tensor using CP decomposition to\ncompress the model, which is also applicable, as a regularization method, to\nother similar GNNs. We train our model using a contrastive loss, which relieves\nthe training limitation of the 1-N method on huge graphs. We achieved favorably\ncompetitive results on FB15-237 and WN18RR with embeddings in comparably lower\ndimensions; particularly, we improved R-GCN performance on FB15-237 by 36% with\nthe same decoder.\n","authors":["Peyman Baghershahi","Reshad Hosseini","Hadi Moradi"],"pdf_url":"https://arxiv.org/pdf/2212.05581v2.pdf","comment":"11 pages, 4 Tables, 2 figures"},{"id":"http://arxiv.org/abs/2208.09449v2","updated":"2022-12-21T16:11:52Z","published":"2022-08-19T17:02:55Z","title":"A Novel Plug-and-Play Approach for Adversarially Robust Generalization","summary":"  In this work, we propose a robust framework that employs adversarially robust\ntraining to safeguard the machine learning models against perturbed testing\ndata. We achieve this by incorporating the worst-case additive adversarial\nerror within a fixed budget for each sample during model estimation. Our main\nfocus is to provide a plug-and-play solution that can be incorporated in the\nexisting machine learning algorithms with minimal changes. To that end, we\nderive the ready-to-use solution for several widely used loss functions with a\nvariety of norm constraints on adversarial perturbation for various supervised\nand unsupervised ML problems, including regression, classification, two-layer\nneural networks, graphical models, and matrix completion. The solutions are\neither in closed-form, 1-D optimization, semidefinite programming, difference\nof convex programming or a sorting-based algorithm. Finally, we validate our\napproach by showing significant performance improvement on real-world datasets\nfor supervised problems such as regression and classification, as well as for\nunsupervised problems such as matrix completion and learning graphical models,\nwith very little computational overhead.\n","authors":["Deepak Maurya","Adarsh Barik","Jean Honorio"],"pdf_url":"https://arxiv.org/pdf/2208.09449v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.01489v4","updated":"2022-12-21T16:10:02Z","published":"2022-08-02T14:38:53Z","title":"Deconstructing Self-Supervised Monocular Reconstruction: The Design\n  Decisions that Matter","summary":"  This paper presents an open and comprehensive framework to systematically\nevaluate state-of-the-art contributions to self-supervised monocular depth\nestimation. This includes pretraining, backbone, architectural design choices\nand loss functions. Many papers in this field claim novelty in either\narchitecture design or loss formulation. However, simply updating the backbone\nof historical systems results in relative improvements of 25%, allowing them to\noutperform the majority of existing systems. A systematic evaluation of papers\nin this field was not straightforward. The need to compare like-with-like in\nprevious papers means that longstanding errors in the evaluation protocol are\nubiquitous in the field. It is likely that many papers were not only optimized\nfor particular datasets, but also for errors in the data and evaluation\ncriteria. To aid future research in this area, we release a modular codebase\n(https://github.com/jspenmar/monodepth_benchmark), allowing for easy evaluation\nof alternate design decisions against corrected data and evaluation criteria.\nWe re-implement, validate and re-evaluate 16 state-of-the-art contributions and\nintroduce a new dataset (SYNS-Patches) containing dense outdoor depth maps in a\nvariety of both natural and urban scenes. This allows for the computation of\ninformative metrics in complex regions such as depth boundaries.\n","authors":["Jaime Spencer","Chris Russell","Simon Hadfield","Richard Bowden"],"pdf_url":"https://arxiv.org/pdf/2208.01489v4.pdf","comment":"https://github.com/jspenmar/monodepth_benchmark"},{"id":"http://arxiv.org/abs/2212.11155v1","updated":"2022-12-21T16:08:47Z","published":"2022-12-21T16:08:47Z","title":"Robust Path Selection in Software-defined WANs using Deep Reinforcement\n  Learning","summary":"  In the context of an efficient network traffic engineering process where the\nnetwork continuously measures a new traffic matrix and updates the set of paths\nin the network, an automated process is required to quickly and efficiently\nidentify when and what set of paths should be used. Unfortunately, the burden\nof finding the optimal solution for the network updating process in each given\ntime interval is high since the computation complexity of optimization\napproaches using linear programming increases significantly as the size of the\nnetwork increases. In this paper, we use deep reinforcement learning to derive\na data-driven algorithm that does the path selection in the network considering\nthe overhead of route computation and path updates. Our proposed scheme\nleverages information about past network behavior to identify a set of robust\npaths to be used for multiple future time intervals to avoid the overhead of\nupdating the forwarding behavior of routers frequently. We compare the results\nof our approach to other traffic engineering solutions through extensive\nsimulations across real network topologies. Our results demonstrate that our\nscheme fares well by a factor of 40% with respect to reducing link utilization\ncompared to traditional TE schemes such as ECMP. Our scheme provides a slightly\nhigher link utilization (around 25%) compared to schemes that only minimize\nlink utilization and do not care about path updating overhead.\n","authors":["Shahrooz Pouryousef","Lixin Gao","Don Towsley"],"pdf_url":"https://arxiv.org/pdf/2212.11155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11143v1","updated":"2022-12-21T16:04:53Z","published":"2022-12-21T16:04:53Z","title":"Efficient First-order Methods for Convex Optimization with Strongly\n  Convex Function Constraints","summary":"  Convex function constrained optimization has received growing research\ninterests lately. For a special convex problem which has strongly convex\nfunction constraints, we develop a new accelerated primal-dual first-order\nmethod that obtains an $\\Ocal(1/\\sqrt{\\vep})$ complexity bound, improving the\n$\\Ocal(1/{\\vep})$ result for the state-of-the-art first-order methods. The key\ningredient to our development is some novel techniques to progressively\nestimate the strong convexity of the Lagrangian function, which enables\nadaptive step-size selection and faster convergence performance. In addition,\nwe show that the complexity is further improvable in terms of the dependence on\nsome problem parameter, via a restart scheme that calls the accelerated method\nrepeatedly. As an application, we consider sparsity-inducing constrained\noptimization which has a separable convex objective and a strongly convex loss\nconstraint. In addition to achieving fast convergence, we show that the\nrestarted method can effectively identify the sparsity pattern (active-set) of\nthe optimal solution in finite steps. To the best of our knowledge, this is the\nfirst active-set identification result for sparsity-inducing constrained\noptimization.\n","authors":["Zhenwei Lin","Qi Deng"],"pdf_url":"https://arxiv.org/pdf/2212.11143v1.pdf","comment":"27 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.11134v1","updated":"2022-12-21T15:59:35Z","published":"2022-12-21T15:59:35Z","title":"Generating music with sentiment using Transformer-GANs","summary":"  The field of Automatic Music Generation has seen significant progress thanks\nto the advent of Deep Learning. However, most of these results have been\nproduced by unconditional models, which lack the ability to interact with their\nusers, not allowing them to guide the generative process in meaningful and\npractical ways. Moreover, synthesizing music that remains coherent across\nlonger timescales while still capturing the local aspects that make it sound\n``realistic'' or ``human-like'' is still challenging. This is due to the large\ncomputational requirements needed to work with long sequences of data, and also\nto limitations imposed by the training schemes that are often employed. In this\npaper, we propose a generative model of symbolic music conditioned by data\nretrieved from human sentiment. The model is a Transformer-GAN trained with\nlabels that correspond to different configurations of the valence and arousal\ndimensions that quantitatively represent human affective states. We try to\ntackle both of the problems above by employing an efficient linear version of\nAttention and using a Discriminator both as a tool to improve the overall\nquality of the generated music and its ability to follow the conditioning\nsignals.\n","authors":["Pedro Neves","Jose Fornari","João Florindo"],"pdf_url":"https://arxiv.org/pdf/2212.11134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11130v1","updated":"2022-12-21T15:57:12Z","published":"2022-12-21T15:57:12Z","title":"Towards dynamic stability analysis of sustainable power grids using\n  graph neural networks","summary":"  To mitigate climate change, the share of renewable needs to be increased.\nRenewable energies introduce new challenges to power grids due to\ndecentralization, reduced inertia and volatility in production. The operation\nof sustainable power grids with a high penetration of renewable energies\nrequires new methods to analyze the dynamic stability. We provide new datasets\nof dynamic stability of synthetic power grids and find that graph neural\nnetworks (GNNs) are surprisingly effective at predicting the highly non-linear\ntarget from topological information only. To illustrate the potential to scale\nto real-sized power grids, we demonstrate the successful prediction on a Texan\npower grid model.\n","authors":["Christian Nauck","Michael Lindner","Konstantin Schürholt","Frank Hellmann"],"pdf_url":"https://arxiv.org/pdf/2212.11130v1.pdf","comment":"main section: 4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.11110v1","updated":"2022-12-21T15:49:20Z","published":"2022-12-21T15:49:20Z","title":"Lifelong Reinforcement Learning with Modulating Masks","summary":"  Lifelong learning aims to create AI systems that continuously and\nincrementally learn during a lifetime, similar to biological learning. Attempts\nso far have met problems, including catastrophic forgetting, interference among\ntasks, and the inability to exploit previous knowledge. While considerable\nresearch has focused on learning multiple input distributions, typically in\nclassification, lifelong reinforcement learning (LRL) must also deal with\nvariations in the state and transition distributions, and in the reward\nfunctions. Modulating masks, recently developed for classification, are\nparticularly suitable to deal with such a large spectrum of task variations. In\nthis paper, we adapted modulating masks to work with deep LRL, specifically PPO\nand IMPALA agents. The comparison with LRL baselines in both discrete and\ncontinuous RL tasks shows competitive performance. We further investigated the\nuse of a linear combination of previously learned masks to exploit previous\nknowledge when learning new tasks: not only is learning faster, the algorithm\nsolves tasks that we could not otherwise solve from scratch due to extremely\nsparse rewards. The results suggest that RL with modulating masks is a\npromising approach to lifelong learning, to the composition of knowledge to\nlearn increasingly complex tasks, and to knowledge reuse for efficient and\nfaster learning.\n","authors":["Eseoghene Ben-Iwhiwhu","Saptarshi Nath","Praveen K. Pilly","Soheil Kolouri","Andrea Soltoggio"],"pdf_url":"https://arxiv.org/pdf/2212.11110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.04690v4","updated":"2022-12-21T15:33:58Z","published":"2022-07-11T08:12:02Z","title":"Dynamic Budget Throttling in Repeated Second-Price Auctions","summary":"  In today's online advertising markets, an important demand for an advertiser\n(buyer) is to control her total expenditure within a time span under some\nbudget. Among all budget control approaches, throttling stands out as a popular\none, where the buyer chooses to participate in only a part of auctions. This\npaper gives a theoretical panorama of a single buyer's dynamic budget\nthrottling process in repeated second-price auctions, which is lacking in the\nliterature. We first establish a lower bound on the regret and an upper bound\non the asymptotic competitive ratio for any algorithm, respectively, on whether\nthe buyer's values are stochastic or adversarial. Second, on the algorithmic\nside, we consider two different information structures, with increasing\ndifficulty in learning the stochastic distribution of the highest competing\nbid. We further propose the OGD-CB algorithm, which is oblivious to whether the\nvalues are stochastic or adversarial and has asymptotically equal results under\nthese two information structures. Specifically, with stochastic values, we\ndemonstrate that this algorithm guarantees a near-optimal expected regret. When\nvalues are adversarial, we prove that the proposed algorithm reaches the upper\nbound on the asymptotic competitive ratio. At last, we compare throttling with\npacing, another widely adopted budget control method, in the dynamic setting.\nIn the stochastic case, we illustrate that dynamic pacing is generally better\nthan dynamic throttling for the buyer, which is an extension of known results\nthat dynamic pacing is asymptotically optimal in this scenario. However, in the\nadversarial case, we give an exciting result indicating that dynamic throttling\nis the asymptotically optimal dynamic bidding strategy. Our results fill the\ngaps in the theoretical research of dynamic throttling and comprehensively\nreveal the ability of this popular budget-smoothing strategy.\n","authors":["Zhaohua Chen","Chang Wang","Qian Wang","Yuqi Pan","Zhuming Shi","Zheng Cai","Yukun Ren","Zhihua Zhu","Xiaotie Deng"],"pdf_url":"https://arxiv.org/pdf/2207.04690v4.pdf","comment":"44 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2212.11087v1","updated":"2022-12-21T15:33:01Z","published":"2022-12-21T15:33:01Z","title":"On Reinforcement Learning for the Game of 2048","summary":"  2048 is a single-player stochastic puzzle game. This intriguing and addictive\ngame has been popular worldwide and has attracted researchers to develop\ngame-playing programs. Due to its simplicity and complexity, 2048 has become an\ninteresting and challenging platform for evaluating the effectiveness of\nmachine learning methods. This dissertation conducts comprehensive research on\nreinforcement learning and computer game algorithms for 2048. First, this\ndissertation proposes optimistic temporal difference learning, which\nsignificantly improves the quality of learning by employing optimistic\ninitialization to encourage exploration for 2048. Furthermore, based on this\napproach, a state-of-the-art program for 2048 is developed, which achieves the\nhighest performance among all learning-based programs, namely an average score\nof 625377 points and a rate of 72% for reaching 32768-tiles. Second, this\ndissertation investigates several techniques related to 2048, including the\nn-tuple network ensemble learning, Monte Carlo tree search, and deep\nreinforcement learning. These techniques are promising for further improving\nthe performance of the current state-of-the-art program. Finally, this\ndissertation discusses pedagogical applications related to 2048 by proposing\ncourse designs and summarizing the teaching experience. The proposed course\ndesigns use 2048-like games as materials for beginners to learn reinforcement\nlearning and computer game algorithms. The courses have been successfully\napplied to graduate-level students and received well by student feedback.\n","authors":["Hung Guei"],"pdf_url":"https://arxiv.org/pdf/2212.11087v1.pdf","comment":"A Ph.D. dissertation submitted to Institute of Computer Science and\n  Engineering, National Yang Ming Chiao Tung University"},{"id":"http://arxiv.org/abs/2211.09639v2","updated":"2022-12-21T15:29:12Z","published":"2022-11-17T16:39:43Z","title":"Why Deep Learning Generalizes","summary":"  Very large deep learning models trained using gradient descent are remarkably\nresistant to memorization given their huge capacity, but are at the same time\ncapable of fitting large datasets of pure noise. Here methods are introduced by\nwhich models may be trained to memorize datasets that normally are generalized.\nWe find that memorization is difficult relative to generalization, but that\nadding noise makes memorization easier. Increasing the dataset size exaggerates\nthe characteristics of that dataset: model access to more training samples\nmakes overfitting easier for random data, but somewhat harder for natural\nimages. The bias of deep learning towards generalization is explored\ntheoretically, and we show that generalization results from a model's\nparameters being attracted to points of maximal stability with respect to that\nmodel's inputs during gradient descent.\n","authors":["Benjamin L. Badger"],"pdf_url":"https://arxiv.org/pdf/2211.09639v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2212.11080v1","updated":"2022-12-21T15:27:52Z","published":"2022-12-21T15:27:52Z","title":"Is it worth it? An experimental comparison of six deep- and classical\n  machine learning methods for unsupervised anomaly detection in time series","summary":"  The detection of anomalies in time series data is crucial in a wide range of\napplications, such as system monitoring, health care or cyber security. While\nthe vast number of available methods makes selecting the right method for a\ncertain application hard enough, different methods have different strengths,\ne.g. regarding the type of anomalies they are able to find. In this work, we\ncompare six unsupervised anomaly detection methods with different complexities\nto answer the questions: Are the more complex methods usually performing\nbetter? And are there specific anomaly types that those method are tailored to?\nThe comparison is done on the UCR anomaly archive, a recent benchmark dataset\nfor anomaly detection. We compare the six methods by analyzing the experimental\nresults on a dataset- and anomaly type level after tuning the necessary\nhyperparameter for each method. Additionally we examine the ability of\nindividual methods to incorporate prior knowledge about the anomalies and\nanalyse the differences of point-wise and sequence wise features. We show with\nbroad experiments, that the classical machine learning methods show a superior\nperformance compared to the deep learning methods across a wide range of\nanomaly types.\n","authors":["Ferdinand Rewicki","Joachim Denzler","Julia Niebling"],"pdf_url":"https://arxiv.org/pdf/2212.11080v1.pdf","comment":"15 Pages, The repository to reproduce the results is available at\n  https://gitlab.com/dlr-dw/is-it-worth-it-benchmark"},{"id":"http://arxiv.org/abs/2210.12388v2","updated":"2022-12-21T15:08:28Z","published":"2022-10-22T08:47:25Z","title":"Diversity-Promoting Ensemble for Medical Image Segmentation","summary":"  Medical image segmentation is an actively studied task in medical imaging,\nwhere the precision of the annotations is of utter importance towards accurate\ndiagnosis and treatment. In recent years, the task has been approached with\nvarious deep learning systems, among the most popular models being U-Net. In\nthis work, we propose a novel strategy to generate ensembles of different\narchitectures for medical image segmentation, by leveraging the diversity\n(decorrelation) of the models forming the ensemble. More specifically, we\nutilize the Dice score among model pairs to estimate the correlation between\nthe outputs of the two models forming each pair. To promote diversity, we\nselect models with low Dice scores among each other. We carry out\ngastro-intestinal tract image segmentation experiments to compare our\ndiversity-promoting ensemble (DiPE) with another strategy to create ensembles\nbased on selecting the top scoring U-Net models. Our empirical results show\nthat DiPE surpasses both individual models as well as the ensemble creation\nstrategy based on selecting the top scoring models.\n","authors":["Mariana-Iuliana Georgescu","Radu Tudor Ionescu","Andreea-Iuliana Miron"],"pdf_url":"https://arxiv.org/pdf/2210.12388v2.pdf","comment":"Accepted at SAC 2023"},{"id":"http://arxiv.org/abs/2210.01549v3","updated":"2022-12-21T14:43:16Z","published":"2022-10-04T12:20:21Z","title":"Diffusion Models for Graphs Benefit From Discrete State Spaces","summary":"  Denoising diffusion probabilistic models and score matching models have\nproven to be very powerful for generative tasks. While these approaches have\nalso been applied to the generation of discrete graphs, they have, so far,\nrelied on continuous Gaussian perturbations. Instead, in this work, we suggest\nusing discrete noise for the forward Markov process. This ensures that in every\nintermediate step the graph remains discrete. Compared to the previous\napproach, our experimental results on four datasets and multiple architectures\nshow that using a discrete noising process results in higher quality generated\nsamples indicated with an average MMDs reduced by a factor of 1.5. Furthermore,\nthe number of denoising steps is reduced from 1000 to 32 steps leading to a 30\ntimes faster sampling procedure.\n","authors":["Kilian Konstantin Haefeli","Karolis Martinkus","Nathanaël Perraudin","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2210.01549v3.pdf","comment":"Presented at the First Learning on Graphs Conference (LoG 2022) and\n  the NeurIPS 2022 New Frontiers in Graph Learning Workshop (NeurIPS\n  GLFrontiers 2022)"},{"id":"http://arxiv.org/abs/1810.12558v7","updated":"2022-12-21T14:31:52Z","published":"2018-10-30T07:41:08Z","title":"Relative Importance Sampling For Off-Policy Actor-Critic in Deep\n  Reinforcement Learning","summary":"  Off-policy learning is more unstable compared to on-policy learning in\nreinforcement learning (RL). One reason for the instability of off-policy\nlearning is a discrepancy between the target ($\\pi$) and behavior (b) policy\ndistributions. The discrepancy between $\\pi$ and b distributions can be\nalleviated by employing a smooth variant of the importance sampling (IS), such\nas the relative importance sampling (RIS). RIS has parameter $\\beta\\in[0, 1]$\nwhich controls smoothness. To cope with instability, we present the first\nrelative importance sampling-off-policy actor-critic (RIS-Off-PAC) model-free\nalgorithms in RL. In our method, the network yields a target policy (the\nactor), a value function (the critic) assessing the current policy ($\\pi$)\nusing samples drawn from behavior policy. We use action value generated from\nthe behavior policy in reward function to train our algorithm rather than from\nthe target policy. We also use deep neural networks to train both actor and\ncritic. We evaluated our algorithm on a number of Open AI Gym benchmark\nproblems and demonstrate better or comparable performance to several\nstate-of-the-art RL baselines.\n","authors":["Mahammad Humayoo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/1810.12558v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05047v2","updated":"2022-12-21T14:28:28Z","published":"2022-05-09T14:54:41Z","title":"Classification and mapping of low-statured 'shrubland' cover types in\n  post-agricultural landscapes of the US Northeast","summary":"  Novel plant communities reshape landscapes and pose challenges for land cover\nclassification and mapping that can constrain research and stewardship efforts.\nIn the US Northeast, emergence of low-statured woody vegetation, or shrublands,\ninstead of secondary forests in post-agricultural landscapes is well-documented\nby field studies, but poorly understood from a landscape perspective, which\nlimits the ability to systematically study and manage these lands. To address\ngaps in classification/mapping of low-statured cover types where they have been\nhistorically rare, we developed models to predict shrubland distributions at\n30m resolution across New York State (NYS), using a stacked ensemble combining\na random forest, gradient boosting machine, and artificial neural network to\nintegrate remote sensing of structural (airborne LIDAR) and optical (satellite\nimagery) properties of vegetation cover. We first classified a 1m canopy height\nmodel (CHM), derived from a patchwork of available LIDAR coverages, to define\nshrubland presence/absence. Next, these non-contiguous maps were used to train\na model ensemble based on temporally-segmented imagery to predict shrubland\nprobability for the entire study landscape (NYS). Approximately 2.5% of the CHM\ncoverage area was classified as shrubland. Models using Landsat predictors\ntrained on the classified CHM were effective at identifying shrubland (test set\nAUC=0.893, real-world AUC=0.904), in discriminating between shrub/young forest\nand other cover classes, and produced qualitatively sensible maps, even when\nextending beyond the original training data. Our results suggest that\nincorporation of airborne LiDAR, even from a discontinuous patchwork of\ncoverages, can improve land cover classification of historically rare but\nincreasingly prevalent shrubland habitats across broader areas.\n","authors":["Michael J Mahoney","Lucas K Johnson","Abigail Z Guinan","Colin M Beier"],"pdf_url":"https://arxiv.org/pdf/2205.05047v2.pdf","comment":"43 pages (35 main text, 8 supplementary materials); 11 figures (10\n  main text, 1 supplementary materials), 10 tables (4 main text, 6\n  supplementary materials)"},{"id":"http://arxiv.org/abs/2211.03232v2","updated":"2022-12-21T14:19:03Z","published":"2022-11-06T22:38:49Z","title":"Exponentially Improving the Complexity of Simulating the\n  Weisfeiler-Lehman Test with Graph Neural Networks","summary":"  Recent work shows that the expressive power of Graph Neural Networks (GNNs)\nin distinguishing non-isomorphic graphs is exactly the same as that of the\nWeisfeiler-Lehman (WL) graph test. In particular, they show that the WL test\ncan be simulated by GNNs. However, those simulations involve neural networks\nfor the 'combine' function of size polynomial or even exponential in the number\nof graph nodes $n$, as well as feature vectors of length linear in $n$.\n  We present an improved simulation of the WL test on GNNs with\n\\emph{exponentially} lower complexity. In particular, the neural network\nimplementing the combine function in each node has only a polylogarithmic\nnumber of parameters in $n$, and the feature vectors exchanged by the nodes of\nGNN consists of only $O(\\log n)$ bits. We also give logarithmic lower bounds\nfor the feature vector length and the size of the neural networks, showing the\n(near)-optimality of our construction.\n","authors":["Anders Aamand","Justin Y. Chen","Piotr Indyk","Shyam Narayanan","Ronitt Rubinfeld","Nicholas Schiefer","Sandeep Silwal","Tal Wagner"],"pdf_url":"https://arxiv.org/pdf/2211.03232v2.pdf","comment":"22 pages,5 figures, published at NeurIPS 2022. Updated funding\n  statements"},{"id":"http://arxiv.org/abs/2212.10426v2","updated":"2022-12-21T13:39:06Z","published":"2022-12-20T17:04:50Z","title":"Deep Riemannian Networks for EEG Decoding","summary":"  State-of-the-art performance in electroencephalography (EEG) decoding tasks\nis currently often achieved with either Deep-Learning or\nRiemannian-Geometry-based decoders. Recently, there is growing interest in Deep\nRiemannian Networks (DRNs) possibly combining the advantages of both previous\nclasses of methods. However, there are still a range of topics where additional\ninsight is needed to pave the way for a more widespread application of DRNs in\nEEG. These include architecture design questions such as network size and\nend-to-end ability as well as model training questions. How these factors\naffect model performance has not been explored. Additionally, it is not clear\nhow the data within these networks is transformed, and whether this would\ncorrelate with traditional EEG decoding. Our study aims to lay the groundwork\nin the area of these topics through the analysis of DRNs for EEG with a wide\nrange of hyperparameters. Networks were tested on two public EEG datasets and\ncompared with state-of-the-art ConvNets. Here we propose end-to-end EEG SPDNet\n(EE(G)-SPDNet), and we show that this wide, end-to-end DRN can outperform the\nConvNets, and in doing so use physiologically plausible frequency regions. We\nalso show that the end-to-end approach learns more complex filters than\ntraditional band-pass filters targeting the classical alpha, beta, and gamma\nfrequency bands of the EEG, and that performance can benefit from channel\nspecific filtering approaches. Additionally, architectural analysis revealed\nareas for further improvement due to the possible loss of Riemannian specific\ninformation throughout the network. Our study thus shows how to design and\ntrain DRNs to infer task-related information from the raw EEG without the need\nof handcrafted filterbanks and highlights the potential of end-to-end DRNs such\nas EE(G)-SPDNet for high-performance EEG decoding.\n","authors":["Daniel Wilson","Robin Tibor Schirrmeister","Lukas Alexander Wilhelm Gemein","Tonio Ball"],"pdf_url":"https://arxiv.org/pdf/2212.10426v2.pdf","comment":"26 pages, 15 Figures"},{"id":"http://arxiv.org/abs/2205.10044v2","updated":"2022-12-21T13:39:00Z","published":"2022-05-20T09:35:26Z","title":"Towards biologically plausible Dreaming and Planning in recurrent\n  spiking networks","summary":"  Humans and animals can learn new skills after practicing for a few hours,\nwhile current reinforcement learning algorithms require a large amount of data\nto achieve good performances. Recent model-based approaches show promising\nresults by reducing the number of necessary interactions with the environment\nto learn a desirable policy. However, these methods require biological\nimplausible ingredients, such as the detailed storage of older experiences, and\nlong periods of offline learning. The optimal way to learn and exploit\nword-models is still an open question. Taking inspiration from biology, we\nsuggest that dreaming might be an efficient expedient to use an inner model. We\npropose a two-module (agent and model) spiking neural network in which\n\"dreaming\" (living new experiences in a model-based simulated environment)\nsignificantly boosts learning. We also explore \"planning\", an online\nalternative to dreaming, that shows comparable performances. Importantly, our\nmodel does not require the detailed storage of experiences, and learns online\nthe world-model and the policy. Moreover, we stress that our network is\ncomposed of spiking neurons, further increasing the biological plausibility and\nimplementability in neuromorphic hardware.\n","authors":["Cristiano Capone","Pier Stanislao Paolucci"],"pdf_url":"https://arxiv.org/pdf/2205.10044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11005v1","updated":"2022-12-21T13:19:25Z","published":"2022-12-21T13:19:25Z","title":"Revisiting Residual Networks for Adversarial Robustness: An\n  Architectural Perspective","summary":"  Efforts to improve the adversarial robustness of convolutional neural\nnetworks have primarily focused on developing more effective adversarial\ntraining methods. In contrast, little attention was devoted to analyzing the\nrole of architectural elements (such as topology, depth, and width) on\nadversarial robustness. This paper seeks to bridge this gap and present a\nholistic study on the impact of architectural design on adversarial robustness.\nWe focus on residual networks and consider architecture design at the block\nlevel, i.e., topology, kernel size, activation, and normalization, as well as\nat the network scaling level, i.e., depth and width of each block in the\nnetwork. In both cases, we first derive insights through systematic ablative\nexperiments. Then we design a robust residual block, dubbed RobustResBlock, and\na compound scaling rule, dubbed RobustScaling, to distribute depth and width at\nthe desired FLOP count. Finally, we combine RobustResBlock and RobustScaling\nand present a portfolio of adversarially robust residual networks,\nRobustResNets, spanning a broad spectrum of model capacities. Experimental\nvalidation across multiple datasets and adversarial attacks demonstrate that\nRobustResNets consistently outperform both the standard WRNs and other existing\nrobust architectures, achieving state-of-the-art AutoAttack robust accuracy of\n61.1% without additional data and 63.7% with 500K external data while being\n$2\\times$ more compact in terms of parameters. Code is available at \\url{\nhttps://github.com/zhichao-lu/robust-residual-network}\n","authors":["Shihua Huang","Zhichao Lu","Kalyanmoy Deb","Vishnu Naresh Boddeti"],"pdf_url":"https://arxiv.org/pdf/2212.11005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.14316v2","updated":"2022-12-21T13:18:10Z","published":"2022-03-27T14:28:16Z","title":"MutexMatch: Semi-Supervised Learning with Mutex-Based Consistency\n  Regularization","summary":"  The core issue in semi-supervised learning (SSL) lies in how to effectively\nleverage unlabeled data, whereas most existing methods tend to put a great\nemphasis on the utilization of high-confidence samples yet seldom fully explore\nthe usage of low-confidence samples. In this paper, we aim to utilize\nlow-confidence samples in a novel way with our proposed mutex-based consistency\nregularization, namely MutexMatch. Specifically, the high-confidence samples\nare required to exactly predict \"what it is\" by conventional True-Positive\nClassifier, while the low-confidence samples are employed to achieve a simpler\ngoal -- to predict with ease \"what it is not\" by True-Negative Classifier. In\nthis sense, we not only mitigate the pseudo-labeling errors but also make full\nuse of the low-confidence unlabeled data by consistency of dissimilarity\ndegree. MutexMatch achieves superior performance on multiple benchmark\ndatasets, i.e., CIFAR-10, CIFAR-100, SVHN, STL-10, mini-ImageNet and\nTiny-ImageNet. More importantly, our method further shows superiority when the\namount of labeled data is scarce, e.g., 92.23% accuracy with only 20 labeled\ndata on CIFAR-10. Our code and model weights have been released at\nhttps://github.com/NJUyued/MutexMatch4SSL.\n","authors":["Yue Duan","Zhen Zhao","Lei Qi","Lei Wang","Luping Zhou","Yinghuan Shi","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2203.14316v2.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)"},{"id":"http://arxiv.org/abs/2212.07428v3","updated":"2022-12-21T13:10:10Z","published":"2022-12-14T10:50:13Z","title":"Towards Linguistically Informed Multi-Objective Pre-Training for Natural\n  Language Inference","summary":"  We introduce a linguistically enhanced combination of pre-training methods\nfor transformers. The pre-training objectives include POS-tagging, synset\nprediction based on semantic knowledge graphs, and parent prediction based on\ndependency parse trees. Our approach achieves competitive results on the\nNatural Language Inference task, compared to the state of the art. Specifically\nfor smaller models, the method results in a significant performance boost,\nemphasizing the fact that intelligent pre-training can make up for fewer\nparameters and help building more efficient models. Combining POS-tagging and\nsynset prediction yields the overall best results.\n","authors":["Maren Pielka","Svetlana Schmidt","Lisa Pucknat","Rafet Sifa"],"pdf_url":"https://arxiv.org/pdf/2212.07428v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10992v1","updated":"2022-12-21T13:00:02Z","published":"2022-12-21T13:00:02Z","title":"LogAnMeta: Log Anomaly Detection Using Meta Learning","summary":"  Modern telecom systems are monitored with performance and system logs from\nmultiple application layers and components. Detecting anomalous events from\nthese logs is key to identify security breaches, resource over-utilization,\ncritical/fatal errors, etc. Current supervised log anomaly detection frameworks\ntend to perform poorly on new types or signatures of anomalies with few or\nunseen samples in the training data. In this work, we propose a\nmeta-learning-based log anomaly detection framework (LogAnMeta) for detecting\nanomalies from sequence of log events with few samples. LoganMeta train a\nhybrid few-shot classifier in an episodic manner. The experimental results\ndemonstrate the efficacy of our proposed method\n","authors":["Abhishek Sarkar","Tanmay Sen","Srimanta Kundu","Arijit Sarkar","Abdul Wazed"],"pdf_url":"https://arxiv.org/pdf/2212.10992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10986v1","updated":"2022-12-21T12:48:30Z","published":"2022-12-21T12:48:30Z","title":"SoK: Let The Privacy Games Begin! A Unified Treatment of Data Inference\n  Privacy in Machine Learning","summary":"  Deploying machine learning models in production may allow adversaries to\ninfer sensitive information about training data. There is a vast literature\nanalyzing different types of inference risks, ranging from membership inference\nto reconstruction attacks. Inspired by the success of games (i.e.,\nprobabilistic experiments) to study security properties in cryptography, some\nauthors describe privacy inference risks in machine learning using a similar\ngame-based style. However, adversary capabilities and goals are often stated in\nsubtly different ways from one presentation to the other, which makes it hard\nto relate and compose results. In this paper, we present a game-based framework\nto systematize the body of knowledge on privacy inference risks in machine\nlearning.\n","authors":["Ahmed Salem","Giovanni Cherubin","David Evans","Boris Köpf","Andrew Paverd","Anshuman Suri","Shruti Tople","Santiago Zanella-Béguelin"],"pdf_url":"https://arxiv.org/pdf/2212.10986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10390v2","updated":"2022-12-21T12:47:03Z","published":"2022-12-20T16:17:40Z","title":"ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic\n  Segmentation","summary":"  State-of-the-art 3D semantic segmentation models are trained on the\noff-the-shelf public benchmarks, but they often face the major challenge when\nthese well-trained models are deployed to a new domain. In this paper, we\npropose an Active-and-Adaptive Segmentation (ADAS) baseline to enhance the weak\ncross-domain generalization ability of a well-trained 3D segmentation model,\nand bridge the point distribution gap between domains. Specifically, before the\ncross-domain adaptation stage begins, ADAS performs an active sampling\noperation to select a maximally-informative subset from both source and target\ndomains for effective adaptation, reducing the adaptation difficulty under 3D\nscenarios. Benefiting from the rise of multi-modal 2D-3D datasets, ADAS\nutilizes a cross-modal attention-based feature fusion module that can extract a\nrepresentative pair of image features and point features to achieve a\nbi-directional image-point feature interaction for better safe adaptation.\nExperimentally, ADAS is verified to be effective in many cross-domain settings\nincluding: 1) Unsupervised Domain Adaptation (UDA), which means that all\nsamples from target domain are unlabeled; 2) Unsupervised Few-shot Domain\nAdaptation (UFDA) which means that only a few unlabeled samples are available\nin the unlabeled target domain; 3) Active Domain Adaptation (ADA) which means\nthat the selected target samples by ADAS are manually annotated. Their results\ndemonstrate that ADAS achieves a significant accuracy gain by easily coupling\nADAS with self-training methods or off-the-shelf UDA works.\n","authors":["Ben Fei","Siyuan Huang","Jiakang Yuan","Botian Shi","Bo Zhang","Tao Chen","Min Dou","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2212.10390v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07368v2","updated":"2022-12-21T12:16:42Z","published":"2022-12-14T17:46:17Z","title":"Reconstruction of Multivariate Sparse Signals from Mismatched Samples","summary":"  Erroneous correspondences between samples and their respective channel or\ntarget commonly arise in several real-world applications. For instance,\nwhole-brain calcium imaging of freely moving organisms, multiple target\ntracking or multi-person contactless vital sign monitoring may be severely\naffected by mismatched sample-channel assignments. To systematically address\nthis fundamental problem, we pose it as a signal reconstruction problem where\nwe have lost correspondences between the samples and their respective channels.\nWe show that under the assumption that the signals of interest admit a sparse\nrepresentation over an overcomplete dictionary, unique signal recovery is\npossible. Our derivations reveal that the problem is equivalent to a structured\nunlabeled sensing problem without precise knowledge of the sensing matrix.\nUnfortunately, existing methods are neither robust to errors in the regressors\nnor do they exploit the structure of the problem. Therefore, we propose a novel\nrobust two-step approach for the reconstruction of shuffled sparse signals. The\nperformance and robustness of the proposed approach is illustrated in an\napplication of whole-brain calcium imaging in computational neuroscience. The\nproposed framework can be generalized to sparse signal representations other\nthan the ones considered in this work to be applied in a variety of real-world\nproblems with imprecise measurement or channel assignment.\n","authors":["Taulant Koka","Michael Muma","Benjamín Béjar Haro"],"pdf_url":"https://arxiv.org/pdf/2212.07368v2.pdf","comment":"There is an error in the use of Corollary 1 in our Paper, which does\n  not apply in our case"},{"id":"http://arxiv.org/abs/2104.00514v3","updated":"2022-12-21T12:09:08Z","published":"2021-03-31T14:19:18Z","title":"Learning Spectral Unions of Partial Deformable 3D Shapes","summary":"  Spectral geometric methods have brought revolutionary changes to the field of\ngeometry processing. Of particular interest is the study of the Laplacian\nspectrum as a compact, isometry and permutation-invariant representation of a\nshape. Some recent works show how the intrinsic geometry of a full shape can be\nrecovered from its spectrum, but there are approaches that consider the more\nchallenging problem of recovering the geometry from the spectral information of\npartial shapes. In this paper, we propose a possible way to fill this gap. We\nintroduce a learning-based method to estimate the Laplacian spectrum of the\nunion of partial non-rigid 3D shapes, without actually computing the 3D\ngeometry of the union or any correspondence between those partial shapes. We do\nso by operating purely in the spectral domain and by defining the union\noperation between short sequences of eigenvalues. We show that the approximated\nunion spectrum can be used as-is to reconstruct the complete geometry [MRC*19],\nperform region localization on a template [RTO*19] and retrieve shapes from a\ndatabase, generalizing ShapeDNA [RWP06] to work with partialities. Working with\neigenvalues allows us to deal with unknown correspondence, different sampling,\nand different discretizations (point clouds and meshes alike), making this\noperation especially robust and general. Our approach is data-driven and can\ngeneralize to isometric and non-isometric deformations of the surface, as long\nas these stay within the same semantic class (e.g., human bodies or horses), as\nwell as to partiality artifacts not seen at training time.\n","authors":["Luca Moschella","Simone Melzi","Luca Cosmo","Filippo Maggioli","Or Litany","Maks Ovsjanikov","Leonidas Guibas","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2104.00514v3.pdf","comment":"18 pages, 20 figures"},{"id":"http://arxiv.org/abs/2212.10960v1","updated":"2022-12-21T12:03:12Z","published":"2022-12-21T12:03:12Z","title":"The Ties that matter: From the perspective of Similarity Measure in\n  Online Social Networks","summary":"  Online Social Networks have embarked on the importance of connection strength\nmeasures which has a broad array of applications such as, analyzing diffusion\nbehaviors, community detection, link predictions, recommender systems. Though\nthere are some existing connection strength measures, the density that a\nconnection shares with it's neighbors and the directionality aspect has not\nreceived much attention. In this paper, we have proposed an asymmetric edge\nsimilarity measure namely, Neighborhood Density-based Edge Similarity (NDES)\nwhich provides a fundamental support to derive the strength of connection. The\ntime complexity of NDES is $O(nk^2)$. An application of NDES for community\ndetection in social network is shown. We have considered a similarity based\ncommunity detection technique and substituted its similarity measure with NDES.\nThe performance of NDES is evaluated on several small real-world datasets in\nterms of the effectiveness in detecting communities and compared with three\nwidely used similarity measures. Empirical results show NDES enables detecting\ncomparatively better communities both in terms of accuracy and quality.\n","authors":["Soumita Das","Anupam Biswas"],"pdf_url":"https://arxiv.org/pdf/2212.10960v1.pdf","comment":"To be published in MINDS-2021"},{"id":"http://arxiv.org/abs/2212.10939v1","updated":"2022-12-21T11:28:52Z","published":"2022-12-21T11:28:52Z","title":"Joint Embedding of 2D and 3D Networks for Medical Image Anomaly\n  Detection","summary":"  Obtaining ground truth data in medical imaging has difficulties due to the\nfact that it requires a lot of annotating time from the experts in the field.\nAlso, when trained with supervised learning, it detects only the cases included\nin the labels. In real practice, we want to also open to other possibilities\nthan the named cases while examining the medical images. As a solution, the\nneed for anomaly detection that can detect and localize abnormalities by\nlearning the normal characteristics using only normal images is emerging. With\nmedical image data, we can design either 2D or 3D networks of self-supervised\nlearning for anomaly detection task. Although 3D networks, which learns 3D\nstructures of the human body, show good performance in 3D medical image anomaly\ndetection, they cannot be stacked in deeper layers due to memory problems.\nWhile 2D networks have advantage in feature detection, they lack 3D context\ninformation. In this paper, we develop a method for combining the strength of\nthe 3D network and the strength of the 2D network through joint embedding. We\nalso propose the pretask of self-supervised learning to make it possible for\nthe networks to learn efficiently. Through the experiments, we show that the\nproposed method achieves better performance in both classification and\nsegmentation tasks compared to the SoTA method.\n","authors":["Inha Kang","Jinah Park"],"pdf_url":"https://arxiv.org/pdf/2212.10939v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.10937v1","updated":"2022-12-21T11:25:07Z","published":"2022-12-21T11:25:07Z","title":"DCC: A Cascade based Approach to Detect Communities in Social Networks","summary":"  Community detection in Social Networks is associated with finding and\ngrouping the most similar nodes inherent in the network. These similar nodes\nare identified by computing tie strength. Stronger ties indicates higher\nproximity shared by connected node pairs. This work is motivated by\nGranovetter's argument that suggests that strong ties lies within densely\nconnected nodes and the theory that community cores in real-world networks are\ndensely connected. In this paper, we have introduced a novel method called\n\\emph{Disjoint Community detection using Cascades (DCC)} which demonstrates the\neffectiveness of a new local density based tie strength measure on detecting\ncommunities. Here, tie strength is utilized to decide the paths followed for\npropagating information. The idea is to crawl through the tuple information of\ncascades towards the community core guided by increasing tie strength.\nConsidering the cascade generation step, a novel preferential membership method\nhas been developed to assign community labels to unassigned nodes. The efficacy\nof $DCC$ has been analyzed based on quality and accuracy on several real-world\ndatasets and baseline community detection algorithms.\n","authors":["Soumita Das","Anupam Biswas","Akrati Saxena"],"pdf_url":"https://arxiv.org/pdf/2212.10937v1.pdf","comment":"To be published in CHSN-2022"},{"id":"http://arxiv.org/abs/2210.02997v2","updated":"2022-12-21T11:24:38Z","published":"2022-10-06T15:36:37Z","title":"Expander Graph Propagation","summary":"  Deploying graph neural networks (GNNs) on whole-graph classification or\nregression tasks is known to be challenging: it often requires computing node\nfeatures that are mindful of both local interactions in their neighbourhood and\nthe global context of the graph structure. GNN architectures that navigate this\nspace need to avoid pathological behaviours, such as bottlenecks and\noversquashing, while ideally having linear time and space complexity\nrequirements. In this work, we propose an elegant approach based on propagating\ninformation over expander graphs. We leverage an efficient method for\nconstructing expander graphs of a given size, and use this insight to propose\nthe EGP model. We show that EGP is able to address all of the above concerns,\nwhile requiring minimal effort to set up, and provide evidence of its empirical\nutility on relevant graph classification datasets and baselines in the Open\nGraph Benchmark. Importantly, using expander graphs as a template for message\npassing necessarily gives rise to negative curvature. While this appears to be\ncounterintuitive in light of recent related work on oversquashing, we\ntheoretically demonstrate that negatively curved edges are likely to be\nrequired to obtain scalable message passing without bottlenecks. To the best of\nour knowledge, this is a previously unstudied result in the context of graph\nrepresentation learning, and we believe our analysis paves the way to a novel\nclass of scalable methods to counter oversquashing in GNNs.\n","authors":["Andreea Deac","Marc Lackenby","Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2210.02997v2.pdf","comment":"Presented at LoG 2022. Best Paper Award at the NeurIPS 2022 Workshop\n  on New Frontiers in Graph Learning (GLFrontiers). 18 pages, 1 figure"},{"id":"http://arxiv.org/abs/2212.10936v1","updated":"2022-12-21T11:24:32Z","published":"2022-12-21T11:24:32Z","title":"A Memetic Algorithm with Reinforcement Learning for Sociotechnical\n  Production Scheduling","summary":"  The following article presents a memetic algorithm with applying deep\nreinforcement learning (DRL) for solving practically oriented dual resource\nconstrained flexible job shop scheduling problems (DRC-FJSSP). In recent years,\nthere has been extensive research on DRL techniques, but without considering\nrealistic, flexible and human-centered shopfloors. A research gap can be\nidentified in the context of make-to-order oriented discontinuous manufacturing\nas it is often represented in medium-size companies with high service levels.\nFrom practical industry projects in this domain, we recognize requirements to\ndepict flexible machines, human workers and capabilities, setup and processing\noperations, material arrival times, complex job paths with parallel tasks for\nbill of material (BOM) manufacturing, sequence-depended setup times and\n(partially) automated tasks. On the other hand, intensive research has been\ndone on metaheuristics in the context of DRC-FJSSP. However, there is a lack of\nsuitable and generic scheduling methods that can be holistically applied in\nsociotechnical production and assembly processes. In this paper, we first\nformulate an extended DRC-FJSSP induced by the practical requirements\nmentioned. Then we present our proposed hybrid framework with parallel\ncomputing for multicriteria optimization. Through numerical experiments with\nreal-world data, we confirm that the framework generates feasible schedules\nefficiently and reliably. Utilizing DRL instead of random operations leads to\nbetter results and outperforms traditional approaches.\n","authors":["Felix Grumbach","Nour Eldin Alaa Badr","Pascal Reusch","Sebastian Trojahn"],"pdf_url":"https://arxiv.org/pdf/2212.10936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10930v1","updated":"2022-12-21T11:20:12Z","published":"2022-12-21T11:20:12Z","title":"Minimizing Worst-Case Violations of Neural Networks","summary":"  Machine learning (ML) algorithms are remarkably good at approximating complex\nnon-linear relationships. Most ML training processes, however, are designed to\ndeliver ML tools with good average performance, but do not offer any guarantees\nabout their worst-case estimation error. For safety-critical systems such as\npower systems, this places a major barrier for their adoption. So far,\napproaches could determine the worst-case violations of only trained ML\nalgorithms. To the best of our knowledge, this is the first paper to introduce\na neural network training procedure designed to achieve both a good average\nperformance and minimum worst-case violations. Using the Optimal Power Flow\n(OPF) problem as a guiding application, our approach (i) introduces a framework\nthat reduces the worst-case generation constraint violations during training,\nincorporating them as a differentiable optimization layer; and (ii) presents a\nneural network sequential learning architecture to significantly accelerate it.\nWe demonstrate the proposed architecture on four different test systems ranging\nfrom 39 buses to 162 buses, for both AC-OPF and DC-OPF applications.\n","authors":["Rahul Nellikkath","Spyros Chatzivasileiadis"],"pdf_url":"https://arxiv.org/pdf/2212.10930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10929v1","updated":"2022-12-21T11:18:09Z","published":"2022-12-21T11:18:09Z","title":"SPT: Semi-Parametric Prompt Tuning for Multitask Prompted Learning","summary":"  Pre-trained large language models can efficiently interpolate human-written\nprompts in a natural way. Multitask prompted learning can help generalization\nthrough a diverse set of tasks at once, thus enhancing the potential for more\neffective downstream fine-tuning. To perform efficient multitask-inference in\nthe same batch, parameter-efficient fine-tuning methods such as prompt tuning\nhave been proposed. However, the existing prompt tuning methods may lack\ngeneralization. We propose SPT, a semi-parametric prompt tuning method for\nmultitask prompted learning. The novel component of SPT is a memory bank from\nwhere memory prompts are retrieved based on discrete prompts. Extensive\nexperiments, such as (i) fine-tuning a full language model with SPT on 31\ndifferent tasks from 8 different domains and evaluating zero-shot\ngeneralization on 9 heldout datasets under 5 NLP task categories and (ii)\npretraining SPT on the GLUE datasets and evaluating fine-tuning on the\nSuperGLUE datasets, demonstrate effectiveness of SPT.\n","authors":["M Saiful Bari","Aston Zhang","Shuai Zheng","Xingjian Shi","Yi Zhu","Shafiq Joty","Mu Li"],"pdf_url":"https://arxiv.org/pdf/2212.10929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.13492v2","updated":"2022-12-21T10:55:11Z","published":"2022-07-27T12:27:57Z","title":"Time to augment self-supervised visual representation learning","summary":"  Biological vision systems are unparalleled in their ability to learn visual\nrepresentations without supervision. In machine learning, self-supervised\nlearning (SSL) has led to major advances in forming object representations in\nan unsupervised fashion. Such systems learn representations invariant to\naugmentation operations over images, like cropping or flipping. In contrast,\nbiological vision systems exploit the temporal structure of the visual\nexperience during natural interactions with objects. This gives access to\n\"augmentations\" not commonly used in SSL, like watching the same object from\nmultiple viewpoints or against different backgrounds. Here, we systematically\ninvestigate and compare the potential benefits of such time-based augmentations\nduring natural interactions for learning object categories. Our results show\nthat time-based augmentations achieve large performance gains over\nstate-of-the-art image augmentations. Specifically, our analyses reveal that:\n1) 3-D object manipulations drastically improve the learning of object\ncategories; 2) viewing objects against changing backgrounds is important for\nlearning to discard background-related information from the latent\nrepresentation. Overall, we conclude that time-based augmentations during\nnatural interactions with objects can substantially improve self-supervised\nlearning, narrowing the gap between artificial and biological vision systems.\n","authors":["Arthur Aubret","Markus Ernst","Céline Teulière","Jochen Triesch"],"pdf_url":"https://arxiv.org/pdf/2207.13492v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2212.10913v1","updated":"2022-12-21T10:50:54Z","published":"2022-12-21T10:50:54Z","title":"Ensemble learning techniques for intrusion detection system in the\n  context of cybersecurity","summary":"  Recently, there has been an interest in improving the resources available in\nIntrusion Detection System (IDS) techniques. In this sense, several studies\nrelated to cybersecurity show that the environment invasions and information\nkidnapping are increasingly recurrent and complex. The criticality of the\nbusiness involving operations in an environment using computing resources does\nnot allow the vulnerability of the information. Cybersecurity has taken on a\ndimension within the universe of indispensable technology in corporations, and\nthe prevention of risks of invasions into the environment is dealt with daily\nby Security teams. Thus, the main objective of the study was to investigate the\nEnsemble Learning technique using the Stacking method, supported by the Support\nVector Machine (SVM) and k-Nearest Neighbour (kNN) algorithms aiming at an\noptimization of the results for DDoS attack detection. For this, the Intrusion\nDetection System concept was used with the application of the Data Mining and\nMachine Learning Orange tool to obtain better results\n","authors":["Andricson Abeline Moreira","Carlos A. C. Tojeiro","Carlos J. Reis","Gustavo Henrique Massaro","Igor Andrade Brito e Kelton A. P. da Costa"],"pdf_url":"https://arxiv.org/pdf/2212.10913v1.pdf","comment":"in Portuguese language. CIACA - Conferencia Ibero-Americana\n  Computa\\c{c}\\~ao Aplicada 2022 Proceedings"},{"id":"http://arxiv.org/abs/2202.07256v2","updated":"2022-12-21T10:09:44Z","published":"2022-02-15T09:05:35Z","title":"Federated Graph Neural Networks: Overview, Techniques and Challenges","summary":"  With its capability to deal with graph data, which is widely found in\npractical applications, graph neural networks (GNNs) have attracted significant\nresearch attention in recent years. As societies become increasingly concerned\nwith the need for data privacy protection, GNNs face the need to adapt to this\nnew normal. Besides, as clients in Federated Learning (FL) may have\nrelationships, more powerful tools are required to utilize such implicit\ninformation to boost performance. This has led to the rapid development of the\nemerging research field of federated graph neural networks (FedGNNs). This\npromising interdisciplinary field is highly challenging for interested\nresearchers to grasp. The lack of an insightful survey on this topic further\nexacerbates the entry difficulty. In this paper, we bridge this gap by offering\na comprehensive survey of this emerging field. We propose a 2-dimensional\ntaxonomy of the FedGNNs literature: 1) the main taxonomy provides a clear\nperspective on the integration of GNNs and FL by analyzing how GNNs enhance FL\ntraining as well as how FL assists GNNs training, and 2) the auxiliary taxonomy\nprovides a view on how FedGNNs deal with heterogeneity across FL clients.\nThrough discussions of key ideas, challenges, and limitations of existing\nworks, we envision future research directions that can help build more robust,\nexplainable, efficient, fair, inductive, and comprehensive FedGNNs.\n","authors":["Rui Liu","Pengwei Xing","Zichao Deng","Anran Li","Cuntai Guan","Han Yu"],"pdf_url":"https://arxiv.org/pdf/2202.07256v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.08677v2","updated":"2022-12-21T10:05:00Z","published":"2021-08-19T13:38:43Z","title":"Order Optimal Bounds for One-Shot Federated Learning over non-Convex\n  Loss Functions","summary":"  We consider the problem of federated learning in a one-shot setting in which\nthere are $m$ machines, each observing $n$ sample functions from an unknown\ndistribution on non-convex loss functions. Let\n$F:[-1,1]^d\\rightarrow\\mathbb{R}$ be the expected loss function with respect to\nthis unknown distribution. The goal is to find an estimate of the minimizer of\n$F$. Based on its observations, each machine generates a signal of bounded\nlength $B$ and sends it to a server. The server collects signals of all\nmachines and outputs an estimate of the minimizer of $F$. We show that the\nexpected loss of any algorithm is lower bounded by\n$\\max\\big(1/(\\sqrt{n}(mB)^{1/d}), 1/\\sqrt{mn}\\big)$, up to a logarithmic\nfactor. We then prove that this lower bound is order optimal in $m$ and $n$ by\npresenting a distributed learning algorithm, called Multi-Resolution Estimator\nfor Non-Convex loss function (MRE-NC), whose expected loss matches the lower\nbound for large $mn$ up to polylogarithmic factors.\n","authors":["Arsalan Sharifnassab","Saber Salehkaleybar","S. Jamaloddin Golestani"],"pdf_url":"https://arxiv.org/pdf/2108.08677v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10888v1","updated":"2022-12-21T09:58:14Z","published":"2022-12-21T09:58:14Z","title":"A Survey of Mix-based Data Augmentation: Taxonomy, Methods,\n  Applications, and Explainability","summary":"  Data augmentation (DA) is indispensable in modern machine learning and deep\nneural networks. The basic idea of DA is to construct new training data to\nimprove the model's generalization by adding slightly disturbed versions of\nexisting data or synthesizing new data. In this work, we review a small but\nessential subset of DA -- Mix-based Data Augmentation (MixDA) that generates\nnovel samples by mixing multiple examples. Unlike conventional DA approaches\nbased on a single-sample operation or requiring domain knowledge, MixDA is more\ngeneral in creating a broad spectrum of new data and has received increasing\nattention in the community. We begin with proposing a new taxonomy classifying\nMixDA into, Mixup-based, Cutmix-based, and hybrid approaches according to a\nhierarchical view of the data mix. Various MixDA techniques are then\ncomprehensively reviewed in a more fine-grained way. Owing to its\ngeneralization, MixDA has penetrated a variety of applications which are also\ncompletely reviewed in this work. We also examine why MixDA works from\ndifferent aspects of improving model performance, generalization, and\ncalibration while explaining the model behavior based on the properties of\nMixDA. Finally, we recapitulate the critical findings and fundamental\nchallenges of current MixDA studies, and outline the potential directions for\nfuture works. Different from previous related works that summarize the DA\napproaches in a specific domain (e.g., images or natural language processing)\nor only review a part of MixDA studies, we are the first to provide a\nsystematical survey of MixDA in terms of its taxonomy, methodology,\napplications, and explainability. This work can serve as a roadmap to MixDA\ntechniques and application reviews while providing promising directions for\nresearchers interested in this exciting area.\n","authors":["Chengtai Cao","Fan Zhou","Yurou Dai","Jianping Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07413v3","updated":"2022-12-21T09:47:49Z","published":"2022-09-15T16:10:16Z","title":"EZNAS: Evolving Zero Cost Proxies For Neural Architecture Scoring","summary":"  Neural Architecture Search (NAS) has significantly improved productivity in\nthe design and deployment of neural networks (NN). As NAS typically evaluates\nmultiple models by training them partially or completely, the improved\nproductivity comes at the cost of significant carbon footprint. To alleviate\nthis expensive training routine, zero-shot/cost proxies analyze an NN at\ninitialization to generate a score, which correlates highly with its true\naccuracy. Zero-cost proxies are currently designed by experts conducting\nmultiple cycles of empirical testing on possible algorithms, datasets, and\nneural architecture design spaces. This experimentation lowers productivity and\nis an unsustainable approach towards zero-cost proxy design as deep learning\nuse-cases diversify in nature. Additionally, existing zero-cost proxies fail to\ngeneralize across neural architecture design spaces. In this paper, we propose\na genetic programming framework to automate the discovery of zero-cost proxies\nfor neural architecture scoring. Our methodology efficiently discovers an\ninterpretable and generalizable zero-cost proxy that gives state of the art\nscore-accuracy correlation on all datasets and search spaces of NASBench-201\nand Network Design Spaces (NDS). We believe that this research indicates a\npromising direction towards automatically discovering zero-cost proxies that\ncan work across network architecture design spaces, datasets, and tasks.\n","authors":["Yash Akhauri","J. Pablo Munoz","Nilesh Jain","Ravi Iyer"],"pdf_url":"https://arxiv.org/pdf/2209.07413v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10876v1","updated":"2022-12-21T09:38:18Z","published":"2022-12-21T09:38:18Z","title":"Hyperparameters in Contextual RL are Highly Situational","summary":"  Although Reinforcement Learning (RL) has shown impressive results in games\nand simulation, real-world application of RL suffers from its instability under\nchanging environment conditions and hyperparameters. We give a first impression\nof the extent of this instability by showing that the hyperparameters found by\nautomatic hyperparameter optimization (HPO) methods are not only dependent on\nthe problem at hand, but even on how well the state describes the environment\ndynamics. Specifically, we show that agents in contextual RL require different\nhyperparameters if they are shown how environmental factors change. In\naddition, finding adequate hyperparameter configurations is not equally easy\nfor both settings, further highlighting the need for research into how\nhyperparameters influence learning and generalization in RL.\n","authors":["Theresa Eimer","Carolin Benjamins","Marius Lindauer"],"pdf_url":"https://arxiv.org/pdf/2212.10876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10873v1","updated":"2022-12-21T09:37:05Z","published":"2022-12-21T09:37:05Z","title":"Prompt-Augmented Linear Probing: Scaling Beyond The Limit of Few-shot\n  In-Context Learners","summary":"  Through in-context learning (ICL), large-scale language models are effective\nfew-shot learners without additional model fine-tuning. However, the ICL\nperformance does not scale well with the number of available training samples\nas it is limited by the inherent input length constraint of the underlying\nlanguage model. Meanwhile, many studies have revealed that language models are\nalso powerful feature extractors, allowing them to be utilized in a black-box\nmanner and enabling the linear probing paradigm, where lightweight\ndiscriminators are trained on top of the pre-extracted input representations.\nThis paper proposes prompt-augmented linear probing (PALP), a hybrid of linear\nprobing and ICL, which leverages the best of both worlds. PALP inherits the\nscalability of linear probing and the capability of enforcing language models\nto derive more meaningful representations via tailoring input into a more\nconceivable form. Throughout in-depth investigations on various datasets, we\nverified that PALP significantly enhances the input representations closing the\ngap between ICL in the data-hungry scenario and fine-tuning in the\ndata-abundant scenario with little training overhead, potentially making PALP a\nstrong alternative in a black-box scenario.\n","authors":["Hyunsoo Cho","Hyuhng Joon Kim","Junyeob Kim","Sang-Woo Lee","Sang-goo Lee","Kang Min Yoo","Taeuk Kim"],"pdf_url":"https://arxiv.org/pdf/2212.10873v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2212.10869v1","updated":"2022-12-21T09:26:33Z","published":"2022-12-21T09:26:33Z","title":"5G Long-Term and Large-Scale Mobile Traffic Forecasting","summary":"  It is crucial for the service provider to comprehend and forecast mobile\ntraffic in large-scale cellular networks in order to govern and manage\nmechanisms for base station placement, load balancing, and network planning.\nThe purpose of this article is to extract and simulate traffic patterns from\nmore than 14,000 cells that have been installed in different metropolitan\nareas. To do this, we create, implement, and assess a method in which cells are\nfirst categorized by their point of interest and then clustered based on the\ntemporal distribution of cells in each region. The proposed model has been\ntested using real-world 5G mobile traffic datasets collected over 31 weeks in\nvarious cities. We found that our proposed model performed well in predicting\nmobile traffic patterns up to 2 weeks in advance. Our model outperformed the\nbase model in most areas of interest and generally achieved up to 15\\% less\nprediction error compared to the na\\\"ive approach. This indicates that our\napproach is effective in predicting mobile traffic patterns in large-scale\ncellular networks.\n","authors":["Ufuk Uyan","M. Tugberk Isyapar","Mahiye Uluyagmur Ozturk"],"pdf_url":"https://arxiv.org/pdf/2212.10869v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10865v1","updated":"2022-12-21T09:15:34Z","published":"2022-12-21T09:15:34Z","title":"Temporal Disaggregation of the Cumulative Grass Growth","summary":"  Information on the grass growth over a year is essential for some models\nsimulating the use of this resource to feed animals on pasture or at barn with\nhay or grass silage. Unfortunately, this information is rarely available. The\nchallenge is to reconstruct grass growth from two sources of information: usual\ndaily climate data (rainfall, radiation, etc.) and cumulative growth over the\nyear. We have to be able to capture the effect of seasonal climatic events\nwhich are known to distort the growth curve within the year. In this paper, we\nformulate this challenge as a problem of disaggregating the cumulative growth\ninto a time series. To address this problem, our method applies time series\nforecasting using climate information and grass growth from previous time\nsteps. Several alternatives of the method are proposed and compared\nexperimentally using a database generated from a grassland process-based model.\nThe results show that our method can accurately reconstruct the time series,\nindependently of the use of the cumulative growth information.\n","authors":["Thomas Guyet","Laurent Spillemaecker","Simon Malinowski","Anne-Isabelle Graux"],"pdf_url":"https://arxiv.org/pdf/2212.10865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10861v1","updated":"2022-12-21T09:08:19Z","published":"2022-12-21T09:08:19Z","title":"PABAU: Privacy Analysis of Biometric API Usage","summary":"  Biometric data privacy is becoming a major concern for many organizations in\nthe age of big data, particularly in the ICT sector, because it may be easily\nexploited in apps. Most apps utilize biometrics by accessing common application\nprogramming interfaces (APIs); hence, we aim to categorize their usage. The\ncategorization based on behavior may be closely correlated with the sensitive\nprocessing of a user's biometric data, hence highlighting crucial biometric\ndata privacy assessment concerns. We propose PABAU, Privacy Analysis of\nBiometric API Usage. PABAU learns semantic features of methods in biometric\nAPIs and uses them to detect and categorize the usage of biometric API\nimplementation in the software according to their privacy-related behaviors.\nThis technique bridges the communication and background knowledge gap between\ntechnical and non-technical individuals in organizations by providing an\nautomated method for both parties to acquire a rapid understanding of the\nessential behaviors of biometric API in apps, as well as future support to data\nprotection officers (DPO) with legal documentation, such as conducting a Data\nProtection Impact Assessment (DPIA).\n","authors":["Feiyang Tang"],"pdf_url":"https://arxiv.org/pdf/2212.10861v1.pdf","comment":"Accepted by The 8th IEEE International Conference on Privacy\n  Computing (PriComp 2022)"},{"id":"http://arxiv.org/abs/2212.09247v2","updated":"2022-12-21T08:58:14Z","published":"2022-12-19T04:49:26Z","title":"ColoristaNet for Photorealistic Video Style Transfer","summary":"  Photorealistic style transfer aims to transfer the artistic style of an image\nonto an input image or video while keeping photorealism. In this paper, we\nthink it's the summary statistics matching scheme in existing algorithms that\nleads to unrealistic stylization. To avoid employing the popular Gram loss, we\npropose a self-supervised style transfer framework, which contains a style\nremoval part and a style restoration part. The style removal network removes\nthe original image styles, and the style restoration network recovers image\nstyles in a supervised manner. Meanwhile, to address the problems in current\nfeature transformation methods, we propose decoupled instance normalization to\ndecompose feature transformation into style whitening and restylization. It\nworks quite well in ColoristaNet and can transfer image styles efficiently\nwhile keeping photorealism. To ensure temporal coherency, we also incorporate\noptical flow methods and ConvLSTM to embed contextual information. Experiments\ndemonstrates that ColoristaNet can achieve better stylization effects when\ncompared with state-of-the-art algorithms.\n","authors":["Xiaowen Qiu","Ruize Xu","Boan He","Yingtao Zhang","Wenqiang Zhang","Weifeng Ge"],"pdf_url":"https://arxiv.org/pdf/2212.09247v2.pdf","comment":"30 pages, 29 figures"},{"id":"http://arxiv.org/abs/2212.10847v1","updated":"2022-12-21T08:45:32Z","published":"2022-12-21T08:45:32Z","title":"VCNet: A self-explaining model for realistic counterfactual generation","summary":"  Counterfactual explanation is a common class of methods to make local\nexplanations of machine learning decisions. For a given instance, these methods\naim to find the smallest modification of feature values that changes the\npredicted decision made by a machine learning model. One of the challenges of\ncounterfactual explanation is the efficient generation of realistic\ncounterfactuals. To address this challenge, we propose VCNet-Variational\nCounter Net-a model architecture that combines a predictor and a counterfactual\ngenerator that are jointly trained, for regression or classification tasks.\nVCNet is able to both generate predictions, and to generate counterfactual\nexplanations without having to solve another minimisation problem. Our\ncontribution is the generation of counterfactuals that are close to the\ndistribution of the predicted class. This is done by learning a variational\nautoencoder conditionally to the output of the predictor in a join-training\nfashion. We present an empirical evaluation on tabular datasets and across\nseveral interpretability metrics. The results are competitive with the\nstate-of-the-art method.\n","authors":["Victor Guyomard","Françoise Fessant","Thomas Guyet","Tassadit Bouadi","Alexandre Termier"],"pdf_url":"https://arxiv.org/pdf/2212.10847v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10844v1","updated":"2022-12-21T08:36:02Z","published":"2022-12-21T08:36:02Z","title":"Greenhouse gases emissions: estimating corporate non-reported emissions\n  using interpretable machine learning","summary":"  As of 2022, greenhouse gases (GHG) emissions reporting and auditing are not\nyet compulsory for all companies and methodologies of measurement and\nestimation are not unified. We propose a machine learning-based model to\nestimate scope 1 and scope 2 GHG emissions of companies not reporting them yet.\nOur model, specifically designed to be transparent and completely adapted to\nthis use case, is able to estimate emissions for a large universe of companies.\nIt shows good out-of-sample global performances as well as good out-of-sample\ngranular performances when evaluating it by sectors, by countries or by\nrevenues buckets. We also compare our results to those of other providers and\nfind our estimates to be more accurate. Thanks to the proposed explainability\ntools using Shapley values, our model is fully interpretable, the user being\nable to understand which factors split explain the GHG emissions for each\nparticular company.\n","authors":["Jeremi Assael","Thibaut Heurtebize","Laurent Carlier","François Soupé"],"pdf_url":"https://arxiv.org/pdf/2212.10844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10841v1","updated":"2022-12-21T08:30:24Z","published":"2022-12-21T08:30:24Z","title":"Predicting the Score of Atomic Candidate OWL Class Axioms","summary":"  Candidate axiom scoring is the task of assessing the acceptability of a\ncandidate axiom against the evidence provided by known facts or data. The\nability to score candidate axioms reliably is required for automated schema or\nontology induction, but it can also be valuable for ontology and/or knowledge\ngraph validation. Accurate axiom scoring heuristics are often computationally\nexpensive, which is an issue if you wish to use them in iterative search\ntechniques like level-wise generate-and-test or evolutionary algorithms, which\nrequire scoring a large number of candidate axioms. We address the problem of\ndeveloping a predictive model as a substitute for reasoning that predicts the\npossibility score of candidate class axioms and is quick enough to be employed\nin such situations. We use a semantic similarity measure taken from an\nontology's subsumption structure for this purpose. We show that the approach\nprovided in this work can accurately learn the possibility scores of candidate\nOWL class axioms and that it can do so for a variety of OWL class axioms.\n","authors":["Ali Ballout","Andrea G B Tettamanzi","Célia da Costa Pereira"],"pdf_url":"https://arxiv.org/pdf/2212.10841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10839v1","updated":"2022-12-21T08:27:49Z","published":"2022-12-21T08:27:49Z","title":"Crab: Learning Certifiably Fair Predictive Models in the Presence of\n  Selection Bias","summary":"  A recent explosion of research focuses on developing methods and tools for\nbuilding fair predictive models. However, most of this work relies on the\nassumption that the training and testing data are representative of the target\npopulation on which the model will be deployed. However, real-world training\ndata often suffer from selection bias and are not representative of the target\npopulation for many reasons, including the cost and feasibility of collecting\nand labeling data, historical discrimination, and individual biases.\n  In this paper, we introduce a new framework for certifying and ensuring the\nfairness of predictive models trained on biased data. We take inspiration from\nquery answering over incomplete and inconsistent databases to present and\nformalize the problem of consistent range approximation (CRA) of answers to\nqueries about aggregate information for the target population. We aim to\nleverage background knowledge about the data collection process, biased data,\nand limited or no auxiliary data sources to compute a range of answers for\naggregate queries over the target population that are consistent with available\ninformation. We then develop methods that use CRA of such aggregate queries to\nbuild predictive models that are certifiably fair on the target population even\nwhen no external information about that population is available during\ntraining. We evaluate our methods on real data and demonstrate improvements\nover state of the art. Significantly, we show that enforcing fairness using our\nmethods can lead to predictive models that are not only fair, but more accurate\non the target population.\n","authors":["Jiongli Zhu","Nazanin Sabri","Sainyam Galhotra","Babak Salimi"],"pdf_url":"https://arxiv.org/pdf/2212.10839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10836v1","updated":"2022-12-21T08:13:43Z","published":"2022-12-21T08:13:43Z","title":"Towards Rapid Prototyping and Comparability in Active Learning for Deep\n  Object Detection","summary":"  Active learning as a paradigm in deep learning is especially important in\napplications involving intricate perception tasks such as object detection\nwhere labels are difficult and expensive to acquire. Development of active\nlearning methods in such fields is highly computationally expensive and time\nconsuming which obstructs the progression of research and leads to a lack of\ncomparability between methods. In this work, we propose and investigate a\nsandbox setup for rapid development and transparent evaluation of active\nlearning in deep object detection. Our experiments with commonly used\nconfigurations of datasets and detection architectures found in the literature\nshow that results obtained in our sandbox environment are representative of\nresults on standard configurations. The total compute time to obtain results\nand assess the learning behavior can thereby be reduced by factors of up to 14\nwhen comparing with Pascal VOC and up to 32 when comparing with BDD100k. This\nallows for testing and evaluating data acquisition and labeling strategies in\nunder half a day and contributes to the transparency and development speed in\nthe field of active learning for object detection.\n","authors":["Tobias Riedlinger","Marius Schubert","Karsten Kahl","Hanno Gottschalk","Matthias Rottmann"],"pdf_url":"https://arxiv.org/pdf/2212.10836v1.pdf","comment":"17 pages, 12 figures, 9 tables"},{"id":"http://arxiv.org/abs/2211.05719v3","updated":"2022-12-21T08:12:46Z","published":"2022-11-10T17:37:04Z","title":"MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal\n  Open-domain Conversation","summary":"  Responding with multi-modal content has been recognized as an essential\ncapability for an intelligent conversational agent. In this paper, we introduce\nthe MMDialog dataset to better facilitate multi-modal conversation. MMDialog is\ncomposed of a curated set of 1.08 million real-world dialogues with 1.53\nmillion unique images across 4,184 topics. MMDialog has two main and unique\nadvantages. First, it is the largest multi-modal conversation dataset by the\nnumber of dialogues by 88x. Second, it contains massive topics to generalize\nthe open-domain. To build engaging dialogue system with this dataset, we\npropose and normalize two response producing tasks based on retrieval and\ngenerative scenarios. In addition, we build two baselines for above tasks with\nstate-of-the-art techniques and report their experimental performance. We also\npropose a novel evaluation metric MM-Relevance to measure the multi-modal\nresponses. Our dataset and scripts are available in\nhttps://github.com/victorsungo/MMDialog.\n","authors":["Jiazhan Feng","Qingfeng Sun","Can Xu","Pu Zhao","Yaming Yang","Chongyang Tao","Dongyan Zhao","Qingwei Lin"],"pdf_url":"https://arxiv.org/pdf/2211.05719v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07072v2","updated":"2022-12-21T07:36:49Z","published":"2022-12-14T07:48:42Z","title":"SMSMix: Sense-Maintained Sentence Mixup for Word Sense Disambiguation","summary":"  Word Sense Disambiguation (WSD) is an NLP task aimed at determining the\ncorrect sense of a word in a sentence from discrete sense choices. Although\ncurrent systems have attained unprecedented performances for such tasks, the\nnonuniform distribution of word senses during training generally results in\nsystems performing poorly on rare senses. To this end, we consider data\naugmentation to increase the frequency of these least frequent senses (LFS) to\nreduce the distributional bias of senses during training. We propose\nSense-Maintained Sentence Mixup (SMSMix), a novel word-level mixup method that\nmaintains the sense of a target word. SMSMix smoothly blends two sentences\nusing mask prediction while preserving the relevant span determined by saliency\nscores to maintain a specific word's sense. To the best of our knowledge, this\nis the first attempt to apply mixup in NLP while preserving the meaning of a\nspecific word. With extensive experiments, we validate that our augmentation\nmethod can effectively give more information about rare senses during training\nwith maintained target sense label.\n","authors":["Hee Suk Yoon","Eunseop Yoon","John Harvill","Sunjae Yoon","Mark Hasegawa-Johnson","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2212.07072v2.pdf","comment":"EMNLP2022"},{"id":"http://arxiv.org/abs/2212.10822v1","updated":"2022-12-21T07:24:03Z","published":"2022-12-21T07:24:03Z","title":"Complete the Missing Half: Augmenting Aggregation Filtering with\n  Diversification for Graph Convolutional Neural Networks","summary":"  The core operation of current Graph Neural Networks (GNNs) is the aggregation\nenabled by the graph Laplacian or message passing, which filters the\nneighborhood information of nodes. Though effective for various tasks, in this\npaper, we show that they are potentially a problematic factor underlying all\nGNN models for learning on certain datasets, as they force the node\nrepresentations similar, making the nodes gradually lose their identity and\nbecome indistinguishable. Hence, we augment the aggregation operations with\ntheir dual, i.e. diversification operators that make the node more distinct and\npreserve the identity. Such augmentation replaces the aggregation with a\ntwo-channel filtering process that, in theory, is beneficial for enriching the\nnode representations. In practice, the proposed two-channel filters can be\neasily patched on existing GNN methods with diverse training strategies,\nincluding spectral and spatial (message passing) methods. In the experiments,\nwe observe desired characteristics of the models and significant performance\nboost upon the baselines on 9 node classification tasks.\n","authors":["Sitao Luan","Mingde Zhao","Chenqing Hua","Xiao-Wen Chang","Doina Precup"],"pdf_url":"https://arxiv.org/pdf/2212.10822v1.pdf","comment":"Accepted as Oral Presentation at NeurIPS 2022 New Frontiers in Graph\n  Learning Workshop (NeurIPS GLFrontiers 2022)"},{"id":"http://arxiv.org/abs/2212.09567v2","updated":"2022-12-21T06:57:32Z","published":"2022-12-19T15:59:00Z","title":"Answering Complex Logical Queries on Knowledge Graphs via Query\n  Computation Tree Optimization","summary":"  Answering complex logical queries on incomplete knowledge graphs is a\nchallenging task, and has been widely studied. Embedding-based methods require\ntraining on complex queries, and cannot generalize well to out-of-distribution\nquery structures. Recent work frames this task as an end-to-end optimization\nproblem, and it only requires a pretrained link predictor. However, due to the\nexponentially large combinatorial search space, the optimal solution can only\nbe approximated, limiting the final accuracy. In this work, we propose QTO\n(Query Computation Tree Optimization) that can efficiently find the exact\noptimal solution. QTO finds the optimal solution by a forward-backward\npropagation on the tree-like computation graph, i.e., query computation tree.\nIn particular, QTO utilizes the independence encoded in the query computation\ntree to reduce the search space, where only local computations are involved\nduring the optimization procedure. Experiments on 3 datasets show that QTO\nobtains state-of-the-art performance on complex query answering, outperforming\nprevious best results by an average of 22%. Moreover, QTO can interpret the\nintermediate solutions for each of the one-hop atoms in the query with over 90%\naccuracy.\n","authors":["Yushi Bai","Xin Lv","Juanzi Li","Lei Hou"],"pdf_url":"https://arxiv.org/pdf/2212.09567v2.pdf","comment":"Code is available at https://github.com/bys0318/QTO"},{"id":"http://arxiv.org/abs/2211.16006v3","updated":"2022-12-21T06:52:05Z","published":"2022-11-29T08:14:05Z","title":"Lie Group Forced Variational Integrator Networks for Learning and\n  Control of Robot Systems","summary":"  Incorporating prior knowledge of physics laws and structural properties of\ndynamical systems into the design of deep learning architectures has proven to\nbe a powerful technique for improving their computational efficiency and\ngeneralization capacity. Learning accurate models of robot dynamics is critical\nfor safe and stable control. Autonomous mobile robots, including wheeled,\naerial, and underwater vehicles, can be modeled as controlled Lagrangian or\nHamiltonian rigid-body systems evolving on matrix Lie groups. In this paper, we\nintroduce a new structure-preserving deep learning architecture, the Lie group\nForced Variational Integrator Network (LieFVIN), capable of learning controlled\nLagrangian or Hamiltonian dynamics on Lie groups, either from position-velocity\nor position-only data. By design, LieFVINs preserve both the Lie group\nstructure on which the dynamics evolve and the symplectic structure underlying\nthe Hamiltonian or Lagrangian systems of interest. The proposed architecture\nlearns surrogate discrete-time flow maps allowing accurate and fast prediction\nwithout numerical-integrator, neural-ODE, or adjoint techniques, which are\nneeded for vector fields. Furthermore, the learnt discrete-time dynamics can be\nutilized with computationally scalable discrete-time (optimal) control\nstrategies.\n","authors":["Valentin Duruisseaux","Thai Duong","Melvin Leok","Nikolay Atanasov"],"pdf_url":"https://arxiv.org/pdf/2211.16006v3.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2212.10802v1","updated":"2022-12-21T06:48:39Z","published":"2022-12-21T06:48:39Z","title":"Semi-Supervised Bifold Teacher-Student Learning for Indoor Presence\n  Detection Under Time-Varying CSI","summary":"  In recent years, there have been abundant researches focused on indoor human\npresence detection based on laborious supervised learning (SL) and channel\nstate information (CSI). These existing studies adopt spatial information of\nCSI to improve detection accuracy. However, channel is susceptible to arbitrary\nenvironmental changes in practice, such as the object movement, atmospheric\nfactors and machine rebooting, which leads to degraded prediction accuracy.\nHowever, the existing SL-based methods require to re-train a new model with\ntime-consuming labeling. Therefore, designing a semi-supervised learning (SSL)\nbased scheme by continuously monitoring model \"life-cycle\" becomes compellingly\nimperative. In this paper, we propose bifold teacher-student (BTS) learning for\npresence detection system, which combines SSL by utilizing partial labeled and\nunlabeled dataset. The proposed primal-dual teacher-student network is capable\nof intelligently learning spatial and temporal features from labeled and\nunlabeled CSI. Additionally, the enhanced penalized loss function leveraging\nentropy and distance measure can distinguish the drifted data, i.e., features\nof new dataset are affected by time-varying effect and are alternated from the\noriginal distribution. The experimental results demonstrate that the proposed\nBTS system can sustain the asymptotic accuracy after retraining the model with\nunlabeled data. Moreover, label-free BTS outperforms the existing SSL-based\nmodels in terms of the highest detection accuracy, while achieving the similar\nperformance of SL-based methods.\n","authors":["Li-Hsiang Shen","Kai-Jui Chen","An-Hung Hsiao","Kai-Ten Feng"],"pdf_url":"https://arxiv.org/pdf/2212.10802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10789v1","updated":"2022-12-21T06:18:31Z","published":"2022-12-21T06:18:31Z","title":"Multi-modal Molecule Structure-text Model for Text-based Retrieval and\n  Editing","summary":"  There is increasing adoption of artificial intelligence in drug discovery.\nHowever, existing works use machine learning to mainly utilize the chemical\nstructures of molecules yet ignore the vast textual knowledge available in\nchemistry. Incorporating textual knowledge enables us to realize new drug\ndesign objectives, adapt to text-based instructions, and predict complex\nbiological activities. We present a multi-modal molecule structure-text model,\nMoleculeSTM, by jointly learning molecule's chemical structures and textual\ndescriptions via a contrastive learning strategy. To train MoleculeSTM, we\nconstruct the largest multi-modal dataset to date, namely PubChemSTM, with over\n280K chemical structure-text pairs. To demonstrate the effectiveness and\nutility of MoleculeSTM, we design two challenging zero-shot tasks based on text\ninstructions, including structure-text retrieval and molecule editing.\nMoleculeSTM possesses two main properties: open vocabulary and compositionality\nvia natural language. In experiments, MoleculeSTM obtains the state-of-the-art\ngeneralization ability to novel biochemical concepts across various benchmarks.\n","authors":["Shengchao Liu","Weili Nie","Chengpeng Wang","Jiarui Lu","Zhuoran Qiao","Ling Liu","Jian Tang","Chaowei Xiao","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2212.10789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10788v1","updated":"2022-12-21T06:17:45Z","published":"2022-12-21T06:17:45Z","title":"GraphIX: Graph-based In silico XAI(explainable artificial intelligence)\n  for drug repositioning from biopharmaceutical network","summary":"  Drug repositioning holds great promise because it can reduce the time and\ncost of new drug development. While drug repositioning can omit various R&D\nprocesses, confirming pharmacological effects on biomolecules is essential for\napplication to new diseases. Biomedical explainability in a drug repositioning\nmodel can support appropriate insights in subsequent in-depth studies. However,\nthe validity of the XAI methodology is still under debate, and the\neffectiveness of XAI in drug repositioning prediction applications remains\nunclear. In this study, we propose GraphIX, an explainable drug repositioning\nframework using biological networks, and quantitatively evaluate its\nexplainability. GraphIX first learns the network weights and node features\nusing a graph neural network from known drug indication and knowledge graph\nthat consists of three types of nodes (but not given node type information):\ndisease, drug, and protein. Analysis of the post-learning features showed that\nnode types that were not known to the model beforehand are distinguished\nthrough the learning process based on the graph structure. From the learned\nweights and features, GraphIX then predicts the disease-drug association and\ncalculates the contribution values of the nodes located in the neighborhood of\nthe predicted disease and drug. We hypothesized that the neighboring protein\nnode to which the model gave a high contribution is important in understanding\nthe actual pharmacological effects. Quantitative evaluation of the validity of\nprotein nodes' contribution using a real-world database showed that the high\ncontribution proteins shown by GraphIX are reasonable as a mechanism of drug\naction. GraphIX is a framework for evidence-based drug discovery that can\npresent to users new disease-drug associations and identify the protein\nimportant for understanding its pharmacological effects from a large and\ncomplex knowledge base.\n","authors":["Atsuko Takagi","Mayumi Kamada","Eri Hamatani","Ryosuke Kojima","Yasushi Okuno"],"pdf_url":"https://arxiv.org/pdf/2212.10788v1.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2207.08412v2","updated":"2022-12-21T06:11:44Z","published":"2022-07-18T07:21:56Z","title":"Multi-branch Cascaded Swin Transformers with Attention to k-space\n  Sampling Pattern for Accelerated MRI Reconstruction","summary":"  Global correlations are widely seen in human anatomical structures due to\nsimilarity across tissues and bones. These correlations are reflected in\nmagnetic resonance imaging (MRI) scans as a result of close-range proton\ndensity and T1/T2 parameters. Furthermore, to achieve accelerated MRI, k-space\ndata are undersampled which causes global aliasing artifacts. Convolutional\nneural network (CNN) models are widely utilized for accelerated MRI\nreconstruction, but those models are limited in capturing global correlations\ndue to the intrinsic locality of the convolution operation. The\nself-attention-based transformer models are capable of capturing global\ncorrelations among image features, however, the current contributions of\ntransformer models for MRI reconstruction are minute. The existing\ncontributions mostly provide CNN-transformer hybrid solutions and rarely\nleverage the physics of MRI. In this paper, we propose a physics-based\nstand-alone (convolution free) transformer model titled, the Multi-head\nCascaded Swin Transformers (McSTRA) for accelerated MRI reconstruction. McSTRA\ncombines several interconnected MRI physics-related concepts with the\ntransformer networks: it exploits global MR features via the shifted window\nself-attention mechanism; it extracts MR features belonging to different\nspectral components separately using a multi-head setup; it iterates between\nintermediate de-aliasing and k-space correction via a cascaded network with\ndata consistency in k-space and intermediate loss computations; furthermore, we\npropose a novel positional embedding generation mechanism to guide\nself-attention utilizing the point spread function corresponding to the\nundersampling mask. Our model significantly outperforms state-of-the-art MRI\nreconstruction methods both visually and quantitatively while depicting\nimproved resolution and removal of aliasing artifacts.\n","authors":["Mevan Ekanayake","Kamlesh Pawar","Mehrtash Harandi","Gary Egan","Zhaolin Chen"],"pdf_url":"https://arxiv.org/pdf/2207.08412v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10786v1","updated":"2022-12-21T06:00:22Z","published":"2022-12-21T06:00:22Z","title":"Multi-hop Evidence Retrieval for Cross-document Relation Extraction","summary":"  Relation Extraction (RE) has been extended to cross-document scenarios\nbecause many relations are not simply described in a single document. This\ninevitably brings the challenge of efficient open-space evidence retrieval to\nsupport the inference of cross-document relations, along with the challenge of\nmulti-hop reasoning on top of entities and evidence scattered in an open set of\ndocuments. To combat these challenges, we propose Mr.CoD, a multi-hop evidence\nretrieval method based on evidence path mining and ranking with adapted dense\nretrievers. We explore multiple variants of retrievers to show evidence\nretrieval is an essential part in cross-document RE. Experiments on CodRED show\nthat evidence retrieval with Mr.Cod effectively acquires cross-document\nevidence that essentially supports open-setting cross-document RE.\nAdditionally, we show that Mr.CoD facilitates evidence retrieval and boosts\nend-to-end RE performance with effective multi-hop reasoning in both closed and\nopen settings of RE.\n","authors":["Keming Lu","I-Hung Hsu","Wenxuan Zhou","Mingyu Derek Ma","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10786v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2204.13299v2","updated":"2022-12-21T05:32:03Z","published":"2022-04-28T06:14:21Z","title":"On the Convergence of Momentum-Based Algorithms for Federated Bilevel\n  Optimization Problems","summary":"  In this paper, we studied the federated bilevel optimization problem, which\nhas widespread applications in machine learning. In particular, we developed\ntwo momentum-based algorithms for optimizing this kind of problem and\nestablished the convergence rate of our two algorithms, providing the sample\nand communication complexities. Importantly, to the best of our knowledge, our\nconvergence rate is the first one achieving the linear speedup with respect to\nthe number of devices for federated bilevel optimization algorithms. At last,\nour extensive experimental results confirm the effectiveness of our two\nalgorithms.\n","authors":["Hongchang Gao"],"pdf_url":"https://arxiv.org/pdf/2204.13299v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10777v1","updated":"2022-12-21T05:27:23Z","published":"2022-12-21T05:27:23Z","title":"Hierarchically branched diffusion models for efficient and interpretable\n  multi-class conditional generation","summary":"  Diffusion models have achieved justifiable popularity by attaining\nstate-of-the-art performance in generating realistic objects from seemingly\narbitrarily complex data distributions, including when conditioning generation\non labels. Unfortunately, however, their iterative nature renders them very\ncomputationally inefficient during the sampling process. For the multi-class\nconditional generation problem, we propose a novel, structurally unique\nframework of diffusion models which are hierarchically branched according to\nthe inherent relationships between classes. In this work, we demonstrate that\nbranched diffusion models offer major improvements in efficiently generating\nsamples from multiple classes. We also showcase several other advantages of\nbranched diffusion models, including ease of extension to novel classes in a\ncontinual-learning setting, and a unique interpretability that offers insight\ninto these generative models. Branched diffusion models represent an\nalternative paradigm to their traditional linear counterparts, and can have\nlarge impacts in how we use diffusion models for efficient generation, online\nlearning, and scientific discovery.\n","authors":["Alex M. Tseng","Tommaso Biancalani","Max Shen","Gabriele Scalia"],"pdf_url":"https://arxiv.org/pdf/2212.10777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10774v1","updated":"2022-12-21T05:17:13Z","published":"2022-12-21T05:17:13Z","title":"Towards Efficient Visual Simplification of Computational Graphs in Deep\n  Neural Networks","summary":"  A computational graph in a deep neural network (DNN) denotes a specific data\nflow diagram (DFD) composed of many tensors and operators. Existing toolkits\nfor visualizing computational graphs are not applicable when the structure is\nhighly complicated and large-scale (e.g., BERT [1]). To address this problem,\nwe propose leveraging a suite of visual simplification techniques, including a\ncycle-removing method, a module-based edge-pruning algorithm, and an isomorphic\nsubgraph stacking strategy. We design and implement an interactive\nvisualization system that is suitable for computational graphs with up to 10\nthousand elements. Experimental results and usage scenarios demonstrate that\nour tool reduces 60% elements on average and hence enhances the performance for\nrecognizing and diagnosing DNN models. Our contributions are integrated into an\nopen-source DNN visualization toolkit, namely, MindInsight [2].\n","authors":["Rusheng Pan","Zhiyong Wang","Yating Wei","Han Gao","Gongchang Ou","Caleb Chen Cao","Jingli Xu","Tong Xu","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10765v1","updated":"2022-12-21T04:52:13Z","published":"2022-12-21T04:52:13Z","title":"Reward Bonuses with Gain Scheduling Inspired by Iterative Deepening\n  Search","summary":"  This paper introduces a novel method of adding intrinsic bonuses to\ntask-oriented reward function in order to efficiently facilitate reinforcement\nlearning search. While various bonuses have been designed to date, they are\nanalogous to the depth-first and breadth-first search algorithms in graph\ntheory. This paper, therefore, first designs two bonuses for each of them.\nThen, a heuristic gain scheduling is applied to the designed bonuses, inspired\nby the iterative deepening search, which is known to inherit the advantages of\nthe two search algorithms. The proposed method is expected to allow agent to\nefficiently reach the best solution in deeper states by gradually exploring\nunknown states. In three locomotion tasks with dense rewards and three simple\ntasks with sparse rewards, it is shown that the two types of bonuses contribute\nto the performance improvement of the different tasks complementarily. In\naddition, by combining them with the proposed gain scheduling, all tasks can be\naccomplished with high performance.\n","authors":["Taisuke Kobayashi"],"pdf_url":"https://arxiv.org/pdf/2212.10765v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.10764v1","updated":"2022-12-21T04:49:55Z","published":"2022-12-21T04:49:55Z","title":"Learning List-Level Domain-Invariant Representations for Ranking","summary":"  Domain adaptation aims to transfer the knowledge acquired by models trained\non (data-rich) source domains to (low-resource) target domains, for which a\npopular method is invariant representation learning. While they have been\nstudied extensively for classification and regression problems, how they apply\nto ranking problems, where the data and metrics have a list structure, is not\nwell understood. Theoretically, we establish a domain adaptation generalization\nbound for ranking under listwise metrics such as MRR and NDCG. The bound\nsuggests an adaptation method via learning list-level domain-invariant feature\nrepresentations, whose benefits are empirically demonstrated by unsupervised\ndomain adaptation experiments on real-world ranking tasks, including passage\nreranking. A key message is that for domain adaptation, the representations\nshould be analyzed at the same level at which the metric is computed, as we\nshow that learning invariant representations at the list level is most\neffective for adaptation on ranking problems.\n","authors":["Ruicheng Xian","Honglei Zhuang","Zhen Qin","Hamed Zamani","Jing Lu","Ji Ma","Kai Hui","Han Zhao","Xuanhui Wang","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2212.10764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.09231v3","updated":"2022-12-21T03:57:23Z","published":"2021-12-16T22:36:17Z","title":"Two-view Graph Neural Networks for Knowledge Graph Completion","summary":"  We present an effective graph neural network (GNN)-based knowledge graph\nembedding model, which we name WGE, to capture entity- and relation-focused\ngraph structures. Given a knowledge graph, WGE builds a single undirected\nentity-focused graph that views entities as nodes. WGE also constructs another\nsingle undirected graph from relation-focused constraints, which views entities\nand relations as nodes. WGE then proposes a GNN-based architecture to better\nlearn vector representations of entities and relations from these two single\nentity- and relation-focused graphs. WGE feeds the learned entity and relation\nrepresentations into a weighted score function to return the triple scores for\nknowledge graph completion. Experimental results show that WGE outperforms\ncompetitive baselines, obtaining state-of-the-art performances on seven\nbenchmark datasets for knowledge graph completion.\n","authors":["Vinh Tong","Dai Quoc Nguyen","Dinh Phung","Dat Quoc Nguyen"],"pdf_url":"https://arxiv.org/pdf/2112.09231v3.pdf","comment":"17 pages; 4 tables; 4 figures"},{"id":"http://arxiv.org/abs/2112.03555v2","updated":"2022-12-21T03:41:27Z","published":"2021-12-07T08:04:12Z","title":"FedDAG: Federated DAG Structure Learning","summary":"  To date, most directed acyclic graphs (DAGs) structure learning approaches\nrequire data to be stored in a central server. However, due to the\nconsideration of privacy protection, data owners gradually refuse to share\ntheir personalized raw data to avoid private information leakage, making this\ntask more troublesome by cutting off the first step. Thus, a puzzle arises:\n\\textit{how do we discover the underlying DAG structure from decentralized\ndata?} In this paper, focusing on the additive noise models (ANMs) assumption\nof data generation, we take the first step in developing a gradient-based\nlearning framework named FedDAG, which can learn the DAG structure without\ndirectly touching the local data and also can naturally handle the data\nheterogeneity. Our method benefits from a two-level structure of each local\nmodel. The first level structure learns the edges and directions of the graph\nand communicates with the server to get the model information from other\nclients during the learning procedure, while the second level structure\napproximates the mechanisms among variables and personally updates on its own\ndata to accommodate the data heterogeneity. Moreover, FedDAG formulates the\noverall learning task as a continuous optimization problem by taking advantage\nof an equality acyclicity constraint, which can be solved by gradient descent\nmethods to boost the searching efficiency. Extensive experiments on both\nsynthetic and real-world datasets verify the efficacy of the proposed method.\n","authors":["Erdun Gao","Junjia Chen","Li Shen","Tongliang Liu","Mingming Gong","Howard Bondell"],"pdf_url":"https://arxiv.org/pdf/2112.03555v2.pdf","comment":"Accepted to Transactions on Machine Learning Research"},{"id":"http://arxiv.org/abs/2107.13132v2","updated":"2022-12-21T03:09:06Z","published":"2021-07-28T02:16:14Z","title":"Unsupervised Learning of Neurosymbolic Encoders","summary":"  We present a framework for the unsupervised learning of neurosymbolic\nencoders, which are encoders obtained by composing neural networks with\nsymbolic programs from a domain-specific language. Our framework naturally\nincorporates symbolic expert knowledge into the learning process, which leads\nto more interpretable and factorized latent representations compared to fully\nneural encoders. We integrate modern program synthesis techniques with the\nvariational autoencoding (VAE) framework, in order to learn a neurosymbolic\nencoder in conjunction with a standard decoder. The programmatic descriptions\nfrom our encoders can benefit many analysis workflows, such as in behavior\nmodeling where interpreting agent actions and movements is important. We\nevaluate our method on learning latent representations for real-world\ntrajectory data from animal biology and sports analytics. We show that our\napproach offers significantly better separation of meaningful categories than\nstandard VAEs and leads to practical gains on downstream analysis tasks, such\nas for behavior classification.\n","authors":["Eric Zhan","Jennifer J. Sun","Ann Kennedy","Yisong Yue","Swarat Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2107.13132v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.02611v2","updated":"2022-12-21T03:02:43Z","published":"2021-12-05T16:17:21Z","title":"Multi-View Active Learning for Short Text Classification in\n  User-Generated Data","summary":"  Mining user-generated data often suffers from the lack of enough labeled\ndata, short document lengths, and the informal user language. In this paper, we\npropose a novel active learning model to overcome these obstacles in the tasks\ntailored for query phrases--e.g., detecting positive reports of natural\ndisasters. Our model has three novelties: 1) It is the first approach to employ\nmulti-view active learning in this domain. 2) It uses the Parzen-Rosenblatt\nwindow method to integrate the representativeness measure into multi-view\nactive learning. 3) It employs a query-by-committee strategy, based on the\nagreement between predictors, to address the usually noisy language of the\ndocuments in this domain. We evaluate our model in four publicly available\nTwitter datasets with distinctly different applications. We also compare our\nmodel with a wide range of baselines including those with multiple classifiers.\nThe experiments testify that our model is highly consistent and outperforms\nexisting models.\n","authors":["Payam Karisani","Negin Karisani","Li Xiong"],"pdf_url":"https://arxiv.org/pdf/2112.02611v2.pdf","comment":"EMNLP Findings 2022"},{"id":"http://arxiv.org/abs/2212.10735v1","updated":"2022-12-21T03:02:18Z","published":"2022-12-21T03:02:18Z","title":"NADBenchmarks -- a compilation of Benchmark Datasets for Machine\n  Learning Tasks related to Natural Disasters","summary":"  Climate change has increased the intensity, frequency, and duration of\nextreme weather events and natural disasters across the world. While the\nincreased data on natural disasters improves the scope of machine learning (ML)\nin this field, progress is relatively slow. One bottleneck is the lack of\nbenchmark datasets that would allow ML researchers to quantify their progress\nagainst a standard metric. The objective of this short paper is to explore the\nstate of benchmark datasets for ML tasks related to natural disasters,\ncategorizing them according to the disaster management cycle. We compile a list\nof existing benchmark datasets introduced in the past five years. We propose a\nweb platform - NADBenchmarks - where researchers can search for benchmark\ndatasets for natural disasters, and we develop a preliminary version of such a\nplatform using our compiled list. This paper is intended to aid researchers in\nfinding benchmark datasets to train their ML models on, and provide general\ndirections for topics where they can contribute new benchmark datasets.\n","authors":["Adiba Mahbub Proma","Md Saiful Islam","Stela Ciko","Raiyan Abdul Baten","Ehsan Hoque"],"pdf_url":"https://arxiv.org/pdf/2212.10735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.07513v2","updated":"2022-12-21T03:01:34Z","published":"2022-04-15T15:16:01Z","title":"Synthesizing Informative Training Samples with GAN","summary":"  Remarkable progress has been achieved in synthesizing photo-realistic images\nwith generative adversarial networks (GANs). Recently, GANs are utilized as the\ntraining sample generator when obtaining or storing real training data is\nexpensive even infeasible. However, traditional GANs generated images are not\nas informative as the real training samples when being used to train deep\nneural networks. In this paper, we propose a novel method to synthesize\nInformative Training samples with GAN (IT-GAN). Specifically, we freeze a\npre-trained GAN model and learn the informative latent vectors that correspond\nto informative training samples. The synthesized images are required to\npreserve information for training deep neural networks rather than visual\nreality or fidelity. Experiments verify that the deep neural networks can learn\nfaster and achieve better performance when being trained with our IT-GAN\ngenerated images. We also show that our method is a promising solution to\ndataset condensation problem.\n","authors":["Bo Zhao","Hakan Bilen"],"pdf_url":"https://arxiv.org/pdf/2204.07513v2.pdf","comment":"NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research,\n  https://openreview.net/forum?id=frAv0jtUMfS"},{"id":"http://arxiv.org/abs/2102.13196v2","updated":"2022-12-21T03:00:53Z","published":"2021-02-25T22:21:30Z","title":"Named Tensor Notation","summary":"  We propose a notation for tensors with named axes, which relieves the author,\nreader, and future implementers of machine learning models from the burden of\nkeeping track of the order of axes and the purpose of each. The notation makes\nit easy to lift operations on low-order tensors to higher order ones, for\nexample, from images to minibatches of images, or from an attention mechanism\nto multiple attention heads.\n  After a brief overview and formal definition of the notation, we illustrate\nit through several examples from modern machine learning, from building blocks\nlike attention and convolution to full models like Transformers and LeNet. We\nthen discuss differential calculus in our notation and compare with some\nalternative notations. Our proposals build on ideas from many previous papers\nand software libraries. We hope that our notation will encourage more authors\nto use named tensors, resulting in clearer papers and more precise\nimplementations.\n","authors":["David Chiang","Alexander M. Rush","Boaz Barak"],"pdf_url":"https://arxiv.org/pdf/2102.13196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10733v1","updated":"2022-12-21T03:00:18Z","published":"2022-12-21T03:00:18Z","title":"Scalable Hybrid Learning Techniques for Scientific Data Compression","summary":"  Data compression is becoming critical for storing scientific data because\nmany scientific applications need to store large amounts of data and post\nprocess this data for scientific discovery. Unlike image and video compression\nalgorithms that limit errors to primary data, scientists require compression\ntechniques that accurately preserve derived quantities of interest (QoIs). This\npaper presents a physics-informed compression technique implemented as an\nend-to-end, scalable, GPU-based pipeline for data compression that addresses\nthis requirement. Our hybrid compression technique combines machine learning\ntechniques and standard compression methods. Specifically, we combine an\nautoencoder, an error-bounded lossy compressor to provide guarantees on raw\ndata error, and a constraint satisfaction post-processing step to preserve the\nQoIs within a minimal error (generally less than floating point error).\n  The effectiveness of the data compression pipeline is demonstrated by\ncompressing nuclear fusion simulation data generated by a large-scale fusion\ncode, XGC, which produces hundreds of terabytes of data in a single day. Our\napproach works within the ADIOS framework and results in compression by a\nfactor of more than 150 while requiring only a few percent of the computational\nresources necessary for generating the data, making the overall approach highly\neffective for practical scenarios.\n","authors":["Tania Banerjee","Jong Choi","Jaemoon Lee","Qian Gong","Jieyang Chen","Scott Klasky","Anand Rangarajan","Sanjay Ranka"],"pdf_url":"https://arxiv.org/pdf/2212.10733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10729v1","updated":"2022-12-21T02:48:15Z","published":"2022-12-21T02:48:15Z","title":"UnICLAM:Contrastive Representation Learning with Adversarial Masking for\n  Unified and Interpretable Medical Vision Question Answering","summary":"  Medical Visual Question Answering (Medical-VQA) aims to answer clinical\nquestions regarding radiology images, assisting doctors with decision-making\noptions. Nevertheless, current Medical-VQA models learn cross-modal\nrepresentations through residing vision and texture encoders in dual separate\nspaces, which lead to indirect semantic alignment. In this paper, we propose\nUnICLAM, a Unified and Interpretable Medical-VQA model through Contrastive\nRepresentation Learning with Adversarial Masking. Specifically, to learn an\naligned image-text representation, we first establish a unified dual-stream\npre-training structure with the gradually soft-parameter sharing strategy.\nTechnically, the proposed strategy learns a constraint for the vision and\ntexture encoders to be close in a same space, which is gradually loosened as\nthe higher number of layers. Moreover, for grasping the semantic\nrepresentation, we extend the unified Adversarial Masking data augmentation\nstrategy to the contrastive representation learning of vision and text in a\nunified manner, alleviating the meaningless of the commonly used random mask.\nConcretely, while the encoder training minimizes the distance between the\noriginal feature and the masking feature, the adversarial masking model keeps\nadversarial learning to conversely maximize the distance. Furthermore, we also\nintuitively take a further exploration of the unified adversarial masking\nstrategy, which improves the potential ante-hoc interpretability with\nremarkable performance and efficiency. Experimental results on VQA-RAD and\nSLAKE public benchmarks demonstrate that UnICLAM outperforms the existing 11\nstate-of-the-art Medical-VQA models. More importantly, we make an additional\ndiscussion about the performance of UnICLAM in diagnosing heart failure,\nverifying that UnICLAM exhibits superior few-shot adaption performance in\npractical disease diagnosis.\n","authors":["Chenlu Zhan","Peng Peng","Hongsen Wang","Tao Chen","Hongwei Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10726v1","updated":"2022-12-21T02:41:40Z","published":"2022-12-21T02:41:40Z","title":"Beyond Contrastive Learning: A Variational Generative Model for\n  Multilingual Retrieval","summary":"  Contrastive learning has been successfully used for retrieval of semantically\naligned sentences, but it often requires large batch sizes or careful\nengineering to work well. In this paper, we instead propose a generative model\nfor learning multilingual text embeddings which can be used to retrieve or\nscore sentence pairs. Our model operates on parallel data in $N$ languages and,\nthrough an approximation we introduce, efficiently encourages source separation\nin this multilingual setting, separating semantic information that is shared\nbetween translations from stylistic or language-specific variation. We show\ncareful large-scale comparisons between contrastive and generation-based\napproaches for learning multilingual text embeddings, a comparison that has not\nbeen done to the best of our knowledge despite the popularity of these\napproaches. We evaluate this method on a suite of tasks including semantic\nsimilarity, bitext mining, and cross-lingual question retrieval -- the last of\nwhich we introduce in this paper. Overall, our Variational Multilingual\nSource-Separation Transformer (VMSST) model outperforms both a strong\ncontrastive and generative baseline on these tasks.\n","authors":["John Wieting","Jonathan H. Clark","William W. Cohen","Graham Neubig","Taylor Berg-Kirkpatrick"],"pdf_url":"https://arxiv.org/pdf/2212.10726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07944v2","updated":"2022-12-21T02:30:54Z","published":"2022-12-15T16:23:25Z","title":"Variable Clustering via Distributionally Robust Nodewise Regression","summary":"  We study a multi-factor block model for variable clustering and connect it to\nthe regularized subspace clustering by formulating a distributionally robust\nversion of the nodewise regression. To solve the latter problem, we derive a\nconvex relaxation, provide guidance on selecting the size of the robust region,\nand hence the regularization weighting parameter, based on the data, and\npropose an ADMM algorithm for implementation. We validate our method in an\nextensive simulation study. Finally, we propose and apply a variant of our\nmethod to stock return data, obtain interpretable clusters that facilitate\nportfolio selection and compare its out-of-sample performance with other\nclustering methods in an empirical study.\n","authors":["Kaizheng Wang","Xiao Xu","Xun Yu Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.07944v2.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2111.06586v2","updated":"2022-12-21T02:17:54Z","published":"2021-11-12T07:08:13Z","title":"AnchorGAE: General Data Clustering via $O(n)$ Bipartite Graph\n  Convolution","summary":"  Since the representative capacity of graph-based clustering methods is\nusually limited by the graph constructed on the original features, it is\nattractive to find whether graph neural networks (GNNs) can be applied to\naugment the capacity. The core problems mainly come from two aspects: (1) the\ngraph is unavailable in the most clustering scenes so that how to construct\nhigh-quality graphs on the non-graph data is usually the most important part;\n(2) given n samples, the graph-based clustering methods usually consume at\nleast $\\mathcal O(n^2)$ time to build graphs and the graph convolution requires\nnearly $\\mathcal O(n^2)$ for a dense graph and $\\mathcal O(|\\mathcal{E}|)$ for\na sparse one with $|\\mathcal{E}|$ edges. Accordingly, both graph-based\nclustering and GNNs suffer from the severe inefficiency problem. To tackle\nthese problems, we propose a novel clustering method, AnchorGAE, with the\nself-supervised estimation of graph and efficient graph convolution. We first\nshow how to convert a non-graph dataset into a graph dataset, by introducing\nthe generative graph model and anchors. We then show that the constructed\nbipartite graph can reduce the computational complexity of graph convolution\nfrom $\\mathcal O(n^2)$ and $\\mathcal O(|\\mathcal{E}|)$ to $\\mathcal O(n)$. The\nsucceeding steps for clustering can be easily designed as $\\mathcal O(n)$\noperations. Interestingly, the anchors naturally lead to siamese architecture\nwith the help of the Markov process. Furthermore, the estimated bipartite graph\nis updated dynamically according to the features extracted by GNN, to promote\nthe quality of the graph. However, we theoretically prove that the\nself-supervised paradigm frequently results in a collapse that often occurs\nafter 2-3 update iterations in experiments, especially when the model is\nwell-trained. A specific strategy is accordingly designed to prevent the\ncollapse.\n","authors":["Hongyuan Zhang","Jiankun Shi","Rui Zhang","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2111.06586v2.pdf","comment":"copyright 2022 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2212.10718v1","updated":"2022-12-21T02:06:26Z","published":"2022-12-21T02:06:26Z","title":"Interpretability and causal discovery of the machine learning models to\n  predict the production of CBM wells after hydraulic fracturing","summary":"  Machine learning approaches are widely studied in the production prediction\nof CBM wells after hydraulic fracturing, but merely used in practice due to the\nlow generalization ability and the lack of interpretability. A novel\nmethodology is proposed in this article to discover the latent causality from\nobserved data, which is aimed at finding an indirect way to interpret the\nmachine learning results. Based on the theory of causal discovery, a causal\ngraph is derived with explicit input, output, treatment and confounding\nvariables. Then, SHAP is employed to analyze the influence of the factors on\nthe production capability, which indirectly interprets the machine learning\nmodels. The proposed method can capture the underlying nonlinear relationship\nbetween the factors and the output, which remedies the limitation of the\ntraditional machine learning routines based on the correlation analysis of\nfactors. The experiment on the data of CBM shows that the detected relationship\nbetween the production and the geological/engineering factors by the presented\nmethod, is coincident with the actual physical mechanism. Meanwhile, compared\nwith traditional methods, the interpretable machine learning models have better\nperformance in forecasting production capability, averaging 20% improvement in\naccuracy.\n","authors":["Chao Min","Guoquan Wen","Liangjie Gou","Xiaogang Li","Zhaozhong Yang"],"pdf_url":"https://arxiv.org/pdf/2212.10718v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.14545v2","updated":"2022-12-21T02:01:04Z","published":"2022-05-28T23:59:50Z","title":"Functional Linear Regression of Cumulative Distribution Functions","summary":"  The estimation of cumulative distribution functions (CDFs) is an important\nlearning task with a great variety of downstream applications, such as risk\nassessments in predictions and decision making. In this paper, we study\nfunctional regression of contextual CDFs where each data point is sampled from\na linear combination of context dependent CDF basis functions. We propose\nfunctional ridge-regression-based estimation methods that estimate CDFs\naccurately everywhere. In particular, given $n$ samples with $d$ basis\nfunctions, we show estimation error upper bounds of $\\widetilde{O}(\\sqrt{d/n})$\nfor fixed design, random design, and adversarial context cases. We also derive\nmatching information theoretic lower bounds, establishing minimax optimality\nfor CDF functional regression. Furthermore, we remove the burn-in time in the\nrandom design setting using an alternative penalized estimator. Then, we\nconsider agnostic settings where there is a mismatch in the data generation\nprocess. We characterize the error of the proposed estimators in terms of the\nmismatched error, and show that the estimators are well-behaved under model\nmismatch. Finally, to complete our study, we formalize infinite dimensional\nmodels where the parameter space is an infinite dimensional Hilbert space, and\nestablish self-normalized estimation error upper bounds for this setting.\n","authors":["Qian Zhang","Anuran Makur","Kamyar Azizzadenesheli"],"pdf_url":"https://arxiv.org/pdf/2205.14545v2.pdf","comment":"62 pages, 2 figures"},{"id":"http://arxiv.org/abs/2212.10717v1","updated":"2022-12-21T01:52:17Z","published":"2022-12-21T01:52:17Z","title":"Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks","summary":"  We introduce camouflaged data poisoning attacks, a new attack vector that\narises in the context of machine unlearning and other settings when model\nretraining may be induced. An adversary first adds a few carefully crafted\npoints to the training dataset such that the impact on the model's predictions\nis minimal. The adversary subsequently triggers a request to remove a subset of\nthe introduced points at which point the attack is unleashed and the model's\npredictions are negatively affected. In particular, we consider clean-label\ntargeted attacks (in which the goal is to cause the model to misclassify a\nspecific test point) on datasets including CIFAR-10, Imagenette, and Imagewoof.\nThis attack is realized by constructing camouflage datapoints that mask the\neffect of a poisoned dataset.\n","authors":["Jimmy Z. Di","Jack Douglas","Jayadev Acharya","Gautam Kamath","Ayush Sekhari"],"pdf_url":"https://arxiv.org/pdf/2212.10717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2008.06595v4","updated":"2022-12-21T01:39:14Z","published":"2020-08-14T22:44:26Z","title":"Decision-making at Unsignalized Intersection for Autonomous Vehicles:\n  Left-turn Maneuver with Deep Reinforcement Learning","summary":"  Decision-making module enables autonomous vehicles to reach appropriate\nmaneuvers in the complex urban environments, especially the intersection\nsituations. This work proposes a deep reinforcement learning (DRL) based\nleft-turn decision-making framework at unsignalized intersection for autonomous\nvehicles. The objective of the studied automated vehicle is to make an\nefficient and safe left-turn maneuver at a four-way unsignalized intersection.\nThe exploited DRL methods include deep Q-learning (DQL) and double DQL.\nSimulation results indicate that the presented decision-making strategy could\nefficaciously reduce the collision rate and improve transport efficiency. This\nwork also reveals that the constructed left-turn control structure has a great\npotential to be applied in real-time.\n","authors":["Feng Wang","Dongjie Shi","Teng Liu","Xiaolin Tang"],"pdf_url":"https://arxiv.org/pdf/2008.06595v4.pdf","comment":"17 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.10712v1","updated":"2022-12-21T01:23:53Z","published":"2022-12-21T01:23:53Z","title":"Neighboring state-based RL Exploration","summary":"  Reinforcement Learning is a powerful tool to model decision-making processes.\nHowever, it relies on an exploration-exploitation trade-off that remains an\nopen challenge for many tasks. In this work, we study neighboring state-based,\nmodel-free exploration led by the intuition that, for an early-stage agent,\nconsidering actions derived from a bounded region of nearby states may lead to\nbetter actions when exploring. We propose two algorithms that choose\nexploratory actions based on a survey of nearby states, and find that one of\nour methods, ${\\rho}$-explore, consistently outperforms the Double DQN baseline\nin an discrete environment by 49\\% in terms of Eval Reward Return.\n","authors":["Jeffery Cheng","Kevin Li","Justin Lin","Pedro Pachuca"],"pdf_url":"https://arxiv.org/pdf/2212.10712v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.09991v2","updated":"2022-12-21T01:06:18Z","published":"2022-05-20T07:02:03Z","title":"Planning with Diffusion for Flexible Behavior Synthesis","summary":"  Model-based reinforcement learning methods often use learning only for the\npurpose of estimating an approximate dynamics model, offloading the rest of the\ndecision-making work to classical trajectory optimizers. While conceptually\nsimple, this combination has a number of empirical shortcomings, suggesting\nthat learned models may not be well-suited to standard trajectory optimization.\nIn this paper, we consider what it would look like to fold as much of the\ntrajectory optimization pipeline as possible into the modeling problem, such\nthat sampling from the model and planning with it become nearly identical. The\ncore of our technical approach lies in a diffusion probabilistic model that\nplans by iteratively denoising trajectories. We show how classifier-guided\nsampling and image inpainting can be reinterpreted as coherent planning\nstrategies, explore the unusual and useful properties of diffusion-based\nplanning methods, and demonstrate the effectiveness of our framework in control\nsettings that emphasize long-horizon decision-making and test-time flexibility.\n","authors":["Michael Janner","Yilun Du","Joshua B. Tenenbaum","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2205.09991v2.pdf","comment":"ICML 2022 (long talk). Project page and code at\n  https://diffusion-planning.github.io/"},{"id":"http://arxiv.org/abs/2212.10707v1","updated":"2022-12-21T00:56:50Z","published":"2022-12-21T00:56:50Z","title":"Extractive Text Summarization Using Generalized Additive Models with\n  Interactions for Sentence Selection","summary":"  Automatic Text Summarization (ATS) is becoming relevant with the growth of\ntextual data; however, with the popularization of public large-scale datasets,\nsome recent machine learning approaches have focused on dense models and\narchitectures that, despite producing notable results, usually turn out in\nmodels difficult to interpret. Given the challenge behind interpretable\nlearning-based text summarization and the importance it may have for evolving\nthe current state of the ATS field, this work studies the application of two\nmodern Generalized Additive Models with interactions, namely Explainable\nBoosting Machine and GAMI-Net, to the extractive summarization problem based on\nlinguistic features and binary classification.\n","authors":["Vinícius Camargo da Silva","João Paulo Papa","Kelton Augusto Pontara da Costa"],"pdf_url":"https://arxiv.org/pdf/2212.10707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10705v1","updated":"2022-12-21T00:52:43Z","published":"2022-12-21T00:52:43Z","title":"Control of Continuous Quantum Systems with Many Degrees of Freedom based\n  on Convergent Reinforcement Learning","summary":"  With the development of experimental quantum technology, quantum control has\nattracted increasing attention due to the realization of controllable\nartificial quantum systems. However, because quantum-mechanical systems are\noften too difficult to analytically deal with, heuristic strategies and\nnumerical algorithms which search for proper control protocols are adopted,\nand, deep learning, especially deep reinforcement learning (RL), is a promising\ngeneric candidate solution for the control problems. Although there have been a\nfew successful applications of deep RL to quantum control problems, most of the\nexisting RL algorithms suffer from instabilities and unsatisfactory\nreproducibility, and require a large amount of fine-tuning and a large\ncomputational budget, both of which limit their applicability. To resolve the\nissue of instabilities, in this dissertation, we investigate the\nnon-convergence issue of Q-learning. Then, we investigate the weakness of\nexisting convergent approaches that have been proposed, and we develop a new\nconvergent Q-learning algorithm, which we call the convergent deep Q network\n(C-DQN) algorithm, as an alternative to the conventional deep Q network (DQN)\nalgorithm. We prove the convergence of C-DQN and apply it to the Atari 2600\nbenchmark. We show that when DQN fail, C-DQN still learns successfully. Then,\nwe apply the algorithm to the measurement-feedback cooling problems of a\nquantum quartic oscillator and a trapped quantum rigid body. We establish the\nphysical models and analyse their properties, and we show that although both\nC-DQN and DQN can learn to cool the systems, C-DQN tends to behave more stably,\nand when DQN suffers from instabilities, C-DQN can achieve a better\nperformance. As the performance of DQN can have a large variance and lack\nconsistency, C-DQN can be a better choice for researches on complicated control\nproblems.\n","authors":["Zhikang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.10705v1.pdf","comment":"PhD Dissertation submitted to the Department of Physics, University\n  of Tokyo"},{"id":"http://arxiv.org/abs/2204.13841v5","updated":"2022-12-21T00:38:06Z","published":"2022-04-29T01:09:38Z","title":"An Extensive Data Processing Pipeline for MIMIC-IV","summary":"  An increasing amount of research is being devoted to applying machine\nlearning methods to electronic health record (EHR) data for various clinical\npurposes. This growing area of research has exposed the challenges of the\naccessibility of EHRs. MIMIC is a popular, public, and free EHR dataset in a\nraw format that has been used in numerous studies. The absence of standardized\npre-processing steps can be, however, a significant barrier to the wider\nadoption of this rare resource. Additionally, this absence can reduce the\nreproducibility of the developed tools and limit the ability to compare the\nresults among similar studies. In this work, we provide a greatly customizable\npipeline to extract, clean, and pre-process the data available in the fourth\nversion of the MIMIC dataset (MIMIC-IV). The pipeline also presents an\nend-to-end wizard-like package supporting predictive model creations and\nevaluations. The pipeline covers a range of clinical prediction tasks which can\nbe broadly classified into four categories - readmission, length of stay,\nmortality, and phenotype prediction. The tool is publicly available at\nhttps://github.com/healthylaife/MIMIC-IV-Data-Pipeline.\n","authors":["Mehak Gupta","Brennan Gallamoza","Nicolas Cutrona","Pranjal Dhakal","Raphael Poulain","Rahmatollah Beheshti"],"pdf_url":"https://arxiv.org/pdf/2204.13841v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10701v1","updated":"2022-12-21T00:33:59Z","published":"2022-12-21T00:33:59Z","title":"A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks","summary":"  A central challenge of building more powerful Graph Neural Networks (GNNs) is\nthe oversmoothing phenomenon, where increasing the network depth leads to\nhomogeneous node representations and thus worse classification performance.\nWhile previous works have only demonstrated that oversmoothing is inevitable\nwhen the number of graph convolutions tends to infinity, in this paper, we\nprecisely characterize the mechanism behind the phenomenon via a non-asymptotic\nanalysis. Specifically, we distinguish between two different effects when\napplying graph convolutions -- an undesirable mixing effect that homogenizes\nnode representations in different classes, and a desirable denoising effect\nthat homogenizes node representations in the same class. By quantifying these\ntwo effects on random graphs sampled from the Contextual Stochastic Block Model\n(CSBM), we show that oversmoothing happens once the mixing effect starts to\ndominate the denoising effect, and the number of layers required for this\ntransition is $O(\\log N/\\log (\\log N))$ for sufficiently dense graphs with $N$\nnodes. We also extend our analysis to study the effects of Personalized\nPageRank (PPR) on oversmoothing. Our results suggest that while PPR mitigates\noversmoothing at deeper layers, PPR-based architectures still achieve their\nbest performance at a shallow depth and are outperformed by the graph\nconvolution approach on certain graphs. Finally, we support our theoretical\nresults with numerical experiments, which further suggest that the\noversmoothing phenomenon observed in practice may be exacerbated by the\ndifficulty of optimizing deep GNN models.\n","authors":["Xinyi Wu","Zhengdao Chen","William Wang","Ali Jadbabaie"],"pdf_url":"https://arxiv.org/pdf/2212.10701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.12061v3","updated":"2022-12-21T00:30:52Z","published":"2020-10-11T21:31:14Z","title":"Simple Neighborhood Representative Pre-processing Boosts Outlier\n  Detectors","summary":"  Over the decades, traditional outlier detectors have ignored the group-level\nfactor when calculating outlier scores for objects in data by evaluating only\nthe object-level factor, failing to capture the collective outliers. To\nmitigate this issue, we present a method called neighborhood representative\n(NR), which empowers all the existing outlier detectors to efficiently detect\noutliers, including collective outliers, while maintaining their computational\nintegrity. It achieves this by selecting representative objects, scoring these\nobjects, then applies the score of the representative objects to its collective\nobjects. Without altering existing detectors, NR is compatible with existing\ndetectors, while improving performance on real world datasets with +8% (0.72 to\n0.78 AUC) relative to state-of-the-art outlier detectors.\n","authors":["Jiawei Yang","Yu Chen","Sylwan Rahardja"],"pdf_url":"https://arxiv.org/pdf/2010.12061v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10696v1","updated":"2022-12-21T00:00:01Z","published":"2022-12-21T00:00:01Z","title":"Analyzing Semantic Faithfulness of Language Models via Input\n  Intervention on Conversational Question Answering","summary":"  Transformer-based language models have been shown to be highly effective for\nseveral NLP tasks. In this paper, we consider three transformer models, BERT,\nRoBERTa, and XLNet, in both small and large version, and investigate how\nfaithful their representations are with respect to the semantic content of\ntexts. We formalize a notion of semantic faithfulness, in which the semantic\ncontent of a text should causally figure in a model's inferences in question\nanswering. We then test this notion by observing a model's behavior on\nanswering questions about a story after performing two novel semantic\ninterventions -- deletion intervention and negation intervention. While\ntransformer models achieve high performance on standard question answering\ntasks, we show that they fail to be semantically faithful once we perform these\ninterventions for a significant number of cases (~50% for deletion\nintervention, and ~20% drop in accuracy for negation intervention). We then\npropose an intervention-based training regime that can mitigate the undesirable\neffects for deletion intervention by a significant margin (from ~50% to ~6%).\nWe analyze the inner-workings of the models to better understand the\neffectiveness of intervention-based training for deletion intervention. But we\nshow that this training does not attenuate other aspects of semantic\nunfaithfulness such as the models' inability to deal with negation intervention\nor to capture the predicate-argument structure of texts. We also test\nInstructGPT, via prompting, for its ability to handle the two interventions and\nto capture predicate-argument structure. While InstructGPT models do achieve\nvery high performance on predicate-argument structure task, they fail to\nrespond adequately to our deletion and negation interventions.\n","authors":["Akshay Chaturvedi","Swarnadeep Bhar","Soumadeep Saha","Utpal Garain","Nicholas Asher"],"pdf_url":"https://arxiv.org/pdf/2212.10696v1.pdf","comment":"27 pages, 4 figures"},{"id":"http://arxiv.org/abs/2212.11415v1","updated":"2022-12-21T23:52:42Z","published":"2022-12-21T23:52:42Z","title":"Circumventing interpretability: How to defeat mind-readers","summary":"  The increasing capabilities of artificial intelligence (AI) systems make it\never more important that we interpret their internals to ensure that their\nintentions are aligned with human values. Yet there is reason to believe that\nmisaligned artificial intelligence will have a convergent instrumental\nincentive to make its thoughts difficult for us to interpret. In this article,\nI discuss many ways that a capable AI might circumvent scalable\ninterpretability methods and suggest a framework for thinking about these\npotential future risks.\n","authors":["Lee Sharkey"],"pdf_url":"https://arxiv.org/pdf/2212.11415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11414v1","updated":"2022-12-21T23:52:09Z","published":"2022-12-21T23:52:09Z","title":"Improving Automated Program Repair with Domain Adaptation","summary":"  Automated Program Repair (APR) is defined as the process of fixing a\nbug/defect in the source code, by an automated tool. APR tools have recently\nexperienced promising results by leveraging state-of-the-art Neural Language\nProcessing (NLP) techniques. APR tools such as TFix and CodeXGLUE combine\ntext-to-text transformers with software-specific techniques are outperforming\nalternatives, these days. However, in most APR studies the train and test sets\nare chosen from the same set of projects. In reality, however, APR models are\nmeant to be generalizable to new and different projects. Therefore, there is a\npotential threat that reported APR models with high effectiveness perform\npoorly when the characteristics of the new project or its bugs are different\nthan the training set's(Domain Shift).\n  In this study, we first define and measure the domain shift problem in\nautomated program repair. Then, we then propose a domain adaptation framework\nthat can adapt an APR model for a given target project. We conduct an empirical\nstudy with three domain adaptation methods FullFineTuning,\nTuningWithLightWeightAdapterLayers, and CurriculumLearning using two\nstate-of-the-art domain adaptation tools (TFix and CodeXGLUE) and two APR\nmodels on 611 bugs from 19 projects. The results show that our proposed\nframework can improve the effectiveness of TFix by 13.05% and CodeXGLUE by\n23.4%. Another contribution of this study is the proposal of a data synthesis\nmethod to address the lack of labelled data in APR. We leverage transformers to\ncreate a bug generator model. We use the generated synthetic data to domain\nadapt TFix and CodeXGLUE on the projects with no data (Zero-shot learning),\nwhich results in an average improvement of 5.76% and 24.42% for TFix and\nCodeXGLUE, respectively.\n","authors":["Armin Zirak","Hadi Hemati"],"pdf_url":"https://arxiv.org/pdf/2212.11414v1.pdf","comment":"43 pages"},{"id":"http://arxiv.org/abs/2212.08049v3","updated":"2022-12-21T23:40:56Z","published":"2022-12-15T18:55:23Z","title":"Sliced Optimal Partial Transport","summary":"  Optimal transport (OT) has become exceedingly popular in machine learning,\ndata science, and computer vision. The core assumption in the OT problem is the\nequal total amount of mass in source and target measures, which limits its\napplication. Optimal Partial Transport (OPT) is a recently proposed solution to\nthis limitation. Similar to the OT problem, the computation of OPT relies on\nsolving a linear programming problem (often in high dimensions), which can\nbecome computationally prohibitive. In this paper, we propose an efficient\nalgorithm for calculating the OPT problem between two non-negative measures in\none dimension. Next, following the idea of sliced OT distances, we utilize\nslicing to define the sliced OPT distance. Finally, we demonstrate the\ncomputational and accuracy benefits of the sliced OPT-based method in various\nnumerical experiments. In particular, we show an application of our proposed\nSliced-OPT in noisy point cloud registration.\n","authors":["Yikun Bai","Bernard Schmitzer","Mathew Thorpe","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2212.08049v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11409v1","updated":"2022-12-21T23:28:53Z","published":"2022-12-21T23:28:53Z","title":"DExT: Detector Explanation Toolkit","summary":"  State-of-the-art object detectors are treated as black boxes due to their\nhighly non-linear internal computations. Even with unprecedented advancements\nin detector performance, the inability to explain how their outputs are\ngenerated limits their use in safety-critical applications. Previous work fails\nto produce explanations for both bounding box and classification decisions, and\ngenerally make individual explanations for various detectors. In this paper, we\npropose an open-source Detector Explanation Toolkit (DExT) which implements the\nproposed approach to generate a holistic explanation for all detector decisions\nusing certain gradient-based explanation methods. We suggests various\nmulti-object visualization methods to merge the explanations of multiple\nobjects detected in an image as well as the corresponding detections in a\nsingle image. The quantitative evaluation show that the Single Shot MultiBox\nDetector (SSD) is more faithfully explained compared to other detectors\nregardless of the explanation methods. Both quantitative and human-centric\nevaluations identify that SmoothGrad with Guided Backpropagation (GBP) provides\nmore trustworthy explanations among selected methods across all detectors. We\nexpect that DExT will motivate practitioners to evaluate object detectors from\nthe interpretability perspective by explaining both bounding box and\nclassification decisions.\n","authors":["Deepan Chakravarthi Padmanabhan","Matias Valdenegro-Toro"],"pdf_url":"https://arxiv.org/pdf/2212.11409v1.pdf","comment":"21 pages, with supplementary"},{"id":"http://arxiv.org/abs/2212.11408v1","updated":"2022-12-21T23:23:24Z","published":"2022-12-21T23:23:24Z","title":"Adaptive and Dynamic Multi-Resolution Hashing for Pairwise Summations","summary":"  In this paper, we propose Adam-Hash: an adaptive and dynamic multi-resolution\nhashing data-structure for fast pairwise summation estimation. Given a data-set\n$X \\subset \\mathbb{R}^d$, a binary function $f:\\mathbb{R}^d\\times\n\\mathbb{R}^d\\to \\mathbb{R}$, and a point $y \\in \\mathbb{R}^d$, the Pairwise\nSummation Estimate $\\mathrm{PSE}_X(y) := \\frac{1}{|X|} \\sum_{x \\in X} f(x,y)$.\nFor any given data-set $X$, we need to design a data-structure such that given\nany query point $y \\in \\mathbb{R}^d$, the data-structure approximately\nestimates $\\mathrm{PSE}_X(y)$ in time that is sub-linear in $|X|$. Prior works\non this problem have focused exclusively on the case where the data-set is\nstatic, and the queries are independent. In this paper, we design a\nhashing-based PSE data-structure which works for the more practical\n\\textit{dynamic} setting in which insertions, deletions, and replacements of\npoints are allowed. Moreover, our proposed Adam-Hash is also robust to adaptive\nPSE queries, where an adversary can choose query $q_j \\in \\mathbb{R}^d$\ndepending on the output from previous queries $q_1, q_2, \\dots, q_{j-1}$.\n","authors":["Lianke Qin","Aravind Reddy","Zhao Song","Zhaozhuo Xu","Danyang Zhuo"],"pdf_url":"https://arxiv.org/pdf/2212.11408v1.pdf","comment":"BigData 2022"},{"id":"http://arxiv.org/abs/2207.13674v2","updated":"2022-12-21T23:12:00Z","published":"2022-07-27T17:40:16Z","title":"Fast expansion into harmonics on the disk: a steerable basis with fast\n  radial convolutions","summary":"  We present a fast and numerically accurate method for expanding digitized $L\n\\times L$ images representing functions on $[-1,1]^2$ supported on the disk\n$\\{x \\in \\mathbb{R}^2 : |x|<1\\}$ in the harmonics (Dirichlet Laplacian\neigenfunctions) on the disk. Our method, which we refer to as the Fast Disk\nHarmonics Transform (FDHT), runs in $O(L^2 \\log L)$ operations. This basis is\nalso known as the Fourier-Bessel basis, and it has several computational\nadvantages: it is orthogonal, ordered by frequency, and steerable in the sense\nthat images expanded in the basis can be rotated by applying a diagonal\ntransform to the coefficients. Moreover, we show that convolution with radial\nfunctions can also be efficiently computed by applying a diagonal transform to\nthe coefficients.\n","authors":["Nicholas F. Marshall","Oscar Mickelin","Amit Singer"],"pdf_url":"https://arxiv.org/pdf/2207.13674v2.pdf","comment":"26 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2212.11396v1","updated":"2022-12-21T22:37:42Z","published":"2022-12-21T22:37:42Z","title":"ABODE-Net: An Attention-based Deep Learning Model for Non-intrusive\n  Building Occupancy Detection Using Smart Meter Data","summary":"  Occupancy information is useful for efficient energy management in the\nbuilding sector. The massive high-resolution electrical power consumption data\ncollected by smart meters in the advanced metering infrastructure (AMI) network\nmake it possible to infer buildings' occupancy status in a non-intrusive way.\nIn this paper, we propose a deep leaning model called ABODE-Net which employs a\nnovel Parallel Attention (PA) block for building occupancy detection using\nsmart meter data. The PA block combines the temporal, variable, and channel\nattention modules in a parallel way to signify important features for occupancy\ndetection. We adopt two smart meter datasets widely used for building occupancy\ndetection in our performance evaluation. A set of state-of-the-art shallow\nmachine learning and deep learning models are included for performance\ncomparison. The results show that ABODE-Net significantly outperforms other\nmodels in all experimental cases, which proves its validity as a solution for\nnon-intrusive building occupancy detection.\n","authors":["Zhirui Luo","Ruobin Qi","Qingqing Li","Jun Zheng","Sihua Shao"],"pdf_url":"https://arxiv.org/pdf/2212.11396v1.pdf","comment":"To be published in The 7th International Conference on Smart\n  Computing and Communication (SmartCom 2022)"},{"id":"http://arxiv.org/abs/2201.10129v3","updated":"2022-12-21T22:37:33Z","published":"2022-01-25T07:02:58Z","title":"Convergence of Invariant Graph Networks","summary":"  Although theoretical properties such as expressive power and over-smoothing\nof graph neural networks (GNN) have been extensively studied recently, its\nconvergence property is a relatively new direction. In this paper, we\ninvestigate the convergence of one powerful GNN, Invariant Graph Network (IGN)\nover graphs sampled from graphons.\n  We first prove the stability of linear layers for general $k$-IGN (of order\n$k$) based on a novel interpretation of linear equivariant layers. Building\nupon this result, we prove the convergence of $k$-IGN under the model of\n\\citet{ruiz2020graphon}, where we access the edge weight but the convergence\nerror is measured for graphon inputs.\n  Under the more natural (and more challenging) setting of\n\\citet{keriven2020convergence} where one can only access 0-1 adjacency matrix\nsampled according to edge probability, we first show a negative result that the\nconvergence of any IGN is not possible. We then obtain the convergence of a\nsubset of IGNs, denoted as IGN-small, after the edge probability estimation. We\nshow that IGN-small still contains function class rich enough that can\napproximate spectral GNNs arbitrarily well. Lastly, we perform experiments on\nvarious graphon models to verify our statements.\n","authors":["Chen Cai","Yusu Wang"],"pdf_url":"https://arxiv.org/pdf/2201.10129v3.pdf","comment":"29 pages, 11 figures"},{"id":"http://arxiv.org/abs/2211.13297v2","updated":"2022-12-21T22:32:01Z","published":"2022-11-23T20:54:26Z","title":"Multiple Imputation with Neural Network Gaussian Process for\n  High-dimensional Incomplete Data","summary":"  Missing data are ubiquitous in real world applications and, if not adequately\nhandled, may lead to the loss of information and biased findings in downstream\nanalysis. Particularly, high-dimensional incomplete data with a moderate sample\nsize, such as analysis of multi-omics data, present daunting challenges.\nImputation is arguably the most popular method for handling missing data,\nthough existing imputation methods have a number of limitations. Single\nimputation methods such as matrix completion methods do not adequately account\nfor imputation uncertainty and hence would yield improper statistical\ninference. In contrast, multiple imputation (MI) methods allow for proper\ninference but existing methods do not perform well in high-dimensional\nsettings. Our work aims to address these significant methodological gaps,\nleveraging recent advances in neural network Gaussian process (NNGP) from a\nBayesian viewpoint. We propose two NNGP-based MI methods, namely MI-NNGP, that\ncan apply multiple imputations for missing values from a joint (posterior\npredictive) distribution. The MI-NNGP methods are shown to significantly\noutperform existing state-of-the-art methods on synthetic and real datasets, in\nterms of imputation error, statistical inference, robustness to missing rates,\nand computation costs, under three missing data mechanisms, MCAR, MAR, and\nMNAR.\n","authors":["Zongyu Dai","Zhiqi Bu","Qi Long"],"pdf_url":"https://arxiv.org/pdf/2211.13297v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11385v1","updated":"2022-12-21T22:03:06Z","published":"2022-12-21T22:03:06Z","title":"Online Statistical Inference for Matrix Contextual Bandit","summary":"  Contextual bandit has been widely used for sequential decision-making based\non the current contextual information and historical feedback data. In modern\napplications, such context format can be rich and can often be formulated as a\nmatrix. Moreover, while existing bandit algorithms mainly focused on\nreward-maximization, less attention has been paid to the statistical inference.\nTo fill in these gaps, in this work we consider a matrix contextual bandit\nframework where the true model parameter is a low-rank matrix, and propose a\nfully online procedure to simultaneously make sequential decision-making and\nconduct statistical inference. The low-rank structure of the model parameter\nand the adaptivity nature of the data collection process makes this difficult:\nstandard low-rank estimators are not fully online and are biased, while\nexisting inference approaches in bandit algorithms fail to account for the\nlow-rankness and are also biased. To address these, we introduce a new online\ndoubly-debiasing inference procedure to simultaneously handle both sources of\nbias. In theory, we establish the asymptotic normality of the proposed online\ndoubly-debiased estimator and prove the validity of the constructed confidence\ninterval. Our inference results are built upon a newly developed low-rank\nstochastic gradient descent estimator and its non-asymptotic convergence\nresult, which is also of independent interest.\n","authors":["Qiyu Han","Will Wei Sun","Yichen Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11385v1.pdf","comment":"81 pages"},{"id":"http://arxiv.org/abs/2212.11377v1","updated":"2022-12-21T21:36:52Z","published":"2022-12-21T21:36:52Z","title":"ReVISE: Self-Supervised Speech Resynthesis with Visual Input for\n  Universal and Generalized Speech Enhancement","summary":"  Prior works on improving speech quality with visual input typically study\neach type of auditory distortion separately (e.g., separation, inpainting,\nvideo-to-speech) and present tailored algorithms. This paper proposes to unify\nthese subjects and study Generalized Speech Enhancement, where the goal is not\nto reconstruct the exact reference clean signal, but to focus on improving\ncertain aspects of speech. In particular, this paper concerns intelligibility,\nquality, and video synchronization. We cast the problem as audio-visual speech\nresynthesis, which is composed of two steps: pseudo audio-visual speech\nrecognition (P-AVSR) and pseudo text-to-speech synthesis (P-TTS). P-AVSR and\nP-TTS are connected by discrete units derived from a self-supervised speech\nmodel. Moreover, we utilize self-supervised audio-visual speech model to\ninitialize P-AVSR. The proposed model is coined ReVISE. ReVISE is the first\nhigh-quality model for in-the-wild video-to-speech synthesis and achieves\nsuperior performance on all LRS3 audio-visual enhancement tasks with a single\nmodel. To demonstrates its applicability in the real world, ReVISE is also\nevaluated on EasyCom, an audio-visual benchmark collected under challenging\nacoustic conditions with only 1.6 hours of training data. Similarly, ReVISE\ngreatly suppresses noise and improves quality. Project page:\nhttps://wnhsu.github.io/ReVISE.\n","authors":["Wei-Ning Hsu","Tal Remez","Bowen Shi","Jacob Donley","Yossi Adi"],"pdf_url":"https://arxiv.org/pdf/2212.11377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11375v1","updated":"2022-12-21T21:32:36Z","published":"2022-12-21T21:32:36Z","title":"Semi-supervised GAN for Bladder Tissue Classification in Multi-Domain\n  Endoscopic Images","summary":"  Objective: Accurate visual classification of bladder tissue during\nTrans-Urethral Resection of Bladder Tumor (TURBT) procedures is essential to\nimprove early cancer diagnosis and treatment. During TURBT interventions, White\nLight Imaging (WLI) and Narrow Band Imaging (NBI) techniques are used for\nlesion detection. Each imaging technique provides diverse visual information\nthat allows clinicians to identify and classify cancerous lesions. Computer\nvision methods that use both imaging techniques could improve endoscopic\ndiagnosis. We address the challenge of tissue classification when annotations\nare available only in one domain, in our case WLI, and the endoscopic images\ncorrespond to an unpaired dataset, i.e. there is no exact equivalent for every\nimage in both NBI and WLI domains. Method: We propose a semi-surprised\nGenerative Adversarial Network (GAN)-based method composed of three main\ncomponents: a teacher network trained on the labeled WLI data; a\ncycle-consistency GAN to perform unpaired image-to-image translation, and a\nmulti-input student network. To ensure the quality of the synthetic images\ngenerated by the proposed GAN we perform a detailed quantitative, and\nqualitative analysis with the help of specialists. Conclusion: The overall\naverage classification accuracy, precision, and recall obtained with the\nproposed method for tissue classification are 0.90, 0.88, and 0.89\nrespectively, while the same metrics obtained in the unlabeled domain (NBI) are\n0.92, 0.64, and 0.94 respectively. The quality of the generated images is\nreliable enough to deceive specialists. Significance: This study shows the\npotential of using semi-supervised GAN-based classification to improve bladder\ntissue classification when annotations are limited in multi-domain data.\n","authors":["Jorge F. Lazo","Benoit Rosa","Michele Catellani","Matteo Fontana","Francesco A. Mistretta","Gennaro Musi","Ottavio de Cobelli","Michel de Mathelin","Elena De Momi"],"pdf_url":"https://arxiv.org/pdf/2212.11375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11369v1","updated":"2022-12-21T21:14:35Z","published":"2022-12-21T21:14:35Z","title":"MM811 Project Report: Cloud Detection and Removal in Satellite Images","summary":"  For satellite images, the presence of clouds presents a problem as clouds\nobscure more than half to two-thirds of the ground information. This problem\ncauses many issues for reliability in a noise-free environment to communicate\ndata and other applications that need seamless monitoring. Removing the clouds\nfrom the images while keeping the background pixels intact can help address the\nmentioned issues. Recently, deep learning methods have become popular for\nresearching cloud removal by demonstrating promising results, among which\nGenerative Adversarial Networks (GAN) have shown considerably better\nperformance. In this project, we aim to address cloud removal from satellite\nimages using AttentionGAN and then compare our results by reproducing the\nresults obtained using traditional GANs and auto-encoders. We use RICE dataset.\nThe outcome of this project can be used to develop applications that require\ncloud-free satellite images. Moreover, our results could be helpful for making\nfurther research improvements.\n","authors":["Dale Chen-Song","Erfan Khalaji","Vaishali Rani"],"pdf_url":"https://arxiv.org/pdf/2212.11369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11368v1","updated":"2022-12-21T21:10:49Z","published":"2022-12-21T21:10:49Z","title":"When and Why Test Generators for Deep Learning Produce Invalid Inputs:\n  an Empirical Study","summary":"  Testing Deep Learning (DL) based systems inherently requires large and\nrepresentative test sets to evaluate whether DL systems generalise beyond their\ntraining datasets. Diverse Test Input Generators (TIGs) have been proposed to\nproduce artificial inputs that expose issues of the DL systems by triggering\nmisbehaviours. Unfortunately, such generated inputs may be invalid, i.e., not\nrecognisable as part of the input domain, thus providing an unreliable quality\nassessment. Automated validators can ease the burden of manually checking the\nvalidity of inputs for human testers, although input validity is a concept\ndifficult to formalise and, thus, automate.\n  In this paper, we investigate to what extent TIGs can generate valid inputs,\naccording to both automated and human validators. We conduct a large empirical\nstudy, involving 2 different automated validators, 220 human assessors, 5\ndifferent TIGs and 3 classification tasks. Our results show that 84%\nartificially generated inputs are valid, according to automated validators, but\ntheir expected label is not always preserved. Automated validators reach a good\nconsensus with humans (78% accuracy), but still have limitations when dealing\nwith feature-rich datasets.\n","authors":["Vincenzo Riccio","Paolo Tonella"],"pdf_url":"https://arxiv.org/pdf/2212.11368v1.pdf","comment":"To be published in Proceedings of the 45th ACM/IEEE International\n  Conference on Software Engineering (ICSE 2023)"},{"id":"http://arxiv.org/abs/2212.11367v1","updated":"2022-12-21T21:08:45Z","published":"2022-12-21T21:08:45Z","title":"Forecasting West Nile Virus with Graph Neural Networks: Harnessing\n  Spatial Dependence in Irregularly Sampled Geospatial Data","summary":"  Machine learning methods have seen increased application to geospatial\nenvironmental problems, such as precipitation nowcasting, haze forecasting, and\ncrop yield prediction. However, many of the machine learning methods applied to\nmosquito population and disease forecasting do not inherently take into account\nthe underlying spatial structure of the given data. In our work, we apply a\nspatially aware graph neural network model consisting of GraphSAGE layers to\nforecast the presence of West Nile virus in Illinois, to aid mosquito\nsurveillance and abatement efforts within the state. More generally, we show\nthat graph neural networks applied to irregularly sampled geospatial data can\nexceed the performance of a range of baseline methods including logistic\nregression, XGBoost, and fully-connected neural networks.\n","authors":["Adam Tonks","Trevor Harris","Bo Li","William Brown","Rebecca Smith"],"pdf_url":"https://arxiv.org/pdf/2212.11367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03932v2","updated":"2022-12-21T20:59:46Z","published":"2022-12-07T19:56:11Z","title":"Low Variance Off-policy Evaluation with State-based Importance Sampling","summary":"  In off-policy reinforcement learning, a behaviour policy performs exploratory\ninteractions with the environment to obtain state-action-reward samples which\nare then used to learn a target policy that optimises the expected return. This\nleads to a problem of off-policy evaluation, where one needs to evaluate the\ntarget policy from samples collected by the often unrelated behaviour policy.\nImportance sampling is a traditional statistical technique that is often\napplied to off-policy evaluation. While importance sampling estimators are\nunbiased, their variance increases exponentially with the horizon of the\ndecision process due to computing the importance weight as a product of action\nprobability ratios, yielding estimates with low accuracy for domains involving\nlong-term planning. This paper proposes state-based importance sampling (SIS),\nwhich drops the action probability ratios of sub-trajectories with \"neglible\nstates\" -- roughly speaking, those for which the chosen actions have no impact\non the return estimate -- from the computation of the importance weight.\nTheoretical results show that this results in a reduction of the exponent in\nthe variance upper bound as well as improving the mean squared error. An\nautomated search algorithm based on covariance testing is proposed to identify\na negligible state set which has minimal MSE when performing state-based\nimportance sampling. Experiments are conducted on a lift domain, which include\n\"lift states\" where the action has no impact on the following state and reward.\nThe results demonstrate that using the search algorithm, SIS yields reduced\nvariance and improved accuracy compared to traditional importance sampling,\nper-decision importance sampling, and incremental importance sampling.\n","authors":["David M. Bossens","Philip Thomas"],"pdf_url":"https://arxiv.org/pdf/2212.03932v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11360v1","updated":"2022-12-21T20:53:44Z","published":"2022-12-21T20:53:44Z","title":"Feature Acquisition using Monte Carlo Tree Search","summary":"  Feature acquisition algorithms address the problem of acquiring informative\nfeatures while balancing the costs of acquisition to improve the learning\nperformances of ML models. Previous approaches have focused on calculating the\nexpected utility values of features to determine the acquisition sequences.\nOther approaches formulated the problem as a Markov Decision Process (MDP) and\napplied reinforcement learning based algorithms. In comparison to previous\napproaches, we focus on 1) formulating the feature acquisition problem as a MDP\nand applying Monte Carlo Tree Search, 2) calculating the intermediary rewards\nfor each acquisition step based on model improvements and acquisition costs and\n3) simultaneously optimizing model improvement and acquisition costs with\nmulti-objective Monte Carlo Tree Search. With Proximal Policy Optimization and\nDeep Q-Network algorithms as benchmark, we show the effectiveness of our\nproposed approach with experimental study.\n","authors":["Sungsoo Lim","Diego Klabjan","Mark Shapiro"],"pdf_url":"https://arxiv.org/pdf/2212.11360v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/1901.10681v2","updated":"2022-12-21T20:52:14Z","published":"2019-01-30T05:51:41Z","title":"End-to-End Learned Early Classification of Time Series for In-Season\n  Crop Type Mapping","summary":"  Remote sensing satellites capture the cyclic dynamics of our Planet in\nregular time intervals recorded in satellite time series data. End-to-end\ntrained deep learning models use this time series data to make predictions at a\nlarge scale, for instance, to produce up-to-date crop cover maps. Most time\nseries classification approaches focus on the accuracy of predictions. However,\nthe earliness of the prediction is also of great importance since coming to an\nearly decision can make a crucial difference in time-sensitive applications. In\nthis work, we present an End-to-End Learned Early Classification of Time Series\n(ELECTS) model that estimates a classification score and a probability of\nwhether sufficient data has been observed to come to an early and still\naccurate decision. ELECTS is modular: any deep time series classification model\ncan adopt the ELECTS conceptual idea by adding a second prediction head that\noutputs a probability of stopping the classification. The ELECTS loss function\nthen optimizes the overall model on a balanced objective of earliness and\naccuracy. Our experiments on four crop classification datasets from Europe and\nAfrica show that ELECTS allows reaching state-of-the-art accuracy while\nreducing the quantity of data massively to be downloaded, stored, and\nprocessed. The source code is available at https://github.com/marccoru/elects.\n","authors":["Marc Rußwurm","Nicolas Courty","Rémi Emonet","Sébastien Lefèvre","Devis Tuia","Romain Tavenard"],"pdf_url":"https://arxiv.org/pdf/1901.10681v2.pdf","comment":"accepted for publication in ISPRS Journal of Photogrammetry and\n  Remote Sensing"},{"id":"http://arxiv.org/abs/2212.11353v1","updated":"2022-12-21T20:43:46Z","published":"2022-12-21T20:43:46Z","title":"Contrastive Distillation Is a Sample-Efficient Self-Supervised Loss\n  Policy for Transfer Learning","summary":"  Traditional approaches to RL have focused on learning decision policies\ndirectly from episodic decisions, while slowly and implicitly learning the\nsemantics of compositional representations needed for generalization. While\nsome approaches have been adopted to refine representations via auxiliary\nself-supervised losses while simultaneously learning decision policies,\nlearning compositional representations from hand-designed and\ncontext-independent self-supervised losses (multi-view) still adapts relatively\nslowly to the real world, which contains many non-IID subspaces requiring rapid\ndistribution shift in both time and spatial attention patterns at varying\nlevels of abstraction. In contrast, supervised language model cascades have\nshown the flexibility to adapt to many diverse manifolds, and hints of\nself-learning needed for autonomous task transfer. However, to date, transfer\nmethods for language models like few-shot learning and fine-tuning still\nrequire human supervision and transfer learning using self-learning methods has\nbeen underexplored. We propose a self-supervised loss policy called contrastive\ndistillation which manifests latent variables with high mutual information with\nboth source and target tasks from weights to tokens. We show how this\noutperforms common methods of transfer learning and suggests a useful design\naxis of trading off compute for generalizability for online transfer.\nContrastive distillation is improved through sampling from memory and suggests\na simple algorithm for more efficiently sampling negative examples for\ncontrastive losses than random sampling.\n","authors":["Chris Lengerich","Gabriel Synnaeve","Amy Zhang","Hugh Leather","Kurt Shuster","François Charton","Charysse Redwood"],"pdf_url":"https://arxiv.org/pdf/2212.11353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11352v1","updated":"2022-12-21T20:43:35Z","published":"2022-12-21T20:43:35Z","title":"Sensitivity analysis of biological washout and depth selection for a\n  machine learning based dose verification framework in proton therapy","summary":"  Dose verification based on proton-induced positron emitters is a promising\nquality assurance tool and may leverage the strength of artificial\nintelligence. To move a step closer towards practical application, the\nsensitivity analysis of two factors needs to be performed: biological washout\nand depth selection. selection. A bi-directional recurrent neural network (RNN)\nmodel was developed. The training dataset was generated based upon a CT\nimage-based phantom (abdomen region) and multiple beam energies/pathways, using\nMonte-Carlo simulation (1 mm spatial resolution, no biological washout). For\nthe modeling of biological washout, a simplified analytical model was applied\nto change raw activity profiles over a period of 5 minutes, incorporating both\nphysical decay and biological washout. For the study of depth selection (a\nchallenge linked to multi field/angle irradiation), truncations were applied at\ndifferent window lengths (100, 125, 150 mm) to raw activity profiles. Finally,\nthe performance of a worst-case scenario was examined by combining both factors\n(depth selection: 125 mm, biological washout: 5 mins). The accuracy was\nquantitatively evaluated in terms of range uncertainty, mean absolute error\n(MAE) and mean relative errors (MRE). Our proposed AI framework shows good\nimmunity to the perturbation associated with two factors. The detection of\nproton-induced positron emitters, combined with machine learning, has great\npotential to implement online patient-specific verification in proton therapy.\n","authors":["Shixiong Yu","Yuxiang Liu","Zongsheng Hu","Haozhao Zhang","Pengyu Qi","Hao Peng"],"pdf_url":"https://arxiv.org/pdf/2212.11352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11346v1","updated":"2022-12-21T20:34:42Z","published":"2022-12-21T20:34:42Z","title":"Deep Unfolded Tensor Robust PCA with Self-supervised Learning","summary":"  Tensor robust principal component analysis (RPCA), which seeks to separate a\nlow-rank tensor from its sparse corruptions, has been crucial in data science\nand machine learning where tensor structures are becoming more prevalent. While\npowerful, existing tensor RPCA algorithms can be difficult to use in practice,\nas their performance can be sensitive to the choice of additional\nhyperparameters, which are not straightforward to tune. In this paper, we\ndescribe a fast and simple self-supervised model for tensor RPCA using deep\nunfolding by only learning four hyperparameters. Despite its simplicity, our\nmodel expunges the need for ground truth labels while maintaining competitive\nor even greater performance compared to supervised deep unfolding. Furthermore,\nour model is capable of operating in extreme data-starved scenarios. We\ndemonstrate these claims on a mix of synthetic data and real-world tasks,\ncomparing performance against previously studied supervised deep unfolding\nmethods and Bayesian optimization baselines.\n","authors":["Harry Dong","Megna Shah","Sean Donegan","Yuejie Chi"],"pdf_url":"https://arxiv.org/pdf/2212.11346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11342v1","updated":"2022-12-21T20:24:45Z","published":"2022-12-21T20:24:45Z","title":"Target Conditioned Representation Independence (TCRI); From\n  Domain-Invariant to Domain-General Representations","summary":"  We propose a Target Conditioned Representation Independence (TCRI) objective\nfor domain generalization. TCRI addresses the limitations of existing domain\ngeneralization methods due to incomplete constraints. Specifically, TCRI\nimplements regularizers motivated by conditional independence constraints that\nare sufficient to strictly learn complete sets of invariant mechanisms, which\nwe show are necessary and sufficient for domain generalization. Empirically, we\nshow that TCRI is effective on both synthetic and real-world data. TCRI is\ncompetitive with baselines in average accuracy while outperforming them in\nworst-domain accuracy, indicating desired cross-domain stability.\n","authors":["Olawale Salaudeen","Oluwasanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2212.11342v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.12727v2","updated":"2022-12-21T20:06:29Z","published":"2022-09-26T14:32:38Z","title":"A Simple Way to Learn Metrics Between Attributed Graphs","summary":"  The choice of good distances and similarity measures between objects is\nimportant for many machine learning methods. Therefore, many metric learning\nalgorithms have been developed in recent years, mainly for Euclidean data in\norder to improve performance of classification or clustering methods. However,\ndue to difficulties in establishing computable, efficient and differentiable\ndistances between attributed graphs, few metric learning algorithms adapted to\ngraphs have been developed despite the strong interest of the community. In\nthis paper, we address this issue by proposing a new Simple Graph Metric\nLearning - SGML - model with few trainable parameters based on Simple Graph\nConvolutional Neural Networks - SGCN - and elements of Optimal Transport\ntheory. This model allows us to build an appropriate distance from a database\nof labeled (attributed) graphs to improve the performance of simple\nclassification algorithms such as $k$-NN. This distance can be quickly trained\nwhile maintaining good performances as illustrated by the experimental study\npresented in this paper.\n","authors":["Yacouba Kaloga","Pierre Borgnat","Amaury Habrard"],"pdf_url":"https://arxiv.org/pdf/2209.12727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.15546v6","updated":"2022-12-21T19:51:33Z","published":"2021-11-30T16:36:58Z","title":"Black-box tests for algorithmic stability","summary":"  Algorithmic stability is a concept from learning theory that expresses the\ndegree to which changes to the input data (e.g., removal of a single data\npoint) may affect the outputs of a regression algorithm. Knowing an algorithm's\nstability properties is often useful for many downstream applications -- for\nexample, stability is known to lead to desirable generalization properties and\npredictive inference guarantees. However, many modern algorithms currently used\nin practice are too complex for a theoretical analysis of their stability\nproperties, and thus we can only attempt to establish these properties through\nan empirical exploration of the algorithm's behavior on various data sets. In\nthis work, we lay out a formal statistical framework for this kind of\n\"black-box testing\" without any assumptions on the algorithm or the data\ndistribution and establish fundamental bounds on the ability of any black-box\ntest to identify algorithmic stability.\n","authors":["Byol Kim","Rina Foygel Barber"],"pdf_url":"https://arxiv.org/pdf/2111.15546v6.pdf","comment":"37 pages. Minor edits to match the journal-submitted version"},{"id":"http://arxiv.org/abs/2211.11754v3","updated":"2022-12-21T19:48:19Z","published":"2022-11-20T16:20:45Z","title":"An Algorithm for Routing Vectors in Sequences","summary":"  We propose a routing algorithm that takes a sequence of vectors and computes\na new sequence with specified length and vector size. Each output vector\nmaximizes \"bang per bit,\" the difference between a net benefit to use and net\ncost to ignore data, by better predicting the input vectors. We describe output\nvectors as geometric objects, as latent variables that assign credit, as query\nstates in a model of associative memory, and as agents in a model of a Society\nof Mind. We implement the algorithm with optimizations that reduce parameter\ncount, computation, and memory use by orders of magnitude, enabling us to route\nsequences of greater length than previously possible. We evaluate our\nimplementation on natural language and visual classification tasks, obtaining\ncompetitive or state-of-the-art accuracy and end-to-end credit assignments that\nare interpretable.\n","authors":["Franz A. Heinsen"],"pdf_url":"https://arxiv.org/pdf/2211.11754v3.pdf","comment":"Source code and instructions for replicating our results are online\n  at https://github.com/glassroom/heinsen_routing"},{"id":"http://arxiv.org/abs/2111.09467v2","updated":"2022-12-21T19:42:52Z","published":"2021-11-18T01:18:36Z","title":"CSI: Contrastive Data Stratification for Interaction Prediction and its\n  Application to Compound-Protein Interaction Prediction","summary":"  Accurately predicting the likelihood of interaction between two objects\n(compound-protein sequence, user-item, author-paper, etc.) is a fundamental\nproblem in Computer Science. Current deep-learning models rely on learning\naccurate representations of the interacting objects. Importantly, relationships\nbetween the interacting objects, or features of the interaction, offer an\nopportunity to partition the data to create multi-views of the interacting\nobjects. The resulting congruent and non-congruent views can then be exploited\nvia contrastive learning techniques to learn enhanced representations of the\nobjects.\n","authors":["Apurva Kalia","Dilip Krishnan","Soha Hassoun"],"pdf_url":"https://arxiv.org/pdf/2111.09467v2.pdf","comment":"11 pages, submitted to BioInformatics"},{"id":"http://arxiv.org/abs/2212.11322v1","updated":"2022-12-21T19:36:48Z","published":"2022-12-21T19:36:48Z","title":"Debiased machine learning for estimating the causal effect of urban\n  traffic on pedestrian crossing behaviour","summary":"  Before the transition of AVs to urban roads and subsequently unprecedented\nchanges in traffic conditions, evaluation of transportation policies and\nfuturistic road design related to pedestrian crossing behavior is of vital\nimportance. Recent studies analyzed the non-causal impact of various variables\non pedestrian waiting time in the presence of AVs. However, we mainly\ninvestigate the causal effect of traffic density on pedestrian waiting time. We\ndevelop a Double/Debiased Machine Learning (DML) model in which the impact of\nconfounders variable influencing both a policy and an outcome of interest is\naddressed, resulting in unbiased policy evaluation. Furthermore, we try to\nanalyze the effect of traffic density by developing a copula-based joint model\nof two main components of pedestrian crossing behavior, pedestrian stress level\nand waiting time. The copula approach has been widely used in the literature,\nfor addressing self-selection problems, which can be classified as a causality\nanalysis in travel behavior modeling. The results obtained from copula approach\nand DML are compared based on the effect of traffic density. In DML model\nstructure, the standard error term of density parameter is lower than copula\napproach and the confidence interval is considerably more reliable. In\naddition, despite the similar sign of effect, the copula approach estimates the\neffect of traffic density lower than DML, due to the spurious effect of\nconfounders. In short, the DML model structure can flexibly adjust the impact\nof confounders by using machine learning algorithms and is more reliable for\nplanning future policies.\n","authors":["Kimia Kamal","Bilal Farooq"],"pdf_url":"https://arxiv.org/pdf/2212.11322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11317v1","updated":"2022-12-21T19:27:51Z","published":"2022-12-21T19:27:51Z","title":"End-to-end AI Framework for Hyperparameter Optimization, Model Training,\n  and Interpretable Inference for Molecules and Crystals","summary":"  We introduce an end-to-end computational framework that enables\nhyperparameter optimization with the DeepHyper library, accelerated training,\nand interpretable AI inference with a suite of state-of-the-art AI models,\nincluding CGCNN, PhysNet, SchNet, MPNN, MPNN-transformer, and TorchMD-Net. We\nuse these AI models and the benchmark QM9, hMOF, and MD17 datasets to showcase\nthe prediction of user-specified materials properties in modern computing\nenvironments, and to demonstrate translational applications for the modeling of\nsmall molecules, crystals and metal organic frameworks with a unified,\nstand-alone framework. We deployed and tested this framework in the ThetaGPU\nsupercomputer at the Argonne Leadership Computing Facility, and the Delta\nsupercomputer at the National Center for Supercomputing Applications to provide\nresearchers with modern tools to conduct accelerated AI-driven discovery in\nleadership class computing environments.\n","authors":["Hyun Park","Ruijie Zhu","E. A. Huerta","Santanu Chaudhuri","Emad Tajkhorshid","Donny Cooper"],"pdf_url":"https://arxiv.org/pdf/2212.11317v1.pdf","comment":"20 pages, 10 images, 6 tables"},{"id":"http://arxiv.org/abs/2212.11311v1","updated":"2022-12-21T19:11:19Z","published":"2022-12-21T19:11:19Z","title":"What do LLMs Know about Financial Markets? A Case Study on Reddit Market\n  Sentiment Analysis","summary":"  Market sentiment analysis on social media content requires knowledge of both\nfinancial markets and social media jargon, which makes it a challenging task\nfor human raters. The resulting lack of high-quality labeled data stands in the\nway of conventional supervised learning methods. Instead, we approach this\nproblem using semi-supervised learning with a large language model (LLM). Our\npipeline generates weak financial sentiment labels for Reddit posts with an LLM\nand then uses that data to train a small model that can be served in\nproduction. We find that prompting the LLM to produce Chain-of-Thought\nsummaries and forcing it through several reasoning paths helps generate more\nstable and accurate labels, while using a regression loss further improves\ndistillation quality. With only a handful of prompts, the final model performs\non par with existing supervised models. Though production applications of our\nmodel are limited by ethical considerations, the model's competitive\nperformance points to the great potential of using LLMs for tasks that\notherwise require skill-intensive annotation.\n","authors":["Xiang Deng","Vasilisa Bashlovkina","Feng Han","Simon Baumgartner","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2212.11311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11296v1","updated":"2022-12-21T19:00:04Z","published":"2022-12-21T19:00:04Z","title":"Towards Neural Variational Monte Carlo That Scales Linearly with System\n  Size","summary":"  Quantum many-body problems are some of the most challenging problems in\nscience and are central to demystifying some exotic quantum phenomena, e.g.,\nhigh-temperature superconductors. The combination of neural networks (NN) for\nrepresenting quantum states, coupled with the Variational Monte Carlo (VMC)\nalgorithm, has been shown to be a promising method for solving such problems.\nHowever, the run-time of this approach scales quadratically with the number of\nsimulated particles, constraining the practically usable NN to - in machine\nlearning terms - minuscule sizes (<10M parameters). Considering the many\nbreakthroughs brought by extreme NN in the +1B parameters scale to other\ndomains, lifting this constraint could significantly expand the set of quantum\nsystems we can accurately simulate on classical computers, both in size and\ncomplexity. We propose a NN architecture called Vector-Quantized Neural Quantum\nStates (VQ-NQS) that utilizes vector-quantization techniques to leverage\nredundancies in the local-energy calculations of the VMC algorithm - the source\nof the quadratic scaling. In our preliminary experiments, we demonstrate VQ-NQS\nability to reproduce the ground state of the 2D Heisenberg model across various\nsystem sizes, while reporting a significant reduction of about ${\\times}10$ in\nthe number of FLOPs in the local-energy calculation.\n","authors":["Or Sharir","Garnet Kin-Lic Chan","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2212.11296v1.pdf","comment":"Appeared on NeurIPS 2022 AI for Science Workshop (a non-archival\n  poster presentation)"},{"id":"http://arxiv.org/abs/2212.11281v1","updated":"2022-12-21T17:58:01Z","published":"2022-12-21T17:58:01Z","title":"Language models are better than humans at next-token prediction","summary":"  Current language models are considered to have sub-human capabilities at\nnatural language tasks like question-answering or writing code. However,\nlanguage models are not trained to perform well at these tasks, they are\ntrained to accurately predict the next token given previous tokes in tokenized\ntext. It is not clear whether language models are better or worse than humans\nat next token prediction. To try to answer this question, we performed two\ndistinct experiments to directly compare humans and language models on this\nfront: one measuring top-1 accuracy and the other measuring perplexity. In both\nexperiments, we find humans to be consistently \\emph{worse} than even\nrelatively small language models like GPT3-Ada at next-token prediction.\n","authors":["Buck Shlegeris","Fabien Roger","Lawrence Chan","Euan McLean"],"pdf_url":"https://arxiv.org/pdf/2212.11281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11278v1","updated":"2022-12-21T14:39:52Z","published":"2022-12-21T14:39:52Z","title":"Decision-making and control with metasurface-based diffractive neural\n  networks","summary":"  The ultimate goal of artificial intelligence is to mimic the human brain to\nperform decision-making and control directly from high-dimensional sensory\ninput. All-optical diffractive neural networks provide a promising solution for\nrealizing artificial intelligence with high-speed and low-power consumption. To\ndate, most of the reported diffractive neural networks focus on single or\nmultiple tasks that do not involve interaction with the environment, such as\nobject recognition and image classification, while the networks that can\nperform decision-making and control, to our knowledge, have not been developed\nyet. Here, we propose to use deep reinforcement learning to realize diffractive\nneural networks that enable imitating the human-level capability of\ndecision-making and control. Such networks allow for finding optimal control\npolicies through interaction with the environment and can be readily realized\nwith the dielectric metasurfaces. The superior performances of these networks\nare verified by engaging three types of classic games, Tic-Tac-Toe, Super Mario\nBros., and Car Racing, and achieving the same or even higher levels comparable\nto human players. Our work represents a solid step of advancement in\ndiffractive neural networks, which promises a fundamental shift from the\ntarget-driven control of a pre-designed state for simple recognition or\nclassification tasks to the high-level sensory capability of artificial\nintelligence. It may find exciting applications in autonomous driving,\nintelligent robots, and intelligent manufacturing.\n","authors":["Jumin Qiu","Tianbao Yu","Lujun Huang","Andrey Miroshnichenko","Shuyuan Xiao"],"pdf_url":"https://arxiv.org/pdf/2212.11278v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2212.10988v1","updated":"2022-12-21T12:50:31Z","published":"2022-12-21T12:50:31Z","title":"Attention-Aware Anime Line Drawing Colorization","summary":"  Automatic colorization of anime line drawing has attracted much attention in\nrecent years since it can substantially benefit the animation industry.\nUser-hint based methods are the mainstream approach for line drawing\ncolorization, while reference-based methods offer a more intuitive approach.\nNevertheless, although reference-based methods can improve feature aggregation\nof the reference image and the line drawing, the colorization results are not\ncompelling in terms of color consistency or semantic correspondence. In this\npaper, we introduce an attention-based model for anime line drawing\ncolorization, in which a channel-wise and spatial-wise Convolutional Attention\nmodule is used to improve the ability of the encoder for feature extraction and\nkey area perception, and a Stop-Gradient Attention module with cross-attention\nand self-attention is used to tackle the cross-domain long-range dependency\nproblem. Extensive experiments show that our method outperforms other SOTA\nmethods, with more accurate line structure and semantic color information.\n","authors":["Yu Cao","Hao Tian","P. Y. Mok"],"pdf_url":"https://arxiv.org/pdf/2212.10988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10901v1","updated":"2022-12-21T10:20:54Z","published":"2022-12-21T10:20:54Z","title":"RECAP: Retrieval Augmented Music Captioner","summary":"  With the prevalence of stream media platforms serving music search and\nrecommendation, interpreting music by understanding audio and lyrics\ninteractively has become an important and challenging task. However, many\nprevious works focus on refining individual components of encoder-decoder\narchitecture mapping music to caption tokens, ignoring the potential usage of\naudio and lyrics correspondence. In this paper, we propose to explicitly learn\nthe multi-modal alignment with retrieval augmentation by contrastive learning.\nBy learning audio-lyrics correspondence, the model is guided to learn better\ncross-modal attention weights, thus generating high-quality caption words. We\nprovide both theoretical and empirical results that demonstrate the advantage\nof the proposed method.\n","authors":["Zihao He","Weituo Hao","Xuchen Song"],"pdf_url":"https://arxiv.org/pdf/2212.10901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10846v1","updated":"2022-12-21T08:39:36Z","published":"2022-12-21T08:39:36Z","title":"From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language\n  Models","summary":"  Large language models (LLMs) have demonstrated excellent zero-shot\ngeneralization to new language tasks. However, effective utilization of LLMs\nfor zero-shot visual question-answering (VQA) remains challenging, primarily\ndue to the modality disconnection and task disconnection between LLM and VQA\ntask. End-to-end training on vision and language data may bridge the\ndisconnections, but is inflexible and computationally expensive. To address\nthis issue, we propose \\emph{Img2Prompt}, a plug-and-play module that provides\nthe prompts that can bridge the aforementioned modality and task\ndisconnections, so that LLMs can perform zero-shot VQA tasks without end-to-end\ntraining. In order to provide such prompts, we further employ LLM-agnostic\nmodels to provide prompts that can describe image content and self-constructed\nquestion-answer pairs, which can effectively guide LLM to perform zero-shot VQA\ntasks. Img2Prompt offers the following benefits: 1) It can flexibly work with\nvarious LLMs to perform VQA. 2)~Without the needing of end-to-end training, it\nsignificantly reduces the cost of deploying LLM for zero-shot VQA tasks. 3) It\nachieves comparable or better performance than methods relying on end-to-end\ntraining. For example, we outperform Flamingo~\\cite{Deepmind:Flamingo2022} by\n5.6\\% on VQAv2. On the challenging A-OKVQA dataset, our method even outperforms\nfew-shot methods by as much as 20\\%.\n","authors":["Jiaxian Guo","Junnan Li","Dongxu Li","Anthony Meng Huat Tiong","Boyang Li","Dacheng Tao","Steven C. H. Hoi"],"pdf_url":"https://arxiv.org/pdf/2212.10846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.05719v3","updated":"2022-12-21T08:12:46Z","published":"2022-11-10T17:37:04Z","title":"MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal\n  Open-domain Conversation","summary":"  Responding with multi-modal content has been recognized as an essential\ncapability for an intelligent conversational agent. In this paper, we introduce\nthe MMDialog dataset to better facilitate multi-modal conversation. MMDialog is\ncomposed of a curated set of 1.08 million real-world dialogues with 1.53\nmillion unique images across 4,184 topics. MMDialog has two main and unique\nadvantages. First, it is the largest multi-modal conversation dataset by the\nnumber of dialogues by 88x. Second, it contains massive topics to generalize\nthe open-domain. To build engaging dialogue system with this dataset, we\npropose and normalize two response producing tasks based on retrieval and\ngenerative scenarios. In addition, we build two baselines for above tasks with\nstate-of-the-art techniques and report their experimental performance. We also\npropose a novel evaluation metric MM-Relevance to measure the multi-modal\nresponses. Our dataset and scripts are available in\nhttps://github.com/victorsungo/MMDialog.\n","authors":["Jiazhan Feng","Qingfeng Sun","Can Xu","Pu Zhao","Yaming Yang","Chongyang Tao","Dongyan Zhao","Qingwei Lin"],"pdf_url":"https://arxiv.org/pdf/2211.05719v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11418v1","updated":"2022-12-21T23:59:13Z","published":"2022-12-21T23:59:13Z","title":"Cattle Detection Occlusion Problem","summary":"  The management of cattle over a huge area is still a challenging problem in\nthe farming sector. With evolution in technology, Unmanned aerial vehicles\n(UAVs) with consumer level digital cameras are becoming a popular alternative\nto manual animal censuses for livestock estimation since they are less risky\nand expensive.This paper evaluated and compared the cutting-edge object\ndetection algorithms, YOLOv7,RetinaNet with ResNet50 backbone, RetinaNet with\nEfficientNet and mask RCNN. It aims to improve the occlusion problem that is to\ndetect hidden cattle from a huge dataset captured by drones using deep learning\nalgorithms for accurate cattle detection. Experimental results showed YOLOv7\nwas superior with precision of 0.612 when compared to the other two algorithms.\nThe proposed method proved superior to the usual competing algorithms for cow\nface detection, especially in very difficult cases.\n","authors":["Aparna Mendu","Bhavya Sehgal","Vaishnavi Mendu"],"pdf_url":"https://arxiv.org/pdf/2212.11418v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1701.01611 by other authors"},{"id":"http://arxiv.org/abs/2212.11344v1","updated":"2022-12-21T20:31:39Z","published":"2022-12-21T20:31:39Z","title":"Advanced Baseline for 3D Human Pose Estimation: A Two-Stage Approach","summary":"  Human pose estimation has been widely applied in various industries. While\nrecent decades have witnessed the introduction of many advanced two-dimensional\n(2D) human pose estimation solutions, three-dimensional (3D) human pose\nestimation is still an active research field in computer vision. Generally\nspeaking, 3D human pose estimation methods can be divided into two categories:\nsingle-stage and two-stage. In this paper, we focused on the 2D-to-3D lifting\nprocess in the two-stage methods and proposed a more advanced baseline model\nfor 3D human pose estimation, based on the existing solutions. Our improvements\ninclude optimization of machine learning models and multiple parameters, as\nwell as introduction of a weighted loss to the training model. Finally, we used\nthe Human3.6M benchmark to test the final performance and it did produce\nsatisfactory results.\n","authors":["Zichen Gui","Jungang Luo"],"pdf_url":"https://arxiv.org/pdf/2212.11344v1.pdf","comment":null}]},"2022-12-22T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2212.11937v1","updated":"2022-12-22T18:16:58Z","published":"2022-12-22T18:16:58Z","title":"Efficient Induction of Language Models Via Probabilistic Concept\n  Formation","summary":"  This paper presents a novel approach to the acquisition of language models\nfrom corpora. The framework builds on Cobweb, an early system for constructing\ntaxonomic hierarchies of probabilistic concepts that used a tabular,\nattribute-value encoding of training cases and concepts, making it unsuitable\nfor sequential input like language. In response, we explore three new\nextensions to Cobweb -- the Word, Leaf, and Path variants. These systems encode\neach training case as an anchor word and surrounding context words, and they\nstore probabilistic descriptions of concepts as distributions over anchor and\ncontext information. As in the original Cobweb, a performance element sorts a\nnew instance downward through the hierarchy and uses the final node to predict\nmissing features. Learning is interleaved with performance, updating concept\nprobabilities and hierarchy structure as classification occurs. Thus, the new\napproaches process training cases in an incremental, online manner that it very\ndifferent from most methods for statistical language learning. We examine how\nwell the three variants place synonyms together and keep homonyms apart, their\nability to recall synonyms as a function of training set size, and their\ntraining efficiency. Finally, we discuss related work on incremental learning\nand directions for further research.\n","authors":["Christopher J. MacLellan","Peter Matsakis","Pat Langley"],"pdf_url":"https://arxiv.org/pdf/2212.11937v1.pdf","comment":"18 pages, 5 figures, Presented at Advances in Cognitive Systems 2022"},{"id":"http://arxiv.org/abs/2212.11126v2","updated":"2022-12-22T17:20:36Z","published":"2022-12-18T16:08:40Z","title":"Chatbots in a Botnet World","summary":"  Question-and-answer formats provide a novel experimental platform for\ninvestigating cybersecurity questions. Unlike previous chatbots, the latest\nChatGPT model from OpenAI supports an advanced understanding of complex coding\nquestions. The research demonstrates thirteen coding tasks that generally\nqualify as stages in the MITRE ATT&CK framework, ranging from credential access\nto defense evasion. With varying success, the experimental prompts generate\nexamples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled\nransomware. The empirical results illustrate cases that support the broad gain\nof functionality, including self-replication and self-modification, evasion,\nand strategic understanding of complex cybersecurity goals. One surprising\nfeature of ChatGPT as a language-only model centers on its ability to spawn\ncoding approaches that yield images that obfuscate or embed executable\nprogramming steps or links.\n","authors":["Forrest McKee","David Noever"],"pdf_url":"https://arxiv.org/pdf/2212.11126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.09800v2","updated":"2022-12-22T17:17:04Z","published":"2020-04-21T07:58:27Z","title":"Keyphrase Generation with Cross-Document Attention","summary":"  Keyphrase generation aims to produce a set of phrases summarizing the\nessentials of a given document. Conventional methods normally apply an\nencoder-decoder architecture to generate the output keyphrases for an input\ndocument, where they are designed to focus on each current document so they\ninevitably omit crucial corpus-level information carried by other similar\ndocuments, i.e., the cross-document dependency and latent topics. In this\npaper, we propose CDKGen, a Transformer-based keyphrase generator, which\nexpands the Transformer to global attention with cross-document attention\nnetworks to incorporate available documents as references so as to generate\nbetter keyphrases with the guidance of topic information. On top of the\nproposed Transformer + cross-document attention architecture, we also adopt a\ncopy mechanism to enhance our model via selecting appropriate words from\ndocuments to deal with out-of-vocabulary words in keyphrases. Experiment\nresults on five benchmark datasets illustrate the validity and effectiveness of\nour model, which achieves the state-of-the-art performance on all datasets.\nFurther analyses confirm that the proposed model is able to generate keyphrases\nconsistent with references while keeping sufficient diversity. The code of\nCDKGen is available at https://github.com/SVAIGBA/CDKGen.\n","authors":["Shizhe Diao","Yan Song","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2004.09800v2.pdf","comment":"This paper will be superseded by another improved version with new\n  approaches, new settings, and new experimental results"},{"id":"http://arxiv.org/abs/2212.07127v4","updated":"2022-12-22T17:10:46Z","published":"2022-12-14T09:26:07Z","title":"Towards mapping the contemporary art world with ArtLM: an art-specific\n  NLP model","summary":"  With an increasing amount of data in the art world, discovering artists and\nartworks suitable to collectors' tastes becomes a challenge. It is no longer\nenough to use visual information, as contextual information about the artist\nhas become just as important in contemporary art. In this work, we present a\ngeneric Natural Language Processing framework (called ArtLM) to discover the\nconnections among contemporary artists based on their biographies. In this\napproach, we first continue to pre-train the existing general English language\nmodels with a large amount of unlabelled art-related data. We then fine-tune\nthis new pre-trained model with our biography pair dataset manually annotated\nby a team of professionals in the art industry. With extensive experiments, we\ndemonstrate that our ArtLM achieves 85.6% accuracy and 84.0% F1 score and\noutperforms other baseline models. We also provide a visualisation and a\nqualitative analysis of the artist network built from ArtLM's outputs.\n","authors":["Qinkai Chen","Mohamed El-Mennaoui","Antoine Fosset","Amine Rebei","Haoyang Cao","Philine Bouscasse","Christy Eóin O'Beirne","Sasha Shevchenko","Mathieu Rosenbaum"],"pdf_url":"https://arxiv.org/pdf/2212.07127v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.15101v3","updated":"2022-12-22T17:05:32Z","published":"2021-09-30T13:06:29Z","title":"Compositional generalization in semantic parsing with pretrained\n  transformers","summary":"  Large-scale pretraining instills large amounts of knowledge in deep neural\nnetworks. This, in turn, improves the generalization behavior of these models\nin downstream tasks. What exactly are the limits to the generalization benefits\nof large-scale pretraining? Here, we report observations from some simple\nexperiments aimed at addressing this question in the context of two semantic\nparsing tasks involving natural language, SCAN and COGS. We show that language\nmodels pretrained exclusively with non-English corpora, or even with\nprogramming language corpora, significantly improve out-of-distribution\ngeneralization in these benchmarks, compared with models trained from scratch,\neven though both benchmarks are English-based. This demonstrates the\nsurprisingly broad transferability of pretrained representations and knowledge.\nPretraining with a large-scale protein sequence prediction task, on the other\nhand, mostly deteriorates the generalization performance in SCAN and COGS,\nsuggesting that pretrained representations do not transfer universally and that\nthere are constraints on the similarity between the pretraining and downstream\ndomains for successful transfer. Finally, we show that larger models are harder\nto train from scratch and their generalization accuracy is lower when trained\nup to convergence on the relatively small SCAN and COGS datasets, but the\nbenefits of large-scale pretraining become much clearer with larger models.\n","authors":["A. Emin Orhan"],"pdf_url":"https://arxiv.org/pdf/2109.15101v3.pdf","comment":"v3 adds one reference, adds further discussion, slightly changes\n  formatting"},{"id":"http://arxiv.org/abs/2212.11856v1","updated":"2022-12-22T16:42:21Z","published":"2022-12-22T16:42:21Z","title":"Multilingual News Location Detection using an Entity-Based Siamese\n  Network with Semi-Supervised Contrastive Learning and Knowledge Base","summary":"  Early detection of relevant locations in a piece of news is especially\nimportant in extreme events such as environmental disasters, war conflicts,\ndisease outbreaks, or political turmoils. Additionally, this detection also\nhelps recommender systems to promote relevant news based on user locations.\nNote that, when the relevant locations are not mentioned explicitly in the\ntext, state-of-the-art methods typically fail to recognize them because these\nmethods rely on syntactic recognition. In contrast, by incorporating a\nknowledge base and connecting entities with their locations, our system\nsuccessfully infers the relevant locations even when they are not mentioned\nexplicitly in the text. To evaluate the effectiveness of our approach, and due\nto the lack of datasets in this area, we also contribute to the research\ncommunity with a gold-standard multilingual news-location dataset, NewsLOC. It\ncontains the annotation of the relevant locations (and their WikiData IDs) of\n600+ Wikinews articles in five different languages: English, French, German,\nItalian, and Spanish. Through experimental evaluations, we show that our\nproposed system outperforms the baselines and the fine-tuned version of the\nmodel using semi-supervised data that increases the classification rate. The\nsource code and the NewsLOC dataset are publicly available for being used by\nthe research community at https://github.com/vsuarezpaniagua/NewsLocation.\n","authors":["Víctor Suárez-Paniagua","Steven Derby","Tri Kurniawan Wijaya"],"pdf_url":"https://arxiv.org/pdf/2212.11856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10498v2","updated":"2022-12-22T16:26:36Z","published":"2022-12-20T18:12:49Z","title":"SimpleStyle: An Adaptable Style Transfer Approach","summary":"  Attribute-controlled text rewriting, also known as text style-transfer, has a\ncrucial role in regulating attributes and biases of textual training data and a\nmachine generated text. In this work we present SimpleStyle, a minimalist yet\neffective approach for style-transfer composed of two simple ingredients:\ncontrolled denoising and output filtering. Despite the simplicity of our\napproach, which can be succinctly described with a few lines of code, it is\ncompetitive with previous state-of-the-art methods both in automatic and in\nhuman evaluation. To demonstrate the adaptability and practical value of our\nsystem beyond academic data, we apply SimpleStyle to transfer a wide range of\ntext attributes appearing in real-world textual data from social networks.\nAdditionally, we introduce a novel \"soft noising\" technique that further\nimproves the performance of our system. We also show that teaching a student\nmodel to generate the output of SimpleStyle can result in a system that\nperforms style transfer of equivalent quality with only a single greedy-decoded\nsample. Finally, we suggest our method as a remedy for the fundamental\nincompatible baseline issue that holds progress in the field. We offer our\nprotocol as a simple yet strong baseline for works that wish to make\nincremental advancements in the field of attribute controlled text rewriting.\n","authors":["Elron Bandel","Yoav Katz","Noam Slonim","Liat Ein-Dor"],"pdf_url":"https://arxiv.org/pdf/2212.10498v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11791v1","updated":"2022-12-22T15:22:36Z","published":"2022-12-22T15:22:36Z","title":"Training Integer-Only Deep Recurrent Neural Networks","summary":"  Recurrent neural networks (RNN) are the backbone of many text and speech\napplications. These architectures are typically made up of several\ncomputationally complex components such as; non-linear activation functions,\nnormalization, bi-directional dependence and attention. In order to maintain\ngood accuracy, these components are frequently run using full-precision\nfloating-point computation, making them slow, inefficient and difficult to\ndeploy on edge devices. In addition, the complex nature of these operations\nmakes them challenging to quantize using standard quantization methods without\na significant performance drop. We present a quantization-aware training method\nfor obtaining a highly accurate integer-only recurrent neural network (iRNN).\nOur approach supports layer normalization, attention, and an adaptive piecewise\nlinear (PWL) approximation of activation functions, to serve a wide range of\nstate-of-the-art RNNs. The proposed method enables RNN-based language models to\nrun on edge devices with $2\\times$ improvement in runtime, and $4\\times$\nreduction in model size while maintaining similar accuracy as its\nfull-precision counterpart.\n","authors":["Vahid Partovi Nia","Eyyüb Sari","Vanessa Courville","Masoud Asgharian"],"pdf_url":"https://arxiv.org/pdf/2212.11791v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2109.09828"},{"id":"http://arxiv.org/abs/1908.11443v2","updated":"2022-12-22T14:34:31Z","published":"2019-08-29T20:09:27Z","title":"NarrativeTime: Dense Temporal Annotation on a Timeline","summary":"  For the past decade, temporal annotation has been sparse: only a small\nportion of event pairs in a text was annotated. We present NarrativeTime, the\nfirst timeline-based annotation framework that achieves full coverage of all\npossible TLinks. To compare with the previous SOTA in dense temporal\nannotation, we perform full re-annotation of TimeBankDense corpus, which shows\ncomparable agreement with a significant increase in density. We contribute\nTimeBankNT corpus (with each text fully annotated by two expert annotators),\nextensive annotation guidelines, open-source tools for annotation and\nconversion to TimeML format, baseline results, as well as quantitative and\nqualitative analysis of inter-annotator agreement.\n","authors":["Anna Rogers","Marzena Karpinska","Ankita Gupta","Vladislav Lialin","Gregory Smelkov","Anna Rumshisky"],"pdf_url":"https://arxiv.org/pdf/1908.11443v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.17094v2","updated":"2022-12-22T13:51:09Z","published":"2022-11-29T17:02:00Z","title":"Better Transcription of UK Supreme Court Hearings","summary":"  Transcription of legal proceedings is very important to enable access to\njustice. However, speech transcription is an expensive and slow process. In\nthis paper we describe part of a combined research and industrial project for\nbuilding an automated transcription tool designed specifically for the Justice\nsector in the UK. We explain the challenges involved in transcribing court room\nhearings and the Natural Language Processing (NLP) techniques we employ to\ntackle these challenges. We will show that fine-tuning a generic off-the-shelf\npre-trained Automatic Speech Recognition (ASR) system with an in-domain\nlanguage model as well as infusing common phrases extracted with a collocation\ndetection model can improve not only the Word Error Rate (WER) of the\ntranscribed hearings but avoid critical errors that are specific of the legal\njargon and terminology commonly used in British courts.\n","authors":["Hadeel Saadany","Catherine Breslin","Constantin Orăsan","Sophie Walker"],"pdf_url":"https://arxiv.org/pdf/2211.17094v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11685v1","updated":"2022-12-22T13:17:11Z","published":"2022-12-22T13:17:11Z","title":"GENIE: Large Scale Pre-training for Text Generation with Diffusion Model","summary":"  In this paper, we propose a large-scale language pre-training for text\nGENeration using dIffusion modEl, which is named GENIE. GENIE is a pre-training\nsequence-to-sequence text generation model which combines Transformer and\ndiffusion. The diffusion model accepts the latent information from the encoder,\nwhich is used to guide the denoising of the current time step. After multiple\nsuch denoise iterations, the diffusion model can restore the Gaussian noise to\nthe diverse output text which is controlled by the input text. Moreover, such\narchitecture design also allows us to adopt large scale pre-training on the\nGENIE. We propose a novel pre-training method named continuous paragraph\ndenoise based on the characteristics of the diffusion model. Extensive\nexperiments on the XSum, CNN/DailyMail, and Gigaword benchmarks shows that\nGENIE can achieves comparable performance with various strong baselines,\nespecially after pre-training, the generation quality of GENIE is greatly\nimproved. We have also conduct a lot of experiments on the generation diversity\nand parameter impact of GENIE. The code for GENIE will be made publicly\navailable.\n","authors":["Zhenghao Lin","Yeyun Gong","Yelong Shen","Tong Wu","Zhihao Fan","Chen Lin","Weizhu Chen","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2212.11685v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2109.10104v2","updated":"2022-12-22T12:15:43Z","published":"2021-09-21T11:35:41Z","title":"InvBERT: Reconstructing Text from Contextualized Word Embeddings by\n  inverting the BERT pipeline","summary":"  Digital Humanities and Computational Literary Studies apply text mining\nmethods to investigate literature. Such automated approaches enable\nquantitative studies on large corpora which would not be feasible by manual\ninspection alone. However, due to copyright restrictions, the availability of\nrelevant digitized literary works is limited. Derived Text Formats (DTFs) have\nbeen proposed as a solution. Here, textual materials are transformed in such a\nway that copyright-critical features are removed, but that the use of certain\nanalytical methods remains possible. Contextualized word embeddings produced by\ntransformer-encoders (like BERT) are promising candidates for DTFs because they\nallow for state-of-the-art performance on various analytical tasks and, at\nfirst sight, do not disclose the original text. However, in this paper we\ndemonstrate that under certain conditions the reconstruction of the original\ncopyrighted text becomes feasible and its publication in the form of\ncontextualized token representations is not safe. Our attempts to invert BERT\nsuggest, that publishing the encoder as a black box together with the\ncontextualized embeddings is critical, since it allows to generate data to\ntrain a decoder with a reconstruction accuracy sufficient to violate copyright\nlaws.\n","authors":["Kai Kugler","Simon Münker","Johannes Höhmann","Achim Rettinger"],"pdf_url":"https://arxiv.org/pdf/2109.10104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14875v3","updated":"2022-12-22T11:58:46Z","published":"2022-11-27T16:11:29Z","title":"Detect-Localize-Repair: A Unified Framework for Learning to Debug with\n  CodeT5","summary":"  Automated software debugging is a crucial task for improving the productivity\nof software developers. Many neural-based techniques have been proven effective\nfor debugging-related tasks such as bug localization and program repair (or bug\nfixing). However, these techniques often focus only on either one of them or\napproach them in a stage-wise manner, ignoring the mutual benefits between\nthem. In this work, we propose a novel unified \\emph{Detect-Localize-Repair}\nframework based on a pretrained programming language model CodeT5 to seamlessly\naddress these tasks, named CodeT5-DLR. Specifically, we propose three\nobjectives to adapt the generic CodeT5 for debugging: a bug detection objective\nto determine whether a given code snippet is buggy or not, a bug localization\nobjective to identify the buggy lines, and a program repair objective to\ntranslate the buggy code to its fixed version. We evaluate it on each of these\ntasks and their combined setting on two newly collected line-level debugging\ndatasets in Java and Python. Extensive results show that our model\nsignificantly outperforms existing baselines from both NLP and software\nengineering domains.\n","authors":["Nghi D. Q. Bui","Yue Wang","Steven Hoi"],"pdf_url":"https://arxiv.org/pdf/2211.14875v3.pdf","comment":"Accepted to EMNLP 2022 Findings Track"},{"id":"http://arxiv.org/abs/2206.02432v2","updated":"2022-12-22T11:18:36Z","published":"2022-06-06T08:48:26Z","title":"Online Neural Diarization of Unlimited Numbers of Speakers Using Global\n  and Local Attractors","summary":"  A method to perform offline and online speaker diarization for an unlimited\nnumber of speakers is described in this paper. End-to-end neural diarization\n(EEND) has achieved overlap-aware speaker diarization by formulating it as a\nmulti-label classification problem. It has also been extended for a flexible\nnumber of speakers by introducing speaker-wise attractors. However, the output\nnumber of speakers of attractor-based EEND is empirically capped; it cannot\ndeal with cases where the number of speakers appearing during inference is\nhigher than that during training because its speaker counting is trained in a\nfully supervised manner. Our method, EEND-GLA, solves this problem by\nintroducing unsupervised clustering into attractor-based EEND. In the method,\nthe input audio is first divided into short blocks, then attractor-based\ndiarization is performed for each block, and finally, the results of each block\nare clustered on the basis of the similarity between locally-calculated\nattractors. While the number of output speakers is limited within each block,\nthe total number of speakers estimated for the entire input can be higher than\nthe limitation. To use EEND-GLA in an online manner, our method also extends\nthe speaker-tracing buffer, which was originally proposed to enable online\ninference of conventional EEND. We introduce a block-wise buffer update to make\nthe speaker-tracing buffer compatible with EEND-GLA. Finally, to improve online\ndiarization, our method improves the buffer update method and revisits the\nvariable chunk-size training of EEND. The experimental results demonstrate that\nEEND-GLA can perform speaker diarization of an unseen number of speakers in\nboth offline and online inferences.\n","authors":["Shota Horiguchi","Shinji Watanabe","Paola Garcia","Yuki Takashima","Yohei Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2206.02432v2.pdf","comment":"Accepted to IEEE/ACM TASLP"},{"id":"http://arxiv.org/abs/2212.10422v2","updated":"2022-12-22T10:29:59Z","published":"2022-12-20T16:59:56Z","title":"Localising In-Domain Adaptation of Transformer-Based Biomedical Language\n  Models","summary":"  In the era of digital healthcare, the huge volumes of textual information\ngenerated every day in hospitals constitute an essential but underused asset\nthat could be exploited with task-specific, fine-tuned biomedical language\nrepresentation models, improving patient care and management. For such\nspecialized domains, previous research has shown that fine-tuning models\nstemming from broad-coverage checkpoints can largely benefit additional\ntraining rounds over large-scale in-domain resources. However, these resources\nare often unreachable for less-resourced languages like Italian, preventing\nlocal medical institutions to employ in-domain adaptation. In order to reduce\nthis gap, our work investigates two accessible approaches to derive biomedical\nlanguage models in languages other than English, taking Italian as a concrete\nuse-case: one based on neural machine translation of English resources,\nfavoring quantity over quality; the other based on a high-grade, narrow-scoped\ncorpus natively written in Italian, thus preferring quality over quantity. Our\nstudy shows that data quantity is a harder constraint than data quality for\nbiomedical adaptation, but the concatenation of high-quality data can improve\nmodel performance even when dealing with relatively size-limited corpora. The\nmodels published from our investigations have the potential to unlock important\nresearch opportunities for Italian hospitals and academia. Finally, the set of\nlessons learned from the study constitutes valuable insights towards a solution\nto build biomedical language models that are generalizable to other\nless-resourced languages and different domain settings.\n","authors":["Tommaso Mario Buonocore","Claudio Crema","Alberto Redolfi","Riccardo Bellazzi","Enea Parimbelli"],"pdf_url":"https://arxiv.org/pdf/2212.10422v2.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.10047v2","updated":"2022-12-22T09:13:04Z","published":"2022-12-20T07:44:25Z","title":"An Augmentation Strategy for Visually Rich Documents","summary":"  Many business workflows require extracting important fields from form-like\ndocuments (e.g. bank statements, bills of lading, purchase orders, etc.).\nRecent techniques for automating this task work well only when trained with\nlarge datasets. In this work we propose a novel data augmentation technique to\nimprove performance when training data is scarce, e.g. 10-250 documents. Our\ntechnique, which we call FieldSwap, works by swapping out the key phrases of a\nsource field with the key phrases of a target field to generate new synthetic\nexamples of the target field for use in training. We demonstrate that this\napproach can yield 1-7 F1 point improvements in extraction performance.\n","authors":["Jing Xie","James B. Wendt","Yichao Zhou","Seth Ebner","Sandeep Tata"],"pdf_url":"https://arxiv.org/pdf/2212.10047v2.pdf","comment":"9 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2212.08482v2","updated":"2022-12-22T09:04:07Z","published":"2022-12-16T13:55:22Z","title":"Implementation of general formal translators","summary":"  The general translator formalism and computing specific implementations are\nproposed. The implementation of specific elements necessary to process the\nsource and destination information within the translators are presented. Some\ncommon directives or instructions, such as classes and procedures, were unified\nand generalized in order to allow general translations implementations. In\norder to cover general cases, two levels of processing are required, related to\nthe source and destination information appropriate transformations, with the\nrelated control and processing instructions. The proposed general translator\nelements are useful for processing natural or artificial information described\nthrough any types of languages or systems.\n","authors":["Iosif Iulian Petrila"],"pdf_url":"https://arxiv.org/pdf/2212.08482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.05890v2","updated":"2022-12-22T06:29:36Z","published":"2022-08-11T15:45:58Z","title":"Speech Synthesis with Mixed Emotions","summary":"  Emotional speech synthesis aims to synthesize human voices with various\nemotional effects. The current studies are mostly focused on imitating an\naveraged style belonging to a specific emotion type. In this paper, we seek to\ngenerate speech with a mixture of emotions at run-time. We propose a novel\nformulation that measures the relative difference between the speech samples of\ndifferent emotions. We then incorporate our formulation into a\nsequence-to-sequence emotional text-to-speech framework. During the training,\nthe framework does not only explicitly characterize emotion styles, but also\nexplores the ordinal nature of emotions by quantifying the differences with\nother emotions. At run-time, we control the model to produce the desired\nemotion mixture by manually defining an emotion attribute vector. The objective\nand subjective evaluations have validated the effectiveness of the proposed\nframework. To our best knowledge, this research is the first study on\nmodelling, synthesizing, and evaluating mixed emotions in speech.\n","authors":["Kun Zhou","Berrak Sisman","Rajib Rana","B. W. Schuller","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2208.05890v2.pdf","comment":"Accepted to IEEE Transactions on Affective Computing"},{"id":"http://arxiv.org/abs/2209.06434v5","updated":"2022-12-22T03:11:59Z","published":"2022-09-14T05:53:37Z","title":"ConvNeXt Based Neural Network for Audio Anti-Spoofing","summary":"  With the rapid development of speech conversion and speech synthesis\nalgorithms, automatic speaker verification (ASV) systems are vulnerable to\nspoofing attacks. In recent years, researchers had proposed a number of\nanti-spoofing methods based on hand-crafted features. However, using\nhand-crafted features rather than raw waveform will lose implicit information\nfor anti-spoofing. Inspired by the promising performance of ConvNeXt in image\nclassification tasks, we revise the ConvNeXt network architecture and propose a\nlightweight end-to-end anti-spoofing model. By integrating with the channel\nattention block and using the focal loss function, the proposed model can focus\non the most informative sub-bands of speech representations and the difficult\nsamples that are hard to classify. Experiments show that our proposed system\ncould achieve an equal error rate of 0.64% and min-tDCF of 0.0187 for the\nASVSpoof 2019 LA evaluation dataset, which outperforms the state-of-the-art\nsystems.\n","authors":["Qiaowei Ma","Jinghui Zhong","Yitao Yang","Weiheng Liu","Ying Gao","Wing W. Y. Ng"],"pdf_url":"https://arxiv.org/pdf/2209.06434v5.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2212.11456v1","updated":"2022-12-22T02:19:25Z","published":"2022-12-22T02:19:25Z","title":"CAMeMBERT: Cascading Assistant-Mediated Multilingual BERT","summary":"  Large language models having hundreds of millions, and even billions, of\nparameters have performed extremely well on a variety of natural language\nprocessing (NLP) tasks. Their widespread use and adoption, however, is hindered\nby the lack of availability and portability of sufficiently large computational\nresources. This paper proposes a knowledge distillation (KD) technique building\non the work of LightMBERT, a student model of multilingual BERT (mBERT). By\nrepeatedly distilling mBERT through increasingly compressed toplayer distilled\nteacher assistant networks, CAMeMBERT aims to improve upon the time and space\ncomplexities of mBERT while keeping loss of accuracy beneath an acceptable\nthreshold. At present, CAMeMBERT has an average accuracy of around 60.1%, which\nis subject to change after future improvements to the hyperparameters used in\nfine-tuning.\n","authors":["Dan DeGenaro","Jugal Kalita"],"pdf_url":"https://arxiv.org/pdf/2212.11456v1.pdf","comment":"4 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2212.11455v1","updated":"2022-12-22T02:13:30Z","published":"2022-12-22T02:13:30Z","title":"Understanding Postpartum Parents' Experiences via Two Digital Platforms","summary":"  Digital platforms, including online forums and helplines, have emerged as\navenues of support for caregivers suffering from postpartum mental health\ndistress. Understanding support seekers' experiences as shared on these\nplatforms could provide crucial insight into caregivers' needs during this\nvulnerable time. In the current work, we provide a descriptive analysis of the\nconcerns, psychological states, and motivations shared by healthy and\ndistressed postpartum support seekers on two digital platforms, a one-on-one\ndigital helpline and a publicly available online forum. Using a combination of\nhuman annotations, dictionary models and unsupervised techniques, we find stark\ndifferences between the experiences of distressed and healthy mothers.\nDistressed mothers described interpersonal problems and a lack of support, with\n8.60% - 14.56% reporting severe symptoms including suicidal ideation. In\ncontrast, the majority of healthy mothers described childcare issues, such as\nquestions about breastfeeding or sleeping, and reported no severe mental health\nconcerns. Across the two digital platforms, we found that distressed mothers\nshared similar content. However, the patterns of speech and affect shared by\ndistressed mothers differed between the helpline vs. the online forum,\nsuggesting the design of these platforms may shape meaningful measures of their\nsupport-seeking experiences. Our results provide new insight into the\nexperiences of caregivers suffering from postpartum mental health distress. We\nconclude by discussing methodological considerations for understanding content\nshared by support seekers and design considerations for the next generation of\nsupport tools for postpartum parents.\n","authors":["Xuewen Yao","Miriam Mikhelson","Megan Micheletti","Eunsol Choi","S Craig Watkins","Edison Thomaz","Kaya De Barbaro"],"pdf_url":"https://arxiv.org/pdf/2212.11455v1.pdf","comment":"Will be published in PACM HCI, CSCW1, April 2023 issue"},{"id":"http://arxiv.org/abs/2212.09400v2","updated":"2022-12-22T01:57:51Z","published":"2022-12-19T12:24:32Z","title":"An Efficient Drug-Drug Interactions Prediction Technology for\n  Molecularly Intelligent Manufacturing","summary":"  Drug-Drug Interactions (DDIs) prediction is an essential issue in the\nmolecular field. Traditional methods of observing DDIs in medical experiments\nrequire plenty of resources and labor. In this paper, we present a\ncomputational model dubbed MedKGQA based on Graph Neural Networks to\nautomatically predict the DDIs after reading multiple medical documents in the\nform of multi-hop machine reading comprehension. We introduced a knowledge\nfusion system to obtain the complete nature of drugs and proteins and exploited\na graph reasoning system to infer the drugs and proteins contained in the\ndocuments. Our model significantly improves the performance compared to\nprevious state-of-the-art models on the QANGAROO MedHop dataset, which obtained\na 4.5% improvement in terms of DDIs prediction accuracy.\n","authors":["Peng Gao","Feng Gao","Jian-Cheng Ni"],"pdf_url":"https://arxiv.org/pdf/2212.09400v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2212.11984v1","updated":"2022-12-22T18:59:59Z","published":"2022-12-22T18:59:59Z","title":"DisCoScene: Spatially Disentangled Generative Radiance Fields for\n  Controllable 3D-aware Scene Synthesis","summary":"  Existing 3D-aware image synthesis approaches mainly focus on generating a\nsingle canonical object and show limited capacity in composing a complex scene\ncontaining a variety of objects. This work presents DisCoScene: a 3Daware\ngenerative model for high-quality and controllable scene synthesis. The key\ningredient of our method is a very abstract object-level representation (i.e.,\n3D bounding boxes without semantic annotation) as the scene layout prior, which\nis simple to obtain, general to describe various scene contents, and yet\ninformative to disentangle objects and background. Moreover, it serves as an\nintuitive user control for scene editing. Based on such a prior, the proposed\nmodel spatially disentangles the whole scene into object-centric generative\nradiance fields by learning on only 2D images with the global-local\ndiscrimination. Our model obtains the generation fidelity and editing\nflexibility of individual objects while being able to efficiently compose\nobjects and the background into a complete scene. We demonstrate\nstate-of-the-art performance on many scene datasets, including the challenging\nWaymo outdoor dataset. Project page:\nhttps://snap-research.github.io/discoscene/\n","authors":["Yinghao Xu","Menglei Chai","Zifan Shi","Sida Peng","Ivan Skorokhodov","Aliaksandr Siarohin","Ceyuan Yang","Yujun Shen","Hsin-Ying Lee","Bolei Zhou","Sergey Tulyakov"],"pdf_url":"https://arxiv.org/pdf/2212.11984v1.pdf","comment":"Project page: https://snap-research.github.io/discoscene/"},{"id":"http://arxiv.org/abs/2212.11979v1","updated":"2022-12-22T18:58:54Z","published":"2022-12-22T18:58:54Z","title":"A Wearable Data Collection System for Studying Micro-Level E-Scooter\n  Behavior in Naturalistic Road Environment","summary":"  As one of the most popular micro-mobility options, e-scooters are spreading\nin hundreds of big cities and college towns in the US and worldwide. In the\nmeantime, e-scooters are also posing new challenges to traffic safety. In\ngeneral, e-scooters are suggested to be ridden in bike lanes/sidewalks or share\nthe road with cars at the maximum speed of about 15-20 mph, which is more\nflexible and much faster than the pedestrains and bicyclists. These features\nmake e-scooters challenging for human drivers, pedestrians, vehicle active\nsafety modules, and self-driving modules to see and interact. To study this new\nmobility option and address e-scooter riders' and other road users' safety\nconcerns, this paper proposes a wearable data collection system for\ninvestigating the micro-level e-Scooter motion behavior in a Naturalistic road\nenvironment. An e-Scooter-based data acquisition system has been developed by\nintegrating LiDAR, cameras, and GPS using the robot operating system (ROS).\nSoftware frameworks are developed to support hardware interfaces, sensor\noperation, sensor synchronization, and data saving. The integrated system can\ncollect data continuously for hours, meeting all the requirements including\ncalibration accuracy and capability of collecting the vehicle and e-Scooter\nencountering data.\n","authors":["Avinash Prabu","Dan Shen","Renran Tian","Stanley Chien","Lingxi Li","Yaobin Chen","Rini Sherony"],"pdf_url":"https://arxiv.org/pdf/2212.11979v1.pdf","comment":"Conference: Fast-zero'21, Kanazawa, Japan Date of publication: Sep\n  2021 Publisher: JSAE"},{"id":"http://arxiv.org/abs/2212.11972v1","updated":"2022-12-22T18:55:45Z","published":"2022-12-22T18:55:45Z","title":"Scalable Adaptive Computation for Iterative Generation","summary":"  We present the Recurrent Interface Network (RIN), a neural net architecture\nthat allocates computation adaptively to the input according to the\ndistribution of information, allowing it to scale to iterative generation of\nhigh-dimensional data. Hidden units of RINs are partitioned into the interface,\nwhich is locally connected to inputs, and latents, which are decoupled from\ninputs and can exchange information globally. The RIN block selectively reads\nfrom the interface into latents for high-capacity processing, with incremental\nupdates written back to the interface. Stacking multiple blocks enables\neffective routing across local and global levels. While routing adds overhead,\nthe cost can be amortized in recurrent computation settings where inputs change\ngradually while more global context persists, such as iterative generation\nusing diffusion models. To this end, we propose a latent self-conditioning\ntechnique that \"warm-starts\" the latents at each iteration of the generation\nprocess. When applied to diffusion models operating directly on pixels, RINs\nyield state-of-the-art image and video generation without cascades or guidance,\nwhile being domain-agnostic and up to 10$\\times$ more efficient compared to\nspecialized 2D and 3D U-Nets.\n","authors":["Allan Jabri","David Fleet","Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2212.11972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11966v1","updated":"2022-12-22T18:51:06Z","published":"2022-12-22T18:51:06Z","title":"Removing Objects From Neural Radiance Fields","summary":"  Neural Radiance Fields (NeRFs) are emerging as a ubiquitous scene\nrepresentation that allows for novel view synthesis. Increasingly, NeRFs will\nbe shareable with other people. Before sharing a NeRF, though, it might be\ndesirable to remove personal information or unsightly objects. Such removal is\nnot easily achieved with the current NeRF editing frameworks. We propose a\nframework to remove objects from a NeRF representation created from an RGB-D\nsequence. Our NeRF inpainting method leverages recent work in 2D image\ninpainting and is guided by a user-provided mask. Our algorithm is underpinned\nby a confidence based view selection procedure. It chooses which of the\nindividual 2D inpainted images to use in the creation of the NeRF, so that the\nresulting inpainted NeRF is 3D consistent. We show that our method for NeRF\nediting is effective for synthesizing plausible inpaintings in a multi-view\ncoherent manner. We validate our approach using a new and still-challenging\ndataset for the task of NeRF inpainting.\n","authors":["Silvan Weder","Guillermo Garcia-Hernando","Aron Monszpart","Marc Pollefeys","Gabriel Brostow","Michael Firman","Sara Vicente"],"pdf_url":"https://arxiv.org/pdf/2212.11966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07771v2","updated":"2022-12-22T18:08:12Z","published":"2022-11-14T22:05:09Z","title":"Edge2Vec: A High Quality Embedding for the Jigsaw Puzzle Problem","summary":"  Pairwise compatibility measure (CM) is a key component in solving the jigsaw\npuzzle problem (JPP) and many of its recently proposed variants. With the rapid\nrise of deep neural networks (DNNs), a trade-off between performance (i.e.,\naccuracy) and computational efficiency has become a very significant issue.\nWhereas an end-to-end DNN-based CM model exhibits high performance, it becomes\nvirtually infeasible on very large puzzles, due to its highly intensive\ncomputation. On the other hand, exploiting the concept of embeddings to\nalleviate significantly the computational efficiency, has resulted in degraded\nperformance, according to recent studies. This paper derives an advanced CM\nmodel (based on modified embeddings and a new loss function, called hard batch\ntriplet loss) for closing the above gap between speed and accuracy; namely a CM\nmodel that achieves SOTA results in terms of performance and efficiency\ncombined. We evaluated our newly derived CM on three commonly used datasets,\nand obtained a reconstruction improvement of 5.8% and 19.5% for so-called\nType-1 and Type-2 problem variants, respectively, compared to best known\nresults due to previous CMs.\n","authors":["Daniel Rika","Dror Sholomon","Eli David","Nathan S. Netanyahu"],"pdf_url":"https://arxiv.org/pdf/2211.07771v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11922v1","updated":"2022-12-22T17:59:48Z","published":"2022-12-22T17:59:48Z","title":"SupeRGB-D: Zero-shot Instance Segmentation in Cluttered Indoor\n  Environments","summary":"  Object instance segmentation is a key challenge for indoor robots navigating\ncluttered environments with many small objects. Limitations in 3D sensing\ncapabilities often make it difficult to detect every possible object. While\ndeep learning approaches may be effective for this problem, manually annotating\n3D data for supervised learning is time-consuming. In this work, we explore\nzero-shot instance segmentation (ZSIS) from RGB-D data to identify unseen\nobjects in a semantic category-agnostic manner. We introduce a zero-shot split\nfor Tabletop Objects Dataset (TOD-Z) to enable this study and present a method\nthat uses annotated objects to learn the ``objectness'' of pixels and\ngeneralize to unseen object categories in cluttered indoor environments. Our\nmethod, SupeRGB-D, groups pixels into small patches based on geometric cues and\nlearns to merge the patches in a deep agglomerative clustering fashion.\nSupeRGB-D outperforms existing baselines on unseen objects while achieving\nsimilar performance on seen objects. Additionally, it is extremely lightweight\n(0.4 MB memory requirement) and suitable for mobile and robotic applications.\nThe dataset split and code will be made publicly available upon acceptance.\n","authors":["Evin Pınar Örnek","Aravindhan K Krishnan","Shreekant Gayaka","Cheng-Hao Kuo","Arnie Sen","Nassir Navab","Federico Tombari"],"pdf_url":"https://arxiv.org/pdf/2212.11922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11920v1","updated":"2022-12-22T17:59:19Z","published":"2022-12-22T17:59:19Z","title":"Beyond SOT: It's Time to Track Multiple Generic Objects at Once","summary":"  Generic Object Tracking (GOT) is the problem of tracking target objects,\nspecified by bounding boxes in the first frame of a video. While the task has\nreceived much attention in the last decades, researchers have almost\nexclusively focused on the single object setting. Multi-object GOT benefits\nfrom a wider applicability, rendering it more attractive in real-world\napplications. We attribute the lack of research interest into this problem to\nthe absence of suitable benchmarks. In this work, we introduce a new\nlarge-scale GOT benchmark, LaGOT, containing multiple annotated target objects\nper sequence. Our benchmark allows researchers to tackle key remaining\nchallenges in GOT, aiming to increase robustness and reduce computation through\njoint tracking of multiple objects simultaneously. Furthermore, we propose a\nTransformer-based GOT tracker TaMOS capable of joint processing of multiple\nobjects through shared computation. TaMOs achieves a 4x faster run-time in case\nof 10 concurrent objects compared to tracking each object independently and\noutperforms existing single object trackers on our new benchmark. Finally,\nTaMOs achieves highly competitive results on single-object GOT datasets,\nsetting a new state-of-the-art on TrackingNet with a success rate AUC of 84.4%.\nOur benchmark, code, and trained models will be made publicly available.\n","authors":["Christoph Mayer","Martin Danelljan","Ming-Hsuan Yang","Vittorio Ferrari","Luc Van Gool","Alina Kuznetsova"],"pdf_url":"https://arxiv.org/pdf/2212.11920v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2210.13452v2","updated":"2022-12-22T17:56:05Z","published":"2022-10-24T17:59:57Z","title":"MetaFormer Baselines for Vision","summary":"  MetaFormer, the abstracted architecture of Transformer, has been found to\nplay a significant role in achieving competitive performance. In this paper, we\nfurther explore the capacity of MetaFormer, again, without focusing on token\nmixer design: we introduce several baseline models under MetaFormer using the\nmost basic or common mixers, and summarize our observations as follows: (1)\nMetaFormer ensures solid lower bound of performance. By merely adopting\nidentity mapping as the token mixer, the MetaFormer model, termed\nIdentityFormer, achieves >80% accuracy on ImageNet-1K. (2) MetaFormer works\nwell with arbitrary token mixers. When specifying the token mixer as even a\nrandom matrix to mix tokens, the resulting model RandFormer yields an accuracy\nof >81%, outperforming IdentityFormer. Rest assured of MetaFormer's results\nwhen new token mixers are adopted. (3) MetaFormer effortlessly offers\nstate-of-the-art results. With just conventional token mixers dated back five\nyears ago, the models instantiated from MetaFormer already beat state of the\nart. (a) ConvFormer outperforms ConvNeXt. Taking the common depthwise separable\nconvolutions as the token mixer, the model termed ConvFormer, which can be\nregarded as pure CNNs, outperforms the strong CNN model ConvNeXt. (b) CAFormer\nsets new record on ImageNet-1K. By simply applying depthwise separable\nconvolutions as token mixer in the bottom stages and vanilla self-attention in\nthe top stages, the resulting model CAFormer sets a new record on ImageNet-1K:\nit achieves an accuracy of 85.5% at 224x224 resolution, under normal supervised\ntraining without external data or distillation. In our expedition to probe\nMetaFormer, we also find that a new activation, StarReLU, reduces 71% FLOPs of\nactivation compared with GELU yet achieves better performance. We expect\nStarReLU to find great potential in MetaFormer-like models alongside other\nneural networks.\n","authors":["Weihao Yu","Chenyang Si","Pan Zhou","Mi Luo","Yichen Zhou","Jiashi Feng","Shuicheng Yan","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2210.13452v2.pdf","comment":"Add more ImageNet-22K pretrained models. Code:\n  https://github.com/sail-sg/metaformer"},{"id":"http://arxiv.org/abs/2211.12446v2","updated":"2022-12-22T17:13:50Z","published":"2022-11-22T18:02:49Z","title":"EDICT: Exact Diffusion Inversion via Coupled Transformations","summary":"  Finding an initial noise vector that produces an input image when fed into\nthe diffusion process (known as inversion) is an important problem in denoising\ndiffusion models (DDMs), with applications for real image editing. The\nstate-of-the-art approach for real image editing with inversion uses denoising\ndiffusion implicit models (DDIMs) to deterministically noise the image to the\nintermediate state along the path that the denoising would follow given the\noriginal conditioning. However, DDIM inversion for real images is unstable as\nit relies on local linearization assumptions, which result in the propagation\nof errors, leading to incorrect image reconstruction and loss of content. To\nalleviate these problems, we propose Exact Diffusion Inversion via Coupled\nTransformations (EDICT), an inversion method that draws inspiration from affine\ncoupling layers. EDICT enables mathematically exact inversion of real and\nmodel-generated images by maintaining two coupled noise vectors which are used\nto invert each other in an alternating fashion. Using Stable Diffusion, a\nstate-of-the-art latent diffusion model, we demonstrate that EDICT successfully\nreconstructs real images with high fidelity. On complex image datasets like\nMS-COCO, EDICT reconstruction significantly outperforms DDIM, improving the\nmean square error of reconstruction by a factor of two. Using noise vectors\ninverted from real images, EDICT enables a wide range of image edits--from\nlocal and global semantic edits to image stylization--while maintaining\nfidelity to the original image structure. EDICT requires no model\ntraining/finetuning, prompt tuning, or extra data and can be combined with any\npretrained DDM. Code is available at https://github.com/salesforce/EDICT.\n","authors":["Bram Wallace","Akash Gokul","Nikhil Naik"],"pdf_url":"https://arxiv.org/pdf/2211.12446v2.pdf","comment":"24 pages, 22 figures. Code now available"},{"id":"http://arxiv.org/abs/2211.01950v3","updated":"2022-12-22T17:05:42Z","published":"2022-10-24T13:33:15Z","title":"Unlocking the potential of two-point cells for energy-efficient and\n  resilient training of deep nets","summary":"  Context-sensitive two-point layer 5 pyramidal cells (L5PCs) were discovered\nas long ago as 1999. However, the potential of this discovery to provide useful\nneural computation has yet to be demonstrated. Here we show for the first time\nhow a transformative L5PCs-driven deep neural network (DNN), termed the\nmultisensory cooperative computing (MCC) architecture, can effectively process\nlarge amounts of heterogeneous real-world audio-visual (AV) data, using far\nless energy compared to best available 'point' neuron-driven DNNs. A novel\nhighly-distributed parallel implementation on a Xilinx UltraScale+ MPSoC device\nestimates energy savings up to 245759 $ \\times $ 50000 $\\mu$J (i.e., 62% less\nthan the baseline model in a semi-supervised learning setup) where a single\nsynapse consumes $8e^{-5}\\mu$J. In a supervised learning setup, the\nenergy-saving can potentially reach up to 1250x less (per feedforward\ntransmission) than the baseline model. The significantly reduced neural\nactivity in MCC leads to inherently fast learning and resilience against sudden\nneural damage. This remarkable performance in pilot experiments demonstrates\nthe embodied neuromorphic intelligence of our proposed cooperative L5PC that\nreceives input from diverse neighbouring neurons as context to amplify the\ntransmission of most salient and relevant information for onward transmission,\nfrom overwhelmingly large multimodal information utilised at the early stages\nof on-chip training. Our proposed approach opens new cross-disciplinary avenues\nfor future on-chip DNN training implementations and posits a radical shift in\ncurrent neuromorphic computing paradigms.\n","authors":["Ahsan Adeel","Adewale Adetomi","Khubaib Ahmed","Amir Hussain","Tughrul Arslan","W. A. Phillips"],"pdf_url":"https://arxiv.org/pdf/2211.01950v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11365v2","updated":"2022-12-22T16:39:40Z","published":"2022-07-22T22:39:57Z","title":"EgoEnv: Human-centric environment representations from egocentric video","summary":"  First-person video highlights a camera-wearer's activities in the context of\ntheir persistent environment. However, current video understanding approaches\nreason over visual features from short video clips that are detached from the\nunderlying physical space and capture only what is immediately visible. We\npresent an approach that links egocentric video and the environment by learning\nrepresentations that are predictive of the camera-wearer's (potentially unseen)\nlocal surroundings to facilitate human-centric environment understanding. We\ntrain such models using videos from agents in simulated 3D environments where\nthe environment is fully observable, and test them on human-captured real-world\nvideos from unseen environments. On two human-centric video tasks, we show that\nstate-of-the-art video models equipped with our environment-aware features\nconsistently outperform their counterparts with traditional clip features.\nMoreover, despite being trained exclusively on simulated videos, our approach\nsuccessfully handles real-world videos from HouseTours and Ego4D. Project page:\nhttps://vision.cs.utexas.edu/projects/ego-env/\n","authors":["Tushar Nagarajan","Santhosh Kumar Ramakrishnan","Ruta Desai","James Hillis","Kristen Grauman"],"pdf_url":"https://arxiv.org/pdf/2207.11365v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12432v3","updated":"2022-12-22T16:26:32Z","published":"2022-11-22T17:39:31Z","title":"Multi-task Learning for Camera Calibration","summary":"  For a number of tasks, such as 3D reconstruction, robotic interface,\nautonomous driving, etc., camera calibration is essential. In this study, we\npresent a unique method for predicting intrinsic (principal point offset and\nfocal length) and extrinsic (baseline, pitch, and translation) properties from\na pair of images. We suggested a novel method where camera model equations are\nrepresented as a neural network in a multi-task learning framework, in contrast\nto existing methods, which build a comprehensive solution. By reconstructing\nthe 3D points using a camera model neural network and then using the loss in\nreconstruction to obtain the camera specifications, this innovative camera\nprojection loss (CPL) method allows us that the desired parameters should be\nestimated. As far as we are aware, our approach is the first one that uses an\napproach to multi-task learning that includes mathematical formulas in a\nframework for learning to estimate camera parameters to predict both the\nextrinsic and intrinsic parameters jointly. Additionally, we provided a new\ndataset named as CVGL Camera Calibration Dataset [1] which has been collected\nusing the CARLA Simulator [2]. Actually, we show that our suggested strategy\nout performs both conventional methods and methods based on deep learning on 8\nout of 10 parameters that were assessed using both real and synthetic data. Our\ncode and generated dataset are available at\nhttps://github.com/thanif/Camera-Calibration-through-Camera-Projection-Loss.\n","authors":["Talha Hanif Butt","Murtaza Taj"],"pdf_url":"https://arxiv.org/pdf/2211.12432v3.pdf","comment":"20 pages, 12 figures, 8 tables"},{"id":"http://arxiv.org/abs/2212.11844v1","updated":"2022-12-22T16:25:58Z","published":"2022-12-22T16:25:58Z","title":"Fully 3D Implementation of the End-to-end Deep Image Prior-based PET\n  Image Reconstruction Using Block Iterative Algorithm","summary":"  Deep image prior (DIP) has recently attracted attention owing to its\nunsupervised positron emission tomography (PET) image reconstruction, which\ndoes not require any prior training dataset. In this paper, we present the\nfirst attempt to implement an end-to-end DIP-based fully 3D PET image\nreconstruction method that incorporates a forward-projection model into a loss\nfunction. To implement a practical fully 3D PET image reconstruction, which\ncould not be performed due to a graphics processing unit memory limitation, we\nmodify the DIP optimization to block-iteration and sequentially learn an\nordered sequence of block sinograms. Furthermore, the relative difference\npenalty (RDP) term was added to the loss function to enhance the quantitative\nPET image accuracy. We evaluated our proposed method using Monte Carlo\nsimulation with [$^{18}$F]FDG PET data of a human brain and a preclinical study\non monkey brain [$^{18}$F]FDG PET data. The proposed method was compared with\nthe maximum-likelihood expectation maximization (EM), maximum-a-posterior EM\nwith RDP, and hybrid DIP-based PET reconstruction methods. The simulation\nresults showed that the proposed method improved the PET image quality by\nreducing statistical noise and preserved a contrast of brain structures and\ninserted tumor compared with other algorithms. In the preclinical experiment,\nfiner structures and better contrast recovery were obtained by the proposed\nmethod. This indicated that the proposed method can produce high-quality images\nwithout a prior training dataset. Thus, the proposed method is a key enabling\ntechnology for the straightforward and practical implementation of end-to-end\nDIP-based fully 3D PET image reconstruction.\n","authors":["Fumio Hashimoto","Yuya Onishi","Kibo Ote","Hideaki Tashima","Taiga Yamaya"],"pdf_url":"https://arxiv.org/pdf/2212.11844v1.pdf","comment":"9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.11824v1","updated":"2022-12-22T16:02:44Z","published":"2022-12-22T16:02:44Z","title":"Jamdani Motif Generation using Conditional GAN","summary":"  Jamdani is the strikingly patterned textile heritage of Bangladesh. The\nexclusive geometric motifs woven on the fabric are the most attractive part of\nthis craftsmanship having a remarkable influence on textile and fine art. In\nthis paper, we have developed a technique based on the Generative Adversarial\nNetwork that can learn to generate entirely new Jamdani patterns from a\ncollection of Jamdani motifs that we assembled, the newly formed motifs can\nmimic the appearance of the original designs. Users can input the skeleton of a\ndesired pattern in terms of rough strokes and our system finalizes the input by\ngenerating the complete motif which follows the geometric structure of real\nJamdani ones. To serve this purpose, we collected and preprocessed a dataset\ncontaining a large number of Jamdani motifs images from authentic sources via\nfieldwork and applied a state-of-the-art method called pix2pix to it. To the\nbest of our knowledge, this dataset is currently the only available dataset of\nJamdani motifs in digital format for computer vision research. Our experimental\nresults of the pix2pix model on this dataset show satisfactory outputs of\ncomputer-generated images of Jamdani motifs and we believe that our work will\nopen a new avenue for further research.\n","authors":["MD Tanvir Rouf Shawon","Raihan Tanvir","Humaira Ferdous Shifa","Susmoy Kar","Mohammad Imrul Jubair"],"pdf_url":"https://arxiv.org/pdf/2212.11824v1.pdf","comment":"2020 23rd International Conference on Computer and Information\n  Technology (ICCIT), 2020, pp. 1-6"},{"id":"http://arxiv.org/abs/2212.11804v1","updated":"2022-12-22T15:36:07Z","published":"2022-12-22T15:36:07Z","title":"Monocular 3D Object Detection using Multi-Stage Approaches with\n  Attention and Slicing aided hyper inference","summary":"  3D object detection is vital as it would enable us to capture objects' sizes,\norientation, and position in the world. As a result, we would be able to use\nthis 3D detection in real-world applications such as Augmented Reality (AR),\nself-driving cars, and robotics which perceive the world the same way we do as\nhumans. Monocular 3D Object Detection is the task to draw 3D bounding box\naround objects in a single 2D RGB image. It is localization task but without\nany extra information like depth or other sensors or multiple images. Monocular\n3D object detection is an important yet challenging task. Beyond the\nsignificant progress in image-based 2D object detection, 3D understanding of\nreal-world objects is an open challenge that has not been explored extensively\nthus far. In addition to the most closely related studies.\n","authors":["Abonia Sojasingarayar","Ashish Patel"],"pdf_url":"https://arxiv.org/pdf/2212.11804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11796v1","updated":"2022-12-22T15:27:25Z","published":"2022-12-22T15:27:25Z","title":"Automatically Annotating Indoor Images with CAD Models via RGB-D Scans","summary":"  We present an automatic method for annotating images of indoor scenes with\nthe CAD models of the objects by relying on RGB-D scans. Through a visual\nevaluation by 3D experts, we show that our method retrieves annotations that\nare at least as accurate as manual annotations, and can thus be used as ground\ntruth without the burden of manually annotating 3D data. We do this using an\nanalysis-by-synthesis approach, which compares renderings of the CAD models\nwith the captured scene. We introduce a 'cloning procedure' that identifies\nobjects that have the same geometry, to annotate these objects with the same\nCAD models. This allows us to obtain complete annotations for the ScanNet\ndataset and the recent ARKitScenes dataset.\n","authors":["Stefan Ainetter","Sinisa Stekovic","Friedrich Fraundorfer","Vincent Lepetit"],"pdf_url":"https://arxiv.org/pdf/2212.11796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08748v2","updated":"2022-12-22T15:09:19Z","published":"2022-06-13T19:20:11Z","title":"ReViSe: Remote Vital Signs Measurement Using Smartphone Camera","summary":"  We propose an end-to-end framework to measure people's vital signs including\nHeart Rate (HR), Heart Rate Variability (HRV), Oxygen Saturation (SpO2) and\nBlood Pressure (BP) based on the rPPG methodology from the video of a user's\nface captured with a smartphone camera. We extract face landmarks with a deep\nlearning-based neural network model in real-time. Multiple face patches also\ncalled Regions-of-Interest (RoIs) are extracted by using the predicted face\nlandmarks. Several filters are applied to reduce the noise from the RoIs in the\nextracted cardiac signals called Blood Volume Pulse (BVP) signal. The\nmeasurements of HR, HRV and SpO2 are validated on two public rPPG datasets\nnamely the TokyoTech rPPG and the Pulse Rate Detection (PURE) datasets, on\nwhich our models achieved the following Mean Absolute Errors (MAE): a) for HR,\n1.73Beats-Per-Minute (bpm) and 3.95bpm respectively; b) for HRV, 18.55ms and\n25.03ms respectively, and c) for SpO2, an MAE of 1.64% on the PURE dataset. We\nvalidated our end-to-end rPPG framework, ReViSe, in daily living environment,\nand thereby created the Video-HR dataset. Our HR estimation model achieved an\nMAE of 2.49bpm on this dataset. Since no publicly available rPPG datasets\nexisted for BP measurement with face videos, we used a dataset with signals\nfrom fingertip sensor to train our deep learning-based BP estimation model and\nalso created our own video dataset, Video-BP. On our Video-BP dataset, our BP\nestimation model achieved an MAE of 6.7mmHg for Systolic Blood Pressure (SBP),\nand an MAE of 9.6mmHg for Diastolic Blood Pressure (DBP). ReViSe framework has\nbeen validated on datasets with videos recorded in daily living environment as\nopposed to less noisy laboratory environment as reported by most\nstate-of-the-art techniques.\n","authors":["Donghao Qiao","Amtul Haq Ayesha","Farhana Zulkernine","Raihan Masroor","Nauman Jaffar"],"pdf_url":"https://arxiv.org/pdf/2206.08748v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11760v1","updated":"2022-12-22T14:52:44Z","published":"2022-12-22T14:52:44Z","title":"Aliasing is a Driver of Adversarial Attacks","summary":"  Aliasing is a highly important concept in signal processing, as careful\nconsideration of resolution changes is essential in ensuring transmission and\nprocessing quality of audio, image, and video. Despite this, up until recently\naliasing has received very little consideration in Deep Learning, with all\ncommon architectures carelessly sub-sampling without considering aliasing\neffects. In this work, we investigate the hypothesis that the existence of\nadversarial perturbations is due in part to aliasing in neural networks. Our\nultimate goal is to increase robustness against adversarial attacks using\nexplainable, non-trained, structural changes only, derived from aliasing first\nprinciples. Our contributions are the following. First, we establish a\nsufficient condition for no aliasing for general image transformations. Next,\nwe study sources of aliasing in common neural network layers, and derive simple\nmodifications from first principles to eliminate or reduce it. Lastly, our\nexperimental results show a solid link between anti-aliasing and adversarial\nattacks. Simply reducing aliasing already results in more robust classifiers,\nand combining anti-aliasing with robust training out-performs solo robust\ntraining on $L_2$ attacks with none or minimal losses in performance on\n$L_{\\infty}$ attacks.\n","authors":["Adrián Rodríguez-Muñoz","Antonio Torralba"],"pdf_url":"https://arxiv.org/pdf/2212.11760v1.pdf","comment":"14 pages, 9 figures, 4 tables"},{"id":"http://arxiv.org/abs/2212.11747v1","updated":"2022-12-22T14:37:47Z","published":"2022-12-22T14:37:47Z","title":"Deep Simplex Classifier for Maximizing the Margin in Both Euclidean and\n  Angular Spaces","summary":"  The classification loss functions used in deep neural network classifiers can\nbe grouped into two categories based on maximizing the margin in either\nEuclidean or angular spaces. Euclidean distances between sample vectors are\nused during classification for the methods maximizing the margin in Euclidean\nspaces whereas the Cosine similarity distance is used during the testing stage\nfor the methods maximizing margin in the angular spaces. This paper introduces\na novel classification loss that maximizes the margin in both the Euclidean and\nangular spaces at the same time. This way, the Euclidean and Cosine distances\nwill produce similar and consistent results and complement each other, which\nwill in turn improve the accuracies. The proposed loss function enforces the\nsamples of classes to cluster around the centers that represent them. The\ncenters approximating classes are chosen from the boundary of a hypersphere,\nand the pairwise distances between class centers are always equivalent. This\nrestriction corresponds to choosing centers from the vertices of a regular\nsimplex. There is not any hyperparameter that must be set by the user in the\nproposed loss function, therefore the use of the proposed method is extremely\neasy for classical classification problems. Moreover, since the class samples\nare compactly clustered around their corresponding means, the proposed\nclassifier is also very suitable for open set recognition problems where test\nsamples can come from the unknown classes that are not seen in the training\nphase. Experimental studies show that the proposed method achieves the\nstate-of-the-art accuracies on open set recognition despite its simplicity.\n","authors":["Hakan Cevikalp","Hasan Saribas"],"pdf_url":"https://arxiv.org/pdf/2212.11747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11741v1","updated":"2022-12-22T14:32:55Z","published":"2022-12-22T14:32:55Z","title":"Depth Estimation maps of lidar and stereo images","summary":"  This paper as technology report is focusing on evaluation and performance\nabout depth estimations based on lidar data and stereo images(front left and\nfront right). The lidar 3d cloud data and stereo images are provided by ford.\nIn addition, this paper also will explain some details about optimization for\ndepth estimation performance. And some reasons why not use machine learning to\ndo depth estimation, replaced by pure mathmatics to do stereo depth estimation.\nThe structure of this paper is made of by following:(1) Performance: to discuss\nand evaluate about depth maps created from stereo images and 3D cloud points,\nand relationships analysis for alignment and errors;(2) Depth estimation by\nstereo images: to explain the methods about how to use stereo images to\nestimate depth;(3)Depth estimation by lidar: to explain the methods about how\nto use 3d cloud datas to estimate depth;In summary, this report is mainly to\nshow the performance of depth maps and their approaches, analysis for them.\n","authors":["Fei Wu","Luoyu Chen"],"pdf_url":"https://arxiv.org/pdf/2212.11741v1.pdf","comment":"10 pages, 13 figures"},{"id":"http://arxiv.org/abs/2212.11720v1","updated":"2022-12-22T14:13:33Z","published":"2022-12-22T14:13:33Z","title":"GOOD: Exploring Geometric Cues for Detecting Objects in an Open World","summary":"  We address the task of open-world class-agnostic object detection, i.e.,\ndetecting every object in an image by learning from a limited number of base\nobject classes. State-of-the-art RGB-based models suffer from overfitting the\ntraining classes and often fail at detecting novel-looking objects. This is\nbecause RGB-based models primarily rely on appearance similarity to detect\nnovel objects and are also prone to overfitting short-cut cues such as textures\nand discriminative parts. To address these shortcomings of RGB-based object\ndetectors, we propose incorporating geometric cues such as depth and normals,\npredicted by general-purpose monocular estimators. Specifically, we use the\ngeometric cues to train an object proposal network for pseudo-labeling\nunannotated novel objects in the training set. Our resulting Geometry-guided\nOpen-world Object Detector (GOOD) significantly improves detection recall for\nnovel object categories and already performs well with only a few training\nclasses. Using a single \"person\" class for training on the COCO dataset, GOOD\nsurpasses SOTA methods by 5.0% AR@100, a relative improvement of 24%.\n","authors":["Haiwen Huang","Andreas Geiger","Dan Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11720v1.pdf","comment":"Under review as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2212.11696v1","updated":"2022-12-22T13:37:59Z","published":"2022-12-22T13:37:59Z","title":"Reversible Column Networks","summary":"  We propose a new neural network design paradigm Reversible Column Network\n(RevCol). The main body of RevCol is composed of multiple copies of\nsubnetworks, named columns respectively, between which multi-level reversible\nconnections are employed. Such architectural scheme attributes RevCol very\ndifferent behavior from conventional networks: during forward propagation,\nfeatures in RevCol are learned to be gradually disentangled when passing\nthrough each column, whose total information is maintained rather than\ncompressed or discarded as other network does. Our experiments suggest that\nCNN-style RevCol models can achieve very competitive performances on multiple\ncomputer vision tasks such as image classification, object detection and\nsemantic segmentation, especially with large parameter budget and large\ndataset. For example, after ImageNet-22K pre-training, RevCol-XL obtains 88.2%\nImageNet-1K accuracy. Given more pre-training data, our largest model RevCol-H\nreaches 90.0% on ImageNet-1K, 63.8% APbox on COCO detection minival set, 61.0%\nmIoU on ADE20k segmentation. To our knowledge, it is the best COCO detection\nand ADE20k segmentation result among pure (static) CNN models. Moreover, as a\ngeneral macro architecture fashion, RevCol can also be introduced into\ntransformers or other neural networks, which is demonstrated to improve the\nperformances in both computer vision and NLP tasks. We release code and models\nat https://github.com/megvii-research/RevCol\n","authors":["Yuxuan Cai","Yizhuang Zhou","Qi Han","Jianjian Sun","Xiangwen Kong","Jun Li","Xiangyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11694v1","updated":"2022-12-22T13:35:00Z","published":"2022-12-22T13:35:00Z","title":"Timestamp-Supervised Action Segmentation in the Perspective of\n  Clustering","summary":"  Video action segmentation aims to slice the video into several action\nsegments. Recently, timestamp supervision has received much attention due to\nlower annotation costs. We find the frames near the boundaries of action\nsegments are in the transition region between two consecutive actions and have\nunclear semantics, which we call ambiguous intervals. Most existing methods\niteratively generate pseudo-labels for all frames in each video to train the\nsegmentation model. However, ambiguous intervals are more likely to be assigned\nwith noisy and incorrect pseudo-labels, which leads to performance degradation.\nWe propose a novel framework to train the model under timestamp supervision\nincluding the following two parts. First, pseudo-label ensembling generates\npseudo-label sequences with ambiguous intervals, where the frames have no\npseudo-labels. Second, iterative clustering iteratively propagates the\npseudo-labels to the ambiguous intervals by clustering, and thus updates the\npseudo-label sequences to train the model. We further introduce a clustering\nloss, which encourages the features of frames within the same action segment\nmore compact. Extensive experiments show the effectiveness of our method.\n","authors":["Dazhao Du","Enhan Li","Lingyu Si","Fanjiang Xu","Fuchun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.11694v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.13505v2","updated":"2022-12-22T13:16:09Z","published":"2022-03-25T08:46:24Z","title":"Contrastive learning of Class-agnostic Activation Map for Weakly\n  Supervised Object Localization and Semantic Segmentation","summary":"  While class activation map (CAM) generated by image classification network\nhas been widely used for weakly supervised object localization (WSOL) and\nsemantic segmentation (WSSS), such classifiers usually focus on discriminative\nobject regions. In this paper, we propose Contrastive learning for\nClass-agnostic Activation Map (C$^2$AM) generation only using unlabeled image\ndata, without the involvement of image-level supervision. The core idea comes\nfrom the observation that i) semantic information of foreground objects usually\ndiffers from their backgrounds; ii) foreground objects with similar appearance\nor background with similar color/texture have similar representations in the\nfeature space. We form the positive and negative pairs based on the above\nrelations and force the network to disentangle foreground and background with a\nclass-agnostic activation map using a novel contrastive loss. As the network is\nguided to discriminate cross-image foreground-background, the class-agnostic\nactivation maps learned by our approach generate more complete object regions.\nWe successfully extracted from C$^2$AM class-agnostic object bounding boxes for\nobject localization and background cues to refine CAM generated by\nclassification network for semantic segmentation. Extensive experiments on\nCUB-200-2011, ImageNet-1K, and PASCAL VOC2012 datasets show that both WSOL and\nWSSS can benefit from the proposed C$^2$AM.\n","authors":["Jinheng Xie","Jianfeng Xiang","Junliang Chen","Xianxu Hou","Xiaodong Zhao","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2203.13505v2.pdf","comment":"Accepted by CVPR 2022"},{"id":"http://arxiv.org/abs/2212.11642v1","updated":"2022-12-22T12:15:37Z","published":"2022-12-22T12:15:37Z","title":"Predictive Coding Based Multiscale Network with Encoder-Decoder LSTM for\n  Video Prediction","summary":"  We are introducing a multi-scale predictive model for video prediction here,\nwhose design is inspired by the \"Predictive Coding\" theories and \"Coarse to\nFine\" approach. As a predictive coding model, it is updated by a combination of\nbottom-up and top-down information flows, which is different from traditional\nbottom-up training style. Its advantage is to reduce the dependence on input\ninformation and improve its ability to predict and generate images.\nImportantly, we achieve with a multi-scale approach -- higher level neurons\ngenerate coarser predictions (lower resolution), while the lower level generate\nfiner predictions (higher resolution). This is different from the traditional\npredictive coding framework in which higher level predict the activity of\nneurons in lower level. To improve the predictive ability, we integrate an\nencoder-decoder network in the LSTM architecture and share the final encoded\nhigh-level semantic information between different levels. Additionally, since\nthe output of each network level is an RGB image, a smaller LSTM hidden state\ncan be used to retain and update the only necessary hidden information,\navoiding being mapped to an overly discrete and complex space. In this way, we\ncan reduce the difficulty of prediction and the computational overhead.\nFinally, we further explore the training strategies, to address the instability\nin adversarial training and mismatch between training and testing in long-term\nprediction. Code is available at https://github.com/Ling-CF/MSPN.\n","authors":["Chaofan Ling","Junpei Zhong","Weihua Li"],"pdf_url":"https://arxiv.org/pdf/2212.11642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.11214v4","updated":"2022-12-22T12:06:43Z","published":"2021-07-23T13:23:10Z","title":"A3GC-IP: Attention-Oriented Adjacency Adaptive Recurrent Graph\n  Convolutions for Human Pose Estimation from Sparse Inertial Measurements","summary":"  Conventional methods for human pose estimation either require a high degree\nof instrumentation, by relying on many inertial measurement units (IMUs), or\nconstraint the recording space, by relying on extrinsic cameras. These deficits\nare tackled through the approach of human pose estimation from sparse IMU data.\nWe define attention-oriented adjacency adaptive graph convolutional long-short\nterm memory networks (A3GC-LSTM), to tackle human pose estimation based on six\nIMUs, through incorporating the human body graph structure directly into the\nnetwork. The A3GC-LSTM combines both spatial and temporal dependency in a\nsingle network operation, more memory efficiently than previous approaches. The\nrecurrent graph learning on arbitrarily long sequences is made possible by\nequipping graph convolutions with adjacency adaptivity, which eliminates the\nproblem of information loss in deep or recurrent graph networks, while it also\nallows for learning unknown dependencies between the human body joints. To\nfurther boost accuracy, a spatial attention formalism is incorporated into the\nrecurrent LSTM cell. With our presented approach, we are able to utilize the\ninherent graph nature of the human body, and thus can outperform the state of\nthe art for human pose estimation from sparse IMU data.\n","authors":["Patrik Puchert","Timo Ropinski"],"pdf_url":"https://arxiv.org/pdf/2107.11214v4.pdf","comment":"Preprint, in submission"},{"id":"http://arxiv.org/abs/2212.11614v1","updated":"2022-12-22T11:18:35Z","published":"2022-12-22T11:18:35Z","title":"Hybrid Quantum-Classical Generative Adversarial Network for High\n  Resolution Image Generation","summary":"  Quantum machine learning (QML) has received increasing attention due to its\npotential to outperform classical machine learning methods in various problems.\nA subclass of QML methods is quantum generative adversarial networks (QGANs)\nwhich have been studied as a quantum counterpart of classical GANs widely used\nin image manipulation and generation tasks. The existing work on QGANs is still\nlimited to small-scale proof-of-concept examples based on images with\nsignificant down-scaling. Here we integrate classical and quantum techniques to\npropose a new hybrid quantum-classical GAN framework. We demonstrate its\nsuperior learning capabilities by generating $28 \\times 28$ pixels grey-scale\nimages without dimensionality reduction or classical pre/post-processing on\nmultiple classes of the standard MNIST and Fashion MNIST datasets, which\nachieves comparable results to classical frameworks with 3 orders of magnitude\nless trainable generator parameters. To gain further insight into the working\nof our hybrid approach, we systematically explore the impact of its parameter\nspace by varying the number of qubits, the size of image patches, the number of\nlayers in the generator, the shape of the patches and the choice of prior\ndistribution. Our results show that increasing the quantum generator size\ngenerally improves the learning capability of the network. The developed\nframework provides a foundation for future design of QGANs with optimal\nparameter set tailored for complex image generation tasks.\n","authors":["Shu Lok Tsang","Maxwell T. West","Sarah M. Erfani","Muhammad Usman"],"pdf_url":"https://arxiv.org/pdf/2212.11614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11613v1","updated":"2022-12-22T11:17:57Z","published":"2022-12-22T11:17:57Z","title":"DDColor: Towards Photo-Realistic and Semantic-Aware Image Colorization\n  via Dual Decoders","summary":"  Automatic image colorization is a particularly challenging problem. Due to\nthe high illness of the problem and multi-modal uncertainty, directly training\na deep neural network usually leads to incorrect semantic colors and low color\nrichness. Existing transformer-based methods can deliver better results but\nhighly depend on hand-crafted dataset-level empirical distribution priors. In\nthis work, we propose DDColor, a new end-to-end method with dual decoders, for\nimage colorization. More specifically, we design a multi-scale image decoder\nand a transformer-based color decoder. The former manages to restore the\nspatial resolution of the image, while the latter establishes the correlation\nbetween semantic representations and color queries via cross-attention. The two\ndecoders incorporate to learn semantic-aware color embedding by leveraging the\nmulti-scale visual features. With the help of these two decoders, our method\nsucceeds in producing semantically consistent and visually plausible\ncolorization results without any additional priors. In addition, a simple but\neffective colorfulness loss is introduced to further improve the color richness\nof generated results. Our extensive experiments demonstrate that the proposed\nDDColor achieves significantly superior performance to existing\nstate-of-the-art works both quantitatively and qualitatively. Codes will be\nmade publicly available.\n","authors":["Xiaoyang Kang","Tao Yang","Wenqi Ouyang","Peiran Ren","Lingzhi Li","Xuansong Xie"],"pdf_url":"https://arxiv.org/pdf/2212.11613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11596v1","updated":"2022-12-22T10:45:08Z","published":"2022-12-22T10:45:08Z","title":"Deformable Surface Reconstruction via Riemannian Metric Preservation","summary":"  Estimating the pose of an object from a monocular image is an inverse problem\nfundamental in computer vision. The ill-posed nature of this problem requires\nincorporating deformation priors to solve it. In practice, many materials do\nnot perceptibly shrink or extend when manipulated, constituting a powerful and\nwell-known prior. Mathematically, this translates to the preservation of the\nRiemannian metric. Neural networks offer the perfect playground to solve the\nsurface reconstruction problem as they can approximate surfaces with arbitrary\nprecision and allow the computation of differential geometry quantities. This\npaper presents an approach to inferring continuous deformable surfaces from a\nsequence of images, which is benchmarked against several techniques and obtains\nstate-of-the-art performance without the need for offline training.\n","authors":["Oriol Barbany","Adrià Colomé","Carme Torras"],"pdf_url":"https://arxiv.org/pdf/2212.11596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11595v1","updated":"2022-12-22T10:39:10Z","published":"2022-12-22T10:39:10Z","title":"Metadata-guided Consistency Learning for High Content Images","summary":"  High content imaging assays can capture rich phenotypic response data for\nlarge sets of compound treatments, aiding in the characterization and discovery\nof novel drugs. However, extracting representative features from high content\nimages that can capture subtle nuances in phenotypes remains challenging. The\nlack of high-quality labels makes it difficult to achieve satisfactory results\nwith supervised deep learning. Self-Supervised learning methods, which learn\nfrom automatically generated labels has shown great success on natural images,\noffer an attractive alternative also to microscopy images. However, we find\nthat self-supervised learning techniques underperform on high content imaging\nassays. One challenge is the undesirable domain shifts present in the data\nknown as batch effects, which may be caused by biological noise or uncontrolled\nexperimental conditions. To this end, we introduce Cross-Domain Consistency\nLearning (CDCL), a novel approach that is able to learn in the presence of\nbatch effects. CDCL enforces the learning of biological similarities while\ndisregarding undesirable batch-specific signals, which leads to more useful and\nversatile representations. These features are organised according to their\nmorphological changes and are more useful for downstream tasks - such as\ndistinguishing treatments and mode of action.\n","authors":["Johan Fredin Haslum","Christos Matsoukas","Karl-Johan Leuchowius","Erik Müllers","Kevin Smith"],"pdf_url":"https://arxiv.org/pdf/2212.11595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04085v2","updated":"2022-12-22T10:21:42Z","published":"2022-12-08T05:42:00Z","title":"Graph Matching with Bi-level Noisy Correspondence","summary":"  In this paper, we study a novel and widely existing problem in graph matching\n(GM), namely, Bi-level Noisy Correspondence (BNC), which refers to node-level\nnoisy correspondence (NNC) and edge-level noisy correspondence (ENC). In brief,\non the one hand, due to the poor recognizability and viewpoint differences\nbetween images, it is inevitable to inaccurately annotate some keypoints with\noffset and confusion, leading to the mismatch between two associated nodes,\ni.e., NNC. On the other hand, the noisy node-to-node correspondence will\nfurther contaminate the edge-to-edge correspondence, thus leading to ENC. For\nthe BNC challenge, we propose a novel method termed Contrastive Matching with\nMomentum Distillation. Specifically, the proposed method is with a robust\nquadratic contrastive loss which enjoys the following merits: i) better\nexploring the node-to-node and edge-to-edge correlations through a GM\ncustomized quadratic contrastive learning paradigm; ii) adaptively penalizing\nthe noisy assignments based on the confidence estimated by the momentum\nteacher. Extensive experiments on three real-world datasets show the robustness\nof our model compared with 12 competitive baselines.\n","authors":["Yijie Lin","Mouxing Yang","Jun Yu","Peng Hu","Changqing Zhang","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2212.04085v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.10598v2","updated":"2022-12-22T10:06:59Z","published":"2022-04-22T09:40:23Z","title":"Sparsely-gated MoE Layers for CNN Interpretability","summary":"  Sparsely-gated Mixture of Expert (MoE) layers have been recently successfully\napplied for scaling large transformers, especially for language modeling tasks.\nAn intriguing side effect of sparse MoE layers is that they convey inherent\ninterpretability to a model via natural expert specialization. In this work, we\napply sparse MoE layers to CNNs for computer vision tasks and analyze the\nresulting effect on model interpretability. To stabilize MoE training, we\npresent both soft and hard constraint-based approaches. With hard constraints,\nthe weights of certain experts are allowed to become zero, while soft\nconstraints balance the contribution of experts with an additional auxiliary\nloss. As a result, soft constraints handle expert utilization better and\nsupport the expert specialization process, while hard constraints maintain more\ngeneralized experts and increase overall model performance. Our findings\ndemonstrate that experts can implicitly focus on individual sub-domains of the\ninput space. For example, experts trained for CIFAR-100 image classification\nspecialize in recognizing different domains such as flowers or animals without\nprevious data clustering. Experiments with RetinaNet and the COCO dataset\nfurther indicate that object detection experts can also specialize in detecting\nobjects of distinct sizes.\n","authors":["Svetlana Pavlitskaya","Christian Hubschneider","Lukas Struppek","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2204.10598v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11565v1","updated":"2022-12-22T09:43:36Z","published":"2022-12-22T09:43:36Z","title":"Tune-A-Video: One-Shot Tuning of Image Diffusion Models for\n  Text-to-Video Generation","summary":"  To reproduce the success of text-to-image (T2I) generation, recent works in\ntext-to-video (T2V) generation employ large-scale text-video dataset for\nfine-tuning. However, such paradigm is computationally expensive. Humans have\nthe amazing ability to learn new visual concepts from just one single exemplar.\nWe hereby study a new T2V generation problem$\\unicode{x2014}$One-Shot Video\nGeneration, where only a single text-video pair is presented for training an\nopen-domain T2V generator. Intuitively, we propose to adapt the T2I diffusion\nmodel pretrained on massive image data for T2V generation. We make two key\nobservations: 1) T2I models are able to generate images that align well with\nthe verb terms; 2) extending T2I models to generate multiple images\nconcurrently exhibits surprisingly good content consistency. To further learn\ncontinuous motion, we propose Tune-A-Video with a tailored Sparse-Causal\nAttention, which generates videos from text prompts via an efficient one-shot\ntuning of pretrained T2I diffusion models. Tune-A-Video is capable of producing\ntemporally-coherent videos over various applications such as change of subject\nor background, attribute editing, style transfer, demonstrating the versatility\nand effectiveness of our method.\n","authors":["Jay Zhangjie Wu","Yixiao Ge","Xintao Wang","Weixian Lei","Yuchao Gu","Wynne Hsu","Ying Shan","Xiaohu Qie","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2212.11565v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2212.11558v1","updated":"2022-12-22T09:25:46Z","published":"2022-12-22T09:25:46Z","title":"DaDe: Delay-adoptive Detector for Streaming Perception","summary":"  Recognizing the surrounding environment at low latency is critical in\nautonomous driving. In real-time environment, surrounding environment changes\nwhen processing is over. Current detection models are incapable of dealing with\nchanges in the environment that occur after processing. Streaming perception is\nproposed to assess the latency and accuracy of real-time video perception.\nHowever, additional problems arise in real-world applications due to limited\nhardware resources, high temperatures, and other factors. In this study, we\ndevelop a model that can reflect processing delays in real time and produce the\nmost reasonable results. By incorporating the proposed feature queue and\nfeature select module, the system gains the ability to forecast specific time\nsteps without any additional computational costs. Our method is tested on the\nArgoverse-HD dataset. It achieves higher performance than the current\nstate-of-the-art methods(2022.10) in various environments when delayed . The\ncode is available at https://github.com/danjos95/DADE\n","authors":["Wonwoo Jo","Kyungshin Lee","Jaewon Baik","Sangsun Lee","Dongho Choi","Hyunkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2212.11558v1.pdf","comment":"This paper is accepted in VISAPP - 2023 (Full Paper, Oral\n  Presentation)"},{"id":"http://arxiv.org/abs/2212.11548v1","updated":"2022-12-22T09:05:07Z","published":"2022-12-22T09:05:07Z","title":"Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and\n  Transformer-Based Method","summary":"  As the quality of optical sensors improves, there is a need for processing\nlarge-scale images. In particular, the ability of devices to capture ultra-high\ndefinition (UHD) images and video places new demands on the image processing\npipeline. In this paper, we consider the task of low-light image enhancement\n(LLIE) and introduce a large-scale database consisting of images at 4K and 8K\nresolution. We conduct systematic benchmarking studies and provide a comparison\nof current LLIE algorithms. As a second contribution, we introduce LLFormer, a\ntransformer-based low-light enhancement method. The core components of LLFormer\nare the axis-based multi-head self-attention and cross-layer attention fusion\nblock, which significantly reduces the linear complexity. Extensive experiments\non the new dataset and existing public datasets show that LLFormer outperforms\nstate-of-the-art methods. We also show that employing existing LLIE methods\ntrained on our benchmark as a pre-processing step significantly improves the\nperformance of downstream tasks, e.g., face detection in low-light conditions.\nThe source code and pre-trained models are available at\nhttps://github.com/TaoWangzj/LLFormer.\n","authors":["Tao Wang","Kaihao Zhang","Tianrun Shen","Wenhan Luo","Bjorn Stenger","Tong Lu"],"pdf_url":"https://arxiv.org/pdf/2212.11548v1.pdf","comment":"Accepted at AAAI 2023. #AAAI2023"},{"id":"http://arxiv.org/abs/2210.02445v2","updated":"2022-12-22T08:57:49Z","published":"2022-09-25T15:08:20Z","title":"Localizing Anatomical Landmarks in Ocular Images using Zoom-In Attentive\n  Networks","summary":"  Localizing anatomical landmarks are important tasks in medical image\nanalysis. However, the landmarks to be localized often lack prominent visual\nfeatures. Their locations are elusive and easily confused with the background,\nand thus precise localization highly depends on the context formed by their\nsurrounding areas. In addition, the required precision is usually higher than\nsegmentation and object detection tasks. Therefore, localization has its unique\nchallenges different from segmentation or detection. In this paper, we propose\na zoom-in attentive network (ZIAN) for anatomical landmark localization in\nocular images. First, a coarse-to-fine, or \"zoom-in\" strategy is utilized to\nlearn the contextualized features in different scales. Then, an attentive\nfusion module is adopted to aggregate multi-scale features, which consists of\n1) a co-attention network with a multiple regions-of-interest (ROIs) scheme\nthat learns complementary features from the multiple ROIs, 2) an\nattention-based fusion module which integrates the multi-ROIs features and\nnon-ROI features. We evaluated ZIAN on two open challenge tasks, i.e., the\nfovea localization in fundus images and scleral spur localization in AS-OCT\nimages. Experiments show that ZIAN achieves promising performances and\noutperforms state-of-the-art localization methods. The source code and trained\nmodels of ZIAN are available at\nhttps://github.com/leixiaofeng-astar/OMIA9-ZIAN.\n","authors":["Xiaofeng Lei","Shaohua Li","Xinxing Xu","Huazhu Fu","Yong Liu","Yih-Chung Tham","Yangqin Feng","Mingrui Tan","Yanyu Xu","Jocelyn Hui Lin Goh","Rick Siow Mong Goh","Ching-Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2210.02445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13353v2","updated":"2022-12-22T08:53:12Z","published":"2022-09-27T12:59:19Z","title":"Suppress with a Patch: Revisiting Universal Adversarial Patch Attacks\n  against Object Detection","summary":"  Adversarial patch-based attacks aim to fool a neural network with an\nintentionally generated noise, which is concentrated in a particular region of\nan input image. In this work, we perform an in-depth analysis of different\npatch generation parameters, including initialization, patch size, and\nespecially positioning a patch in an image during training. We focus on the\nobject vanishing attack and run experiments with YOLOv3 as a model under attack\nin a white-box setting and use images from the COCO dataset. Our experiments\nhave shown, that inserting a patch inside a window of increasing size during\ntraining leads to a significant increase in attack strength compared to a fixed\nposition. The best results were obtained when a patch was positioned randomly\nduring training, while patch position additionally varied within a batch.\n","authors":["Svetlana Pavlitskaya","Jonas Hendl","Sebastian Kleim","Leopold Müller","Fabian Wylczoch","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2209.13353v2.pdf","comment":"Accepted for publication at ICECCME 2022"},{"id":"http://arxiv.org/abs/2212.11542v1","updated":"2022-12-22T08:43:02Z","published":"2022-12-22T08:43:02Z","title":"Mask Focal Loss for dense crowd counting with canonical object detection\n  networks","summary":"  Crowd counting plays an important role in risk perception and early warning,\ntraffic control and scene statistical analysis. The challenges of crowd\ncounting in highly dense and complex scenes lie in the mutual occlusion of the\nhuman body parts, the large variation of the body scales and the complexity of\nimaging conditions. Deep learning based head detection is a promising method\nfor crowd counting. However the highly concerned object detection networks\ncannot be well applied to this field for two main reasons. First, most of the\nexisting head detection datasets are only annotated with the center points\ninstead of bounding boxes which is mandatory for the canonical detectors.\nSecond, the sample imbalance has not been overcome yet in highly dense and\ncomplex scenes because the existing loss functions calculate the positive loss\nat a single key point or in the entire target area with the same weight. To\naddress these problems, We propose a novel loss function, called Mask Focal\nLoss, to unify the loss functions based on heatmap ground truth (GT) and binary\nfeature map GT. Mask Focal Loss redefines the weight of the loss contributions\naccording to the situ value of the heatmap with a Gaussian kernel. For better\nevaluation and comparison, a new synthetic dataset GTA\\_Head is made public,\nincluding 35 sequences, 5096 images and 1732043 head labels with bounding\nboxes. Experimental results show the overwhelming performance and demonstrate\nthat our proposed Mask Focal Loss is applicable to all of the canonical\ndetectors and to various datasets with different GT. This provides a strong\nbasis for surpassing the crowd counting methods based on density estimation.\n","authors":["Xiaopin Zhong","Guankun Wang","Weixiang Liua","Zongze Wua","Yuanlong Deng"],"pdf_url":"https://arxiv.org/pdf/2212.11542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09759v3","updated":"2022-12-22T08:41:53Z","published":"2022-07-20T09:04:12Z","title":"Task-adaptive Spatial-Temporal Video Sampler for Few-shot Action\n  Recognition","summary":"  A primary challenge faced in few-shot action recognition is inadequate video\ndata for training. To address this issue, current methods in this field mainly\nfocus on devising algorithms at the feature level while little attention is\npaid to processing input video data. Moreover, existing frame sampling\nstrategies may omit critical action information in temporal and spatial\ndimensions, which further impacts video utilization efficiency. In this paper,\nwe propose a novel video frame sampler for few-shot action recognition to\naddress this issue, where task-specific spatial-temporal frame sampling is\nachieved via a temporal selector (TS) and a spatial amplifier (SA).\nSpecifically, our sampler first scans the whole video at a small computational\ncost to obtain a global perception of video frames. The TS plays its role in\nselecting top-T frames that contribute most significantly and subsequently. The\nSA emphasizes the discriminative information of each frame by amplifying\ncritical regions with the guidance of saliency maps. We further adopt\ntask-adaptive learning to dynamically adjust the sampling strategy according to\nthe episode task at hand. Both the implementations of TS and SA are\ndifferentiable for end-to-end optimization, facilitating seamless integration\nof our proposed sampler with most few-shot action recognition methods.\nExtensive experiments show a significant boost in the performances on various\nbenchmarks including long-term videos.The code is available at\nhttps://github.com/R00Kie-Liu/Sampler\n","authors":["Huabin Liu","Weixian Lv","John See","Weiyao Lin"],"pdf_url":"https://arxiv.org/pdf/2207.09759v3.pdf","comment":"Accepted by ACM MM 2022"},{"id":"http://arxiv.org/abs/2107.04782v4","updated":"2022-12-22T08:40:02Z","published":"2021-07-10T07:22:49Z","title":"TA2N: Two-Stage Action Alignment Network for Few-shot Action Recognition","summary":"  Few-shot action recognition aims to recognize novel action classes (query)\nusing just a few samples (support). The majority of current approaches follow\nthe metric learning paradigm, which learns to compare the similarity between\nvideos. Recently, it has been observed that directly measuring this similarity\nis not ideal since different action instances may show distinctive temporal\ndistribution, resulting in severe misalignment issues across query and support\nvideos. In this paper, we arrest this problem from two distinct aspects --\naction duration misalignment and action evolution misalignment. We address them\nsequentially through a Two-stage Action Alignment Network (TA2N). The first\nstage locates the action by learning a temporal affine transform, which warps\neach video feature to its action duration while dismissing the\naction-irrelevant feature (e.g. background). Next, the second stage coordinates\nquery feature to match the spatial-temporal action evolution of support by\nperforming temporally rearrange and spatially offset prediction. Extensive\nexperiments on benchmark datasets show the potential of the proposed method in\nachieving state-of-the-art performance for few-shot action recognition.The code\nof this project can be found at https://github.com/R00Kie-Liu/TA2N\n","authors":["Shuyuan Li","Huabin Liu","Rui Qian","Yuxi Li","John See","Mengjuan Fei","Xiaoyuan Yu","Weiyao Lin"],"pdf_url":"https://arxiv.org/pdf/2107.04782v4.pdf","comment":"Published in AAAI 2022"},{"id":"http://arxiv.org/abs/2212.11541v1","updated":"2022-12-22T08:36:55Z","published":"2022-12-22T08:36:55Z","title":"Generative Colorization of Structured Mobile Web Pages","summary":"  Color is a critical design factor for web pages, affecting important factors\nsuch as viewer emotions and the overall trust and satisfaction of a website.\nEffective coloring requires design knowledge and expertise, but if this process\ncould be automated through data-driven modeling, efficient exploration and\nalternative workflows would be possible. However, this direction remains\nunderexplored due to the lack of a formalization of the web page colorization\nproblem, datasets, and evaluation protocols. In this work, we propose a new\ndataset consisting of e-commerce mobile web pages in a tractable format, which\nare created by simplifying the pages and extracting canonical color styles with\na common web browser. The web page colorization problem is then formalized as a\ntask of estimating plausible color styles for a given web page content with a\ngiven hierarchical structure of the elements. We present several\nTransformer-based methods that are adapted to this task by prepending\nstructural message passing to capture hierarchical relationships between\nelements. Experimental results, including a quantitative evaluation designed\nfor this task, demonstrate the advantages of our methods over statistical and\nimage colorization methods. The code is available at\nhttps://github.com/CyberAgentAILab/webcolor.\n","authors":["Kotaro Kikuchi","Naoto Inoue","Mayu Otani","Edgar Simo-Serra","Kota Yamaguchi"],"pdf_url":"https://arxiv.org/pdf/2212.11541v1.pdf","comment":"Accepted to WACV 2023"},{"id":"http://arxiv.org/abs/2212.05262v2","updated":"2022-12-22T08:27:56Z","published":"2022-12-10T10:38:00Z","title":"Position Embedding Needs an Independent Layer Normalization","summary":"  The Position Embedding (PE) is critical for Vision Transformers (VTs) due to\nthe permutation-invariance of self-attention operation. By analyzing the input\nand output of each encoder layer in VTs using reparameterization and\nvisualization, we find that the default PE joining method (simply adding the PE\nand patch embedding together) operates the same affine transformation to token\nembedding and PE, which limits the expressiveness of PE and hence constrains\nthe performance of VTs. To overcome this limitation, we propose a simple,\neffective, and robust method. Specifically, we provide two independent layer\nnormalizations for token embeddings and PE for each layer, and add them\ntogether as the input of each layer's Muti-Head Self-Attention module. Since\nthe method allows the model to adaptively adjust the information of PE for\ndifferent layers, we name it as Layer-adaptive Position Embedding, abbreviated\nas LaPE. Extensive experiments demonstrate that LaPE can improve various VTs\nwith different types of PE and make VTs robust to PE types. For example, LaPE\nimproves 0.94% accuracy for ViT-Lite on Cifar10, 0.98% for CCT on Cifar100, and\n1.72% for DeiT on ImageNet-1K, which is remarkable considering the negligible\nextra parameters, memory and computational cost brought by LaPE. The code is\npublicly available at https://github.com/Ingrid725/LaPE.\n","authors":["Runyi Yu","Zhennan Wang","Yinhuai Wang","Kehan Li","Yian Zhao","Jian Zhang","Guoli Song","Jie Chen"],"pdf_url":"https://arxiv.org/pdf/2212.05262v2.pdf","comment":"14 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.11538v1","updated":"2022-12-22T08:27:21Z","published":"2022-12-22T08:27:21Z","title":"SHLE: Devices Tracking and Depth Filtering for Stereo-based Height Limit\n  Estimation","summary":"  Recently, over-height vehicle strike frequently occurs, causing great\neconomic cost and serious safety problems. Hence, an alert system which can\naccurately discover any possible height limiting devices in advance is\nnecessary to be employed in modern large or medium sized cars, such as touring\ncars. Detecting and estimating the height limiting devices act as the key point\nof a successful height limit alert system. Though there are some works research\nheight limit estimation, existing methods are either too computational\nexpensive or not accurate enough. In this paper, we propose a novel\nstereo-based pipeline named SHLE for height limit estimation. Our SHLE pipeline\nconsists of two stages. In stage 1, a novel devices detection and tracking\nscheme is introduced, which accurately locate the height limit devices in the\nleft or right image. Then, in stage 2, the depth is temporally measured,\nextracted and filtered to calculate the height limit device. To benchmark the\nheight limit estimation task, we build a large-scale dataset named \"Disparity\nHeight\", where stereo images, pre-computed disparities and ground-truth height\nlimit annotations are provided. We conducted extensive experiments on\n\"Disparity Height\" and the results show that SHLE achieves an average error\nbelow than 10cm though the car is 70m away from the devices. Our method also\noutperforms all compared baselines and achieves state-of-the-art performance.\nCode is available at https://github.com/Yang-Kaixing/SHLE.\n","authors":["Zhaoxin Fan","Kaixing Yang","Min Zhang","Zhenbo Song","Hongyan Liu","Jun He"],"pdf_url":"https://arxiv.org/pdf/2212.11538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11533v1","updated":"2022-12-22T08:20:08Z","published":"2022-12-22T08:20:08Z","title":"LaneAF: Robust Multi-Lane Detection with Affinity Fields","summary":"  Lane detection is a long-standing task and a basic module in autonomous\ndriving. The task is to detect the lane of the current driving road, and\nprovide relevant information such as the ID, direction, curvature, width,\nlength, with visualization. Our work is based on CNN backbone DLA-34, along\nwith Affinity Fields, aims to achieve robust detection of various lanes without\nassuming the number of lanes. Besides, we investigate novel decoding methods to\nachieve more efficient lane detection algorithm.\n","authors":["Genze Zhou","Luoyu Chen","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2212.11533v1.pdf","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.11511v1","updated":"2022-12-22T07:19:15Z","published":"2022-12-22T07:19:15Z","title":"Confidence-Aware Paced-Curriculum Learning by Label Smoothing for\n  Surgical Scene Understanding","summary":"  Curriculum learning and self-paced learning are the training strategies that\ngradually feed the samples from easy to more complex. They have captivated\nincreasing attention due to their excellent performance in robotic vision. Most\nrecent works focus on designing curricula based on difficulty levels in input\nsamples or smoothing the feature maps. However, smoothing labels to control the\nlearning utility in a curriculum manner is still unexplored. In this work, we\ndesign a paced curriculum by label smoothing (P-CBLS) using paced learning with\nuniform label smoothing (ULS) for classification tasks and fuse uniform and\nspatially varying label smoothing (SVLS) for semantic segmentation tasks in a\ncurriculum manner. In ULS and SVLS, a bigger smoothing factor value enforces a\nheavy smoothing penalty in the true label and limits learning less information.\nTherefore, we design the curriculum by label smoothing (CBLS). We set a bigger\nsmoothing value at the beginning of training and gradually decreased it to zero\nto control the model learning utility from lower to higher. We also designed a\nconfidence-aware pacing function and combined it with our CBLS to investigate\nthe benefits of various curricula. The proposed techniques are validated on\nfour robotic surgery datasets of multi-class, multi-label classification,\ncaptioning, and segmentation tasks. We also investigate the robustness of our\nmethod by corrupting validation data into different severity levels. Our\nextensive analysis shows that the proposed method improves prediction accuracy\nand robustness.\n","authors":["Mengya Xu","Mobarakol Islam","Ben Glocker","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.11511v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2207.11406v2","updated":"2022-12-22T06:54:21Z","published":"2022-07-23T03:55:18Z","title":"PS-NeRF: Neural Inverse Rendering for Multi-view Photometric Stereo","summary":"  Traditional multi-view photometric stereo (MVPS) methods are often composed\nof multiple disjoint stages, resulting in noticeable accumulated errors. In\nthis paper, we present a neural inverse rendering method for MVPS based on\nimplicit representation. Given multi-view images of a non-Lambertian object\nilluminated by multiple unknown directional lights, our method jointly\nestimates the geometry, materials, and lights. Our method first employs\nmulti-light images to estimate per-view surface normal maps, which are used to\nregularize the normals derived from the neural radiance field. It then jointly\noptimizes the surface normals, spatially-varying BRDFs, and lights based on a\nshadow-aware differentiable rendering layer. After optimization, the\nreconstructed object can be used for novel-view rendering, relighting, and\nmaterial editing. Experiments on both synthetic and real datasets demonstrate\nthat our method achieves far more accurate shape reconstruction than existing\nMVPS and neural rendering methods. Our code and model can be found at\nhttps://ywq.github.io/psnerf.\n","authors":["Wenqi Yang","Guanying Chen","Chaofeng Chen","Zhenfang Chen","Kwan-Yee K. Wong"],"pdf_url":"https://arxiv.org/pdf/2207.11406v2.pdf","comment":"ECCV 2022, Project page: https://ywq.github.io/psnerf"},{"id":"http://arxiv.org/abs/2212.11507v1","updated":"2022-12-22T06:39:52Z","published":"2022-12-22T06:39:52Z","title":"Supervised Anomaly Detection Method Combining Generative Adversarial\n  Networks and Three-Dimensional Data in Vehicle Inspections","summary":"  The external visual inspections of rolling stock's underfloor equipment are\ncurrently being performed via human visual inspection. In this study, we\nattempt to partly automate visual inspection by investigating anomaly\ninspection algorithms that use image processing technology. As the railroad\nmaintenance studies tend to have little anomaly data, unsupervised learning\nmethods are usually preferred for anomaly detection; however, training cost and\naccuracy is still a challenge. Additionally, a researcher created anomalous\nimages from normal images by adding noise, etc., but the anomalous targeted in\nthis study is the rotation of piping cocks that was difficult to create using\nnoise. Therefore, in this study, we propose a new method that uses style\nconversion via generative adversarial networks on three-dimensional computer\ngraphics and imitates anomaly images to apply anomaly detection based on\nsupervised learning. The geometry-consistent style conversion model was used to\nconvert the image, and because of this the color and texture of the image were\nsuccessfully made to imitate the real image while maintaining the anomalous\nshape. Using the generated anomaly images as supervised data, the anomaly\ndetection model can be easily trained without complex adjustments and\nsuccessfully detects anomalies.\n","authors":["Yohei Baba","Takuro Hoshi","Ryosuke Mori","Gaurang Gavai"],"pdf_url":"https://arxiv.org/pdf/2212.11507v1.pdf","comment":"6 pages, 12 figures"},{"id":"http://arxiv.org/abs/2210.07845v2","updated":"2022-12-22T06:29:18Z","published":"2022-10-14T14:14:39Z","title":"Flame-state monitoring based on very low number of visible or infrared\n  images via few-shot learning","summary":"  The current success of machine learning on image-based combustion monitoring\nis based on massive data, which is costly even impossible for industrial\napplications. To address this conflict, we introduce few-shot learning in order\nto achieve combustion monitoring and classification for the first time. Two\nalgorithms, Siamese Network coupled with k Nearest Neighbors (SN-kNN) and\nPrototypical Network (PN), were tested. Rather than utilizing solely visible\nimages as discussed in previous studies, we also used Infrared (IR) images. We\nanalyzed the training process, test performance and inference speed of two\nalgorithms on both image formats, and also used t-SNE to visualize learned\nfeatures. The results demonstrated that both SN-kNN and PN were capable to\ndistinguish flame states from learning with merely 20 images per flame state.\nThe worst performance, which was realized by PN on IR images, still possessed\nprecision, accuracy, recall, and F1-score above 0.95. We showed that visible\nimages demonstrated more substantial differences between classes and presented\nmore consistent patterns inside the class, which made the training speed and\nmodel performance better compared to IR images. In contrast, the relatively low\nquality of IR images made it difficult for PN to extract distinguishable\nprototypes, which caused relatively weak performance. With the entrire training\nset supporting classification, SN-kNN performed well with IR images. On the\nother hand, benefitting from the architecture design, PN has a much faster\nspeed in training and inference than SN-kNN. The presented work analyzed the\ncharacteristics of both algorithms and image formats for the first time, thus\nproviding guidance for their future utilization in combustion monitoring tasks.\n","authors":["Ruiyuan Kang","Panos Liatsis","Dimitrios C. Kyritsis"],"pdf_url":"https://arxiv.org/pdf/2210.07845v2.pdf","comment":"16 pages, 12 figures, four tables"},{"id":"http://arxiv.org/abs/2212.11501v1","updated":"2022-12-22T06:25:53Z","published":"2022-12-22T06:25:53Z","title":"Group Sparse Coding for Image Denoising","summary":"  Group sparse representation has shown promising results in image debulrring\nand image inpainting in GSR [3] , the main reason that lead to the success is\nby exploiting Sparsity and Nonlocal self-similarity (NSS) between patches on\nnatural images, and solve a regularized optimization problem. However, directly\nadapting GSR[3] in image denoising yield very unstable and non-satisfactory\nresults, to overcome these issues, this paper proposes a progressive image\ndenoising algorithm that successfully adapt GSR [3] model and experiments shows\nthe superior performance than some of the state-of-the-art methods.\n","authors":["Luoyu Chen","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2212.11501v1.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.11491v1","updated":"2022-12-22T05:42:54Z","published":"2022-12-22T05:42:54Z","title":"Understanding and Improving the Role of Projection Head in\n  Self-Supervised Learning","summary":"  Self-supervised learning (SSL) aims to produce useful feature representations\nwithout access to any human-labeled data annotations. Due to the success of\nrecent SSL methods based on contrastive learning, such as SimCLR, this problem\nhas gained popularity. Most current contrastive learning approaches append a\nparametrized projection head to the end of some backbone network to optimize\nthe InfoNCE objective and then discard the learned projection head after\ntraining. This raises a fundamental question: Why is a learnable projection\nhead required if we are to discard it after training? In this work, we first\nperform a systematic study on the behavior of SSL training focusing on the role\nof the projection head layers. By formulating the projection head as a\nparametric component for the InfoNCE objective rather than a part of the\nnetwork, we present an alternative optimization scheme for training contrastive\nlearning based SSL frameworks. Our experimental study on multiple image\nclassification datasets demonstrates the effectiveness of the proposed approach\nover alternatives in the SSL literature.\n","authors":["Kartik Gupta","Thalaiyasingam Ajanthan","Anton van den Hengel","Stephen Gould"],"pdf_url":"https://arxiv.org/pdf/2212.11491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11484v1","updated":"2022-12-22T05:00:18Z","published":"2022-12-22T05:00:18Z","title":"SALVE: Self-supervised Adaptive Low-light Video Enhancement","summary":"  A self-supervised adaptive low-light video enhancement (SALVE) method is\nproposed in this work. SALVE first conducts an effective Retinex-based\nlow-light image enhancement on a few key frames of an input low-light video.\nNext, it learns mappings from the low- to enhanced-light frames via Ridge\nregression. Finally, it uses these mappings to enhance the remaining frames in\nthe input video. SALVE is a hybrid method that combines components from a\ntraditional Retinex-based image enhancement method and a learning-based method.\nThe former component leads to a robust solution which is easily adaptive to new\nreal-world environments. The latter component offers a fast, computationally\ninexpensive and temporally consistent solution. We conduct extensive\nexperiments to show the superior performance of SALVE. Our user study shows\nthat 87% of participants prefer SALVE over prior work.\n","authors":["Zohreh Azizi","C. -C. Jay Kuo"],"pdf_url":"https://arxiv.org/pdf/2212.11484v1.pdf","comment":"11 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2212.11477v1","updated":"2022-12-22T04:21:34Z","published":"2022-12-22T04:21:34Z","title":"Spatio-Visual Fusion-Based Person Re-Identification for Overhead Fisheye\n  Images","summary":"  Reliable and cost-effective counting of people in large indoor spaces is a\nsignificant challenge with many applications. An emerging approach is to deploy\nmultiple fisheye cameras mounted overhead to monitor the whole space. However,\ndue to the overlapping fields of view, person re-identificaiton (PRID) is\ncritical for the accuracy of counting. While PRID has been thoroughly\nresearched for traditional rectilinear cameras, few methods have been proposed\nfor fisheye cameras and their performance is comparatively lower. To close this\nperformance gap, we propose a multi-feature framework for fisheye PRID where we\ncombine deep-learning, color-based and location-based features by means of\nnovel feature fusion. We evaluate the performance of our framework for various\nfeature combinations on FRIDA, a public fisheye PRID dataset. The results\ndemonstrate that our multi-feature approach outperforms recent appearance-based\ndeep-learning methods by almost 18% points and location-based methods by almost\n3% points in accuracy.\n","authors":["Mertcan Cokbas","Prakash Ishwar","Janusz Konrad"],"pdf_url":"https://arxiv.org/pdf/2212.11477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11473v1","updated":"2022-12-22T03:57:06Z","published":"2022-12-22T03:57:06Z","title":"Restoring Vision in Hazy Weather with Hierarchical Contrastive Learning","summary":"  Image restoration under hazy weather condition, which is called single image\ndehazing, has been of significant interest for various computer vision\napplications. In recent years, deep learning-based methods have achieved\nsuccess. However, existing image dehazing methods typically neglect the\nhierarchy of features in the neural network and fail to exploit their\nrelationships fully. To this end, we propose an effective image dehazing method\nnamed Hierarchical Contrastive Dehazing (HCD), which is based on feature fusion\nand contrastive learning strategies. HCD consists of a hierarchical dehazing\nnetwork (HDN) and a novel hierarchical contrastive loss (HCL). Specifically,\nthe core design in the HDN is a Hierarchical Interaction Module, which utilizes\nmulti-scale activation to revise the feature responses hierarchically. To\ncooperate with the training of HDN, we propose HCL which performs contrastive\nlearning on hierarchically paired exemplars, facilitating haze removal.\nExtensive experiments on public datasets, RESIDE, HazeRD, and DENSE-HAZE,\ndemonstrate that HCD quantitatively outperforms the state-of-the-art methods in\nterms of PSNR, SSIM and achieves better visual quality.\n","authors":["Tao Wang","Guangpin Tao","Wanglong Lu","Kaihao Zhang","Wenhan Luo","Xiaoqin Zhang","Tong Lu"],"pdf_url":"https://arxiv.org/pdf/2212.11473v1.pdf","comment":"27 pages, 9 figures"},{"id":"http://arxiv.org/abs/2212.11471v1","updated":"2022-12-22T03:47:14Z","published":"2022-12-22T03:47:14Z","title":"Multi-queue Momentum Contrast for Microvideo-Product Retrieval","summary":"  The booming development and huge market of micro-videos bring new e-commerce\nchannels for merchants. Currently, more micro-video publishers prefer to embed\nrelevant ads into their micro-videos, which not only provides them with\nbusiness income but helps the audiences to discover their interesting products.\nHowever, due to the micro-video recording by unprofessional equipment,\ninvolving various topics and including multiple modalities, it is challenging\nto locate the products related to micro-videos efficiently, appropriately, and\naccurately. We formulate the microvideo-product retrieval task, which is the\nfirst attempt to explore the retrieval between the multi-modal and multi-modal\ninstances.\n  A novel approach named Multi-Queue Momentum Contrast (MQMC) network is\nproposed for bidirectional retrieval, consisting of the uni-modal feature and\nmulti-modal instance representation learning. Moreover, a discriminative\nselection strategy with a multi-queue is used to distinguish the importance of\ndifferent negatives based on their categories. We collect two large-scale\nmicrovideo-product datasets (MVS and MVS-large) for evaluation and manually\nconstruct the hierarchical category ontology, which covers sundry products in\ndaily life. Extensive experiments show that MQMC outperforms the\nstate-of-the-art baselines. Our replication package (including code, dataset,\netc.) is publicly available at https://github.com/duyali2000/MQMC.\n","authors":["Yali Du","Yinwei Wei","Wei Ji","Fan Liu","Xin Luo","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2212.11471v1.pdf","comment":"Proceedings of the Sixteenth ACM International Conference on Web\n  Search and Data Mining (WSDM '23), February 27-March 3, 2023, Singapore,\n  Singapore"},{"id":"http://arxiv.org/abs/2212.11468v1","updated":"2022-12-22T03:36:19Z","published":"2022-12-22T03:36:19Z","title":"IPProtect: protecting the intellectual property of visual datasets\n  during data valuation","summary":"  Data trading is essential to accelerate the development of data-driven\nmachine learning pipelines. The central problem in data trading is to estimate\nthe utility of a seller's dataset with respect to a given buyer's machine\nlearning task, also known as data valuation. Typically, data valuation requires\none or more participants to share their raw dataset with others, leading to\npotential risks of intellectual property (IP) violations. In this paper, we\ntackle the novel task of preemptively protecting the IP of datasets that need\nto be shared during data valuation. First, we identify and formalize two kinds\nof novel IP risks in visual datasets: data-item (image) IP and statistical\n(dataset) IP. Then, we propose a novel algorithm to convert the raw dataset\ninto a sanitized version, that provides resistance to IP violations, while at\nthe same time allowing accurate data valuation. The key idea is to limit the\ntransfer of information from the raw dataset to the sanitized dataset, thereby\nprotecting against potential intellectual property violations. Next, we analyze\nour method for the likely existence of a solution and immunity against\nreconstruction attacks. Finally, we conduct extensive experiments on three\ncomputer vision datasets demonstrating the advantages of our method in\ncomparison to other baselines.\n","authors":["Gursimran Singh","Chendi Wang","Ahnaf Tazwar","Lanjun Wang","Yong Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11468v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2110.04181v3","updated":"2022-12-22T02:50:07Z","published":"2021-10-08T15:02:30Z","title":"Dataset Condensation with Distribution Matching","summary":"  Computational cost of training state-of-the-art deep models in many learning\nproblems is rapidly increasing due to more sophisticated models and larger\ndatasets. A recent promising direction for reducing training cost is dataset\ncondensation that aims to replace the original large training set with a\nsignificantly smaller learned synthetic set while preserving the original\ninformation. While training deep models on the small set of condensed images\ncan be extremely fast, their synthesis remains computationally expensive due to\nthe complex bi-level optimization and second-order derivative computation. In\nthis work, we propose a simple yet effective method that synthesizes condensed\nimages by matching feature distributions of the synthetic and original training\nimages in many sampled embedding spaces. Our method significantly reduces the\nsynthesis cost while achieving comparable or better performance. Thanks to its\nefficiency, we apply our method to more realistic and larger datasets with\nsophisticated neural architectures and obtain a significant performance boost.\nWe also show promising practical benefits of our method in continual learning\nand neural architecture search.\n","authors":["Bo Zhao","Hakan Bilen"],"pdf_url":"https://arxiv.org/pdf/2110.04181v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10806v2","updated":"2022-12-22T02:37:48Z","published":"2022-12-21T06:56:22Z","title":"Semi-Supervised Learning of Monocular Depth Estimation via Consistency\n  Regularization with K-way Disjoint Masking","summary":"  Semi-Supervised Learning (SSL) has recently accomplished successful\nachievements in various fields such as image classification, object detection,\nand semantic segmentation, which typically require a lot of labour to construct\nground-truth. Especially in the depth estimation task, annotating training data\nis very costly and time-consuming, and thus recent SSL regime seems an\nattractive solution. In this paper, for the first time, we introduce a novel\nframework for semi-supervised learning of monocular depth estimation networks,\nusing consistency regularization to mitigate the reliance on large ground-truth\ndepth data. We propose a novel data augmentation approach, called K-way\ndisjoint masking, which allows the network for learning how to reconstruct\ninvisible regions so that the model not only becomes robust to perturbations\nbut also generates globally consistent output depth maps. Experiments on the\nKITTI and NYU-Depth-v2 datasets demonstrate the effectiveness of each component\nin our pipeline, robustness to the use of fewer and fewer annotated images, and\nsuperior results compared to other state-of-the-art, semi-supervised methods\nfor monocular depth estimation. Our code is available at\nhttps://github.com/KU-CVLAB/MaskingDepth.\n","authors":["Jongbeom Baek","Gyeongnyeon Kim","Seonghoon Park","Honggyu An","Matteo Poggi","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2212.10806v2.pdf","comment":"Project page: https://github.com/KU-CVLAB/MaskingDepth"},{"id":"http://arxiv.org/abs/2112.06910v2","updated":"2022-12-22T02:10:39Z","published":"2021-12-13T18:59:30Z","title":"DenseGAP: Graph-Structured Dense Correspondence Learning with Anchor\n  Points","summary":"  Establishing dense correspondence between two images is a fundamental\ncomputer vision problem, which is typically tackled by matching local feature\ndescriptors. However, without global awareness, such local features are often\ninsufficient for disambiguating similar regions. And computing the pairwise\nfeature correlation across images is both computation-expensive and\nmemory-intensive. To make the local features aware of the global context and\nimprove their matching accuracy, we introduce DenseGAP, a new solution for\nefficient Dense correspondence learning with a Graph-structured neural network\nconditioned on Anchor Points. Specifically, we first propose a graph structure\nthat utilizes anchor points to provide sparse but reliable prior on inter- and\nintra-image context and propagates them to all image points via directed edges.\nWe also design a graph-structured network to broadcast multi-level contexts via\nlight-weighted message-passing layers and generate high-resolution feature maps\nat low memory cost. Finally, based on the predicted feature maps, we introduce\na coarse-to-fine framework for accurate correspondence prediction using cycle\nconsistency. Our feature descriptors capture both local and global information,\nthus enabling a continuous feature field for querying arbitrary points at high\nresolution. Through comprehensive ablative experiments and evaluations on\nlarge-scale indoor and outdoor datasets, we demonstrate that our method\nadvances the state-of-the-art of correspondence learning on most benchmarks.\n","authors":["Zhengfei Kuang","Jiaman Li","Mingming He","Tong Wang","Yajie Zhao"],"pdf_url":"https://arxiv.org/pdf/2112.06910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11453v1","updated":"2022-12-22T01:59:58Z","published":"2022-12-22T01:59:58Z","title":"Vision-Based Environmental Perception for Autonomous Driving","summary":"  Visual perception plays an important role in autonomous driving. One of the\nprimary tasks is object detection and identification. Since the vision sensor\nis rich in color and texture information, it can quickly and accurately\nidentify various road information. The commonly used technique is based on\nextracting and calculating various features of the image. The recent\ndevelopment of deep learning-based method has better reliability and processing\nspeed and has a greater advantage in recognizing complex elements. For depth\nestimation, vision sensor is also used for ranging due to their small size and\nlow cost. Monocular camera uses image data from a single viewpoint as input to\nestimate object depth. In contrast, stereo vision is based on parallax and\nmatching feature points of different views, and the application of deep\nlearning also further improves the accuracy. In addition, Simultaneous Location\nand Mapping (SLAM) can establish a model of the road environment, thus helping\nthe vehicle perceive the surrounding environment and complete the tasks. In\nthis paper, we introduce and compare various methods of object detection and\nidentification, then explain the development of depth estimation and compare\nvarious methods based on monocular, stereo, and RDBG sensors, next review and\ncompare various methods of SLAM, and finally summarize the current problems and\npresent the future development trends of vision technologies.\n","authors":["Fei Liu","Zihao Lu","Xianke Lin"],"pdf_url":"https://arxiv.org/pdf/2212.11453v1.pdf","comment":"39 pages, 17 figures"},{"id":"http://arxiv.org/abs/2212.11444v1","updated":"2022-12-22T01:26:38Z","published":"2022-12-22T01:26:38Z","title":"Offline Clustering Approach to Self-supervised Learning for\n  Class-imbalanced Image Data","summary":"  Class-imbalanced datasets are known to cause the problem of model being\nbiased towards the majority classes. In this project, we set up two research\nquestions: 1) when is the class-imbalance problem more prevalent in\nself-supervised pre-training? and 2) can offline clustering of feature\nrepresentations help pre-training on class-imbalanced data? Our experiments\ninvestigate the former question by adjusting the degree of {\\it\nclass-imbalance} when training the baseline models, namely SimCLR and SimSiam\non CIFAR-10 database. To answer the latter question, we train each expert model\non each subset of the feature clusters. We then distill the knowledge of expert\nmodels into a single model, so that we will be able to compare the performance\nof this model to our baselines.\n","authors":["Hye-min Chang","Sungkyun Chang"],"pdf_url":"https://arxiv.org/pdf/2212.11444v1.pdf","comment":"5 pages, 3 figures, Technical report"},{"id":"http://arxiv.org/abs/2212.11439v1","updated":"2022-12-22T01:15:08Z","published":"2022-12-22T01:15:08Z","title":"Novel Deep Learning Framework For Bovine Iris Segmentation","summary":"  Iris segmentation is the initial step to identify biometric of animals to\nestablish a traceability system of livestock. In this study, we propose a novel\ndeep learning framework for pixel-wise segmentation with minimum use of\nannotation labels using BovineAAEyes80 public dataset. In the experiment, U-Net\nwith VGG16 backbone was selected as the best combination of encoder and decoder\nmodel, demonstrating a 99.50% accuracy and a 98.35% Dice coefficient score.\nRemarkably, the selected model accurately segmented corrupted images even\nwithout proper annotation data. This study contributes to the advancement of\nthe iris segmentation and the development of a reliable DNNs training\nframework.\n","authors":["Heemoon Yoon","Mira Park","Sang-Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2212.11439v1.pdf","comment":"5 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2208.04278v2","updated":"2022-12-22T00:59:43Z","published":"2022-08-08T17:16:02Z","title":"Self-Supervised Contrastive Representation Learning for 3D Mesh\n  Segmentation","summary":"  3D deep learning is a growing field of interest due to the vast amount of\ninformation stored in 3D formats. Triangular meshes are an efficient\nrepresentation for irregular, non-uniform 3D objects. However, meshes are often\nchallenging to annotate due to their high geometrical complexity. Specifically,\ncreating segmentation masks for meshes is tedious and time-consuming.\nTherefore, it is desirable to train segmentation networks with limited-labeled\ndata. Self-supervised learning (SSL), a form of unsupervised representation\nlearning, is a growing alternative to fully-supervised learning which can\ndecrease the burden of supervision for training. We propose SSL-MeshCNN, a\nself-supervised contrastive learning method for pre-training CNNs for mesh\nsegmentation. We take inspiration from traditional contrastive learning\nframeworks to design a novel contrastive learning algorithm specifically for\nmeshes. Our preliminary experiments show promising results in reducing the\nheavy labeled data requirement needed for mesh segmentation by at least 33%.\n","authors":["Ayaan Haque","Hankyu Moon","Heng Hao","Sima Didari","Jae Oh Woo","Patrick Bangert"],"pdf_url":"https://arxiv.org/pdf/2208.04278v2.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2206.09592v3","updated":"2022-12-22T00:55:29Z","published":"2022-06-20T06:43:17Z","title":"DALL-E for Detection: Language-driven Compositional Image Synthesis for\n  Object Detection","summary":"  We propose a new paradigm to automatically generate training data with\naccurate labels at scale using the text-toimage synthesis frameworks (e.g.,\nDALL-E, Stable Diffusion, etc.). The proposed approach decouples training data\ngeneration into foreground object mask generation and background (context)\nimage generation. For foreground object mask generation, we use a simple\ntextual template with object class name as input to DALL-E to generate a\ndiverse set of foreground images. A foreground-background segmentation\nalgorithm is then used to generate foreground object masks. Next, in order to\ngenerate context images, first a language description of the context is\ngenerated by applying an image captioning method on a small set of images\nrepresenting the context. These language descriptions are then used to generate\ndiverse sets of context images using the DALL-E framework. These are then\ncomposited with object masks generated in the first step to provide an\naugmented training set for a classifier. We demonstrate the advantages of our\napproach on four object detection datasets including on Pascal VOC and COCO\nobject detection tasks. Furthermore, we also highlight the compositional nature\nof our data generation approach on out-of-distribution and zero-shot data\ngeneration scenarios.\n","authors":["Yunhao Ge","Jiashu Xu","Brian Nlong Zhao","Neel Joshi","Laurent Itti","Vibhav Vineet"],"pdf_url":"https://arxiv.org/pdf/2206.09592v3.pdf","comment":"v3(same as v2) version, update structure (add foreground generation,\n  stable diffusion), add more experiments"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.05035v3","updated":"2022-12-22T16:17:52Z","published":"2022-12-05T06:25:24Z","title":"COVID-19 Activity Risk Calculator as a Gamified Public Health\n  Intervention Tool","summary":"  Public health intervention techniques have been highly significant in\nreducing the negative impact of several epidemics and pandemics. Among all of\nthe wide-spread diseases, one of the most dangerous one has been severe acute\nrespiratory syndrome coronavirus 2 (SARS-CoV-2) or Coronavirus disease 2019\n(COVID-19). The impact of the virus has been observed in over 200 countries\nleading to hospitalizations and deaths of millions of people. Currently\nexisting COVID-19 risk estimation tools provided to the general public have\nbeen highly variable during the pandemic due to its dependency on rapidly\nevolving factors such as community transmission levels and variants. There has\nalso been confusion surrounding certain personal protective strategies such as\nrisk reduction by mask-wearing and vaccination. In order to create a simplified\neasy-to-use tool for estimating different individual risks associated with\ncarrying out daily-life activity, we developed COVID-19 Activity Risk\nCalculator (CovARC). CovARC serves as a gamified public health intervention as\nusers can \"play with\" how different risks associated with COVID-19 would change\ndepending on several different factors when carrying out a daily routine\nactivity. Empowering the public to make informed, data-driven decisions about\nsafely engaging in activities may help to reduce COVID- 19 levels in the\ncommunity. In this study, we demonstrate a streamlined, scalable and accurate\nCOVID-19 risk calculation system. Our study also showcases quantitatively, the\nincreased impact of interventions such as vaccination and mask-wearing when\ncases are higher, which could prove as a validity to inform and support policy\ndecisions around mask mandate case thresholds and other non-pharmaceutical\ninterventions.\n","authors":["Shreyasvi Natraj","Malhar Bhide","Nathan Yap","Meng Liu","Agrima Seth","Jonathan Berman","Christin Glorioso"],"pdf_url":"https://arxiv.org/pdf/2212.05035v3.pdf","comment":"12 pages, 6 figures (main paper) + 1 figure (supplementary section.)"},{"id":"http://arxiv.org/abs/2212.11735v1","updated":"2022-12-22T14:28:10Z","published":"2022-12-22T14:28:10Z","title":"Response to Moffat's Comment on \"Towards Meaningful Statements in IR\n  Evaluation: Mapping Evaluation Measures to Interval Scales\"","summary":"  Moffat recently commented on our previous work. Our work focused on how\nlaying the foundations of our evaluation methodology into the theory of\nmeasurement can improve our knowledge and understanding of the evaluation\nmeasures we use in IR and how it can shed light on the different types of\nscales adopted by our evaluation measures; we also provided evidence, through\nextensive experimentation, on the impact of the different types of scales on\nthe statistical analyses, as well as on the impact of departing from their\nassumptions. Moreover, we investigated, for the first time in IR, the concept\nof meaningfulness, i.e. the invariance of the experimental statements and\ninferences you draw, and proposed it as a way to ensure more valid and\ngeneralizabile results. Moffat's comments build on: (i) misconceptions about\nthe representational theory of measurement, such as what an interval scale\nactually is and what axioms it has to comply with; (ii) they totally miss the\ncentral concept of meaningfulness. Therefore, we reply to Moffat's comments by\nproperly framing them in the representational theory of measurement and in the\nconcept of meaningfulness. All in all, we can only reiterate what we said\nseveral times: the goal of this research line is to theoretically ground our\nevaluation methodology - and IR is a field where it is extremely challenging to\nperform any theoretical advances - in order to aim for more robust and\ngeneralizable inferences - something we currently lack in the field. Possibly\nthere are other and better ways to achieve this objective and these proposals\ncould emerge from an open discussion in the field and from the work of others.\nOn the other hand, reducing everything to a contrast on what is (or pretend to\nbe) an interval scale or whether all or none evaluation measures are interval\nscales may be more a barrier from than a help in progressing towards this goal.\n","authors":["Marco Ferrante","Nicola Ferro","Norbert Fuhr"],"pdf_url":"https://arxiv.org/pdf/2212.11735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11709v1","updated":"2022-12-22T13:52:53Z","published":"2022-12-22T13:52:53Z","title":"Reinforcement Learning Based Approaches to Adaptive Context Caching in\n  Distributed Context Management Systems","summary":"  Performance metrics-driven context caching has a profound impact on\nthroughput and response time in distributed context management systems for\nreal-time context queries. This paper proposes a reinforcement learning based\napproach to adaptively cache context with the objective of minimizing the cost\nincurred by context management systems in responding to context queries. Our\nnovel algorithms enable context queries and sub-queries to reuse and repurpose\ncached context in an efficient manner. This approach is distinctive to\ntraditional data caching approaches by three main features. First, we make\nselective context cache admissions using no prior knowledge of the context, or\nthe context query load. Secondly, we develop and incorporate innovative\nheuristic models to calculate expected performance of caching an item when\nmaking the decisions. Thirdly, our strategy defines a time-aware continuous\ncache action space. We present two reinforcement learning agents, a value\nfunction estimating actor-critic agent and a policy search agent using deep\ndeterministic policy gradient method. The paper also proposes adaptive policies\nsuch as eviction and cache memory scaling to complement our objective. Our\nmethod is evaluated using a synthetically generated load of context sub-queries\nand a synthetic data set inspired from real world data and query samples. We\nfurther investigate optimal adaptive caching configurations under different\nsettings. This paper presents, compares, and discusses our findings that the\nproposed selective caching methods reach short- and long-term cost- and\nperformance-efficiency. The paper demonstrates that the proposed methods\noutperform other modes of context management such as redirector mode, and\ndatabase mode, and cache all policy by up to 60% in cost efficiency.\n","authors":["Shakthi Weerasinghe","Arkady Zaslavsky","Seng W. Loke","Amin Abken","Alireza Hassani"],"pdf_url":"https://arxiv.org/pdf/2212.11709v1.pdf","comment":"This is a pre-print version of the journal paper submitted to ACM\n  Transactions in Internet of Things, which is currently under review"},{"id":"http://arxiv.org/abs/2211.11159v2","updated":"2022-12-22T01:58:16Z","published":"2022-11-21T03:09:42Z","title":"Directed Acyclic Graph Factorization Machines for CTR Prediction via\n  Knowledge Distillation","summary":"  With the growth of high-dimensional sparse data in web-scale recommender\nsystems, the computational cost to learn high-order feature interaction in CTR\nprediction task largely increases, which limits the use of high-order\ninteraction models in real industrial applications. Some recent knowledge\ndistillation based methods transfer knowledge from complex teacher models to\nshallow student models for accelerating the online model inference. However,\nthey suffer from the degradation of model accuracy in knowledge distillation\nprocess. It is challenging to balance the efficiency and effectiveness of the\nshallow student models. To address this problem, we propose a Directed Acyclic\nGraph Factorization Machine (KD-DAGFM) to learn the high-order feature\ninteractions from existing complex interaction models for CTR prediction via\nKnowledge Distillation. The proposed lightweight student model DAGFM can learn\narbitrary explicit feature interactions from teacher networks, which achieves\napproximately lossless performance and is proved by a dynamic programming\nalgorithm. Besides, an improved general model KD-DAGFM+ is shown to be\neffective in distilling both explicit and implicit feature interactions from\nany complex teacher model. Extensive experiments are conducted on four\nreal-world datasets, including a large-scale industrial dataset from WeChat\nplatform with billions of feature dimensions. KD-DAGFM achieves the best\nperformance with less than 21.5% FLOPs of the state-of-the-art method on both\nonline and offline experiments, showing the superiority of DAGFM to deal with\nthe industrial scale data in CTR prediction task. Our implementation code is\navailable at: https://github.com/RUCAIBox/DAGFM.\n","authors":["Zhen Tian","Ting Bai","Zibin Zhang","Zhiyuan Xu","Kangyi Lin","Ji-Rong Wen","Wayne Xin Zhao"],"pdf_url":"https://arxiv.org/pdf/2211.11159v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11431v1","updated":"2022-12-22T00:47:40Z","published":"2022-12-22T00:47:40Z","title":"Local Policy Improvement for Recommender Systems","summary":"  Recommender systems aim to answer the following question: given the items\nthat a user has interacted with, what items will this user likely interact with\nnext? Historically this problem is often framed as a predictive task via\n(self-)supervised learning. In recent years, we have seen more emphasis placed\non approaching the recommendation problem from a policy optimization\nperspective: learning a policy that maximizes some reward function (e.g., user\nengagement). However, it is commonly the case in recommender systems that we\nare only able to train a new policy given data collected from a\npreviously-deployed policy. The conventional way to address such a policy\nmismatch is through importance sampling correction, which unfortunately comes\nwith its own limitations. In this paper, we suggest an alternative approach,\nwhich involves the use of local policy improvement without off-policy\ncorrection. Drawing from a number of related results in the fields of causal\ninference, bandits, and reinforcement learning, we present a suite of methods\nthat compute and optimize a lower bound of the expected reward of the target\npolicy. Crucially, this lower bound is a function that is easy to estimate from\ndata, and which does not involve density ratios (such as those appearing in\nimportance sampling correction). We argue that this local policy improvement\nparadigm is particularly well suited for recommender systems, given that in\npractice the previously-deployed policy is typically of reasonably high\nquality, and furthermore it tends to be re-trained frequently and gets\ncontinuously updated. We discuss some practical recipes on how to apply some of\nthe proposed techniques in a sequential recommendation setting.\n","authors":["Dawen Liang","Nikos Vlassis"],"pdf_url":"https://arxiv.org/pdf/2212.11431v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2206.05442v4","updated":"2022-12-22T18:59:36Z","published":"2022-06-11T06:38:06Z","title":"Automatically Answering and Generating Machine Learning Final Exams","summary":"  Can a machine learn machine learning? We propose to answer this question\nusing the same criteria we use to answer a similar question: can a human learn\nmachine learning? We automatically answer final exams in MIT's, Harvard's and\nCornell's large machine learning courses and generate new questions at a human\nlevel. Recently, program synthesis and few-shot learning solved\nuniversity-level problem set questions in mathematics and STEM courses at a\nhuman level. In this work, we solve questions from final exams that differ from\nproblem sets in several ways: the questions are longer, have multiple parts,\nare more complicated, and span a broader set of topics. We provide a new\ndataset and benchmark of questions from machine learning final exams and code\nfor automatically answering these questions and generating new questions. To\nmake our dataset a reproducible benchmark, we use automatic checkers for\nmultiple choice questions, questions with numeric answers, and questions with\nexpression answers, and evaluate a large free language model, Meta's OPT, and\ncompare the results with Open AI's GPT-3, ChatGPT, and Codex. A student survey\ncomparing the quality, appropriateness, and difficulty of machine-generated\nquestions with human-written questions shows that across multiple aspects,\nmachine-generated questions are indistinguishable from human-generated\nquestions and are suitable for final exams. We perform ablation studies\ncomparing zero-shot learning with few-shot learning, chain-of-thought\nprompting, GPT-3, ChatGPT, and OPT pre-trained on text and Codex fine-tuned on\ncode on a range of machine learning topics and find that few-shot learning\nmethods perform best. We make our data and code publicly available for the\nmachine learning community.\n","authors":["Sarah Zhang","Reece Shuttleworth","Zad Chin","Pedro Lantigua","Saisamrit Surbehera","Gregory Hunter","Derek Austin","Yann Hicke","Leonard Tang","Sathwik Karnik","Darnell Granberry","Iddo Drori"],"pdf_url":"https://arxiv.org/pdf/2206.05442v4.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2212.11972v1","updated":"2022-12-22T18:55:45Z","published":"2022-12-22T18:55:45Z","title":"Scalable Adaptive Computation for Iterative Generation","summary":"  We present the Recurrent Interface Network (RIN), a neural net architecture\nthat allocates computation adaptively to the input according to the\ndistribution of information, allowing it to scale to iterative generation of\nhigh-dimensional data. Hidden units of RINs are partitioned into the interface,\nwhich is locally connected to inputs, and latents, which are decoupled from\ninputs and can exchange information globally. The RIN block selectively reads\nfrom the interface into latents for high-capacity processing, with incremental\nupdates written back to the interface. Stacking multiple blocks enables\neffective routing across local and global levels. While routing adds overhead,\nthe cost can be amortized in recurrent computation settings where inputs change\ngradually while more global context persists, such as iterative generation\nusing diffusion models. To this end, we propose a latent self-conditioning\ntechnique that \"warm-starts\" the latents at each iteration of the generation\nprocess. When applied to diffusion models operating directly on pixels, RINs\nyield state-of-the-art image and video generation without cascades or guidance,\nwhile being domain-agnostic and up to 10$\\times$ more efficient compared to\nspecialized 2D and 3D U-Nets.\n","authors":["Allan Jabri","David Fleet","Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2212.11972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11937v1","updated":"2022-12-22T18:16:58Z","published":"2022-12-22T18:16:58Z","title":"Efficient Induction of Language Models Via Probabilistic Concept\n  Formation","summary":"  This paper presents a novel approach to the acquisition of language models\nfrom corpora. The framework builds on Cobweb, an early system for constructing\ntaxonomic hierarchies of probabilistic concepts that used a tabular,\nattribute-value encoding of training cases and concepts, making it unsuitable\nfor sequential input like language. In response, we explore three new\nextensions to Cobweb -- the Word, Leaf, and Path variants. These systems encode\neach training case as an anchor word and surrounding context words, and they\nstore probabilistic descriptions of concepts as distributions over anchor and\ncontext information. As in the original Cobweb, a performance element sorts a\nnew instance downward through the hierarchy and uses the final node to predict\nmissing features. Learning is interleaved with performance, updating concept\nprobabilities and hierarchy structure as classification occurs. Thus, the new\napproaches process training cases in an incremental, online manner that it very\ndifferent from most methods for statistical language learning. We examine how\nwell the three variants place synonyms together and keep homonyms apart, their\nability to recall synonyms as a function of training set size, and their\ntraining efficiency. Finally, we discuss related work on incremental learning\nand directions for further research.\n","authors":["Christopher J. MacLellan","Peter Matsakis","Pat Langley"],"pdf_url":"https://arxiv.org/pdf/2212.11937v1.pdf","comment":"18 pages, 5 figures, Presented at Advances in Cognitive Systems 2022"},{"id":"http://arxiv.org/abs/2212.11933v1","updated":"2022-12-22T18:12:27Z","published":"2022-12-22T18:12:27Z","title":"Word Embedding Neural Networks to Advance Knee Osteoarthritis Research","summary":"  Osteoarthritis (OA) is the most prevalent chronic joint disease worldwide,\nwhere knee OA takes more than 80% of commonly affected joints. Knee OA is not a\ncurable disease yet, and it affects large columns of patients, making it costly\nto patients and healthcare systems. Etiology, diagnosis, and treatment of knee\nOA might be argued by variability in its clinical and physical manifestations.\nAlthough knee OA carries a list of well-known terminology aiming to standardize\nthe nomenclature of the diagnosis, prognosis, treatment, and clinical outcomes\nof the chronic joint disease, in practice there is a wide range of terminology\nassociated with knee OA across different data sources, including but not\nlimited to biomedical literature, clinical notes, healthcare literacy, and\nhealth-related social media. Among these data sources, the scientific articles\npublished in the biomedical literature usually make a principled pipeline to\nstudy disease. Rapid yet, accurate text mining on large-scale scientific\nliterature may discover novel knowledge and terminology to better understand\nknee OA and to improve the quality of knee OA diagnosis, prevention, and\ntreatment. The present works aim to utilize artificial neural network\nstrategies to automatically extract vocabularies associated with knee OA\ndiseases. Our finding indicates the feasibility of developing word embedding\nneural networks for autonomous keyword extraction and abstraction of knee OA.\n","authors":["Soheyla Amirian","Husam Ghazaleh","Mehdi Assefi","Hilal Maradit Kremers","Hamid R. Arabnia","Johannes F. Plate","Ahmad P. Tafti"],"pdf_url":"https://arxiv.org/pdf/2212.11933v1.pdf","comment":"5 pages, 3 figures, Accepted in Computational Science and\n  Computational Intelligence; 2022 International Conference on IEEE CPS (IEEE\n  XPLORE, Scopus)"},{"id":"http://arxiv.org/abs/2210.13452v2","updated":"2022-12-22T17:56:05Z","published":"2022-10-24T17:59:57Z","title":"MetaFormer Baselines for Vision","summary":"  MetaFormer, the abstracted architecture of Transformer, has been found to\nplay a significant role in achieving competitive performance. In this paper, we\nfurther explore the capacity of MetaFormer, again, without focusing on token\nmixer design: we introduce several baseline models under MetaFormer using the\nmost basic or common mixers, and summarize our observations as follows: (1)\nMetaFormer ensures solid lower bound of performance. By merely adopting\nidentity mapping as the token mixer, the MetaFormer model, termed\nIdentityFormer, achieves >80% accuracy on ImageNet-1K. (2) MetaFormer works\nwell with arbitrary token mixers. When specifying the token mixer as even a\nrandom matrix to mix tokens, the resulting model RandFormer yields an accuracy\nof >81%, outperforming IdentityFormer. Rest assured of MetaFormer's results\nwhen new token mixers are adopted. (3) MetaFormer effortlessly offers\nstate-of-the-art results. With just conventional token mixers dated back five\nyears ago, the models instantiated from MetaFormer already beat state of the\nart. (a) ConvFormer outperforms ConvNeXt. Taking the common depthwise separable\nconvolutions as the token mixer, the model termed ConvFormer, which can be\nregarded as pure CNNs, outperforms the strong CNN model ConvNeXt. (b) CAFormer\nsets new record on ImageNet-1K. By simply applying depthwise separable\nconvolutions as token mixer in the bottom stages and vanilla self-attention in\nthe top stages, the resulting model CAFormer sets a new record on ImageNet-1K:\nit achieves an accuracy of 85.5% at 224x224 resolution, under normal supervised\ntraining without external data or distillation. In our expedition to probe\nMetaFormer, we also find that a new activation, StarReLU, reduces 71% FLOPs of\nactivation compared with GELU yet achieves better performance. We expect\nStarReLU to find great potential in MetaFormer-like models alongside other\nneural networks.\n","authors":["Weihao Yu","Chenyang Si","Pan Zhou","Mi Luo","Yichen Zhou","Jiashi Feng","Shuicheng Yan","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2210.13452v2.pdf","comment":"Add more ImageNet-22K pretrained models. Code:\n  https://github.com/sail-sg/metaformer"},{"id":"http://arxiv.org/abs/2212.11910v1","updated":"2022-12-22T17:53:25Z","published":"2022-12-22T17:53:25Z","title":"Realizing Molecular Machine Learning through Communications for\n  Biological AI: Future Directions and Challenges","summary":"  Artificial Intelligence (AI) and Machine Learning (ML) are weaving their way\ninto the fabric of society, where they are playing a crucial role in numerous\nfacets of our lives. As we witness the increased deployment of AI and ML in\nvarious types of devices, we benefit from their use into energy-efficient\nalgorithms for low powered devices. In this paper, we investigate a scale and\nmedium that is far smaller than conventional devices as we move towards\nmolecular systems that can be utilized to perform machine learning functions,\ni.e., Molecular Machine Learning (MML). Fundamental to the operation of MML is\nthe transport, processing, and interpretation of information propagated by\nmolecules through chemical reactions. We begin by reviewing the current\napproaches that have been developed for MML, before we move towards potential\nnew directions that rely on gene regulatory networks inside biological\norganisms as well as their population interactions to create neural networks.\nWe then investigate mechanisms for training machine learning structures in\nbiological cells based on calcium signaling and demonstrate their application\nto build an Analog to Digital Converter (ADC). Lastly, we look at potential\nfuture directions as well as challenges that this area could solve.\n","authors":["Sasitharan Balasubramaniam","Samitha Somathilaka","Sehee Sun","Adrian Ratwatte","Massimiliano Pierobon"],"pdf_url":"https://arxiv.org/pdf/2212.11910v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10318v2","updated":"2022-12-22T17:36:03Z","published":"2022-12-20T15:09:30Z","title":"Learned Systems Security","summary":"  A learned system uses machine learning (ML) internally to improve\nperformance. We can expect such systems to be vulnerable to some adversarial-ML\nattacks. Often, the learned component is shared between mutually-distrusting\nusers or processes, much like microarchitectural resources such as caches,\npotentially giving rise to highly-realistic attacker models. However, compared\nto attacks on other ML-based systems, attackers face a level of indirection as\nthey cannot interact directly with the learned model. Additionally, the\ndifference between the attack surface of learned and non-learned versions of\nthe same system is often subtle. These factors obfuscate the de-facto risks\nthat the incorporation of ML carries. We analyze the root causes of\npotentially-increased attack surface in learned systems and develop a framework\nfor identifying vulnerabilities that stem from the use of ML. We apply our\nframework to a broad set of learned systems under active development. To\nempirically validate the many vulnerabilities surfaced by our framework, we\nchoose 3 of them and implement and evaluate exploits against prominent\nlearned-system instances. We show that the use of ML caused leakage of past\nqueries in a database, enabled a poisoning attack that causes exponential\nmemory blowup in an index structure and crashes it in seconds, and enabled\nindex users to snoop on each others' key distributions by timing queries over\ntheir own keys. We find that adversarial ML is a universal threat against\nlearned systems, point to open research gaps in our understanding of\nlearned-systems security, and conclude by discussing mitigations, while noting\nthat data leakage is inherent in systems whose learned component is shared\nbetween multiple parties.\n","authors":["Roei Schuster","Jin Peng Zhou","Thorsten Eisenhofer","Paul Grubbs","Nicolas Papernot"],"pdf_url":"https://arxiv.org/pdf/2212.10318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11890v1","updated":"2022-12-22T17:24:32Z","published":"2022-12-22T17:24:32Z","title":"Decoding surface codes with deep reinforcement learning and\n  probabilistic policy reuse","summary":"  Quantum computing (QC) promises significant advantages on certain hard\ncomputational tasks over classical computers. However, current quantum\nhardware, also known as noisy intermediate-scale quantum computers (NISQ), are\nstill unable to carry out computations faithfully mainly because of the lack of\nquantum error correction (QEC) capability. A significant amount of theoretical\nstudies have provided various types of QEC codes; one of the notable\ntopological codes is the surface code, and its features, such as the\nrequirement of only nearest-neighboring two-qubit control gates and a large\nerror threshold, make it a leading candidate for scalable quantum computation.\nRecent developments of machine learning (ML)-based techniques especially the\nreinforcement learning (RL) methods have been applied to the decoding problem\nand have already made certain progress. Nevertheless, the device noise pattern\nmay change over time, making trained decoder models ineffective. In this paper,\nwe propose a continual reinforcement learning method to address these decoding\nchallenges. Specifically, we implement double deep Q-learning with\nprobabilistic policy reuse (DDQN-PPR) model to learn surface code decoding\nstrategies for quantum environments with varying noise patterns. Through\nnumerical simulations, we show that the proposed DDQN-PPR model can\nsignificantly reduce the computational complexity. Moreover, increasing the\nnumber of trained policies can further improve the agent's performance. Our\nresults open a way to build more capable RL agents which can leverage\npreviously gained knowledge to tackle QEC challenges.\n","authors":["Elisha Siddiqui Matekole","Esther Ye","Ramya Iyer","Samuel Yen-Chi Chen"],"pdf_url":"https://arxiv.org/pdf/2212.11890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11126v2","updated":"2022-12-22T17:20:36Z","published":"2022-12-18T16:08:40Z","title":"Chatbots in a Botnet World","summary":"  Question-and-answer formats provide a novel experimental platform for\ninvestigating cybersecurity questions. Unlike previous chatbots, the latest\nChatGPT model from OpenAI supports an advanced understanding of complex coding\nquestions. The research demonstrates thirteen coding tasks that generally\nqualify as stages in the MITRE ATT&CK framework, ranging from credential access\nto defense evasion. With varying success, the experimental prompts generate\nexamples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled\nransomware. The empirical results illustrate cases that support the broad gain\nof functionality, including self-replication and self-modification, evasion,\nand strategic understanding of complex cybersecurity goals. One surprising\nfeature of ChatGPT as a language-only model centers on its ability to spawn\ncoding approaches that yield images that obfuscate or embed executable\nprogramming steps or links.\n","authors":["Forrest McKee","David Noever"],"pdf_url":"https://arxiv.org/pdf/2212.11126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12446v2","updated":"2022-12-22T17:13:50Z","published":"2022-11-22T18:02:49Z","title":"EDICT: Exact Diffusion Inversion via Coupled Transformations","summary":"  Finding an initial noise vector that produces an input image when fed into\nthe diffusion process (known as inversion) is an important problem in denoising\ndiffusion models (DDMs), with applications for real image editing. The\nstate-of-the-art approach for real image editing with inversion uses denoising\ndiffusion implicit models (DDIMs) to deterministically noise the image to the\nintermediate state along the path that the denoising would follow given the\noriginal conditioning. However, DDIM inversion for real images is unstable as\nit relies on local linearization assumptions, which result in the propagation\nof errors, leading to incorrect image reconstruction and loss of content. To\nalleviate these problems, we propose Exact Diffusion Inversion via Coupled\nTransformations (EDICT), an inversion method that draws inspiration from affine\ncoupling layers. EDICT enables mathematically exact inversion of real and\nmodel-generated images by maintaining two coupled noise vectors which are used\nto invert each other in an alternating fashion. Using Stable Diffusion, a\nstate-of-the-art latent diffusion model, we demonstrate that EDICT successfully\nreconstructs real images with high fidelity. On complex image datasets like\nMS-COCO, EDICT reconstruction significantly outperforms DDIM, improving the\nmean square error of reconstruction by a factor of two. Using noise vectors\ninverted from real images, EDICT enables a wide range of image edits--from\nlocal and global semantic edits to image stylization--while maintaining\nfidelity to the original image structure. EDICT requires no model\ntraining/finetuning, prompt tuning, or extra data and can be combined with any\npretrained DDM. Code is available at https://github.com/salesforce/EDICT.\n","authors":["Bram Wallace","Akash Gokul","Nikhil Naik"],"pdf_url":"https://arxiv.org/pdf/2211.12446v2.pdf","comment":"24 pages, 22 figures. Code now available"},{"id":"http://arxiv.org/abs/2212.07127v4","updated":"2022-12-22T17:10:46Z","published":"2022-12-14T09:26:07Z","title":"Towards mapping the contemporary art world with ArtLM: an art-specific\n  NLP model","summary":"  With an increasing amount of data in the art world, discovering artists and\nartworks suitable to collectors' tastes becomes a challenge. It is no longer\nenough to use visual information, as contextual information about the artist\nhas become just as important in contemporary art. In this work, we present a\ngeneric Natural Language Processing framework (called ArtLM) to discover the\nconnections among contemporary artists based on their biographies. In this\napproach, we first continue to pre-train the existing general English language\nmodels with a large amount of unlabelled art-related data. We then fine-tune\nthis new pre-trained model with our biography pair dataset manually annotated\nby a team of professionals in the art industry. With extensive experiments, we\ndemonstrate that our ArtLM achieves 85.6% accuracy and 84.0% F1 score and\noutperforms other baseline models. We also provide a visualisation and a\nqualitative analysis of the artist network built from ArtLM's outputs.\n","authors":["Qinkai Chen","Mohamed El-Mennaoui","Antoine Fosset","Amine Rebei","Haoyang Cao","Philine Bouscasse","Christy Eóin O'Beirne","Sasha Shevchenko","Mathieu Rosenbaum"],"pdf_url":"https://arxiv.org/pdf/2212.07127v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01950v3","updated":"2022-12-22T17:05:42Z","published":"2022-10-24T13:33:15Z","title":"Unlocking the potential of two-point cells for energy-efficient and\n  resilient training of deep nets","summary":"  Context-sensitive two-point layer 5 pyramidal cells (L5PCs) were discovered\nas long ago as 1999. However, the potential of this discovery to provide useful\nneural computation has yet to be demonstrated. Here we show for the first time\nhow a transformative L5PCs-driven deep neural network (DNN), termed the\nmultisensory cooperative computing (MCC) architecture, can effectively process\nlarge amounts of heterogeneous real-world audio-visual (AV) data, using far\nless energy compared to best available 'point' neuron-driven DNNs. A novel\nhighly-distributed parallel implementation on a Xilinx UltraScale+ MPSoC device\nestimates energy savings up to 245759 $ \\times $ 50000 $\\mu$J (i.e., 62% less\nthan the baseline model in a semi-supervised learning setup) where a single\nsynapse consumes $8e^{-5}\\mu$J. In a supervised learning setup, the\nenergy-saving can potentially reach up to 1250x less (per feedforward\ntransmission) than the baseline model. The significantly reduced neural\nactivity in MCC leads to inherently fast learning and resilience against sudden\nneural damage. This remarkable performance in pilot experiments demonstrates\nthe embodied neuromorphic intelligence of our proposed cooperative L5PC that\nreceives input from diverse neighbouring neurons as context to amplify the\ntransmission of most salient and relevant information for onward transmission,\nfrom overwhelmingly large multimodal information utilised at the early stages\nof on-chip training. Our proposed approach opens new cross-disciplinary avenues\nfor future on-chip DNN training implementations and posits a radical shift in\ncurrent neuromorphic computing paradigms.\n","authors":["Ahsan Adeel","Adewale Adetomi","Khubaib Ahmed","Amir Hussain","Tughrul Arslan","W. A. Phillips"],"pdf_url":"https://arxiv.org/pdf/2211.01950v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.15101v3","updated":"2022-12-22T17:05:32Z","published":"2021-09-30T13:06:29Z","title":"Compositional generalization in semantic parsing with pretrained\n  transformers","summary":"  Large-scale pretraining instills large amounts of knowledge in deep neural\nnetworks. This, in turn, improves the generalization behavior of these models\nin downstream tasks. What exactly are the limits to the generalization benefits\nof large-scale pretraining? Here, we report observations from some simple\nexperiments aimed at addressing this question in the context of two semantic\nparsing tasks involving natural language, SCAN and COGS. We show that language\nmodels pretrained exclusively with non-English corpora, or even with\nprogramming language corpora, significantly improve out-of-distribution\ngeneralization in these benchmarks, compared with models trained from scratch,\neven though both benchmarks are English-based. This demonstrates the\nsurprisingly broad transferability of pretrained representations and knowledge.\nPretraining with a large-scale protein sequence prediction task, on the other\nhand, mostly deteriorates the generalization performance in SCAN and COGS,\nsuggesting that pretrained representations do not transfer universally and that\nthere are constraints on the similarity between the pretraining and downstream\ndomains for successful transfer. Finally, we show that larger models are harder\nto train from scratch and their generalization accuracy is lower when trained\nup to convergence on the relatively small SCAN and COGS datasets, but the\nbenefits of large-scale pretraining become much clearer with larger models.\n","authors":["A. Emin Orhan"],"pdf_url":"https://arxiv.org/pdf/2109.15101v3.pdf","comment":"v3 adds one reference, adds further discussion, slightly changes\n  formatting"},{"id":"http://arxiv.org/abs/2212.11870v1","updated":"2022-12-22T17:03:57Z","published":"2022-12-22T17:03:57Z","title":"Impossibility Theorems for Feature Attribution","summary":"  Despite a sea of interpretability methods that can produce plausible\nexplanations, the field has also empirically seen many failure cases of such\nmethods. In light of these results, it remains unclear for practitioners how to\nuse these methods and choose between them in a principled way. In this paper,\nwe show that for even moderately rich model classes (easily satisfied by neural\nnetworks), any feature attribution method that is complete and linear--for\nexample, Integrated Gradients and SHAP--can provably fail to improve on random\nguessing for inferring model behaviour. Our results apply to common end-tasks\nsuch as identifying local model behaviour, spurious feature identification, and\nalgorithmic recourse. One takeaway from our work is the importance of\nconcretely defining end-tasks. In particular, we show that once such an\nend-task is defined, a simple and direct approach of repeated model evaluations\ncan outperform many other complex feature attribution methods.\n","authors":["Blair Bilodeau","Natasha Jaques","Pang Wei Koh","Been Kim"],"pdf_url":"https://arxiv.org/pdf/2212.11870v1.pdf","comment":"33 pages, 4 figures"},{"id":"http://arxiv.org/abs/2202.04599v5","updated":"2022-12-22T16:47:28Z","published":"2022-02-09T17:50:52Z","title":"Missing Data Imputation and Acquisition with Deep Hierarchical Models\n  and Hamiltonian Monte Carlo","summary":"  Variational Autoencoders (VAEs) have recently been highly successful at\nimputing and acquiring heterogeneous missing data. However, within this\nspecific application domain, existing VAE methods are restricted by using only\none layer of latent variables and strictly Gaussian posterior approximations.\nTo address these limitations, we present HH-VAEM, a Hierarchical VAE model for\nmixed-type incomplete data that uses Hamiltonian Monte Carlo with automatic\nhyper-parameter tuning for improved approximate inference. Our experiments show\nthat HH-VAEM outperforms existing baselines in the tasks of missing data\nimputation and supervised learning with missing features. Finally, we also\npresent a sampling-based approach for efficiently computing the information\ngain when missing features are to be acquired with HH-VAEM. Our experiments\nshow that this sampling-based approach is superior to alternatives based on\nGaussian approximations.\n","authors":["Ignacio Peis","Chao Ma","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2202.04599v5.pdf","comment":"Published at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.11851v1","updated":"2022-12-22T16:35:42Z","published":"2022-12-22T16:35:42Z","title":"StoRM: A Diffusion-based Stochastic Regeneration Model for Speech\n  Enhancement and Dereverberation","summary":"  Diffusion models have shown a great ability at bridging the performance gap\nbetween predictive and generative approaches for speech enhancement. We have\nshown that they may even outperform their predictive counterparts for\nnon-additive corruption types or when they are evaluated on mismatched\nconditions. However, diffusion models suffer from a high computational burden,\nmainly as they require to run a neural network for each reverse diffusion step,\nwhereas predictive approaches only require one pass. As diffusion models are\ngenerative approaches they may also produce vocalizing and breathing artifacts\nin adverse conditions. In comparison, in such difficult scenarios, predictive\nmodels typically do not produce such artifacts but tend to distort the target\nspeech instead, thereby degrading the speech quality. In this work, we present\na stochastic regeneration approach where an estimate given by a predictive\nmodel is provided as a guide for further diffusion. We show that the proposed\napproach uses the predictive model to remove the vocalizing and breathing\nartifacts while producing very high quality samples thanks to the diffusion\nmodel, even in adverse conditions. We further show that this approach enables\nto use lighter sampling schemes with fewer diffusion steps without sacrificing\nquality, thus lifting the computational burden by an order of magnitude. Source\ncode and audio examples are available online (https://uhh.de/inf-sp-storm).\n","authors":["Jean-Marie Lemercier","Julius Richter","Simon Welker","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2212.11851v1.pdf","comment":"This work has been submitted to the IEEE for publication. Copyright\n  may be transferred without notice"},{"id":"http://arxiv.org/abs/2212.11844v1","updated":"2022-12-22T16:25:58Z","published":"2022-12-22T16:25:58Z","title":"Fully 3D Implementation of the End-to-end Deep Image Prior-based PET\n  Image Reconstruction Using Block Iterative Algorithm","summary":"  Deep image prior (DIP) has recently attracted attention owing to its\nunsupervised positron emission tomography (PET) image reconstruction, which\ndoes not require any prior training dataset. In this paper, we present the\nfirst attempt to implement an end-to-end DIP-based fully 3D PET image\nreconstruction method that incorporates a forward-projection model into a loss\nfunction. To implement a practical fully 3D PET image reconstruction, which\ncould not be performed due to a graphics processing unit memory limitation, we\nmodify the DIP optimization to block-iteration and sequentially learn an\nordered sequence of block sinograms. Furthermore, the relative difference\npenalty (RDP) term was added to the loss function to enhance the quantitative\nPET image accuracy. We evaluated our proposed method using Monte Carlo\nsimulation with [$^{18}$F]FDG PET data of a human brain and a preclinical study\non monkey brain [$^{18}$F]FDG PET data. The proposed method was compared with\nthe maximum-likelihood expectation maximization (EM), maximum-a-posterior EM\nwith RDP, and hybrid DIP-based PET reconstruction methods. The simulation\nresults showed that the proposed method improved the PET image quality by\nreducing statistical noise and preserved a contrast of brain structures and\ninserted tumor compared with other algorithms. In the preclinical experiment,\nfiner structures and better contrast recovery were obtained by the proposed\nmethod. This indicated that the proposed method can produce high-quality images\nwithout a prior training dataset. Thus, the proposed method is a key enabling\ntechnology for the straightforward and practical implementation of end-to-end\nDIP-based fully 3D PET image reconstruction.\n","authors":["Fumio Hashimoto","Yuya Onishi","Kibo Ote","Hideaki Tashima","Taiga Yamaya"],"pdf_url":"https://arxiv.org/pdf/2212.11844v1.pdf","comment":"9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.04288v2","updated":"2022-12-22T16:13:33Z","published":"2022-12-08T14:30:59Z","title":"Secure Over-the-Air Computation using Zero-Forced Artificial Noise","summary":"  Over-the-air computation has the potential to increase the\ncommunication-efficiency of data-dependent distributed wireless systems, but is\nvulnerable to eavesdropping. We consider over-the-air computation over\nblock-fading additive white Gaussian noise channels in the presence of a\npassive eavesdropper. The goal is to design a secure over-the-air computation\nscheme. We propose a scheme that achieves MSE-security against the eavesdropper\nby employing zero-forced artificial noise, while keeping the distortion at the\nlegitimate receiver small. In contrast to former approaches, the security does\nnot depend on external helper nodes to jam the eavesdropper's received signal.\nWe thoroughly design the system parameters of the scheme, propose an artificial\nnoise design that harnesses unused transmit power for security, and give an\nexplicit construction rule. Our design approach is applicable in both cases, if\nthe eavesdropper's channel coefficients are known and if they are unknown in\nthe signal design. Simulations demonstrate the performance, and show that our\nnoise design outperforms other methods.\n","authors":["Luis Maßny","Antonia Wachter-Zeh"],"pdf_url":"https://arxiv.org/pdf/2212.04288v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11826v1","updated":"2022-12-22T16:06:24Z","published":"2022-12-22T16:06:24Z","title":"The Quantum Path Kernel: a Generalized Quantum Neural Tangent Kernel for\n  Deep Quantum Machine Learning","summary":"  Building a quantum analog of classical deep neural networks represents a\nfundamental challenge in quantum computing. A key issue is how to address the\ninherent non-linearity of classical deep learning, a problem in the quantum\ndomain due to the fact that the composition of an arbitrary number of quantum\ngates, consisting of a series of sequential unitary transformations, is\nintrinsically linear. This problem has been variously approached in the\nliterature, principally via the introduction of measurements between layers of\nunitary transformations. In this paper, we introduce the Quantum Path Kernel, a\nformulation of quantum machine learning capable of replicating those aspects of\ndeep machine learning typically associated with superior generalization\nperformance in the classical domain, specifically, hierarchical feature\nlearning. Our approach generalizes the notion of Quantum Neural Tangent Kernel,\nwhich has been used to study the dynamics of classical and quantum machine\nlearning models. The Quantum Path Kernel exploits the parameter trajectory,\ni.e. the curve delineated by model parameters as they evolve during training,\nenabling the representation of differential layer-wise convergence behaviors,\nor the formation of hierarchical parametric dependencies, in terms of their\nmanifestation in the gradient space of the predictor function. We evaluate our\napproach with respect to variants of the classification of Gaussian XOR\nmixtures - an artificial but emblematic problem that intrinsically requires\nmultilevel learning in order to achieve optimal class separation.\n","authors":["Massimiliano Incudini","Michele Grossi","Antonio Mandarino","Sofia Vallecorsa","Alessandra Di Pierro","David Windridge"],"pdf_url":"https://arxiv.org/pdf/2212.11826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11811v1","updated":"2022-12-22T15:41:13Z","published":"2022-12-22T15:41:13Z","title":"Renormalization in the neural network-quantum field theory\n  correspondence","summary":"  A statistical ensemble of neural networks can be described in terms of a\nquantum field theory (NN-QFT correspondence). The infinite-width limit is\nmapped to a free field theory, while finite N corrections are mapped to\ninteractions. After reviewing the correspondence, we will describe how to\nimplement renormalization in this context and discuss preliminary numerical\nresults for translation-invariant kernels. A major outcome is that changing the\nstandard deviation of the neural network weight distribution corresponds to a\nrenormalization flow in the space of networks.\n","authors":["Harold Erbin","Vincent Lahoche","Dine Ousmane Samary"],"pdf_url":"https://arxiv.org/pdf/2212.11811v1.pdf","comment":"A shorter version of this paper has been accepted in the NeurIPS 2022\n  workshop: Machine learning and the physical sciences\n  (https://ml4physicalsciences.github.io/2022/)"},{"id":"http://arxiv.org/abs/2212.11810v1","updated":"2022-12-22T15:40:53Z","published":"2022-12-22T15:40:53Z","title":"GAN-based Domain Inference Attack","summary":"  Model-based attacks can infer training data information from deep neural\nnetwork models. These attacks heavily depend on the attacker's knowledge of the\napplication domain, e.g., using it to determine the auxiliary data for\nmodel-inversion attacks. However, attackers may not know what the model is used\nfor in practice. We propose a generative adversarial network (GAN) based method\nto explore likely or similar domains of a target model -- the model domain\ninference (MDI) attack. For a given target (classification) model, we assume\nthat the attacker knows nothing but the input and output formats and can use\nthe model to derive the prediction for any input in the desired form. Our basic\nidea is to use the target model to affect a GAN training process for a\ncandidate domain's dataset that is easy to obtain. We find that the target\nmodel may distract the training procedure less if the domain is more similar to\nthe target domain. We then measure the distraction level with the distance\nbetween GAN-generated datasets, which can be used to rank candidate domains for\nthe target model. Our experiments show that the auxiliary dataset from an MDI\ntop-ranked domain can effectively boost the result of model-inversion attacks.\n","authors":["Yuechun Gu","Keke Chen"],"pdf_url":"https://arxiv.org/pdf/2212.11810v1.pdf","comment":"accepted by AAAI23"},{"id":"http://arxiv.org/abs/2203.06271v4","updated":"2022-12-22T15:36:56Z","published":"2022-03-11T22:43:37Z","title":"Bit-Metric Decoding Rate in Multi-User MIMO Systems: Theory","summary":"  Link-adaptation (LA) is one of the most important aspects of wireless\ncommunications where the modulation and coding scheme (MCS) used by the\ntransmitter is adapted to the channel conditions in order to meet a certain\ntarget error-rate. In a single-user SISO (SU-SISO) system with out-of-cell\ninterference, LA is performed by computing the post-equalization\nsignal-to-interference-noise ratio (SINR) at the receiver. The same technique\ncan be employed in multi-user MIMO (MU-MIMO) receivers that use linear\ndetectors. Another important use of post-equalization SINR is for physical\nlayer (PHY) abstraction, where several PHY blocks like the channel encoder, the\ndetector, and the channel decoder are replaced by an abstraction model in order\nto speed up system-level simulations. However, for MU-MIMO systems with\nnon-linear receivers, there is no known equivalent of post-equalization SINR\nwhich makes both LA and PHY abstraction extremely challenging. This important\nissue is addressed in this two-part paper. In this part, a metric called the\nbit-metric decoding rate (BMDR) of a detector, which is the proposed equivalent\nof post-equalization SINR, is presented. Since BMDR does not have a closed form\nexpression that would enable its instantaneous calculation, a machine-learning\napproach to predict it is presented along with extensive simulation results.\n","authors":["K. Pavan Srinath","Jakob Hoydis"],"pdf_url":"https://arxiv.org/pdf/2203.06271v4.pdf","comment":"This is the first part of a two-part paper and has 30 pages and 6\n  figures. The second part is titled \"Bit-Metric Decoding Rate in Multi-User\n  MIMO Systems: Applications\". This part has been significantly revised. In\n  particular, we relate BMDR to the mismatched decoding framework that exists\n  in the literature, and have rewritten the claims and proof of the main\n  theorem"},{"id":"http://arxiv.org/abs/2212.11805v1","updated":"2022-12-22T15:36:15Z","published":"2022-12-22T15:36:15Z","title":"Device Selection for the Coexistence of URLLC and Distributed Learning\n  Services","summary":"  Recent advances in distributed artificial intelligence (AI) have led to\ntremendous breakthroughs in various communication services, from fault-tolerant\nfactory automation to smart cities. When distributed learning is run over a set\nof wirelessly connected devices, random channel fluctuations and the incumbent\nservices running on the same network impact the performance of both distributed\nlearning and the coexisting service. In this paper, we investigate a mixed\nservice scenario where distributed AI workflow and ultra-reliable low latency\ncommunication (URLLC) services run concurrently over a network. Consequently,\nwe propose a risk sensitivity-based formulation for device selection to\nminimize the AI training delays during its convergence period while ensuring\nthat the operational requirements of the URLLC service are met. To address this\nchallenging coexistence problem, we transform it into a deep reinforcement\nlearning problem and address it via a framework based on soft actor-critic\nalgorithm. We evaluate our solution with a realistic and 3GPP-compliant\nsimulator for factory automation use cases. Our simulation results confirm that\nour solution can significantly decrease the training delay of the distributed\nAI service while keeping the URLLC availability above its required threshold\nand close to the scenario where URLLC solely consumes all network resources.\n","authors":["Milad Ganjalizadeh","Hossein Shokri Ghadikolaei","Deniz Gündüz","Marina Petrova"],"pdf_url":"https://arxiv.org/pdf/2212.11805v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2212.11803v1","updated":"2022-12-22T15:35:42Z","published":"2022-12-22T15:35:42Z","title":"EuclidNets: An Alternative Operation for Efficient Inference of Deep\n  Learning Models","summary":"  With the advent of deep learning application on edge devices, researchers\nactively try to optimize their deployments on low-power and restricted memory\ndevices. There are established compression method such as quantization,\npruning, and architecture search that leverage commodity hardware. Apart from\nconventional compression algorithms, one may redesign the operations of deep\nlearning models that lead to more efficient implementation. To this end, we\npropose EuclidNet, a compression method, designed to be implemented on hardware\nwhich replaces multiplication, $xw$, with Euclidean distance $(x-w)^2$. We show\nthat EuclidNet is aligned with matrix multiplication and it can be used as a\nmeasure of similarity in case of convolutional layers. Furthermore, we show\nthat under various transformations and noise scenarios, EuclidNet exhibits the\nsame performance compared to the deep learning models designed with\nmultiplication operations.\n","authors":["Xinlin Li","Mariana Parazeres","Adam Oberman","Alireza Ghaffari","Masoud Asgharian","Vahid Partovi Nia"],"pdf_url":"https://arxiv.org/pdf/2212.11803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.00600v2","updated":"2022-12-22T15:27:52Z","published":"2021-12-01T16:14:49Z","title":"Towards Futuristic Autonomous Experimentation--A Surprise-Reacting\n  Sequential Experiment Policy","summary":"  An autonomous experimentation platform in manufacturing is supposedly capable\nof conducting a sequential search for finding suitable manufacturing conditions\nfor advanced materials by itself or even for discovering new materials with\nminimal human intervention. The core of the intelligent control of such\nplatforms is the policy directing sequential experiments, namely, to decide\nwhere to conduct the next experiment based on what has been done thus far. Such\npolicy inevitably trades off exploitation versus exploration and the current\npractice is under the Bayesian optimization framework using the expected\nimprovement criterion or its variants. We discuss whether it is beneficial to\ntrade off exploitation versus exploration by measuring the element and degree\nof surprise associated with the immediate past observation. We devise a\nsurprise-reacting policy using two existing surprise metrics, known as the\nShannon surprise and Bayesian surprise. Our analysis shows that the\nsurprise-reacting policy appears to be better suited for quickly characterizing\nthe overall landscape of a response surface or a design place under resource\nconstraints. We argue that such capability is much needed for futuristic\nautonomous experimentation platforms. We do not claim that we have a fully\nautonomous experimentation platform, but believe that our current effort sheds\nnew lights or provides a different view angle as researchers are racing to\nelevate the autonomy of various primitive autonomous experimentation systems.\n","authors":["Imtiaz Ahmed","Satish Bukkapatnam","Bhaskar Botcha","Yu Ding"],"pdf_url":"https://arxiv.org/pdf/2112.00600v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11791v1","updated":"2022-12-22T15:22:36Z","published":"2022-12-22T15:22:36Z","title":"Training Integer-Only Deep Recurrent Neural Networks","summary":"  Recurrent neural networks (RNN) are the backbone of many text and speech\napplications. These architectures are typically made up of several\ncomputationally complex components such as; non-linear activation functions,\nnormalization, bi-directional dependence and attention. In order to maintain\ngood accuracy, these components are frequently run using full-precision\nfloating-point computation, making them slow, inefficient and difficult to\ndeploy on edge devices. In addition, the complex nature of these operations\nmakes them challenging to quantize using standard quantization methods without\na significant performance drop. We present a quantization-aware training method\nfor obtaining a highly accurate integer-only recurrent neural network (iRNN).\nOur approach supports layer normalization, attention, and an adaptive piecewise\nlinear (PWL) approximation of activation functions, to serve a wide range of\nstate-of-the-art RNNs. The proposed method enables RNN-based language models to\nrun on edge devices with $2\\times$ improvement in runtime, and $4\\times$\nreduction in model size while maintaining similar accuracy as its\nfull-precision counterpart.\n","authors":["Vahid Partovi Nia","Eyyüb Sari","Vanessa Courville","Masoud Asgharian"],"pdf_url":"https://arxiv.org/pdf/2212.11791v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2109.09828"},{"id":"http://arxiv.org/abs/2212.11778v1","updated":"2022-12-22T15:13:03Z","published":"2022-12-22T15:13:03Z","title":"Adversarial Machine Learning and Defense Game for NextG Signal\n  Classification with Deep Learning","summary":"  This paper presents a game-theoretic framework to study the interactions of\nattack and defense for deep learning-based NextG signal classification. NextG\nsystems such as the one envisioned for a massive number of IoT devices can\nemploy deep neural networks (DNNs) for various tasks such as user equipment\nidentification, physical layer authentication, and detection of incumbent users\n(such as in the Citizens Broadband Radio Service (CBRS) band). By training\nanother DNN as the surrogate model, an adversary can launch an inference\n(exploratory) attack to learn the behavior of the victim model, predict\nsuccessful operation modes (e.g., channel access), and jam them. A defense\nmechanism can increase the adversary's uncertainty by introducing controlled\nerrors in the victim model's decisions (i.e., poisoning the adversary's\ntraining data). This defense is effective against an attack but reduces the\nperformance when there is no attack. The interactions between the defender and\nthe adversary are formulated as a non-cooperative game, where the defender\nselects the probability of defending or the defense level itself (i.e., the\nratio of falsified decisions) and the adversary selects the probability of\nattacking. The defender's objective is to maximize its reward (e.g., throughput\nor transmission success ratio), whereas the adversary's objective is to\nminimize this reward and its attack cost. The Nash equilibrium strategies are\ndetermined as operation modes such that no player can unilaterally improve its\nutility given the other's strategy is fixed. A fictitious play is formulated\nfor each player to play the game repeatedly in response to the empirical\nfrequency of the opponent's actions. The performance in Nash equilibrium is\ncompared to the fixed attack and defense cases, and the resilience of NextG\nsignal classification against attacks is quantified.\n","authors":["Yalin E. Sagduyu"],"pdf_url":"https://arxiv.org/pdf/2212.11778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11776v1","updated":"2022-12-22T15:12:29Z","published":"2022-12-22T15:12:29Z","title":"Fixed-budget online adaptive mesh learning for physics-informed neural\n  networks. Towards parameterized problem inference","summary":"  Physics-Informed Neural Networks (PINNs) have gained much attention in\nvarious fields of engineering thanks to their capability of incorporating\nphysical laws into the models. PINNs integrate the physical constraints by\nminimizing the partial differential equations (PDEs) residuals on a set of\ncollocation points. The distribution of these collocation points appears to\nhave a huge impact on the performance of PINNs and the assessment of the\nsampling methods for these points is still an active topic. In this paper, we\npropose a Fixed-Budget Online Adaptive Mesh Learning (FBOAML) method, which\ndecomposes the domain into sub-domains, for training collocation points based\non local maxima and local minima of the PDEs residuals. The stopping criterion\nis based on a data set of reference, which leads to an adaptive number of\niterations for each specific problem. The effectiveness of FBOAML is\ndemonstrated in the context of non-parameterized and parameterized problems.\nThe impact of the hyper-parameters in FBOAML is investigated in this work. The\ncomparison with other adaptive sampling methods is also illustrated. The\nnumerical results demonstrate important gains in terms of accuracy of PINNs\nwith FBOAML over the classical PINNs with non-adaptive collocation points. We\nalso apply FBOAML in a complex industrial application involving coupling\nbetween mechanical and thermal fields. We show that FBOAML is able to identify\nthe high-gradient location and even give better prediction for some physical\nfields than the classical PINNs with collocation points taken on a pre-adapted\nfinite element mesh.\n","authors":["Thi Nguyen Khoa Nguyen","Thibault Dairay","Raphaël Meunier","Christophe Millet","Mathilde Mougeot"],"pdf_url":"https://arxiv.org/pdf/2212.11776v1.pdf","comment":"15 pages, 16 figures, 2 tables"},{"id":"http://arxiv.org/abs/2206.08748v2","updated":"2022-12-22T15:09:19Z","published":"2022-06-13T19:20:11Z","title":"ReViSe: Remote Vital Signs Measurement Using Smartphone Camera","summary":"  We propose an end-to-end framework to measure people's vital signs including\nHeart Rate (HR), Heart Rate Variability (HRV), Oxygen Saturation (SpO2) and\nBlood Pressure (BP) based on the rPPG methodology from the video of a user's\nface captured with a smartphone camera. We extract face landmarks with a deep\nlearning-based neural network model in real-time. Multiple face patches also\ncalled Regions-of-Interest (RoIs) are extracted by using the predicted face\nlandmarks. Several filters are applied to reduce the noise from the RoIs in the\nextracted cardiac signals called Blood Volume Pulse (BVP) signal. The\nmeasurements of HR, HRV and SpO2 are validated on two public rPPG datasets\nnamely the TokyoTech rPPG and the Pulse Rate Detection (PURE) datasets, on\nwhich our models achieved the following Mean Absolute Errors (MAE): a) for HR,\n1.73Beats-Per-Minute (bpm) and 3.95bpm respectively; b) for HRV, 18.55ms and\n25.03ms respectively, and c) for SpO2, an MAE of 1.64% on the PURE dataset. We\nvalidated our end-to-end rPPG framework, ReViSe, in daily living environment,\nand thereby created the Video-HR dataset. Our HR estimation model achieved an\nMAE of 2.49bpm on this dataset. Since no publicly available rPPG datasets\nexisted for BP measurement with face videos, we used a dataset with signals\nfrom fingertip sensor to train our deep learning-based BP estimation model and\nalso created our own video dataset, Video-BP. On our Video-BP dataset, our BP\nestimation model achieved an MAE of 6.7mmHg for Systolic Blood Pressure (SBP),\nand an MAE of 9.6mmHg for Diastolic Blood Pressure (DBP). ReViSe framework has\nbeen validated on datasets with videos recorded in daily living environment as\nopposed to less noisy laboratory environment as reported by most\nstate-of-the-art techniques.\n","authors":["Donghao Qiao","Amtul Haq Ayesha","Farhana Zulkernine","Raihan Masroor","Nauman Jaffar"],"pdf_url":"https://arxiv.org/pdf/2206.08748v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11771v1","updated":"2022-12-22T15:06:24Z","published":"2022-12-22T15:06:24Z","title":"Few-shot human motion prediction for heterogeneous sensors","summary":"  Human motion prediction is a complex task as it involves forecasting\nvariables over time on a graph of connected sensors. This is especially true in\nthe case of few-shot learning, where we strive to forecast motion sequences for\npreviously unseen actions based on only a few examples. Despite this, almost\nall related approaches for few-shot motion prediction do not incorporate the\nunderlying graph, while it is a common component in classical motion\nprediction. Furthermore, state-of-the-art methods for few-shot motion\nprediction are restricted to motion tasks with a fixed output space meaning\nthese tasks are all limited to the same sensor graph. In this work, we propose\nto extend recent works on few-shot time-series forecasting with heterogeneous\nattributes with graph neural networks to introduce the first few-shot motion\napproach that explicitly incorporates the spatial graph while also generalizing\nacross motion tasks with heterogeneous sensors. In our experiments on motion\ntasks with heterogeneous sensors, we demonstrate significant performance\nimprovements with lifts from 10.4% up to 39.3% compared to best\nstate-of-the-art models. Moreover, we show that our model can perform on par\nwith the best approach so far when evaluating on tasks with a fixed output\nspace while maintaining two magnitudes fewer parameters.\n","authors":["Rafael Rego Drumond","Lukas Brinkmeyer","Lars Schmidt-Thieme"],"pdf_url":"https://arxiv.org/pdf/2212.11771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11751v1","updated":"2022-12-22T14:43:48Z","published":"2022-12-22T14:43:48Z","title":"Mind Your Heart: Stealthy Backdoor Attack on Dynamic Deep Neural Network\n  in Edge Computing","summary":"  Transforming off-the-shelf deep neural network (DNN) models into dynamic\nmulti-exit architectures can achieve inference and transmission efficiency by\nfragmenting and distributing a large DNN model in edge computing scenarios\n(e.g., edge devices and cloud servers). In this paper, we propose a novel\nbackdoor attack specifically on the dynamic multi-exit DNN models.\nParticularly, we inject a backdoor by poisoning one DNN model's shallow hidden\nlayers targeting not this vanilla DNN model but only its dynamically deployed\nmulti-exit architectures. Our backdoored vanilla model behaves normally on\nperformance and cannot be activated even with the correct trigger. However, the\nbackdoor will be activated when the victims acquire this model and transform it\ninto a dynamic multi-exit architecture at their deployment. We conduct\nextensive experiments to prove the effectiveness of our attack on three\nstructures (ResNet-56, VGG-16, and MobileNet) with four datasets (CIFAR-10,\nSVHN, GTSRB, and Tiny-ImageNet) and our backdoor is stealthy to evade multiple\nstate-of-the-art backdoor detection or removal methods.\n","authors":["Tian Dong","Ziyuan Zhang","Han Qiu","Tianwei Zhang","Hewu Li","Terry Wang"],"pdf_url":"https://arxiv.org/pdf/2212.11751v1.pdf","comment":"Accepted to IEEE INFOCOM 2023"},{"id":"http://arxiv.org/abs/2212.11746v1","updated":"2022-12-22T14:36:27Z","published":"2022-12-22T14:36:27Z","title":"Certified Policy Smoothing for Cooperative Multi-Agent Reinforcement\n  Learning","summary":"  Cooperative multi-agent reinforcement learning (c-MARL) is widely applied in\nsafety-critical scenarios, thus the analysis of robustness for c-MARL models is\nprofoundly important. However, robustness certification for c-MARLs has not yet\nbeen explored in the community. In this paper, we propose a novel certification\nmethod, which is the first work to leverage a scalable approach for c-MARLs to\ndetermine actions with guaranteed certified bounds. c-MARL certification poses\ntwo key challenges compared with single-agent systems: (i) the accumulated\nuncertainty as the number of agents increases; (ii) the potential lack of\nimpact when changing the action of a single agent into a global team reward.\nThese challenges prevent us from directly using existing algorithms. Hence, we\nemploy the false discovery rate (FDR) controlling procedure considering the\nimportance of each agent to certify per-state robustness and propose a\ntree-search-based algorithm to find a lower bound of the global reward under\nthe minimal certified perturbation. As our method is general, it can also be\napplied in single-agent environments. We empirically show that our\ncertification bounds are much tighter than state-of-the-art RL certification\nsolutions. We also run experiments on two popular c-MARL algorithms: QMIX and\nVDN, in two different environments, with two and four agents. The experimental\nresults show that our method produces meaningful guaranteed robustness for all\nmodels and environments. Our tool CertifyCMARL is available at\nhttps://github.com/TrustAI/CertifyCMA\n","authors":["Ronghui Mu","Wenjie Ruan","Leandro Soriano Marcolino","Gaojie Jin","Qiang Ni"],"pdf_url":"https://arxiv.org/pdf/2212.11746v1.pdf","comment":"This paper will appear in AAAI2023"},{"id":"http://arxiv.org/abs/2212.11737v1","updated":"2022-12-22T14:29:43Z","published":"2022-12-22T14:29:43Z","title":"The State of the Art in Enhancing Trust in Machine Learning Models with\n  the Use of Visualizations","summary":"  Machine learning (ML) models are nowadays used in complex applications in\nvarious domains, such as medicine, bioinformatics, and other sciences. Due to\ntheir black box nature, however, it may sometimes be hard to understand and\ntrust the results they provide. This has increased the demand for reliable\nvisualization tools related to enhancing trust in ML models, which has become a\nprominent topic of research in the visualization community over the past\ndecades. To provide an overview and present the frontiers of current research\non the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in\nML models with the use of interactive visualization. We define and describe the\nbackground of the topic, introduce a categorization for visualization\ntechniques that aim to accomplish this goal, and discuss insights and\nopportunities for future research directions. Among our contributions is a\ncategorization of trust against different facets of interactive ML, expanded\nand improved from previous research. Our results are investigated from\ndifferent analytical perspectives: (a) providing a statistical overview, (b)\nsummarizing key findings, (c) performing topic analyses, and (d) exploring the\ndata sets used in the individual papers, all with the support of an interactive\nweb-based survey browser. We intend this survey to be beneficial for\nvisualization researchers whose interests involve making ML models more\ntrustworthy, as well as researchers and practitioners from other disciplines in\ntheir search for effective visualization techniques suitable for solving their\ntasks with confidence and conveying meaning to their data.\n","authors":["A. Chatzimparmpas","R. Martins","I. Jusufi","K. Kucher","Fabrice Rossi","A. Kerren"],"pdf_url":"https://arxiv.org/pdf/2212.11737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11730v1","updated":"2022-12-22T14:26:11Z","published":"2022-12-22T14:26:11Z","title":"TransPath: Learning Heuristics For Grid-Based Pathfinding via\n  Transformers","summary":"  Heuristic search algorithms, e.g. A*, are the commonly used tools for\npathfinding on grids, i.e. graphs of regular structure that are widely employed\nto represent environments in robotics, video games etc. Instance-independent\nheuristics for grid graphs, e.g. Manhattan distance, do not take the obstacles\ninto account and, thus, the search led by such heuristics performs poorly in\nthe obstacle-rich environments. To this end, we suggest learning the\ninstance-dependent heuristic proxies that are supposed to notably increase the\nefficiency of the search. The first heuristic proxy we suggest to learn is the\ncorrection factor, i.e. the ratio between the instance independent cost-to-go\nestimate and the perfect one (computed offline at the training phase). Unlike\nlearning the absolute values of the cost-to-go heuristic function, which was\nknown before, when learning the correction factor the knowledge of the\ninstance-independent heuristic is utilized. The second heuristic proxy is the\npath probability, which indicates how likely the grid cell is lying on the\nshortest path. This heuristic can be utilized in the Focal Search framework as\nthe secondary heuristic, allowing us to preserve the guarantees on the bounded\nsub-optimality of the solution. We learn both suggested heuristics in a\nsupervised fashion with the state-of-the-art neural networks containing\nattention blocks (transformers). We conduct a thorough empirical evaluation on\na comprehensive dataset of planning tasks, showing that the suggested\ntechniques i) reduce the computational effort of the A* up to a factor of $4$x\nwhile producing the solutions, which costs exceed the costs of the optimal\nsolutions by less than $0.3$% on average; ii) outperform the competitors, which\ninclude the conventional techniques from the heuristic search, i.e. weighted\nA*, as well as the state-of-the-art learnable planners.\n","authors":["Daniil Kirilenko","Anton Andreychuk","Aleksandr Panov","Konstantin Yakovlev"],"pdf_url":"https://arxiv.org/pdf/2212.11730v1.pdf","comment":"Pre-print of the paper accepted to AAAI'23"},{"id":"http://arxiv.org/abs/2212.11729v1","updated":"2022-12-22T14:25:44Z","published":"2022-12-22T14:25:44Z","title":"Federated Learning -- Methods, Applications and beyond","summary":"  In recent years the applications of machine learning models have increased\nrapidly, due to the large amount of available data and technological\nprogress.While some domains like web analysis can benefit from this with only\nminor restrictions, other fields like in medicine with patient data are\nstrongerregulated. In particular \\emph{data privacy} plays an important role as\nrecently highlighted by the trustworthy AI initiative of the EU or general\nprivacy regulations in legislation. Another major challenge is, that the\nrequired training \\emph{data is} often \\emph{distributed} in terms of features\nor samples and unavailable for classicalbatch learning approaches. In 2016\nGoogle came up with a framework, called \\emph{Federated Learning} to solve both\nof these problems. We provide a brief overview on existing Methods and\nApplications in the field of vertical and horizontal \\emph{Federated Learning},\nas well as \\emph{Fderated Transfer Learning}.\n","authors":["Moritz Heusinger","Christoph Raab","Fabrice Rossi","Frank-Michael Schleif"],"pdf_url":"https://arxiv.org/pdf/2212.11729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11728v1","updated":"2022-12-22T14:23:50Z","published":"2022-12-22T14:23:50Z","title":"Co-clustering based exploratory analysis of mixed-type data tables","summary":"  Co-clustering is a class of unsupervised data analysis techniques that\nextract the existing underlying dependency structure between the instances and\nvariables of a data table as homogeneous blocks. Most of those techniques are\nlimited to variables of the same type. In this paper, we propose a mixed data\nco-clustering method based on a two-step methodology. In the first step, all\nthe variables are binarized according to a number of bins chosen by the\nanalyst, by equal frequency discretization in the numerical case, or keeping\nthe most frequent values in the categorical case. The second step applies a\nco-clustering to the instances and the binary variables, leading to groups of\ninstances and groups of variable parts. We apply this methodology on several\ndata sets and compare with the results of a Multiple Correspondence Analysis\napplied to the same data.\n","authors":["Aichetou Bouchareb","Marc Boullé","Fabrice Clérot","Fabrice Rossi"],"pdf_url":"https://arxiv.org/pdf/2212.11728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11726v1","updated":"2022-12-22T14:19:35Z","published":"2022-12-22T14:19:35Z","title":"Reusable Options through Gradient-based Meta Learning","summary":"  Hierarchical methods in reinforcement learning have the potential to reduce\nthe amount of decisions that the agent needs to perform when learning new\ntasks. However, finding a reusable useful temporal abstractions that facilitate\nfast learning remains a challenging problem. Recently, several deep learning\napproaches were proposed to learn such temporal abstractions in the form of\noptions in an end-to-end manner. In this work, we point out several\nshortcomings of these methods and discuss their potential negative\nconsequences. Subsequently, we formulate the desiderata for reusable options\nand use these to frame the problem of learning options as a gradient-based\nmeta-learning problem. This allows us to formulate an objective that explicitly\nincentivizes options which allow a higher-level decision maker to adjust in few\nsteps to different tasks. Experimentally, we show that our method is able to\nlearn transferable components which accelerate learning and performs better\nthan existing prior methods developed for this setting. Additionally, we\nperform ablations to quantify the impact of using gradient-based meta-learning\nas well as other proposed changes.\n","authors":["David Kuric","Herke van Hoof"],"pdf_url":"https://arxiv.org/pdf/2212.11726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11725v1","updated":"2022-12-22T14:16:08Z","published":"2022-12-22T14:16:08Z","title":"Model Based Co-clustering of Mixed Numerical and Binary Data","summary":"  Co-clustering is a data mining technique used to extract the underlying block\nstructure between the rows and columns of a data matrix. Many approaches have\nbeen studied and have shown their capacity to extract such structures in\ncontinuous, binary or contingency tables. However, very little work has been\ndone to perform co-clustering on mixed type data. In this article, we extend\nthe latent block models based co-clustering to the case of mixed data\n(continuous and binary variables). We then evaluate the effectiveness of the\nproposed approach on simulated data and we discuss its advantages and potential\nlimits.\n","authors":["Aichetou Bouchareb","Marc Boullé","Fabrice Clérot","Fabrice Rossi"],"pdf_url":"https://arxiv.org/pdf/2212.11725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11720v1","updated":"2022-12-22T14:13:33Z","published":"2022-12-22T14:13:33Z","title":"GOOD: Exploring Geometric Cues for Detecting Objects in an Open World","summary":"  We address the task of open-world class-agnostic object detection, i.e.,\ndetecting every object in an image by learning from a limited number of base\nobject classes. State-of-the-art RGB-based models suffer from overfitting the\ntraining classes and often fail at detecting novel-looking objects. This is\nbecause RGB-based models primarily rely on appearance similarity to detect\nnovel objects and are also prone to overfitting short-cut cues such as textures\nand discriminative parts. To address these shortcomings of RGB-based object\ndetectors, we propose incorporating geometric cues such as depth and normals,\npredicted by general-purpose monocular estimators. Specifically, we use the\ngeometric cues to train an object proposal network for pseudo-labeling\nunannotated novel objects in the training set. Our resulting Geometry-guided\nOpen-world Object Detector (GOOD) significantly improves detection recall for\nnovel object categories and already performs well with only a few training\nclasses. Using a single \"person\" class for training on the COCO dataset, GOOD\nsurpasses SOTA methods by 5.0% AR@100, a relative improvement of 24%.\n","authors":["Haiwen Huang","Andreas Geiger","Dan Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11720v1.pdf","comment":"Under review as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2212.11709v1","updated":"2022-12-22T13:52:53Z","published":"2022-12-22T13:52:53Z","title":"Reinforcement Learning Based Approaches to Adaptive Context Caching in\n  Distributed Context Management Systems","summary":"  Performance metrics-driven context caching has a profound impact on\nthroughput and response time in distributed context management systems for\nreal-time context queries. This paper proposes a reinforcement learning based\napproach to adaptively cache context with the objective of minimizing the cost\nincurred by context management systems in responding to context queries. Our\nnovel algorithms enable context queries and sub-queries to reuse and repurpose\ncached context in an efficient manner. This approach is distinctive to\ntraditional data caching approaches by three main features. First, we make\nselective context cache admissions using no prior knowledge of the context, or\nthe context query load. Secondly, we develop and incorporate innovative\nheuristic models to calculate expected performance of caching an item when\nmaking the decisions. Thirdly, our strategy defines a time-aware continuous\ncache action space. We present two reinforcement learning agents, a value\nfunction estimating actor-critic agent and a policy search agent using deep\ndeterministic policy gradient method. The paper also proposes adaptive policies\nsuch as eviction and cache memory scaling to complement our objective. Our\nmethod is evaluated using a synthetically generated load of context sub-queries\nand a synthetic data set inspired from real world data and query samples. We\nfurther investigate optimal adaptive caching configurations under different\nsettings. This paper presents, compares, and discusses our findings that the\nproposed selective caching methods reach short- and long-term cost- and\nperformance-efficiency. The paper demonstrates that the proposed methods\noutperform other modes of context management such as redirector mode, and\ndatabase mode, and cache all policy by up to 60% in cost efficiency.\n","authors":["Shakthi Weerasinghe","Arkady Zaslavsky","Seng W. Loke","Amin Abken","Alireza Hassani"],"pdf_url":"https://arxiv.org/pdf/2212.11709v1.pdf","comment":"This is a pre-print version of the journal paper submitted to ACM\n  Transactions in Internet of Things, which is currently under review"},{"id":"http://arxiv.org/abs/2212.04322v2","updated":"2022-12-22T13:52:36Z","published":"2022-12-05T11:04:08Z","title":"Encrypted machine learning of molecular quantum properties","summary":"  Large machine learning models with improved predictions have become widely\navailable in the chemical sciences. Unfortunately, these models do not protect\nthe privacy necessary within commercial settings, prohibiting the use of\npotentially extremely valuable data by others. Encrypting the prediction\nprocess can solve this problem by double-blind model evaluation and prohibits\nthe extraction of training or query data. However, contemporary ML models based\non fully homomorphic encryption or federated learning are either too expensive\nfor practical use or have to trade higher speed for weaker security. We have\nimplemented secure and computationally feasible encrypted machine learning\nmodels using oblivious transfer enabling and secure predictions of molecular\nquantum properties across chemical compound space. However, we find that\nencrypted predictions using kernel ridge regression models are a million times\nmore expensive than without encryption. This demonstrates a dire need for a\ncompact machine learning model architecture, including molecular representation\nand kernel matrix size, that minimizes model evaluation costs.\n","authors":["Jan Weinreich","Guido Falk von Rudorff","O. Anatole von Lilienfeld"],"pdf_url":"https://arxiv.org/pdf/2212.04322v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11702v1","updated":"2022-12-22T13:46:47Z","published":"2022-12-22T13:46:47Z","title":"Robust Meta-Representation Learning via Global Label Inference and\n  Classification","summary":"  Few-shot learning (FSL) is a central problem in meta-learning, where learners\nmust efficiently learn from few labeled examples. Within FSL, feature\npre-training has recently become an increasingly popular strategy to\nsignificantly improve generalization performance. However, the contribution of\npre-training is often overlooked and understudied, with limited theoretical\nunderstanding of its impact on meta-learning performance. Further, pre-training\nrequires a consistent set of global labels shared across training tasks, which\nmay be unavailable in practice. In this work, we address the above issues by\nfirst showing the connection between pre-training and meta-learning. We discuss\nwhy pre-training yields more robust meta-representation and connect the\ntheoretical analysis to existing works and empirical results. Secondly, we\nintroduce Meta Label Learning (MeLa), a novel meta-learning algorithm that\nlearns task relations by inferring global labels across tasks. This allows us\nto exploit pre-training for FSL even when global labels are unavailable or\nill-defined. Lastly, we introduce an augmented pre-training procedure that\nfurther improves the learned meta-representation. Empirically, MeLa outperforms\nexisting methods across a diverse range of benchmarks, in particular under a\nmore challenging setting where the number of training tasks is limited and\nlabels are task-specific. We also provide extensive ablation study to highlight\nits key properties.\n","authors":["Ruohan Wang","Isak Falk","Massimiliano Pontil","Carlo Ciliberto"],"pdf_url":"https://arxiv.org/pdf/2212.11702v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11685v1","updated":"2022-12-22T13:17:11Z","published":"2022-12-22T13:17:11Z","title":"GENIE: Large Scale Pre-training for Text Generation with Diffusion Model","summary":"  In this paper, we propose a large-scale language pre-training for text\nGENeration using dIffusion modEl, which is named GENIE. GENIE is a pre-training\nsequence-to-sequence text generation model which combines Transformer and\ndiffusion. The diffusion model accepts the latent information from the encoder,\nwhich is used to guide the denoising of the current time step. After multiple\nsuch denoise iterations, the diffusion model can restore the Gaussian noise to\nthe diverse output text which is controlled by the input text. Moreover, such\narchitecture design also allows us to adopt large scale pre-training on the\nGENIE. We propose a novel pre-training method named continuous paragraph\ndenoise based on the characteristics of the diffusion model. Extensive\nexperiments on the XSum, CNN/DailyMail, and Gigaword benchmarks shows that\nGENIE can achieves comparable performance with various strong baselines,\nespecially after pre-training, the generation quality of GENIE is greatly\nimproved. We have also conduct a lot of experiments on the generation diversity\nand parameter impact of GENIE. The code for GENIE will be made publicly\navailable.\n","authors":["Zhenghao Lin","Yeyun Gong","Yelong Shen","Tong Wu","Zhihao Fan","Chen Lin","Weizhu Chen","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2212.11685v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2212.11671v1","updated":"2022-12-22T13:10:44Z","published":"2022-12-22T13:10:44Z","title":"Set-Transformer BeamsNet for AUV Velocity Forecasting in Complete DVL\n  Outage Scenarios","summary":"  Autonomous underwater vehicles (AUVs) are regularly used for deep ocean\napplications. Commonly, the autonomous navigation task is carried out by a\nfusion between two sensors: the inertial navigation system and the Doppler\nvelocity log (DVL). The DVL operates by transmitting four acoustic beams to the\nsea floor, and once reflected back, the AUV velocity vector can be estimated.\nHowever, in real-life scenarios, such as an uneven seabed, sea creatures\nblocking the DVL's view and, roll/pitch maneuvers, the acoustic beams'\nreflection is resulting in a scenario known as DVL outage. Consequently, a\nvelocity update is not available to bind the inertial solution drift. To cope\nwith such situations, in this paper, we leverage our BeamsNet framework and\npropose a Set-Transformer-based BeamsNet (ST-BeamsNet) that utilizes inertial\ndata readings and previous DVL velocity measurements to regress the current AUV\nvelocity in case of a complete DVL outage. The proposed approach was evaluated\nusing data from experiments held in the Mediterranean Sea with the Snapir AUV\nand was compared to a moving average (MA) estimator. Our ST-BeamsNet estimated\nthe AUV velocity vector with an 8.547% speed error, which is 26% better than\nthe MA approach.\n","authors":["Nadav Cohen","Zeev Yampolsky","Itzik Klein"],"pdf_url":"https://arxiv.org/pdf/2212.11671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15432v2","updated":"2022-12-22T12:52:23Z","published":"2022-10-27T13:53:37Z","title":"Many-Objective Reinforcement Learning for Online Testing of DNN-Enabled\n  Systems","summary":"  Deep Neural Networks (DNNs) have been widely used to perform real-world tasks\nin cyber-physical systems such as Autonomous Driving Systems (ADS). Ensuring\nthe correct behavior of such DNN-Enabled Systems (DES) is a crucial topic.\nOnline testing is one of the promising modes for testing such systems with\ntheir application environments (simulated or real) in a closed loop taking into\naccount the continuous interaction between the systems and their environments.\nHowever, the environmental variables (e.g., lighting conditions) that might\nchange during the systems' operation in the real world, causing the DES to\nviolate requirements (safety, functional), are often kept constant during the\nexecution of an online test scenario due to the two major challenges: (1) the\nspace of all possible scenarios to explore would become even larger if they\nchanged and (2) there are typically many requirements to test simultaneously.\nIn this paper, we present MORLOT (Many-Objective Reinforcement Learning for\nOnline Testing), a novel online testing approach to address these challenges by\ncombining Reinforcement Learning (RL) and many-objective search. MORLOT\nleverages RL to incrementally generate sequences of environmental changes while\nrelying on many-objective search to determine the changes so that they are more\nlikely to achieve any of the uncovered objectives. We empirically evaluate\nMORLOT using CARLA, a high-fidelity simulator widely used for autonomous\ndriving research, integrated with Transfuser, a DNN-enabled ADS for end-to-end\ndriving. The evaluation results show that MORLOT is significantly more\neffective and efficient than alternatives with a large effect size. In other\nwords, MORLOT is a good option to test DES with dynamically changing\nenvironments while accounting for multiple safety requirements.\n","authors":["Fitash Ul Haq","Donghwan Shin","Lionel Briand"],"pdf_url":"https://arxiv.org/pdf/2210.15432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02946v2","updated":"2022-12-22T12:35:51Z","published":"2022-09-07T05:47:59Z","title":"On the Sparse DAG Structure Learning Based on Adaptive Lasso","summary":"  Learning the underlying Bayesian Networks (BNs), represented by directed\nacyclic graphs (DAGs), of the concerned events from purely-observational data\nis a crucial part of evidential reasoning. This task remains challenging due to\nthe large and discrete search space. A recent flurry of developments followed\nNOTEARS[1] recast this combinatorial problem into a continuous optimization\nproblem by leveraging an algebraic equality characterization of acyclicity.\nHowever, the continuous optimization methods suffer from obtaining non-spare\ngraphs after the numerical optimization, which leads to the inflexibility to\nrule out the potentially cycle-inducing edges or false discovery edges with\nsmall values. To address this issue, in this paper, we develop a completely\ndata-driven DAG structure learning method without a predefined value to\npost-threshold small values. We name our method NOTEARS with adaptive Lasso\n(NOTEARS-AL), which is achieved by applying the adaptive penalty method to\nensure the sparsity of the estimated DAG. Moreover, we show that NOTEARS-AL\nalso inherits the oracle properties under some specific conditions. Extensive\nexperiments on both synthetic and a real-world dataset verify the efficacy of\nthe proposed method.\n","authors":["Danru Xu","Erdun Gao","Wei Huang","Andy Song","Mingming Gong"],"pdf_url":"https://arxiv.org/pdf/2209.02946v2.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2107.11214v4","updated":"2022-12-22T12:06:43Z","published":"2021-07-23T13:23:10Z","title":"A3GC-IP: Attention-Oriented Adjacency Adaptive Recurrent Graph\n  Convolutions for Human Pose Estimation from Sparse Inertial Measurements","summary":"  Conventional methods for human pose estimation either require a high degree\nof instrumentation, by relying on many inertial measurement units (IMUs), or\nconstraint the recording space, by relying on extrinsic cameras. These deficits\nare tackled through the approach of human pose estimation from sparse IMU data.\nWe define attention-oriented adjacency adaptive graph convolutional long-short\nterm memory networks (A3GC-LSTM), to tackle human pose estimation based on six\nIMUs, through incorporating the human body graph structure directly into the\nnetwork. The A3GC-LSTM combines both spatial and temporal dependency in a\nsingle network operation, more memory efficiently than previous approaches. The\nrecurrent graph learning on arbitrarily long sequences is made possible by\nequipping graph convolutions with adjacency adaptivity, which eliminates the\nproblem of information loss in deep or recurrent graph networks, while it also\nallows for learning unknown dependencies between the human body joints. To\nfurther boost accuracy, a spatial attention formalism is incorporated into the\nrecurrent LSTM cell. With our presented approach, we are able to utilize the\ninherent graph nature of the human body, and thus can outperform the state of\nthe art for human pose estimation from sparse IMU data.\n","authors":["Patrik Puchert","Timo Ropinski"],"pdf_url":"https://arxiv.org/pdf/2107.11214v4.pdf","comment":"Preprint, in submission"},{"id":"http://arxiv.org/abs/2212.11636v1","updated":"2022-12-22T12:06:37Z","published":"2022-12-22T12:06:37Z","title":"Towards Causal Credit Assignment","summary":"  Adequately assigning credit to actions for future outcomes based on their\ncontributions is a long-standing open challenge in Reinforcement Learning. The\nassumptions of the most commonly used credit assignment method are\ndisadvantageous in tasks where the effects of decisions are not immediately\nevident. Furthermore, this method can only evaluate actions that have been\nselected by the agent, making it highly inefficient. Still, no alternative\nmethods have been widely adopted in the field. Hindsight Credit Assignment is a\npromising, but still unexplored candidate, which aims to solve the problems of\nboth long-term and counterfactual credit assignment. In this thesis, we\nempirically investigate Hindsight Credit Assignment to identify its main\nbenefits, and key points to improve. Then, we apply it to factored state\nrepresentations, and in particular to state representations based on the causal\nstructure of the environment. In this setting, we propose a variant of\nHindsight Credit Assignment that effectively exploits a given causal structure.\nWe show that our modification greatly decreases the workload of Hindsight\nCredit Assignment, making it more efficient and enabling it to outperform the\nbaseline credit assignment method on various tasks. This opens the way to other\nmethods based on given or learned causal structures.\n","authors":["Mátyás Schubert"],"pdf_url":"https://arxiv.org/pdf/2212.11636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10936v2","updated":"2022-12-22T11:34:28Z","published":"2022-12-21T11:24:32Z","title":"A Memetic Algorithm with Reinforcement Learning for Sociotechnical\n  Production Scheduling","summary":"  The following article presents a memetic algorithm with applying deep\nreinforcement learning (DRL) for solving practically oriented dual resource\nconstrained flexible job shop scheduling problems (DRC-FJSSP). In recent years,\nthere has been extensive research on DRL techniques, but without considering\nrealistic, flexible and human-centered shopfloors. A research gap can be\nidentified in the context of make-to-order oriented discontinuous manufacturing\nas it is often represented in medium-size companies with high service levels.\nFrom practical industry projects in this domain, we recognize requirements to\ndepict flexible machines, human workers and capabilities, setup and processing\noperations, material arrival times, complex job paths with parallel tasks for\nbill of material (BOM) manufacturing, sequence-depended setup times and\n(partially) automated tasks. On the other hand, intensive research has been\ndone on metaheuristics in the context of DRC-FJSSP. However, there is a lack of\nsuitable and generic scheduling methods that can be holistically applied in\nsociotechnical production and assembly processes. In this paper, we first\nformulate an extended DRC-FJSSP induced by the practical requirements\nmentioned. Then we present our proposed hybrid framework with parallel\ncomputing for multicriteria optimization. Through numerical experiments with\nreal-world data, we confirm that the framework generates feasible schedules\nefficiently and reliably. Utilizing DRL instead of random operations leads to\nbetter results and outperforms traditional approaches.\n","authors":["Felix Grumbach","Nour Eldin Alaa Badr","Pascal Reusch","Sebastian Trojahn"],"pdf_url":"https://arxiv.org/pdf/2212.10936v2.pdf","comment":"This article was submitted to IEEE Access in October 2022. The\n  provisions on copyright specified by IEEE apply:\n  https://www.ieee.org/publications/rights/copyright-policy.html"},{"id":"http://arxiv.org/abs/2212.11614v1","updated":"2022-12-22T11:18:35Z","published":"2022-12-22T11:18:35Z","title":"Hybrid Quantum-Classical Generative Adversarial Network for High\n  Resolution Image Generation","summary":"  Quantum machine learning (QML) has received increasing attention due to its\npotential to outperform classical machine learning methods in various problems.\nA subclass of QML methods is quantum generative adversarial networks (QGANs)\nwhich have been studied as a quantum counterpart of classical GANs widely used\nin image manipulation and generation tasks. The existing work on QGANs is still\nlimited to small-scale proof-of-concept examples based on images with\nsignificant down-scaling. Here we integrate classical and quantum techniques to\npropose a new hybrid quantum-classical GAN framework. We demonstrate its\nsuperior learning capabilities by generating $28 \\times 28$ pixels grey-scale\nimages without dimensionality reduction or classical pre/post-processing on\nmultiple classes of the standard MNIST and Fashion MNIST datasets, which\nachieves comparable results to classical frameworks with 3 orders of magnitude\nless trainable generator parameters. To gain further insight into the working\nof our hybrid approach, we systematically explore the impact of its parameter\nspace by varying the number of qubits, the size of image patches, the number of\nlayers in the generator, the shape of the patches and the choice of prior\ndistribution. Our results show that increasing the quantum generator size\ngenerally improves the learning capability of the network. The developed\nframework provides a foundation for future design of QGANs with optimal\nparameter set tailored for complex image generation tasks.\n","authors":["Shu Lok Tsang","Maxwell T. West","Sarah M. Erfani","Muhammad Usman"],"pdf_url":"https://arxiv.org/pdf/2212.11614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11603v1","updated":"2022-12-22T10:55:10Z","published":"2022-12-22T10:55:10Z","title":"Sequential Decision Problems with Weak Feedback","summary":"  This thesis considers sequential decision problems, where the loss/reward\nincurred by selecting an action may not be inferred from observed feedback. A\nmajor part of this thesis focuses on the unsupervised sequential selection\nproblem, where one can not infer the loss incurred for selecting an action from\nobserved feedback. We also introduce a new setup named Censored Semi Bandits,\nwhere the loss incurred for selecting an action can be observed under certain\nconditions. Finally, we study the channel selection problem in the\ncommunication networks, where the reward for an action is only observed when no\nother player selects that action to play in the round. These problems find\napplications in many fields like healthcare, crowd-sourcing, security, adaptive\nresource allocation, among many others. This thesis aims to address the\nabove-described sequential decision problems by exploiting specific structures\nthese problems exhibit. We develop provably optimal algorithms for each of\nthese setups with weak feedback and validate their empirical performance on\ndifferent problem instances derived from synthetic and real datasets.\n","authors":["Arun Verma"],"pdf_url":"https://arxiv.org/pdf/2212.11603v1.pdf","comment":"Ph.D. Thesis"},{"id":"http://arxiv.org/abs/2206.04356v3","updated":"2022-12-22T10:51:28Z","published":"2022-06-09T08:56:12Z","title":"A Simple Unified Approach to Testing High-Dimensional Conditional\n  Independences for Categorical and Ordinal Data","summary":"  Conditional independence (CI) tests underlie many approaches to model testing\nand structure learning in causal inference. Most existing CI tests for\ncategorical and ordinal data stratify the sample by the conditioning variables,\nperform simple independence tests in each stratum, and combine the results.\nUnfortunately, the statistical power of this approach degrades rapidly as the\nnumber of conditioning variables increases. Here we propose a simple unified CI\ntest for ordinal and categorical data that maintains reasonable calibration and\npower in high dimensions. We show that our test outperforms existing baselines\nin model testing and structure learning for dense directed graphical models\nwhile being comparable for sparse models. Our approach could be attractive for\ncausal model testing because it is easy to implement, can be used with\nnon-parametric or parametric probability models, has the symmetry property, and\nhas reasonable computational requirements.\n","authors":["Ankur Ankan","Johannes Textor"],"pdf_url":"https://arxiv.org/pdf/2206.04356v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11599v1","updated":"2022-12-22T10:48:56Z","published":"2022-12-22T10:48:56Z","title":"Synopsis: Sequential Decision Problems with Weak Feedback","summary":"  This thesis considers sequential decision problems, where the loss/reward\nincurred by selecting an action may not be inferred from observed feedback. A\nmajor part of this thesis focuses on the unsupervised sequential selection\nproblem, where one can not infer the loss incurred for selecting an action from\nobserved feedback. We also introduce a new setup named Censored Semi Bandits,\nwhere the loss incurred for selecting an action can be observed under certain\nconditions. Finally, we study the channel selection problem in the\ncommunication networks, where the reward for an action is only observed when no\nother player selects that action to play in the round. These problems find\napplications in many fields like healthcare, crowd-sourcing, security, adaptive\nresource allocation, among many others. This thesis aims to address the\nabove-described sequential decision problems by exploiting specific structures\nthese problems exhibit. We develop provably optimal algorithms for each of\nthese setups with weak feedback and validate their empirical performance on\ndifferent problem instances derived from synthetic and real datasets.\n","authors":["Arun Verma"],"pdf_url":"https://arxiv.org/pdf/2212.11599v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2010.12353,\n  arXiv:2009.07554"},{"id":"http://arxiv.org/abs/2212.10422v2","updated":"2022-12-22T10:29:59Z","published":"2022-12-20T16:59:56Z","title":"Localising In-Domain Adaptation of Transformer-Based Biomedical Language\n  Models","summary":"  In the era of digital healthcare, the huge volumes of textual information\ngenerated every day in hospitals constitute an essential but underused asset\nthat could be exploited with task-specific, fine-tuned biomedical language\nrepresentation models, improving patient care and management. For such\nspecialized domains, previous research has shown that fine-tuning models\nstemming from broad-coverage checkpoints can largely benefit additional\ntraining rounds over large-scale in-domain resources. However, these resources\nare often unreachable for less-resourced languages like Italian, preventing\nlocal medical institutions to employ in-domain adaptation. In order to reduce\nthis gap, our work investigates two accessible approaches to derive biomedical\nlanguage models in languages other than English, taking Italian as a concrete\nuse-case: one based on neural machine translation of English resources,\nfavoring quantity over quality; the other based on a high-grade, narrow-scoped\ncorpus natively written in Italian, thus preferring quality over quantity. Our\nstudy shows that data quantity is a harder constraint than data quality for\nbiomedical adaptation, but the concatenation of high-quality data can improve\nmodel performance even when dealing with relatively size-limited corpora. The\nmodels published from our investigations have the potential to unlock important\nresearch opportunities for Italian hospitals and academia. Finally, the set of\nlessons learned from the study constitutes valuable insights towards a solution\nto build biomedical language models that are generalizable to other\nless-resourced languages and different domain settings.\n","authors":["Tommaso Mario Buonocore","Claudio Crema","Alberto Redolfi","Riccardo Bellazzi","Enea Parimbelli"],"pdf_url":"https://arxiv.org/pdf/2212.10422v2.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2204.10598v2","updated":"2022-12-22T10:06:59Z","published":"2022-04-22T09:40:23Z","title":"Sparsely-gated MoE Layers for CNN Interpretability","summary":"  Sparsely-gated Mixture of Expert (MoE) layers have been recently successfully\napplied for scaling large transformers, especially for language modeling tasks.\nAn intriguing side effect of sparse MoE layers is that they convey inherent\ninterpretability to a model via natural expert specialization. In this work, we\napply sparse MoE layers to CNNs for computer vision tasks and analyze the\nresulting effect on model interpretability. To stabilize MoE training, we\npresent both soft and hard constraint-based approaches. With hard constraints,\nthe weights of certain experts are allowed to become zero, while soft\nconstraints balance the contribution of experts with an additional auxiliary\nloss. As a result, soft constraints handle expert utilization better and\nsupport the expert specialization process, while hard constraints maintain more\ngeneralized experts and increase overall model performance. Our findings\ndemonstrate that experts can implicitly focus on individual sub-domains of the\ninput space. For example, experts trained for CIFAR-100 image classification\nspecialize in recognizing different domains such as flowers or animals without\nprevious data clustering. Experiments with RetinaNet and the COCO dataset\nfurther indicate that object detection experts can also specialize in detecting\nobjects of distinct sizes.\n","authors":["Svetlana Pavlitskaya","Christian Hubschneider","Lukas Struppek","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2204.10598v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11209v2","updated":"2022-12-22T09:43:32Z","published":"2022-12-21T17:30:17Z","title":"A Theoretical Study of The Effects of Adversarial Attacks on Sparse\n  Regression","summary":"  This paper analyzes $\\ell_1$ regularized linear regression under the\nchallenging scenario of having only adversarially corrupted data for training.\nWe use the primal-dual witness paradigm to provide provable performance\nguarantees for the support of the estimated regression parameter vector to\nmatch the actual parameter. Our theoretical analysis shows the\ncounter-intuitive result that an adversary can influence sample complexity by\ncorrupting the irrelevant features, i.e., those corresponding to zero\ncoefficients of the regression parameter vector, which, consequently, do not\naffect the dependent variable. As any adversarially robust algorithm has its\nlimitations, our theoretical analysis identifies the regimes under which the\nlearning algorithm and adversary can dominate over each other. It helps us to\nanalyze these fundamental limits and address critical scientific questions of\nwhich parameters (like mutual incoherence, the maximum and minimum eigenvalue\nof the covariance matrix, and the budget of adversarial perturbation) play a\nrole in the high or low probability of success of the LASSO algorithm. Also,\nthe derived sample complexity is logarithmic with respect to the size of the\nregression parameter vector, and our theoretical claims are validated by\nempirical analysis on synthetic and real-world datasets.\n","authors":["Deepak Maurya","Jean Honorio"],"pdf_url":"https://arxiv.org/pdf/2212.11209v2.pdf","comment":"first version"},{"id":"http://arxiv.org/abs/2211.16994v3","updated":"2022-12-22T09:08:26Z","published":"2022-11-30T13:49:43Z","title":"Continual Learning with Distributed Optimization: Does CoCoA Forget?","summary":"  We focus on the continual learning problem where the tasks arrive\nsequentially and the aim is to perform well on the newly arrived task without\nperformance degradation on the previously seen tasks. In contrast to the\ncontinual learning literature focusing on the centralized setting, we\ninvestigate the distributed estimation framework. We consider the\nwell-established distributed learning algorithm CoCoA. We derive closed form\nexpressions for the iterations for the overparametrized case. We illustrate the\nconvergence and the error performance of the algorithm based on the\nover/under-parametrization of the problem. Our results show that depending on\nthe problem dimensions and data generation assumptions, CoCoA can perform\ncontinual learning over a sequence of tasks, i.e., it can learn a new task\nwithout forgetting previously learned tasks, with access only to one task at a\ntime.\n","authors":["Martin Hellkvist","Ayça Özçelikkale","Anders Ahlén"],"pdf_url":"https://arxiv.org/pdf/2211.16994v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02445v2","updated":"2022-12-22T08:57:49Z","published":"2022-09-25T15:08:20Z","title":"Localizing Anatomical Landmarks in Ocular Images using Zoom-In Attentive\n  Networks","summary":"  Localizing anatomical landmarks are important tasks in medical image\nanalysis. However, the landmarks to be localized often lack prominent visual\nfeatures. Their locations are elusive and easily confused with the background,\nand thus precise localization highly depends on the context formed by their\nsurrounding areas. In addition, the required precision is usually higher than\nsegmentation and object detection tasks. Therefore, localization has its unique\nchallenges different from segmentation or detection. In this paper, we propose\na zoom-in attentive network (ZIAN) for anatomical landmark localization in\nocular images. First, a coarse-to-fine, or \"zoom-in\" strategy is utilized to\nlearn the contextualized features in different scales. Then, an attentive\nfusion module is adopted to aggregate multi-scale features, which consists of\n1) a co-attention network with a multiple regions-of-interest (ROIs) scheme\nthat learns complementary features from the multiple ROIs, 2) an\nattention-based fusion module which integrates the multi-ROIs features and\nnon-ROI features. We evaluated ZIAN on two open challenge tasks, i.e., the\nfovea localization in fundus images and scleral spur localization in AS-OCT\nimages. Experiments show that ZIAN achieves promising performances and\noutperforms state-of-the-art localization methods. The source code and trained\nmodels of ZIAN are available at\nhttps://github.com/leixiaofeng-astar/OMIA9-ZIAN.\n","authors":["Xiaofeng Lei","Shaohua Li","Xinxing Xu","Huazhu Fu","Yong Liu","Yih-Chung Tham","Yangqin Feng","Mingrui Tan","Yanyu Xu","Jocelyn Hui Lin Goh","Rick Siow Mong Goh","Ching-Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2210.02445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.06444v4","updated":"2022-12-22T08:55:27Z","published":"2022-01-17T14:55:15Z","title":"Black-box Error Diagnosis in Deep Neural Networks for Computer Vision: a\n  Survey of Tools","summary":"  The application of Deep Neural Networks (DNNs) to a broad variety of tasks\ndemands methods for coping with the complex and opaque nature of these\narchitectures. When a gold standard is available, performance assessment treats\nthe DNN as a black box and computes standard metrics based on the comparison of\nthe predictions with the ground truth. A deeper understanding of performances\nrequires going beyond such evaluation metrics to diagnose the model behavior\nand the prediction errors. This goal can be pursued in two complementary ways.\nOn one side, model interpretation techniques \"open the box\" and assess the\nrelationship between the input, the inner layers and the output, so as to\nidentify the architecture modules most likely to cause the performance loss. On\nthe other hand, black-box error diagnosis techniques study the correlation\nbetween the model response and some properties of the input not used for\ntraining, so as to identify the features of the inputs that make the model\nfail. Both approaches give hints on how to improve the architecture and/or the\ntraining process. This paper focuses on the application of DNNs to Computer\nVision (CV) tasks and presents a survey of the tools that support the black-box\nperformance diagnosis paradigm. It illustrates the features and gaps of the\ncurrent proposals, discusses the relevant research directions and provides a\nbrief overview of the diagnosis tools in sectors other than CV.\n","authors":["Piero Fraternali","Federico Milani","Rocio Nahime Torres","Niccolò Zangrando"],"pdf_url":"https://arxiv.org/pdf/2201.06444v4.pdf","comment":"Published in Springer Neural Computing and Applications,\n  https://link.springer.com/article/10.1007/s00521-022-08100-9"},{"id":"http://arxiv.org/abs/2105.10197v2","updated":"2022-12-22T08:48:50Z","published":"2021-05-21T08:15:21Z","title":"Yes We Care! -- Certification for Machine Learning Methods through the\n  Care Label Framework","summary":"  Machine learning applications have become ubiquitous. Their applications\nrange from embedded control in production machines over process optimization in\ndiverse areas (e.g., traffic, finance, sciences) to direct user interactions\nlike advertising and recommendations. This has led to an increased effort of\nmaking machine learning trustworthy. Explainable and fair AI have already\nmatured. They address the knowledgeable user and the application engineer.\nHowever, there are users that want to deploy a learned model in a similar way\nas their washing machine. These stakeholders do not want to spend time in\nunderstanding the model, but want to rely on guaranteed properties. What are\nthe relevant properties? How can they be expressed to the stakeholder without\npresupposing machine learning knowledge? How can they be guaranteed for a\ncertain implementation of a machine learning model? These questions move far\nbeyond the current state of the art and we want to address them here. We\npropose a unified framework that certifies learning methods via care labels.\nThey are easy to understand and draw inspiration from well-known certificates\nlike textile labels or property cards of electronic devices. Our framework\nconsiders both, the machine learning theory and a given implementation. We test\nthe implementation's compliance with theoretical properties and bounds.\n","authors":["Katharina Morik","Helena Kotthaus","Raphael Fischer","Sascha Mücke","Matthias Jakobs","Nico Piatkowski","Andreas Pauly","Lukas Heppe","Danny Heinrich"],"pdf_url":"https://arxiv.org/pdf/2105.10197v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02251v2","updated":"2022-12-22T08:18:51Z","published":"2022-12-02T05:30:59Z","title":"Multiscale Graph Neural Networks for Protein Residue Contact Map\n  Prediction","summary":"  Machine learning (ML) is revolutionizing protein structural analysis,\nincluding an important subproblem of predicting protein residue contact maps,\ni.e., which amino-acid residues are in close spatial proximity given the\namino-acid sequence of a protein. Despite recent progresses in ML-based protein\ncontact prediction, predicting contacts with a wide range of distances\n(commonly classified into short-, medium- and long-range contacts) remains a\nchallenge. Here, we propose a multiscale graph neural network (GNN) based\napproach taking a cue from multiscale physics simulations, in which a standard\npipeline involving a recurrent neural network (RNN) is augmented with three\nGNNs to refine predictive capability for short-, medium- and long-range residue\ncontacts, respectively. Test results on the ProteinNet dataset show improved\naccuracy for contacts of all ranges using the proposed multiscale RNN+GNN\napproach over the conventional approach, including the most challenging case of\nlong-range contact prediction.\n","authors":["Kuang Liu","Rajiv K. Kalia","Xinlian Liu","Aiichiro Nakano","Ken-ichi Nomura","Priya Vashishta","Rafael Zamora-Resendizc"],"pdf_url":"https://arxiv.org/pdf/2212.02251v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11522v1","updated":"2022-12-22T07:52:30Z","published":"2022-12-22T07:52:30Z","title":"AsyncFLEO: Asynchronous Federated Learning for LEO Satellite\n  Constellations with High-Altitude Platforms","summary":"  Low Earth Orbit (LEO) constellations, each comprising a large number of\nsatellites, have become a new source of big data \"from the sky\". Downloading\nsuch data to a ground station (GS) for big data analytics demands very high\nbandwidth and involves large propagation delays. Federated Learning (FL) offers\na promising solution because it allows data to stay in-situ (never leaving\nsatellites) and it only needs to transmit machine learning model parameters\n(trained on the satellites' data). However, the conventional, synchronous FL\nprocess can take several days to train a single FL model in the context of\nsatellite communication (Satcom), due to a bottleneck caused by straggler\nsatellites. In this paper, we propose an asynchronous FL framework for LEO\nconstellations called AsyncFLEO to improve FL efficiency in Satcom. Not only\ndoes AsynFLEO address the bottleneck (idle waiting) in synchronous FL, but it\nalso solves the issue of model staleness caused by straggler satellites.\nAsyncFLEO utilizes high-altitude platforms (HAPs) positioned \"in the sky\" as\nparameter servers, and consists of three technical components: (1) a\nring-of-stars communication topology, (2) a model propagation algorithm, and\n(3) a model aggregation algorithm with satellite grouping and staleness\ndiscounting. Our extensive evaluation with both IID and non-IID data shows that\nAsyncFLEO outperforms the state of the art by a large margin, cutting down\nconvergence delay by 22 times and increasing accuracy by 40%.\n","authors":["Mohamed Elmahallawy","Tie Luo"],"pdf_url":"https://arxiv.org/pdf/2212.11522v1.pdf","comment":"2022 IEEE International Conference on Big Data (IEEE BigData 2022),\n  December 2022"},{"id":"http://arxiv.org/abs/2106.04114v3","updated":"2022-12-22T07:18:22Z","published":"2021-06-08T05:26:58Z","title":"Theoretically Motivated Data Augmentation and Regularization for\n  Portfolio Construction","summary":"  The task we consider is portfolio construction in a speculative market, a\nfundamental problem in modern finance. While various empirical works now exist\nto explore deep learning in finance, the theory side is almost non-existent. In\nthis work, we focus on developing a theoretical framework for understanding the\nuse of data augmentation for deep-learning-based approaches to quantitative\nfinance. The proposed theory clarifies the role and necessity of data\naugmentation for finance; moreover, our theory implies that a simple algorithm\nof injecting a random noise of strength $\\sqrt{|r_{t-1}|}$ to the observed\nreturn $r_{t}$ is better than not injecting any noise and a few other\nfinancially irrelevant data augmentation techniques.\n","authors":["Liu Ziyin","Kentaro Minami","Kentaro Imajo"],"pdf_url":"https://arxiv.org/pdf/2106.04114v3.pdf","comment":"The full version of our work published at 3rd ACM International\n  Conference on AI in Finance (ICAIF'22)"},{"id":"http://arxiv.org/abs/2212.11507v1","updated":"2022-12-22T06:39:52Z","published":"2022-12-22T06:39:52Z","title":"Supervised Anomaly Detection Method Combining Generative Adversarial\n  Networks and Three-Dimensional Data in Vehicle Inspections","summary":"  The external visual inspections of rolling stock's underfloor equipment are\ncurrently being performed via human visual inspection. In this study, we\nattempt to partly automate visual inspection by investigating anomaly\ninspection algorithms that use image processing technology. As the railroad\nmaintenance studies tend to have little anomaly data, unsupervised learning\nmethods are usually preferred for anomaly detection; however, training cost and\naccuracy is still a challenge. Additionally, a researcher created anomalous\nimages from normal images by adding noise, etc., but the anomalous targeted in\nthis study is the rotation of piping cocks that was difficult to create using\nnoise. Therefore, in this study, we propose a new method that uses style\nconversion via generative adversarial networks on three-dimensional computer\ngraphics and imitates anomaly images to apply anomaly detection based on\nsupervised learning. The geometry-consistent style conversion model was used to\nconvert the image, and because of this the color and texture of the image were\nsuccessfully made to imitate the real image while maintaining the anomalous\nshape. Using the generated anomaly images as supervised data, the anomaly\ndetection model can be easily trained without complex adjustments and\nsuccessfully detects anomalies.\n","authors":["Yohei Baba","Takuro Hoshi","Ryosuke Mori","Gaurang Gavai"],"pdf_url":"https://arxiv.org/pdf/2212.11507v1.pdf","comment":"6 pages, 12 figures"},{"id":"http://arxiv.org/abs/2212.11506v1","updated":"2022-12-22T06:38:40Z","published":"2022-12-22T06:38:40Z","title":"Accelerating Barnes-Hut t-SNE Algorithm by Efficient Parallelization on\n  Multi-Core CPUs","summary":"  t-SNE remains one of the most popular embedding techniques for visualizing\nhigh-dimensional data. Most standard packages of t-SNE, such as scikit-learn,\nuse the Barnes-Hut t-SNE (BH t-SNE) algorithm for large datasets. However,\nexisting CPU implementations of this algorithm are inefficient. In this work,\nwe accelerate the BH t-SNE on CPUs via cache optimizations, SIMD, parallelizing\nsequential steps, and improving parallelization of multithreaded steps. Our\nimplementation (Acc-t-SNE) is up to 261x and 4x faster than scikit-learn and\nthe state-of-the-art BH t-SNE implementation from daal4py, respectively, on a\n32-core Intel(R) Icelake cloud instance.\n","authors":["Narendra Chaudhary","Alexander Pivovar","Pavel Yakovlev","Andrey Gorshkov","Sanchit Misra"],"pdf_url":"https://arxiv.org/pdf/2212.11506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13298v2","updated":"2022-12-22T06:32:34Z","published":"2022-08-28T22:01:10Z","title":"Goal-Conditioned Q-Learning as Knowledge Distillation","summary":"  Many applications of reinforcement learning can be formalized as\ngoal-conditioned environments, where, in each episode, there is a \"goal\" that\naffects the rewards obtained during that episode but does not affect the\ndynamics. Various techniques have been proposed to improve performance in\ngoal-conditioned environments, such as automatic curriculum generation and goal\nrelabeling. In this work, we explore a connection between off-policy\nreinforcement learning in goal-conditioned settings and knowledge distillation.\nIn particular: the current Q-value function and the target Q-value estimate are\nboth functions of the goal, and we would like to train the Q-value function to\nmatch its target for all goals. We therefore apply Gradient-Based Attention\nTransfer (Zagoruyko and Komodakis 2017), a knowledge distillation technique, to\nthe Q-function update. We empirically show that this can improve the\nperformance of goal-conditioned off-policy reinforcement learning when the\nspace of goals is high-dimensional. We also show that this technique can be\nadapted to allow for efficient learning in the case of multiple simultaneous\nsparse goals, where the agent can attain a reward by achieving any one of a\nlarge set of objectives, all specified at test time. Finally, to provide\ntheoretical support, we give examples of classes of environments where (under\nsome assumptions) standard off-policy algorithms such as DDPG require at least\nO(d^2) replay buffer transitions to learn an optimal policy, while our proposed\ntechnique requires only O(d) transitions, where d is the dimensionality of the\ngoal and state space. Code is available at\nhttps://github.com/alevine0/ReenGAGE.\n","authors":["Alexander Levine","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2208.13298v2.pdf","comment":"AAAI 2023 Accepted paper"},{"id":"http://arxiv.org/abs/2212.11498v1","updated":"2022-12-22T06:18:41Z","published":"2022-12-22T06:18:41Z","title":"Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with\n  Robotic and Human Co-Workers","summary":"  This project leverages advances in multi-agent reinforcement learning (MARL)\nto improve the efficiency and flexibility of order-picking systems for\ncommercial warehouses. We envision a warehouse of the future in which dozens of\nmobile robots and human pickers work together to collect and deliver items\nwithin the warehouse. The fundamental problem we tackle, called the\norder-picking problem, is how these worker agents must coordinate their\nmovement and actions in the warehouse to maximise performance (e.g. order\nthroughput) under given resource constraints. Established industry methods\nusing heuristic approaches require large engineering efforts to optimise for\ninnately variable warehouse configurations. In contrast, the MARL framework can\nbe flexibly applied to any warehouse configuration (e.g. size, layout,\nnumber/types of workers, item replenishment frequency) and the agents learn via\na process of trial-and-error how to optimally cooperate with one another. This\npaper details the current status of the R&D effort initiated by Dematic and the\nUniversity of Edinburgh towards a general-purpose and scalable MARL solution\nfor the order-picking problem in realistic warehouses.\n","authors":["Aleksandar Krnjaic","Jonathan D. Thomas","Georgios Papoudakis","Lukas Schäfer","Peter Börsting","Stefano V. Albrecht"],"pdf_url":"https://arxiv.org/pdf/2212.11498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11491v1","updated":"2022-12-22T05:42:54Z","published":"2022-12-22T05:42:54Z","title":"Understanding and Improving the Role of Projection Head in\n  Self-Supervised Learning","summary":"  Self-supervised learning (SSL) aims to produce useful feature representations\nwithout access to any human-labeled data annotations. Due to the success of\nrecent SSL methods based on contrastive learning, such as SimCLR, this problem\nhas gained popularity. Most current contrastive learning approaches append a\nparametrized projection head to the end of some backbone network to optimize\nthe InfoNCE objective and then discard the learned projection head after\ntraining. This raises a fundamental question: Why is a learnable projection\nhead required if we are to discard it after training? In this work, we first\nperform a systematic study on the behavior of SSL training focusing on the role\nof the projection head layers. By formulating the projection head as a\nparametric component for the InfoNCE objective rather than a part of the\nnetwork, we present an alternative optimization scheme for training contrastive\nlearning based SSL frameworks. Our experimental study on multiple image\nclassification datasets demonstrates the effectiveness of the proposed approach\nover alternatives in the SSL literature.\n","authors":["Kartik Gupta","Thalaiyasingam Ajanthan","Anton van den Hengel","Stephen Gould"],"pdf_url":"https://arxiv.org/pdf/2212.11491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.04690v5","updated":"2022-12-22T05:01:10Z","published":"2022-07-11T08:12:02Z","title":"Dynamic Budget Throttling in Repeated Second-Price Auctions","summary":"  In today's online advertising markets, an important demand for an advertiser\n(buyer) is to control her total expenditure within a time span under some\nbudget. Among all budget control approaches, throttling stands out as a popular\none, where the buyer participates in only a part of auctions. This paper gives\na theoretical panorama of a single buyer's dynamic budget throttling process in\nrepeated second-price auctions, which is lacking in the literature. We first\nestablish a lower bound on the regret and an upper bound on the asymptotic\ncompetitive ratio for any throttling algorithm, respectively, on whether the\nbuyer's values are stochastic or adversarial. Second, on the algorithmic side,\nwe consider two different information structures, with increasing difficulty in\nlearning the stochastic distribution of the highest competing bid. We further\npropose the OGD-CB algorithm, which is oblivious to stochastic or adversarial\nvalues and has asymptotically equal results under these two information\nstructures. Specifically, with stochastic values, we demonstrate that this\nalgorithm guarantees a near-optimal expected regret. When values are\nadversarial, we prove that the proposed algorithm reaches the upper bound on\nthe asymptotic competitive ratio. At last, we compare throttling with pacing,\nanother widely adopted budget control method, in repeated second-price\nauctions. In the stochastic case, we illustrate that pacing is generally better\nthan throttling for the buyer, which is an extension of known results that\npacing is asymptotically optimal in this scenario. However, in the adversarial\ncase, we give an exciting result indicating that throttling is the\nasymptotically optimal dynamic bidding strategy. Our results fill the gaps in\nthe theoretical research of throttling in repeated auctions and comprehensively\nreveal the ability of this popular budget-smoothing strategy.\n","authors":["Zhaohua Chen","Chang Wang","Qian Wang","Yuqi Pan","Zhuming Shi","Zheng Cai","Yukun Ren","Zhihua Zhu","Xiaotie Deng"],"pdf_url":"https://arxiv.org/pdf/2207.04690v5.pdf","comment":"45 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2212.11482v1","updated":"2022-12-22T04:51:47Z","published":"2022-12-22T04:51:47Z","title":"Learning to swim efficiently in a nonuniform flow field","summary":"  Microswimmers can acquire information on the surrounding fluid by sensing\nmechanical queues. They can then navigate in response to these signals. We\nanalyse this navigation by combining deep reinforcement learning with direct\nnumerical simulations to resolve the hydrodynamics. We study how local and\nnon-local information can be used to train a swimmer to achieve particular\nswimming tasks in a non-uniform flow field, in particular a zig-zag shear flow.\nThe swimming tasks are (1) learning how to swim in the vorticity direction, (2)\nthe shear-gradient direction, and (3) the shear flow direction. We find that\naccess to lab frame information on the swimmer's instantaneous orientation is\nall that is required in order to reach the optimal policy for (1,2). However,\ninformation on both the translational and rotational velocities seem to be\nrequired to achieve (3). Inspired by biological microorganisms we also consider\nthe case where the swimmers sense local information, i.e. surface hydrodynamic\nforces, together with a signal direction. This might correspond to gravity or,\nfor micro-organisms with light sensors, a light source. In this case, we show\nthat the swimmer can reach a comparable level of performance as a swimmer with\naccess to lab frame variables. We also analyse the role of different swimming\nmodes, i.e. pusher, puller, and neutral swimmers.\n","authors":["Krongtum Sankaewtong","John J. Molina","Matthew S. Turner","Ryoichi Yamamoto"],"pdf_url":"https://arxiv.org/pdf/2212.11482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11155v2","updated":"2022-12-22T04:45:15Z","published":"2022-12-21T16:08:47Z","title":"Robust Path Selection in Software-defined WANs using Deep Reinforcement\n  Learning","summary":"  In the context of an efficient network traffic engineering process where the\nnetwork continuously measures a new traffic matrix and updates the set of paths\nin the network, an automated process is required to quickly and efficiently\nidentify when and what set of paths should be used. Unfortunately, the burden\nof finding the optimal solution for the network updating process in each given\ntime interval is high since the computation complexity of optimization\napproaches using linear programming increases significantly as the size of the\nnetwork increases. In this paper, we use deep reinforcement learning to derive\na data-driven algorithm that does the path selection in the network considering\nthe overhead of route computation and path updates. Our proposed scheme\nleverages information about past network behavior to identify a set of robust\npaths to be used for multiple future time intervals to avoid the overhead of\nupdating the forwarding behavior of routers frequently. We compare the results\nof our approach to other traffic engineering solutions through extensive\nsimulations across real network topologies. Our results demonstrate that our\nscheme fares well by a factor of 40% with respect to reducing link utilization\ncompared to traditional TE schemes such as ECMP. Our scheme provides a slightly\nhigher link utilization (around 25%) compared to schemes that only minimize\nlink utilization and do not care about path updating overhead.\n","authors":["Shahrooz Pouryousef","Lixin Gao","Don Towsley"],"pdf_url":"https://arxiv.org/pdf/2212.11155v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11481v1","updated":"2022-12-22T04:41:45Z","published":"2022-12-22T04:41:45Z","title":"A Mathematical Framework for Learning Probability Distributions","summary":"  The modeling of probability distributions, specifically generative modeling\nand density estimation, has become an immensely popular subject in recent years\nby virtue of its outstanding performance on sophisticated data such as images\nand texts. Nevertheless, a theoretical understanding of its success is still\nincomplete. One mystery is the paradox between memorization and generalization:\nIn theory, the model is trained to be exactly the same as the empirical\ndistribution of the finite samples, whereas in practice, the trained model can\ngenerate new samples or estimate the likelihood of unseen samples. Likewise,\nthe overwhelming diversity of distribution learning models calls for a unified\nperspective on this subject. This paper provides a mathematical framework such\nthat all the well-known models can be derived based on simple principles. To\ndemonstrate its efficacy, we present a survey of our results on the\napproximation error, training error and generalization error of these models,\nwhich can all be established based on this framework. In particular, the\naforementioned paradox is resolved by proving that these models enjoy implicit\nregularization during training, so that the generalization error at\nearly-stopping avoids the curse of dimensionality. Furthermore, we provide some\nnew results on landscape analysis and the mode collapse phenomenon.\n","authors":["Hongkang Yang"],"pdf_url":"https://arxiv.org/pdf/2212.11481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.14094v3","updated":"2022-12-22T03:06:31Z","published":"2022-03-26T15:06:13Z","title":"SlimFL: Federated Learning with Superposition Coding over Slimmable\n  Neural Networks","summary":"  Federated learning (FL) is a key enabler for efficient communication and\ncomputing, leveraging devices' distributed computing capabilities. However,\napplying FL in practice is challenging due to the local devices' heterogeneous\nenergy, wireless channel conditions, and non-independently and identically\ndistributed (non-IID) data distributions. To cope with these issues, this paper\nproposes a novel learning framework by integrating FL and width-adjustable\nslimmable neural networks (SNN). Integrating FL with SNNs is challenging due to\ntime-varying channel conditions and data distributions. In addition, existing\nmulti-width SNN training algorithms are sensitive to the data distributions\nacross devices, which makes SNN ill-suited for FL. Motivated by this, we\npropose a communication and energy-efficient SNN-based FL (named SlimFL) that\njointly utilizes superposition coding (SC) for global model aggregation and\nsuperposition training (ST) for updating local models. By applying SC, SlimFL\nexchanges the superposition of multiple-width configurations decoded as many\ntimes as possible for a given communication throughput. Leveraging ST, SlimFL\naligns the forward propagation of different width configurations while avoiding\ninter-width interference during backpropagation. We formally prove the\nconvergence of SlimFL. The result reveals that SlimFL is not only\ncommunication-efficient but also deals with non-IID data distributions and poor\nchannel conditions, which is also corroborated by data-intensive simulations.\n","authors":["Won Joon Yun","Yunseok Kwak","Hankyul Baek","Soyi Jung","Mingyue Ji","Mehdi Bennis","Jihong Park","Joongheon Kim"],"pdf_url":"https://arxiv.org/pdf/2203.14094v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2112.02543"},{"id":"http://arxiv.org/abs/2211.07533v2","updated":"2022-12-22T03:04:45Z","published":"2022-11-14T17:03:56Z","title":"Generalized Stable Weights via Neural Gibbs Density","summary":"  We present a generalized balancing method -- stable weights via Neural Gibbs\nDensity -- fully available for estimating causal effects for an arbitrary\nmixture of discrete and continuous interventions. Our weights are trainable\nthrough back-propagation and can be obtained with neural network algorithms. In\naddition, we also provide a method to measure the performance of our weights by\nestimating the mutual information for the balanced distribution. Our method is\neasy to implement with any present deep learning libraries, and the weights\nfrom it can be used in most state-of-art supervised algorithms.\n","authors":["Yoshiaki Kitazawa"],"pdf_url":"https://arxiv.org/pdf/2211.07533v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.04181v3","updated":"2022-12-22T02:50:07Z","published":"2021-10-08T15:02:30Z","title":"Dataset Condensation with Distribution Matching","summary":"  Computational cost of training state-of-the-art deep models in many learning\nproblems is rapidly increasing due to more sophisticated models and larger\ndatasets. A recent promising direction for reducing training cost is dataset\ncondensation that aims to replace the original large training set with a\nsignificantly smaller learned synthetic set while preserving the original\ninformation. While training deep models on the small set of condensed images\ncan be extremely fast, their synthesis remains computationally expensive due to\nthe complex bi-level optimization and second-order derivative computation. In\nthis work, we propose a simple yet effective method that synthesizes condensed\nimages by matching feature distributions of the synthetic and original training\nimages in many sampled embedding spaces. Our method significantly reduces the\nsynthesis cost while achieving comparable or better performance. Thanks to its\nefficiency, we apply our method to more realistic and larger datasets with\nsophisticated neural architectures and obtain a significant performance boost.\nWe also show promising practical benefits of our method in continual learning\nand neural architecture search.\n","authors":["Bo Zhao","Hakan Bilen"],"pdf_url":"https://arxiv.org/pdf/2110.04181v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11159v2","updated":"2022-12-22T01:58:16Z","published":"2022-11-21T03:09:42Z","title":"Directed Acyclic Graph Factorization Machines for CTR Prediction via\n  Knowledge Distillation","summary":"  With the growth of high-dimensional sparse data in web-scale recommender\nsystems, the computational cost to learn high-order feature interaction in CTR\nprediction task largely increases, which limits the use of high-order\ninteraction models in real industrial applications. Some recent knowledge\ndistillation based methods transfer knowledge from complex teacher models to\nshallow student models for accelerating the online model inference. However,\nthey suffer from the degradation of model accuracy in knowledge distillation\nprocess. It is challenging to balance the efficiency and effectiveness of the\nshallow student models. To address this problem, we propose a Directed Acyclic\nGraph Factorization Machine (KD-DAGFM) to learn the high-order feature\ninteractions from existing complex interaction models for CTR prediction via\nKnowledge Distillation. The proposed lightweight student model DAGFM can learn\narbitrary explicit feature interactions from teacher networks, which achieves\napproximately lossless performance and is proved by a dynamic programming\nalgorithm. Besides, an improved general model KD-DAGFM+ is shown to be\neffective in distilling both explicit and implicit feature interactions from\nany complex teacher model. Extensive experiments are conducted on four\nreal-world datasets, including a large-scale industrial dataset from WeChat\nplatform with billions of feature dimensions. KD-DAGFM achieves the best\nperformance with less than 21.5% FLOPs of the state-of-the-art method on both\nonline and offline experiments, showing the superiority of DAGFM to deal with\nthe industrial scale data in CTR prediction task. Our implementation code is\navailable at: https://github.com/RUCAIBox/DAGFM.\n","authors":["Zhen Tian","Ting Bai","Zibin Zhang","Zhiyuan Xu","Kangyi Lin","Ji-Rong Wen","Wayne Xin Zhao"],"pdf_url":"https://arxiv.org/pdf/2211.11159v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11451v1","updated":"2022-12-22T01:58:04Z","published":"2022-12-22T01:58:04Z","title":"A machine learning framework for neighbor generation in metaheuristic\n  search","summary":"  This paper presents a methodology for integrating machine learning techniques\ninto metaheuristics for solving combinatorial optimization problems. Namely, we\npropose a general machine learning framework for neighbor generation in\nmetaheuristic search. We first define an efficient neighborhood structure\nconstructed by applying a transformation to a selected subset of variables from\nthe current solution. Then, the key of the proposed methodology is to generate\npromising neighbors by selecting a proper subset of variables that contains a\ndescent of the objective in the solution space. To learn a good variable\nselection strategy, we formulate the problem as a classification task that\nexploits structural information from the characteristics of the problem and\nfrom high-quality solutions. We validate our methodology on two metaheuristic\napplications: a Tabu Search scheme for solving a Wireless Network Optimization\nproblem and a Large Neighborhood Search heuristic for solving Mixed-Integer\nPrograms. The experimental results show that our approach is able to achieve a\nsatisfactory trade-off between the exploration of a larger solution space and\nthe exploitation of high-quality solution regions on both applications.\n","authors":["Defeng Liu","Vincent Perreault","Alain Hertz","Andrea Lodi"],"pdf_url":"https://arxiv.org/pdf/2212.11451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11446v1","updated":"2022-12-22T01:30:54Z","published":"2022-12-22T01:30:54Z","title":"Commitment with Signaling under Double-sided Information Asymmetry","summary":"  Information asymmetry in games enables players with the information advantage\nto manipulate others' beliefs by strategically revealing information to other\nplayers. This work considers a double-sided information asymmetry in a Bayesian\nStackelberg game, where the leader's realized action, sampled from the mixed\nstrategy commitment, is hidden from the follower. In contrast, the follower\nholds private information about his payoff. Given asymmetric information on\nboth sides, an important question arises: \\emph{Does the leader's information\nadvantage outweigh the follower's?} We answer this question affirmatively in\nthis work, where we demonstrate that by adequately designing a signaling device\nthat reveals partial information regarding the leader's realized action to the\nfollower, the leader can achieve a higher expected utility than that without\nsignaling. Moreover, unlike previous works on the Bayesian Stackelberg game\nwhere mathematical programming tools are utilized, we interpret the leader's\ncommitment as a probability measure over the belief space. Such a probabilistic\nlanguage greatly simplifies the analysis and allows an indirect signaling\nscheme, leading to a geometric characterization of the equilibrium under the\nproposed game model.\n","authors":["Tao Li","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.11446v1.pdf","comment":"Working paper; 18 pages"},{"id":"http://arxiv.org/abs/2212.11444v1","updated":"2022-12-22T01:26:38Z","published":"2022-12-22T01:26:38Z","title":"Offline Clustering Approach to Self-supervised Learning for\n  Class-imbalanced Image Data","summary":"  Class-imbalanced datasets are known to cause the problem of model being\nbiased towards the majority classes. In this project, we set up two research\nquestions: 1) when is the class-imbalance problem more prevalent in\nself-supervised pre-training? and 2) can offline clustering of feature\nrepresentations help pre-training on class-imbalanced data? Our experiments\ninvestigate the former question by adjusting the degree of {\\it\nclass-imbalance} when training the baseline models, namely SimCLR and SimSiam\non CIFAR-10 database. To answer the latter question, we train each expert model\non each subset of the feature clusters. We then distill the knowledge of expert\nmodels into a single model, so that we will be able to compare the performance\nof this model to our baselines.\n","authors":["Hye-min Chang","Sungkyun Chang"],"pdf_url":"https://arxiv.org/pdf/2212.11444v1.pdf","comment":"5 pages, 3 figures, Technical report"},{"id":"http://arxiv.org/abs/2212.11439v1","updated":"2022-12-22T01:15:08Z","published":"2022-12-22T01:15:08Z","title":"Novel Deep Learning Framework For Bovine Iris Segmentation","summary":"  Iris segmentation is the initial step to identify biometric of animals to\nestablish a traceability system of livestock. In this study, we propose a novel\ndeep learning framework for pixel-wise segmentation with minimum use of\nannotation labels using BovineAAEyes80 public dataset. In the experiment, U-Net\nwith VGG16 backbone was selected as the best combination of encoder and decoder\nmodel, demonstrating a 99.50% accuracy and a 98.35% Dice coefficient score.\nRemarkably, the selected model accurately segmented corrupted images even\nwithout proper annotation data. This study contributes to the advancement of\nthe iris segmentation and the development of a reliable DNNs training\nframework.\n","authors":["Heemoon Yoon","Mira Park","Sang-Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2212.11439v1.pdf","comment":"5 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2208.04278v2","updated":"2022-12-22T00:59:43Z","published":"2022-08-08T17:16:02Z","title":"Self-Supervised Contrastive Representation Learning for 3D Mesh\n  Segmentation","summary":"  3D deep learning is a growing field of interest due to the vast amount of\ninformation stored in 3D formats. Triangular meshes are an efficient\nrepresentation for irregular, non-uniform 3D objects. However, meshes are often\nchallenging to annotate due to their high geometrical complexity. Specifically,\ncreating segmentation masks for meshes is tedious and time-consuming.\nTherefore, it is desirable to train segmentation networks with limited-labeled\ndata. Self-supervised learning (SSL), a form of unsupervised representation\nlearning, is a growing alternative to fully-supervised learning which can\ndecrease the burden of supervision for training. We propose SSL-MeshCNN, a\nself-supervised contrastive learning method for pre-training CNNs for mesh\nsegmentation. We take inspiration from traditional contrastive learning\nframeworks to design a novel contrastive learning algorithm specifically for\nmeshes. Our preliminary experiments show promising results in reducing the\nheavy labeled data requirement needed for mesh segmentation by at least 33%.\n","authors":["Ayaan Haque","Hankyu Moon","Heng Hao","Sima Didari","Jae Oh Woo","Patrick Bangert"],"pdf_url":"https://arxiv.org/pdf/2208.04278v2.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2212.11431v1","updated":"2022-12-22T00:47:40Z","published":"2022-12-22T00:47:40Z","title":"Local Policy Improvement for Recommender Systems","summary":"  Recommender systems aim to answer the following question: given the items\nthat a user has interacted with, what items will this user likely interact with\nnext? Historically this problem is often framed as a predictive task via\n(self-)supervised learning. In recent years, we have seen more emphasis placed\non approaching the recommendation problem from a policy optimization\nperspective: learning a policy that maximizes some reward function (e.g., user\nengagement). However, it is commonly the case in recommender systems that we\nare only able to train a new policy given data collected from a\npreviously-deployed policy. The conventional way to address such a policy\nmismatch is through importance sampling correction, which unfortunately comes\nwith its own limitations. In this paper, we suggest an alternative approach,\nwhich involves the use of local policy improvement without off-policy\ncorrection. Drawing from a number of related results in the fields of causal\ninference, bandits, and reinforcement learning, we present a suite of methods\nthat compute and optimize a lower bound of the expected reward of the target\npolicy. Crucially, this lower bound is a function that is easy to estimate from\ndata, and which does not involve density ratios (such as those appearing in\nimportance sampling correction). We argue that this local policy improvement\nparadigm is particularly well suited for recommender systems, given that in\npractice the previously-deployed policy is typically of reasonably high\nquality, and furthermore it tends to be re-trained frequently and gets\ncontinuously updated. We discuss some practical recipes on how to apply some of\nthe proposed techniques in a sequential recommendation setting.\n","authors":["Dawen Liang","Nikos Vlassis"],"pdf_url":"https://arxiv.org/pdf/2212.11431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11429v1","updated":"2022-12-22T00:43:06Z","published":"2022-12-22T00:43:06Z","title":"Automatically Bounding the Taylor Remainder Series: Tighter Bounds and\n  New Applications","summary":"  We present a new algorithm for automatically bounding the Taylor remainder\nseries. In the special case of a scalar function $f: \\mathbb{R} \\mapsto\n\\mathbb{R}$, our algorithm takes as input a reference point $x_0$, trust region\n$[a, b]$, and integer $k \\ge 0$, and returns an interval $I$ such that $f(x) -\n\\sum_{i=0}^k \\frac {f^{(i)}(x_0)} {i!} (x - x_0)^i \\in I (x - x_0)^{k+1}$ for\nall $x \\in [a, b]$. As in automatic differentiation, the function $f$ is\nprovided to the algorithm in symbolic form, and must be composed of known\nelementary functions.\n  At a high level, our algorithm has two steps. First, for a variety of\ncommonly-used elementary functions (e.g., $\\exp$, $\\log$), we derive sharp\npolynomial upper and lower bounds on the Taylor remainder series. We then\nrecursively combine the bounds for the elementary functions using an interval\narithmetic variant of Taylor-mode automatic differentiation. Our algorithm can\nmake efficient use of machine learning hardware accelerators, and we provide an\nopen source implementation in JAX.\n  We then turn our attention to applications. Most notably, we use our new\nmachinery to create the first universal majorization-minimization optimization\nalgorithms: algorithms that iteratively minimize an arbitrary loss using a\nmajorizer that is derived automatically, rather than by hand. Applied to\nmachine learning, this leads to architecture-specific optimizers for training\ndeep networks that converge from any starting point, without hyperparameter\ntuning. Our experiments show that for some optimization problems, these\nhyperparameter-free optimizers outperform tuned versions of gradient descent,\nAdam, and AdaGrad. We also show that our automatically-derived bounds can be\nused for verified global optimization and numerical integration, and to prove\nsharper versions of Jensen's inequality.\n","authors":["Matthew Streeter","Joshua V. Dillon"],"pdf_url":"https://arxiv.org/pdf/2212.11429v1.pdf","comment":"85 pages, 17 figures"}],"Multimedia":[{"id":"http://arxiv.org/abs/2212.11541v1","updated":"2022-12-22T08:36:55Z","published":"2022-12-22T08:36:55Z","title":"Generative Colorization of Structured Mobile Web Pages","summary":"  Color is a critical design factor for web pages, affecting important factors\nsuch as viewer emotions and the overall trust and satisfaction of a website.\nEffective coloring requires design knowledge and expertise, but if this process\ncould be automated through data-driven modeling, efficient exploration and\nalternative workflows would be possible. However, this direction remains\nunderexplored due to the lack of a formalization of the web page colorization\nproblem, datasets, and evaluation protocols. In this work, we propose a new\ndataset consisting of e-commerce mobile web pages in a tractable format, which\nare created by simplifying the pages and extracting canonical color styles with\na common web browser. The web page colorization problem is then formalized as a\ntask of estimating plausible color styles for a given web page content with a\ngiven hierarchical structure of the elements. We present several\nTransformer-based methods that are adapted to this task by prepending\nstructural message passing to capture hierarchical relationships between\nelements. Experimental results, including a quantitative evaluation designed\nfor this task, demonstrate the advantages of our methods over statistical and\nimage colorization methods. The code is available at\nhttps://github.com/CyberAgentAILab/webcolor.\n","authors":["Kotaro Kikuchi","Naoto Inoue","Mayu Otani","Edgar Simo-Serra","Kota Yamaguchi"],"pdf_url":"https://arxiv.org/pdf/2212.11541v1.pdf","comment":"Accepted to WACV 2023"},{"id":"http://arxiv.org/abs/2212.11471v1","updated":"2022-12-22T03:47:14Z","published":"2022-12-22T03:47:14Z","title":"Multi-queue Momentum Contrast for Microvideo-Product Retrieval","summary":"  The booming development and huge market of micro-videos bring new e-commerce\nchannels for merchants. Currently, more micro-video publishers prefer to embed\nrelevant ads into their micro-videos, which not only provides them with\nbusiness income but helps the audiences to discover their interesting products.\nHowever, due to the micro-video recording by unprofessional equipment,\ninvolving various topics and including multiple modalities, it is challenging\nto locate the products related to micro-videos efficiently, appropriately, and\naccurately. We formulate the microvideo-product retrieval task, which is the\nfirst attempt to explore the retrieval between the multi-modal and multi-modal\ninstances.\n  A novel approach named Multi-Queue Momentum Contrast (MQMC) network is\nproposed for bidirectional retrieval, consisting of the uni-modal feature and\nmulti-modal instance representation learning. Moreover, a discriminative\nselection strategy with a multi-queue is used to distinguish the importance of\ndifferent negatives based on their categories. We collect two large-scale\nmicrovideo-product datasets (MVS and MVS-large) for evaluation and manually\nconstruct the hierarchical category ontology, which covers sundry products in\ndaily life. Extensive experiments show that MQMC outperforms the\nstate-of-the-art baselines. Our replication package (including code, dataset,\netc.) is publicly available at https://github.com/duyali2000/MQMC.\n","authors":["Yali Du","Yinwei Wei","Wei Ji","Fan Liu","Xin Luo","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2212.11471v1.pdf","comment":"Proceedings of the Sixteenth ACM International Conference on Web\n  Search and Data Mining (WSDM '23), February 27-March 3, 2023, Singapore,\n  Singapore"}]}}